[
  {
    "doc_id": "doc_1",
    "original_uuid": "5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145",
    "content": "//! Executor for differential fuzzing.\n//! It wraps two executors that will be run after each other with the same input.\n//! In comparison to the [`crate::executors::CombinedExecutor`] it also runs the secondary executor in `run_target`.\n//!\nuse core::{cell::UnsafeCell, fmt::Debug, ptr};\n\nuse libafl_bolts::{ownedref::OwnedMutPtr, tuples::MatchName};\nuse serde::{Deserialize, Serialize};\n\nuse crate::{\n    executors::{Executor, ExitKind, HasObservers},\n    inputs::UsesInput,\n    observers::{DifferentialObserversTuple, ObserversTuple, UsesObservers},\n    state::UsesState,\n    Error,\n};\n\n/// A [`DiffExecutor`] wraps a primary executor, forwarding its methods, and a secondary one\n#[derive(Debug)]\npub struct DiffExecutor<A, B, OTA, OTB, DOT> {\n    primary: A,\n    secondary: B,\n    observers: UnsafeCell<ProxyObserversTuple<OTA, OTB, DOT>>,\n}\n\nimpl<A, B, OTA, OTB, DOT> DiffExecutor<A, B, OTA, OTB, DOT> {\n    /// Create a new `DiffExecutor`, wrapping the given `executor`s.\n    pub fn new(primary: A, secondary: B, observers: DOT) -> Self\n    where\n        A: UsesState + HasObservers<Observers = OTA>,\n        B: UsesState<State = A::State> + HasObservers<Observers = OTB>,\n        DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\n        OTA: ObserversTuple<A::State>,\n        OTB: ObserversTuple<A::State>,\n    {\n        Self {\n            primary,\n            secondary,\n            observers: UnsafeCell::new(ProxyObserversTuple {\n                primary: OwnedMutPtr::Ptr(ptr::null_mut()),\n                secondary: OwnedMutPtr::Ptr(ptr::null_mut()),\n                differential: observers,\n            }),\n        }\n    }\n\n    /// Retrieve the primary `Executor` that is wrapped by this `DiffExecutor`.\n    pub fn primary(&mut self) -> &mut A {\n        &mut self.primary\n    }\n\n    /// Retrieve the secondary `Executor` that is wrapped by this `DiffExecutor`.\n    pub fn secondary(&mut self) -> &mut B {\n        &mut self.secondary\n    }\n}\n\nimpl<A, B, EM, DOT, Z> Executor<EM, Z> for DiffExecutor<A, B, A::Observers, B::Observers, DOT>\nwhere\n    A: Executor<EM, Z> + HasObservers,\n    B: Executor<EM, Z, State = A::State> + HasObservers,\n    EM: UsesState<State = A::State>,\n    DOT: DifferentialObserversTuple<A::Observers, B::Observers, A::State>,\n    Z: UsesState<State = A::State>,\n{\n    fn run_target(\n        &mut self,\n        fuzzer: &mut Z,\n        state: &mut Self::State,\n        mgr: &mut EM,\n        input: &Self::Input,\n    ) -> Result<ExitKind, Error> {\n        self.observers(); // update in advance\n        let observers = self.observers.get_mut();\n        observers\n            .differential\n            .pre_observe_first_all(observers.primary.as_mut())?;\n        observers.primary.as_mut().pre_exec_all(state, input)?;\n        let ret1 = self.primary.run_target(fuzzer, state, mgr, input)?;\n        observers\n            .primary\n            .as_mut()\n            .post_exec_all(state, input, &ret1)?;\n        observers\n            .differential\n            .post_observe_first_all(observers.primary.as_mut())?;\n        observers\n            .differential\n            .pre_observe_second_all(observers.secondary.as_mut())?;\n        observers.secondary.as_mut().pre_exec_all(state, input)?;\n        let ret2 = self.secondary.run_target(fuzzer, state, mgr, input)?;\n        observers\n            .secondary\n            .as_mut()\n            .post_exec_all(state, input, &ret2)?;\n        observers\n            .differential\n            .post_observe_second_all(observers.secondary.as_mut())?;\n        if ret1 == ret2 {\n            Ok(ret1)\n        } else {\n            // We found a diff in the exit codes!\n            Ok(ExitKind::Diff {\n                primary: ret1.into(),\n                secondary: ret2.into(),\n            })\n        }\n    }\n}\n\n/// Proxy the observers of the inner executors\n#[derive(Serialize, Deserialize, Debug)]\n#[serde(\n    bound = \"A: serde::Serialize + serde::de::DeserializeOwned, B: serde::Serialize + serde::de::DeserializeOwned, DOT: serde::Serialize + serde::de::DeserializeOwned\"\n)]\npub struct ProxyObserversTuple<A, B, DOT> {\n    primary: OwnedMutPtr<A>,\n    secondary: OwnedMutPtr<B>,\n    differential: DOT,\n}\n\nimpl<A, B, DOT, S> ObserversTuple<S> for ProxyObserversTuple<A, B, DOT>\nwhere\n    A: ObserversTuple<S>,\n    B: ObserversTuple<S>,\n    DOT: DifferentialObserversTuple<A, B, S>,\n    S: UsesInput,\n{\n    fn pre_exec_all(&mut self, state: &mut S, input: &S::Input) -> Result<(), Error> {\n        self.differential.pre_exec_all(state, input)\n    }\n\n    fn post_exec_all(\n        &mut self,\n        state: &mut S,\n        input: &S::Input,\n        exit_kind: &ExitKind,\n    ) -> Result<(), Error> {\n        self.differential.post_exec_all(state, input, exit_kind)\n    }\n\n    fn pre_exec_child_all(&mut self, state: &mut S, input: &S::Input) -> Result<(), Error> {\n        self.differential.pre_exec_child_all(state, input)\n    }\n\n    fn post_exec_child_all(\n        &mut self,\n        state: &mut S,\n        input: &S::Input,\n        exit_kind: &ExitKind,\n    ) -> Result<(), Error> {\n        self.differential\n            .post_exec_child_all(state, input, exit_kind)\n    }\n\n    /// Returns true if a `stdout` observer was added to the list\n    #[inline]\n    fn observes_stdout(&self) -> bool {\n        self.primary.as_ref().observes_stdout() || self.secondary.as_ref().observes_stdout()\n    }\n    /// Returns true if a `stderr` observer was added to the list\n    #[inline]\n    fn observes_stderr(&self) -> bool {\n        self.primary.as_ref().observes_stderr() || self.secondary.as_ref().observes_stderr()\n    }\n\n    /// Runs `observe_stdout` for all stdout observers in the list\n    fn observe_stdout(&mut self, stdout: &[u8]) {\n        self.primary.as_mut().observe_stderr(stdout);\n        self.secondary.as_mut().observe_stderr(stdout);\n    }\n\n    /// Runs `observe_stderr` for all stderr observers in the list\n    fn observe_stderr(&mut self, stderr: &[u8]) {\n        self.primary.as_mut().observe_stderr(stderr);\n        self.secondary.as_mut().observe_stderr(stderr);\n    }\n}\n\nimpl<A, B, DOT> MatchName for ProxyObserversTuple<A, B, DOT>\nwhere\n    A: MatchName,\n    B: MatchName,\n    DOT: MatchName,\n{\n    fn match_name<T>(&self, name: &str) -> Option<&T> {\n        if let Some(t) = self.primary.as_ref().match_name::<T>(name) {\n            Some(t)\n        } else if let Some(t) = self.secondary.as_ref().match_name::<T>(name) {\n            Some(t)\n        } else {\n            self.differential.match_name::<T>(name)\n        }\n    }\n    fn match_name_mut<T>(&mut self, name: &str) -> Option<&mut T> {\n        if let Some(t) = self.primary.as_mut().match_name_mut::<T>(name) {\n            Some(t)\n        } else if let Some(t) = self.secondary.as_mut().match_name_mut::<T>(name) {\n            Some(t)\n        } else {\n            self.differential.match_name_mut::<T>(name)\n        }\n    }\n}\n\nimpl<A, B, DOT> ProxyObserversTuple<A, B, DOT> {\n    fn set(&mut self, primary: &A, secondary: &B) {\n        self.primary = OwnedMutPtr::Ptr(ptr::from_ref(primary) as *mut A);\n        self.secondary = OwnedMutPtr::Ptr(ptr::from_ref(secondary) as *mut B);\n    }\n}\n\nimpl<A, B, OTA, OTB, DOT> UsesObservers for DiffExecutor<A, B, OTA, OTB, DOT>\nwhere\n    A: HasObservers<Observers = OTA>,\n    B: HasObservers<Observers = OTB, State = A::State>,\n    OTA: ObserversTuple<A::State>,\n    OTB: ObserversTuple<A::State>,\n    DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\n{\n    type Observers = ProxyObserversTuple<OTA, OTB, DOT>;\n}\n\nimpl<A, B, OTA, OTB, DOT> UsesState for DiffExecutor<A, B, OTA, OTB, DOT>\nwhere\n    A: UsesState,\n    B: UsesState<State = A::State>,\n{\n    type State = A::State;\n}\n\nimpl<A, B, OTA, OTB, DOT> HasObservers for DiffExecutor<A, B, OTA, OTB, DOT>\nwhere\n    A: HasObservers<Observers = OTA>,\n    B: HasObservers<Observers = OTB, State = A::State>,\n    OTA: ObserversTuple<A::State>,\n    OTB: ObserversTuple<A::State>,\n    DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\n{\n    #[inline]\n    fn observers(&self) -> &ProxyObserversTuple<OTA, OTB, DOT> {\n        unsafe {\n            self.observers\n                .get()\n                .as_mut()\n                .unwrap()\n                .set(self.primary.observers(), self.secondary.observers());\n            self.observers.get().as_ref().unwrap()\n        }\n    }\n\n    #[inline]\n    fn observers_mut(&mut self) -> &mut ProxyObserversTuple<OTA, OTB, DOT> {\n        unsafe {\n            self.observers\n                .get()\n                .as_mut()\n                .unwrap()\n                .set(self.primary.observers(), self.secondary.observers());\n            self.observers.get().as_mut().unwrap()\n        }\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_1_chunk_0",
        "original_index": 0,
        "content": "//! Executor for differential fuzzing.\n//! It wraps two executors that will be run after each other with the same input.\n//! In comparison to the [`crate::executors::CombinedExecutor`] it also runs the secondary executor in `run_target`.\n//!\nuse core::{cell::UnsafeCell, fmt::Debug, ptr};\n\nuse libafl_bolts::{ownedref::OwnedMutPtr, tuples::MatchName};\nuse serde::{Deserialize, Serialize};\n\nuse crate::{\n    executors::{Executor, ExitKind, HasObservers},\n    inputs::UsesInput,\n    observers::{DifferentialObserversTuple, ObserversTuple, UsesObservers},\n    state::UsesState,\n    Error,\n};\n\n/// A [`DiffExecutor`] wraps a primary executor, forwarding its methods, and a secondary one\n#[derive(Debug)]\npub struct DiffExecutor<A, B, OTA, OTB, DOT> {\n    primary: A,\n    secondary: B,\n    observers: UnsafeCell<ProxyObserversTuple<OTA, OTB, DOT>>,\n}\n\n"
      },
      {
        "chunk_id": "doc_1_chunk_1",
        "original_index": 1,
        "content": "impl<A, B, OTA, OTB, DOT> DiffExecutor<A, B, OTA, OTB, DOT> {\n    /// Create a new `DiffExecutor`, wrapping the given `executor`s.\n    pub fn new(primary: A, secondary: B, observers: DOT) -> Self\n    where\n        A: UsesState + HasObservers<Observers = OTA>,\n        B: UsesState<State = A::State> + HasObservers<Observers = OTB>,\n        DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\n        OTA: ObserversTuple<A::State>,\n        OTB: ObserversTuple<A::State>,\n    {\n        Self {\n            primary,\n            secondary,\n            observers: UnsafeCell::new(ProxyObserversTuple {\n                primary: OwnedMutPtr::Ptr(ptr::null_mut()),\n                secondary: OwnedMutPtr::Ptr(ptr::null_mut()),\n                differential: observers,\n            }),\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_1_chunk_2",
        "original_index": 2,
        "content": "    /// Retrieve the primary `Executor` that is wrapped by this `DiffExecutor`.\n    pub fn primary(&mut self) -> &mut A {\n        &mut self.primary\n    }\n\n    /// Retrieve the secondary `Executor` that is wrapped by this `DiffExecutor`.\n    pub fn secondary(&mut self) -> &mut B {\n        &mut self.secondary\n    }\n}\n\nimpl<A, B, EM, DOT, Z> Executor<EM, Z> for DiffExecutor<A, B, A::Observers, B::Observers, DOT>\nwhere\n    A: Executor<EM, Z> + HasObservers,\n    B: Executor<EM, Z, State = A::State> + HasObservers,\n    EM: UsesState<State = A::State>,\n    DOT: DifferentialObserversTuple<A::Observers, B::Observers, A::State>,\n    Z: UsesState<State = A::State>,\n{\n    fn run_target(\n        &mut self,\n        fuzzer: &mut Z,\n        state: &mut Self::State,\n        mgr: &mut EM,\n        input: &Self::Input,\n    ) -> Result<ExitKind, Error> {\n        self.observers(); // update in advance\n        let observers = self.observers.get_mut();\n        observers\n            .differential\n"
      },
      {
        "chunk_id": "doc_1_chunk_3",
        "original_index": 3,
        "content": "            .pre_observe_first_all(observers.primary.as_mut())?;\n        observers.primary.as_mut().pre_exec_all(state, input)?;\n        let ret1 = self.primary.run_target(fuzzer, state, mgr, input)?;\n        observers\n            .primary\n            .as_mut()\n            .post_exec_all(state, input, &ret1)?;\n        observers\n            .differential\n            .post_observe_first_all(observers.primary.as_mut())?;\n        observers\n            .differential\n"
      },
      {
        "chunk_id": "doc_1_chunk_4",
        "original_index": 4,
        "content": "            .pre_observe_second_all(observers.secondary.as_mut())?;\n        observers.secondary.as_mut().pre_exec_all(state, input)?;\n        let ret2 = self.secondary.run_target(fuzzer, state, mgr, input)?;\n        observers\n            .secondary\n            .as_mut()\n            .post_exec_all(state, input, &ret2)?;\n        observers\n            .differential\n            .post_observe_second_all(observers.secondary.as_mut())?;\n        if ret1 == ret2 {\n            Ok(ret1)\n        } else {\n            // We found a diff in the exit codes!\n            Ok(ExitKind::Diff {\n                primary: ret1.into(),\n                secondary: ret2.into(),\n            })\n        }\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_1_chunk_5",
        "original_index": 5,
        "content": "/// Proxy the observers of the inner executors\n#[derive(Serialize, Deserialize, Debug)]\n#[serde(\n    bound = \"A: serde::Serialize + serde::de::DeserializeOwned, B: serde::Serialize + serde::de::DeserializeOwned, DOT: serde::Serialize + serde::de::DeserializeOwned\"\n)]\npub struct ProxyObserversTuple<A, B, DOT> {\n    primary: OwnedMutPtr<A>,\n    secondary: OwnedMutPtr<B>,\n    differential: DOT,\n}\n\nimpl<A, B, DOT, S> ObserversTuple<S> for ProxyObserversTuple<A, B, DOT>\nwhere\n    A: ObserversTuple<S>,\n    B: ObserversTuple<S>,\n    DOT: DifferentialObserversTuple<A, B, S>,\n    S: UsesInput,\n{\n    fn pre_exec_all(&mut self, state: &mut S, input: &S::Input) -> Result<(), Error> {\n        self.differential.pre_exec_all(state, input)\n    }\n\n"
      },
      {
        "chunk_id": "doc_1_chunk_6",
        "original_index": 6,
        "content": "    fn post_exec_all(\n        &mut self,\n        state: &mut S,\n        input: &S::Input,\n        exit_kind: &ExitKind,\n    ) -> Result<(), Error> {\n        self.differential.post_exec_all(state, input, exit_kind)\n    }\n\n    fn pre_exec_child_all(&mut self, state: &mut S, input: &S::Input) -> Result<(), Error> {\n        self.differential.pre_exec_child_all(state, input)\n    }\n\n    fn post_exec_child_all(\n        &mut self,\n        state: &mut S,\n        input: &S::Input,\n        exit_kind: &ExitKind,\n    ) -> Result<(), Error> {\n        self.differential\n            .post_exec_child_all(state, input, exit_kind)\n    }\n\n"
      },
      {
        "chunk_id": "doc_1_chunk_7",
        "original_index": 7,
        "content": "    /// Returns true if a `stdout` observer was added to the list\n    #[inline]\n    fn observes_stdout(&self) -> bool {\n        self.primary.as_ref().observes_stdout() || self.secondary.as_ref().observes_stdout()\n    }\n    /// Returns true if a `stderr` observer was added to the list\n    #[inline]\n    fn observes_stderr(&self) -> bool {\n        self.primary.as_ref().observes_stderr() || self.secondary.as_ref().observes_stderr()\n    }\n\n"
      },
      {
        "chunk_id": "doc_1_chunk_8",
        "original_index": 8,
        "content": "    /// Runs `observe_stdout` for all stdout observers in the list\n    fn observe_stdout(&mut self, stdout: &[u8]) {\n        self.primary.as_mut().observe_stderr(stdout);\n        self.secondary.as_mut().observe_stderr(stdout);\n    }\n\n    /// Runs `observe_stderr` for all stderr observers in the list\n    fn observe_stderr(&mut self, stderr: &[u8]) {\n        self.primary.as_mut().observe_stderr(stderr);\n        self.secondary.as_mut().observe_stderr(stderr);\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_1_chunk_9",
        "original_index": 9,
        "content": "impl<A, B, DOT> MatchName for ProxyObserversTuple<A, B, DOT>\nwhere\n    A: MatchName,\n    B: MatchName,\n    DOT: MatchName,\n{\n    fn match_name<T>(&self, name: &str) -> Option<&T> {\n        if let Some(t) = self.primary.as_ref().match_name::<T>(name) {\n            Some(t)\n        } else if let Some(t) = self.secondary.as_ref().match_name::<T>(name) {\n            Some(t)\n        } else {\n            self.differential.match_name::<T>(name)\n        }\n    }\n    fn match_name_mut<T>(&mut self, name: &str) -> Option<&mut T> {\n        if let Some(t) = self.primary.as_mut().match_name_mut::<T>(name) {\n            Some(t)\n        } else if let Some(t) = self.secondary.as_mut().match_name_mut::<T>(name) {\n            Some(t)\n        } else {\n            self.differential.match_name_mut::<T>(name)\n        }\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_1_chunk_10",
        "original_index": 10,
        "content": "impl<A, B, DOT> ProxyObserversTuple<A, B, DOT> {\n    fn set(&mut self, primary: &A, secondary: &B) {\n        self.primary = OwnedMutPtr::Ptr(ptr::from_ref(primary) as *mut A);\n        self.secondary = OwnedMutPtr::Ptr(ptr::from_ref(secondary) as *mut B);\n    }\n}\n\nimpl<A, B, OTA, OTB, DOT> UsesObservers for DiffExecutor<A, B, OTA, OTB, DOT>\nwhere\n    A: HasObservers<Observers = OTA>,\n    B: HasObservers<Observers = OTB, State = A::State>,\n    OTA: ObserversTuple<A::State>,\n    OTB: ObserversTuple<A::State>,\n    DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\n{\n    type Observers = ProxyObserversTuple<OTA, OTB, DOT>;\n}\n\nimpl<A, B, OTA, OTB, DOT> UsesState for DiffExecutor<A, B, OTA, OTB, DOT>\nwhere\n    A: UsesState,\n    B: UsesState<State = A::State>,\n{\n    type State = A::State;\n}\n\n"
      },
      {
        "chunk_id": "doc_1_chunk_11",
        "original_index": 11,
        "content": "impl<A, B, OTA, OTB, DOT> HasObservers for DiffExecutor<A, B, OTA, OTB, DOT>\nwhere\n    A: HasObservers<Observers = OTA>,\n    B: HasObservers<Observers = OTB, State = A::State>,\n    OTA: ObserversTuple<A::State>,\n    OTB: ObserversTuple<A::State>,\n    DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\n{\n    #[inline]\n    fn observers(&self) -> &ProxyObserversTuple<OTA, OTB, DOT> {\n        unsafe {\n            self.observers\n                .get()\n                .as_mut()\n                .unwrap()\n                .set(self.primary.observers(), self.secondary.observers());\n            self.observers.get().as_ref().unwrap()\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_1_chunk_12",
        "original_index": 12,
        "content": "    #[inline]\n    fn observers_mut(&mut self) -> &mut ProxyObserversTuple<OTA, OTB, DOT> {\n        unsafe {\n            self.observers\n                .get()\n                .as_mut()\n                .unwrap()\n                .set(self.primary.observers(), self.secondary.observers());\n            self.observers.get().as_mut().unwrap()\n        }\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_2",
    "original_uuid": "78cd6ead8e87695b47c2904e3027ae2b7251677caa5c5815b38c8756fe1a0b0c",
    "content": "#[cfg(windows)]\nuse std::ptr::write_volatile;\nuse std::{path::PathBuf, ptr::write};\n\n#[cfg(feature = \"tui\")]\nuse libafl::monitors::tui::{ui::TuiUI, TuiMonitor};\n#[cfg(not(feature = \"tui\"))]\nuse libafl::monitors::SimpleMonitor;\nuse libafl::{\n    corpus::{InMemoryCorpus, OnDiskCorpus},\n    events::SimpleEventManager,\n    executors::{inprocess::InProcessExecutor, ExitKind},\n    feedbacks::{CrashFeedback, MaxMapFeedback},\n    fuzzer::{Fuzzer, StdFuzzer},\n    inputs::{BytesInput, HasTargetBytes},\n    mutators::{StdScheduledMutator, StringCategoryRandMutator, StringSubcategoryRandMutator},\n    observers::StdMapObserver,\n    schedulers::QueueScheduler,\n    stages::{mutational::StdMutationalStage, StringIdentificationStage},\n    state::StdState,\n    Evaluator,\n};\nuse libafl_bolts::{current_nanos, rands::StdRand, tuples::tuple_list, AsSlice};\n\n/// Coverage map with explicit assignments due to the lack of instrumentation\nstatic mut SIGNALS: [u8; 64] = [0; 64];\nstatic mut SIGNALS_PTR: *mut u8 = unsafe { SIGNALS.as_mut_ptr() };\n\n/// Assign a signal to the signals map\nfn signals_set(idx: usize) {\n    unsafe { write(SIGNALS_PTR.add(idx), 1) };\n}\n\n#[allow(clippy::similar_names, clippy::manual_assert)]\npub fn main() {\n    // The closure that we want to fuzz\n    let mut harness = |input: &BytesInput| {\n        let target = input.target_bytes();\n        let buf = target.as_slice();\n        let goal = b\"abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz\";\n        let mut i = 0;\n        for _ in buf.iter().zip(goal).take_while(|(b, c)| b == c) {\n            signals_set(i);\n            i += 1;\n        }\n        if i == goal.len() {\n            #[cfg(unix)]\n            panic!(\"Artificial bug triggered =)\");\n\n            #[cfg(windows)]\n            unsafe {\n                write_volatile(0 as *mut u32, 0);\n            }\n        }\n        ExitKind::Ok\n    };\n\n    // Create an observation channel using the signals map\n    let observer = unsafe { StdMapObserver::from_mut_ptr(\"signals\", SIGNALS_PTR, SIGNALS.len()) };\n\n    // Feedback to rate the interestingness of an input\n    let mut feedback = MaxMapFeedback::new(&observer);\n\n    // A feedback to choose if an input is a solution or not\n    let mut objective = CrashFeedback::new();\n\n    // create a State from scratch\n    let mut state = StdState::new(\n        // RNG\n        StdRand::with_seed(current_nanos()),\n        // Corpus that will be evolved, we keep it in memory for performance\n        InMemoryCorpus::new(),\n        // Corpus in which we store solutions (crashes in this example),\n        // on disk so the user can get them after stopping the fuzzer\n        OnDiskCorpus::new(PathBuf::from(\"./crashes\")).unwrap(),\n        // States of the feedbacks.\n        // The feedbacks can report the data that should persist in the State.\n        &mut feedback,\n        // Same for objective feedbacks\n        &mut objective,\n    )\n    .unwrap();\n\n    // The Monitor trait define how the fuzzer stats are displayed to the user\n    #[cfg(not(feature = \"tui\"))]\n    let mon = SimpleMonitor::new(|s| println!(\"{s}\"));\n    #[cfg(feature = \"tui\")]\n    let ui = TuiUI::with_version(String::from(\"Baby Fuzzer\"), String::from(\"0.0.1\"), false);\n    #[cfg(feature = \"tui\")]\n    let mon = TuiMonitor::new(ui);\n\n    // The event manager handle the various events generated during the fuzzing loop\n    // such as the notification of the addition of a new item to the corpus\n    let mut mgr = SimpleEventManager::new(mon);\n\n    // A queue policy to get testcasess from the corpus\n    let scheduler = QueueScheduler::new();\n\n    // A fuzzer with feedbacks and a corpus scheduler\n    let mut fuzzer = StdFuzzer::new(scheduler, feedback, objective);\n\n    // Create the executor for an in-process function with just one observer\n    let mut executor = InProcessExecutor::new(\n        &mut harness,\n        tuple_list!(observer),\n        &mut fuzzer,\n        &mut state,\n        &mut mgr,\n    )\n    .expect(\"Failed to create the Executor\");\n\n    // Generate 8 initial inputs\n    fuzzer\n        .evaluate_input(\n            &mut state,\n            &mut executor,\n            &mut mgr,\n            BytesInput::new(vec![b'a']),\n        )\n        .unwrap();\n\n    // Setup a mutational stage with a basic bytes mutator\n    let mutator = StdScheduledMutator::new(tuple_list!(\n        StringCategoryRandMutator,\n        StringSubcategoryRandMutator,\n        StringSubcategoryRandMutator,\n        StringSubcategoryRandMutator,\n        StringSubcategoryRandMutator\n    ));\n    let mut stages = tuple_list!(\n        StringIdentificationStage::new(),\n        StdMutationalStage::transforming(mutator)\n    );\n\n    fuzzer\n        .fuzz_loop(&mut stages, &mut executor, &mut state, &mut mgr)\n        .expect(\"Error in the fuzzing loop\");\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_2_chunk_0",
        "original_index": 0,
        "content": "#[cfg(windows)]\nuse std::ptr::write_volatile;\nuse std::{path::PathBuf, ptr::write};\n\n#[cfg(feature = \"tui\")]\nuse libafl::monitors::tui::{ui::TuiUI, TuiMonitor};\n#[cfg(not(feature = \"tui\"))]\nuse libafl::monitors::SimpleMonitor;\nuse libafl::{\n    corpus::{InMemoryCorpus, OnDiskCorpus},\n    events::SimpleEventManager,\n    executors::{inprocess::InProcessExecutor, ExitKind},\n    feedbacks::{CrashFeedback, MaxMapFeedback},\n    fuzzer::{Fuzzer, StdFuzzer},\n    inputs::{BytesInput, HasTargetBytes},\n    mutators::{StdScheduledMutator, StringCategoryRandMutator, StringSubcategoryRandMutator},\n    observers::StdMapObserver,\n    schedulers::QueueScheduler,\n    stages::{mutational::StdMutationalStage, StringIdentificationStage},\n    state::StdState,\n    Evaluator,\n};\nuse libafl_bolts::{current_nanos, rands::StdRand, tuples::tuple_list, AsSlice};\n\n"
      },
      {
        "chunk_id": "doc_2_chunk_1",
        "original_index": 1,
        "content": "/// Coverage map with explicit assignments due to the lack of instrumentation\nstatic mut SIGNALS: [u8; 64] = [0; 64];\nstatic mut SIGNALS_PTR: *mut u8 = unsafe { SIGNALS.as_mut_ptr() };\n\n/// Assign a signal to the signals map\nfn signals_set(idx: usize) {\n    unsafe { write(SIGNALS_PTR.add(idx), 1) };\n}\n\n#[allow(clippy::similar_names, clippy::manual_assert)]\npub fn main() {\n    // The closure that we want to fuzz\n    let mut harness = |input: &BytesInput| {\n        let target = input.target_bytes();\n        let buf = target.as_slice();\n        let goal = b\"abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz\";\n        let mut i = 0;\n        for _ in buf.iter().zip(goal).take_while(|(b, c)| b == c) {\n            signals_set(i);\n            i += 1;\n        }\n        if i == goal.len() {\n            #[cfg(unix)]\n            panic!(\"Artificial bug triggered =)\");\n\n"
      },
      {
        "chunk_id": "doc_2_chunk_2",
        "original_index": 2,
        "content": "            #[cfg(windows)]\n            unsafe {\n                write_volatile(0 as *mut u32, 0);\n            }\n        }\n        ExitKind::Ok\n    };\n\n    // Create an observation channel using the signals map\n    let observer = unsafe { StdMapObserver::from_mut_ptr(\"signals\", SIGNALS_PTR, SIGNALS.len()) };\n\n    // Feedback to rate the interestingness of an input\n    let mut feedback = MaxMapFeedback::new(&observer);\n\n    // A feedback to choose if an input is a solution or not\n    let mut objective = CrashFeedback::new();\n\n"
      },
      {
        "chunk_id": "doc_2_chunk_3",
        "original_index": 3,
        "content": "    // create a State from scratch\n    let mut state = StdState::new(\n        // RNG\n        StdRand::with_seed(current_nanos()),\n        // Corpus that will be evolved, we keep it in memory for performance\n        InMemoryCorpus::new(),\n        // Corpus in which we store solutions (crashes in this example),\n        // on disk so the user can get them after stopping the fuzzer\n        OnDiskCorpus::new(PathBuf::from(\"./crashes\")).unwrap(),\n        // States of the feedbacks.\n        // The feedbacks can report the data that should persist in the State.\n        &mut feedback,\n        // Same for objective feedbacks\n        &mut objective,\n    )\n    .unwrap();\n\n"
      },
      {
        "chunk_id": "doc_2_chunk_4",
        "original_index": 4,
        "content": "    // The Monitor trait define how the fuzzer stats are displayed to the user\n    #[cfg(not(feature = \"tui\"))]\n    let mon = SimpleMonitor::new(|s| println!(\"{s}\"));\n    #[cfg(feature = \"tui\")]\n    let ui = TuiUI::with_version(String::from(\"Baby Fuzzer\"), String::from(\"0.0.1\"), false);\n    #[cfg(feature = \"tui\")]\n    let mon = TuiMonitor::new(ui);\n\n    // The event manager handle the various events generated during the fuzzing loop\n    // such as the notification of the addition of a new item to the corpus\n    let mut mgr = SimpleEventManager::new(mon);\n\n    // A queue policy to get testcasess from the corpus\n    let scheduler = QueueScheduler::new();\n\n    // A fuzzer with feedbacks and a corpus scheduler\n    let mut fuzzer = StdFuzzer::new(scheduler, feedback, objective);\n\n"
      },
      {
        "chunk_id": "doc_2_chunk_5",
        "original_index": 5,
        "content": "    // Create the executor for an in-process function with just one observer\n    let mut executor = InProcessExecutor::new(\n        &mut harness,\n        tuple_list!(observer),\n        &mut fuzzer,\n        &mut state,\n        &mut mgr,\n    )\n    .expect(\"Failed to create the Executor\");\n\n    // Generate 8 initial inputs\n    fuzzer\n        .evaluate_input(\n            &mut state,\n            &mut executor,\n            &mut mgr,\n            BytesInput::new(vec![b'a']),\n        )\n        .unwrap();\n\n"
      },
      {
        "chunk_id": "doc_2_chunk_6",
        "original_index": 6,
        "content": "    // Setup a mutational stage with a basic bytes mutator\n    let mutator = StdScheduledMutator::new(tuple_list!(\n        StringCategoryRandMutator,\n        StringSubcategoryRandMutator,\n        StringSubcategoryRandMutator,\n        StringSubcategoryRandMutator,\n        StringSubcategoryRandMutator\n    ));\n    let mut stages = tuple_list!(\n        StringIdentificationStage::new(),\n        StdMutationalStage::transforming(mutator)\n    );\n\n    fuzzer\n        .fuzz_loop(&mut stages, &mut executor, &mut state, &mut mgr)\n        .expect(\"Error in the fuzzing loop\");\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_3",
    "original_uuid": "2b9a8221386274740c40ffa7cdeee92c189fa3f9f59f17c347bfa99abbfa84cd",
    "content": "use core::{ffi::c_void, fmt::Debug};\nuse std::sync::atomic::{AtomicBool, AtomicUsize, Ordering};\n\nuse libafl::{\n    events::EventFirer,\n    executors::ExitKind,\n    feedbacks::Feedback,\n    inputs::UsesInput,\n    observers::{Observer, ObserversTuple},\n    state::State,\n    Error,\n};\nuse libafl_bolts::Named;\nuse libc::SIGABRT;\nuse serde::{Deserialize, Serialize};\n\nextern \"C\" {\n    fn libafl_check_malloc_size(ptr: *const c_void) -> usize;\n}\n\nstatic RUNNING: AtomicBool = AtomicBool::new(false);\nstatic OOMED: AtomicBool = AtomicBool::new(false);\nstatic RSS_MAX: AtomicUsize = AtomicUsize::new(2 << 30);\n// 2GB, which is the default\nstatic MALLOC_MAX: AtomicUsize = AtomicUsize::new(2 << 30);\n\nstatic MALLOC_SIZE: AtomicUsize = AtomicUsize::new(0);\n\n/// malloc hook which will be invoked if address sanitizer is present. Used to detect if the target makes a malloc call\n/// that will exceed the permissible size\n///\n/// # Safety\n/// Is only safe to call with valid freshly allocated pointers backed by allocations of `size`.\n#[no_mangle]\npub unsafe extern \"C\" fn __sanitizer_malloc_hook(ptr: *const c_void, size: usize) {\n    if RUNNING.load(Ordering::Relaxed) {\n        let size = match unsafe { libafl_check_malloc_size(ptr) } {\n            0 => size, // either the malloc size function didn't work or it's really zero-sized\n            real => real,\n        };\n\n        let total = MALLOC_SIZE.fetch_add(size, Ordering::Relaxed) + size;\n        if (size > MALLOC_MAX.load(Ordering::Relaxed) || total > RSS_MAX.load(Ordering::Relaxed))\n            && !OOMED.swap(true, Ordering::Relaxed)\n        {\n            unsafe {\n                // we need to kill the process in a way that immediately triggers the crash handler\n                libc::raise(SIGABRT);\n            }\n        }\n    }\n}\n\n/// free hook which will be invoked if ASAN is present. Used to detect if the target makes a malloc call that will\n/// exceed the permissible size\n///\n/// # Safety\n/// Is only safe to call with valid allocated pointers, about to be freed.\n#[no_mangle]\npub unsafe extern \"C\" fn __sanitizer_free_hook(ptr: *const c_void) {\n    if RUNNING.load(Ordering::Relaxed) {\n        let size = unsafe { libafl_check_malloc_size(ptr) };\n        MALLOC_SIZE\n            .fetch_update(Ordering::Relaxed, Ordering::Relaxed, |existing| {\n                Some(existing.saturating_sub(size))\n            })\n            .expect(\"must complete successfully\");\n    }\n}\n\nconst OOM_OBS_NAME: &str = \"libfuzzer-like-oom\";\n\n/// Observer which detects if the target would run out of memory or otherwise violate the permissible usage of malloc\n#[derive(Debug, Serialize, Deserialize)]\npub struct OomObserver {\n    oomed: bool,\n}\n\nimpl OomObserver {\n    /// Create a [`OomObserver`] with the provided `rss_max` (total heap size) and `malloc_max` (largest permissible malloc\n    /// allocation size)\n    pub fn new(rss_max: usize, malloc_max: usize) -> Self {\n        RSS_MAX.store(rss_max, Ordering::Relaxed);\n        MALLOC_MAX.store(malloc_max, Ordering::Relaxed);\n        Self { oomed: false }\n    }\n}\n\nimpl Named for OomObserver {\n    // strictly one name to prevent two from being registered\n    fn name(&self) -> &str {\n        OOM_OBS_NAME\n    }\n}\n\nimpl<S> Observer<S> for OomObserver\nwhere\n    S: UsesInput,\n{\n    fn pre_exec(&mut self, _state: &mut S, _input: &S::Input) -> Result<(), Error> {\n        OOMED.store(false, Ordering::Relaxed);\n        // must reset for platforms which do not offer malloc tracking\n        MALLOC_SIZE.store(0, Ordering::Relaxed);\n        RUNNING.store(true, Ordering::Relaxed);\n        Ok(())\n    }\n\n    fn post_exec(\n        &mut self,\n        _state: &mut S,\n        _input: &S::Input,\n        _exit_kind: &ExitKind,\n    ) -> Result<(), Error> {\n        RUNNING.store(false, Ordering::Relaxed);\n        self.oomed = OOMED.load(Ordering::Relaxed);\n        Ok(())\n    }\n\n    fn pre_exec_child(&mut self, state: &mut S, input: &S::Input) -> Result<(), Error> {\n        self.pre_exec(state, input)\n    }\n\n    fn post_exec_child(\n        &mut self,\n        state: &mut S,\n        input: &S::Input,\n        exit_kind: &ExitKind,\n    ) -> Result<(), Error> {\n        self.post_exec(state, input, exit_kind)\n    }\n}\n\n/// Feedback for the similarly named [`OomObserver`] to detect if the target crashed due to an observed OOM\n#[derive(Debug, Serialize, Deserialize, Copy, Clone, Default)]\npub struct OomFeedback;\n\nimpl OomFeedback {\n    /// Whether the target OOM'd in the last execution\n    pub fn oomed() -> bool {\n        OOMED.load(Ordering::Relaxed)\n    }\n}\n\nimpl Named for OomFeedback {\n    fn name(&self) -> &str {\n        \"oom\"\n    }\n}\n\nimpl<S> Feedback<S> for OomFeedback\nwhere\n    S: State,\n{\n    fn is_interesting<EM, OT>(\n        &mut self,\n        _state: &mut S,\n        _manager: &mut EM,\n        _input: &S::Input,\n        _observers: &OT,\n        _exit_kind: &ExitKind,\n    ) -> Result<bool, Error>\n    where\n        EM: EventFirer<State = S>,\n        OT: ObserversTuple<S>,\n    {\n        Ok(Self::oomed())\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_3_chunk_0",
        "original_index": 0,
        "content": "use core::{ffi::c_void, fmt::Debug};\nuse std::sync::atomic::{AtomicBool, AtomicUsize, Ordering};\n\nuse libafl::{\n    events::EventFirer,\n    executors::ExitKind,\n    feedbacks::Feedback,\n    inputs::UsesInput,\n    observers::{Observer, ObserversTuple},\n    state::State,\n    Error,\n};\nuse libafl_bolts::Named;\nuse libc::SIGABRT;\nuse serde::{Deserialize, Serialize};\n\nextern \"C\" {\n    fn libafl_check_malloc_size(ptr: *const c_void) -> usize;\n}\n\nstatic RUNNING: AtomicBool = AtomicBool::new(false);\nstatic OOMED: AtomicBool = AtomicBool::new(false);\nstatic RSS_MAX: AtomicUsize = AtomicUsize::new(2 << 30);\n// 2GB, which is the default\nstatic MALLOC_MAX: AtomicUsize = AtomicUsize::new(2 << 30);\n\nstatic MALLOC_SIZE: AtomicUsize = AtomicUsize::new(0);\n\n"
      },
      {
        "chunk_id": "doc_3_chunk_1",
        "original_index": 1,
        "content": "/// malloc hook which will be invoked if address sanitizer is present. Used to detect if the target makes a malloc call\n/// that will exceed the permissible size\n///\n/// # Safety\n/// Is only safe to call with valid freshly allocated pointers backed by allocations of `size`.\n#[no_mangle]\npub unsafe extern \"C\" fn __sanitizer_malloc_hook(ptr: *const c_void, size: usize) {\n    if RUNNING.load(Ordering::Relaxed) {\n        let size = match unsafe { libafl_check_malloc_size(ptr) } {\n            0 => size, // either the malloc size function didn't work or it's really zero-sized\n            real => real,\n        };\n\n"
      },
      {
        "chunk_id": "doc_3_chunk_2",
        "original_index": 2,
        "content": "        let total = MALLOC_SIZE.fetch_add(size, Ordering::Relaxed) + size;\n        if (size > MALLOC_MAX.load(Ordering::Relaxed) || total > RSS_MAX.load(Ordering::Relaxed))\n            && !OOMED.swap(true, Ordering::Relaxed)\n        {\n            unsafe {\n                // we need to kill the process in a way that immediately triggers the crash handler\n                libc::raise(SIGABRT);\n            }\n        }\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_3_chunk_3",
        "original_index": 3,
        "content": "/// free hook which will be invoked if ASAN is present. Used to detect if the target makes a malloc call that will\n/// exceed the permissible size\n///\n/// # Safety\n/// Is only safe to call with valid allocated pointers, about to be freed.\n#[no_mangle]\npub unsafe extern \"C\" fn __sanitizer_free_hook(ptr: *const c_void) {\n    if RUNNING.load(Ordering::Relaxed) {\n        let size = unsafe { libafl_check_malloc_size(ptr) };\n        MALLOC_SIZE\n            .fetch_update(Ordering::Relaxed, Ordering::Relaxed, |existing| {\n                Some(existing.saturating_sub(size))\n            })\n            .expect(\"must complete successfully\");\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_3_chunk_4",
        "original_index": 4,
        "content": "const OOM_OBS_NAME: &str = \"libfuzzer-like-oom\";\n\n/// Observer which detects if the target would run out of memory or otherwise violate the permissible usage of malloc\n#[derive(Debug, Serialize, Deserialize)]\npub struct OomObserver {\n    oomed: bool,\n}\n\nimpl OomObserver {\n    /// Create a [`OomObserver`] with the provided `rss_max` (total heap size) and `malloc_max` (largest permissible malloc\n    /// allocation size)\n    pub fn new(rss_max: usize, malloc_max: usize) -> Self {\n        RSS_MAX.store(rss_max, Ordering::Relaxed);\n        MALLOC_MAX.store(malloc_max, Ordering::Relaxed);\n        Self { oomed: false }\n    }\n}\n\nimpl Named for OomObserver {\n    // strictly one name to prevent two from being registered\n    fn name(&self) -> &str {\n        OOM_OBS_NAME\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_3_chunk_5",
        "original_index": 5,
        "content": "impl<S> Observer<S> for OomObserver\nwhere\n    S: UsesInput,\n{\n    fn pre_exec(&mut self, _state: &mut S, _input: &S::Input) -> Result<(), Error> {\n        OOMED.store(false, Ordering::Relaxed);\n        // must reset for platforms which do not offer malloc tracking\n        MALLOC_SIZE.store(0, Ordering::Relaxed);\n        RUNNING.store(true, Ordering::Relaxed);\n        Ok(())\n    }\n\n    fn post_exec(\n        &mut self,\n        _state: &mut S,\n        _input: &S::Input,\n        _exit_kind: &ExitKind,\n    ) -> Result<(), Error> {\n        RUNNING.store(false, Ordering::Relaxed);\n        self.oomed = OOMED.load(Ordering::Relaxed);\n        Ok(())\n    }\n\n    fn pre_exec_child(&mut self, state: &mut S, input: &S::Input) -> Result<(), Error> {\n        self.pre_exec(state, input)\n    }\n\n    fn post_exec_child(\n        &mut self,\n        state: &mut S,\n        input: &S::Input,\n        exit_kind: &ExitKind,\n    ) -> Result<(), Error> {\n        self.post_exec(state, input, exit_kind)\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_3_chunk_6",
        "original_index": 6,
        "content": "/// Feedback for the similarly named [`OomObserver`] to detect if the target crashed due to an observed OOM\n#[derive(Debug, Serialize, Deserialize, Copy, Clone, Default)]\npub struct OomFeedback;\n\nimpl OomFeedback {\n    /// Whether the target OOM'd in the last execution\n    pub fn oomed() -> bool {\n        OOMED.load(Ordering::Relaxed)\n    }\n}\n\nimpl Named for OomFeedback {\n    fn name(&self) -> &str {\n        \"oom\"\n    }\n}\n\nimpl<S> Feedback<S> for OomFeedback\nwhere\n    S: State,\n{\n    fn is_interesting<EM, OT>(\n        &mut self,\n        _state: &mut S,\n        _manager: &mut EM,\n        _input: &S::Input,\n        _observers: &OT,\n        _exit_kind: &ExitKind,\n    ) -> Result<bool, Error>\n    where\n        EM: EventFirer<State = S>,\n        OT: ObserversTuple<S>,\n    {\n        Ok(Self::oomed())\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_4",
    "original_uuid": "531430fb53d5505059ecf3d7c8b4b6dd2a8ea035e0b37da202c385b706c7890f",
    "content": "#include \"common.h\"\n\nbool both_require(const uint8_t *bytes, size_t len) {\n  if (len >= 1 && bytes[0] == 'a') {\n    if (len >= 2 && bytes[1] == 'b') {\n      if (len >= 3 && bytes[2] == 'c') { return ACCEPT; }\n    }\n  }\n  return REJECT;\n}",
    "chunks": [
      {
        "chunk_id": "doc_4_chunk_0",
        "original_index": 0,
        "content": "#include \"common.h\"\n\nbool both_require(const uint8_t *bytes, size_t len) {\n  if (len >= 1 && bytes[0] == 'a') {\n    if (len >= 2 && bytes[1] == 'b') {\n      if (len >= 3 && bytes[2] == 'c') { return ACCEPT; }\n    }\n  }\n  return REJECT;\n}"
      }
    ]
  },
  {
    "doc_id": "doc_5",
    "original_uuid": "0732e22d364e4359bf093902d674d9ec891bf9a2b4281da5c5bebc1d67879f95",
    "content": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n// The following line is needed for shared memory testcase fuzzing\n__AFL_FUZZ_INIT();\n\nvoid vuln(char *buf) {\n  if (strcmp(buf, \"vuln\") == 0) { abort(); }\n}\n\nint main(int argc, char **argv) {\n  // Start the forkserver at this point (i.e., forks will happen here)\n  __AFL_INIT();\n\n  // The following five lines are for normal fuzzing.\n  /*\n  FILE *file = stdin;\n  if (argc > 1) { file = fopen(argv[1], \"rb\"); }\n  char  buf[16];\n  char *p = fgets(buf, 16, file);\n  buf[15] = 0;\n  */\n\n  // The following line is also needed for shared memory testcase fuzzing\n  unsigned char *buf = __AFL_FUZZ_TESTCASE_BUF;  // must be after __AFL_INIT\n\n  // printf(\"input: %s\\n\", buf);\n  if (buf[0] == 'b') {\n    if (buf[1] == 'a') {\n      if (buf[2] == 'd') { abort(); }\n    }\n  }\n  vuln((char *)buf);\n\n  return 0;\n}",
    "chunks": [
      {
        "chunk_id": "doc_5_chunk_0",
        "original_index": 0,
        "content": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n// The following line is needed for shared memory testcase fuzzing\n__AFL_FUZZ_INIT();\n\nvoid vuln(char *buf) {\n  if (strcmp(buf, \"vuln\") == 0) { abort(); }\n}\n\nint main(int argc, char **argv) {\n  // Start the forkserver at this point (i.e., forks will happen here)\n  __AFL_INIT();\n\n  // The following five lines are for normal fuzzing.\n  /*\n  FILE *file = stdin;\n  if (argc > 1) { file = fopen(argv[1], \"rb\"); }\n  char  buf[16];\n  char *p = fgets(buf, 16, file);\n  buf[15] = 0;\n  */\n\n  // The following line is also needed for shared memory testcase fuzzing\n  unsigned char *buf = __AFL_FUZZ_TESTCASE_BUF;  // must be after __AFL_INIT\n\n  // printf(\"input: %s\\n\", buf);\n  if (buf[0] == 'b') {\n    if (buf[1] == 'a') {\n      if (buf[2] == 'd') { abort(); }\n    }\n  }\n  vuln((char *)buf);\n\n  return 0;\n}"
      }
    ]
  },
  {
    "doc_id": "doc_6",
    "original_uuid": "9de08c4cbd3e0aca53020c82fcb434e39fc07d85fc092617f89c993d1fd28210",
    "content": "use std::{\n    collections::{BTreeSet, HashMap},\n    marker::PhantomData,\n};\n\nuse libafl::{\n    corpus::{Corpus, CorpusId, Testcase},\n    feedbacks::MapNoveltiesMetadata,\n    inputs::UsesInput,\n    schedulers::{RemovableScheduler, Scheduler},\n    state::{HasCorpus, HasMetadata, State, UsesState},\n    Error,\n};\n\n#[derive(Clone, Debug)]\npub struct MergeScheduler<S> {\n    mapping: HashMap<usize, CorpusId>,\n    all: BTreeSet<CorpusId>,\n    phantom: PhantomData<S>,\n}\n\nimpl<S> UsesState for MergeScheduler<S>\nwhere\n    S: State,\n{\n    type State = S;\n}\n\nimpl<S> RemovableScheduler for MergeScheduler<S>\nwhere\n    S: State + HasCorpus,\n{\n    fn on_remove(\n        &mut self,\n        _state: &mut Self::State,\n        idx: CorpusId,\n        _testcase: &Option<Testcase<<Self::State as UsesInput>::Input>>,\n    ) -> Result<(), Error> {\n        self.all.remove(&idx);\n        Ok(())\n    }\n}\n\nimpl<S> Scheduler for MergeScheduler<S>\nwhere\n    S: State + HasCorpus,\n{\n    fn on_add(&mut self, state: &mut Self::State, idx: CorpusId) -> Result<(), Error> {\n        self.all.insert(idx);\n        let testcase = state.corpus().get(idx)?.borrow();\n        let meta = testcase.metadata::<MapNoveltiesMetadata>()?;\n        for cov_idx in &meta.list {\n            self.mapping.insert(*cov_idx, idx);\n        }\n        Ok(())\n    }\n\n    fn next(&mut self, _state: &mut Self::State) -> Result<CorpusId, Error> {\n        unimplemented!(\"Not suitable for actual scheduling.\");\n    }\n}\n\nimpl<S> MergeScheduler<S> {\n    pub fn new() -> Self {\n        Self {\n            mapping: HashMap::default(),\n            all: BTreeSet::default(),\n            phantom: PhantomData,\n        }\n    }\n\n    pub fn removable(&self) -> BTreeSet<CorpusId> {\n        self.all\n            .difference(&self.mapping.values().copied().collect())\n            .copied()\n            .collect()\n    }\n\n    pub fn current(&self) -> &BTreeSet<CorpusId> {\n        &self.all\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_6_chunk_0",
        "original_index": 0,
        "content": "use std::{\n    collections::{BTreeSet, HashMap},\n    marker::PhantomData,\n};\n\nuse libafl::{\n    corpus::{Corpus, CorpusId, Testcase},\n    feedbacks::MapNoveltiesMetadata,\n    inputs::UsesInput,\n    schedulers::{RemovableScheduler, Scheduler},\n    state::{HasCorpus, HasMetadata, State, UsesState},\n    Error,\n};\n\n#[derive(Clone, Debug)]\npub struct MergeScheduler<S> {\n    mapping: HashMap<usize, CorpusId>,\n    all: BTreeSet<CorpusId>,\n    phantom: PhantomData<S>,\n}\n\nimpl<S> UsesState for MergeScheduler<S>\nwhere\n    S: State,\n{\n    type State = S;\n}\n\n"
      },
      {
        "chunk_id": "doc_6_chunk_1",
        "original_index": 1,
        "content": "impl<S> RemovableScheduler for MergeScheduler<S>\nwhere\n    S: State + HasCorpus,\n{\n    fn on_remove(\n        &mut self,\n        _state: &mut Self::State,\n        idx: CorpusId,\n        _testcase: &Option<Testcase<<Self::State as UsesInput>::Input>>,\n    ) -> Result<(), Error> {\n        self.all.remove(&idx);\n        Ok(())\n    }\n}\n\nimpl<S> Scheduler for MergeScheduler<S>\nwhere\n    S: State + HasCorpus,\n{\n    fn on_add(&mut self, state: &mut Self::State, idx: CorpusId) -> Result<(), Error> {\n        self.all.insert(idx);\n        let testcase = state.corpus().get(idx)?.borrow();\n        let meta = testcase.metadata::<MapNoveltiesMetadata>()?;\n        for cov_idx in &meta.list {\n            self.mapping.insert(*cov_idx, idx);\n        }\n        Ok(())\n    }\n\n"
      },
      {
        "chunk_id": "doc_6_chunk_2",
        "original_index": 2,
        "content": "    fn next(&mut self, _state: &mut Self::State) -> Result<CorpusId, Error> {\n        unimplemented!(\"Not suitable for actual scheduling.\");\n    }\n}\n\nimpl<S> MergeScheduler<S> {\n    pub fn new() -> Self {\n        Self {\n            mapping: HashMap::default(),\n            all: BTreeSet::default(),\n            phantom: PhantomData,\n        }\n    }\n\n    pub fn removable(&self) -> BTreeSet<CorpusId> {\n        self.all\n            .difference(&self.mapping.values().copied().collect())\n            .copied()\n            .collect()\n    }\n\n    pub fn current(&self) -> &BTreeSet<CorpusId> {\n        &self.all\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_7",
    "original_uuid": "a72987c2673fe8ea07415380a869075c4e492ac6323ef0d1126bec73e8d4319f",
    "content": "use std::sync::OnceLock;\n\nuse capstone::arch::BuildsCapstone;\nuse enum_map::{enum_map, EnumMap};\nuse num_enum::{IntoPrimitive, TryFromPrimitive};\npub use strum_macros::EnumIter;\npub use syscall_numbers::aarch64::*;\n\nuse crate::{sync_backdoor::BackdoorArgs, CallingConvention};\n\n#[derive(IntoPrimitive, TryFromPrimitive, Debug, Clone, Copy, EnumIter)]\n#[repr(i32)]\npub enum Regs {\n    X0 = 0,\n    X1 = 1,\n    X2 = 2,\n    X3 = 3,\n    X4 = 4,\n    X5 = 5,\n    X6 = 6,\n    X7 = 7,\n    X8 = 8,\n    X9 = 9,\n    X10 = 10,\n    X11 = 11,\n    X12 = 12,\n    X13 = 13,\n    X14 = 14,\n    X15 = 15,\n    X16 = 16,\n    X17 = 17,\n    X18 = 18,\n    X19 = 19,\n    X20 = 20,\n    X21 = 21,\n    X22 = 22,\n    X23 = 23,\n    X24 = 24,\n    X25 = 25,\n    X26 = 26,\n    X27 = 27,\n    X28 = 28,\n    X29 = 29,\n    X30 = 30,\n    Sp = 31,\n    Pc = 32,\n    Pstate = 33,\n}\n\nstatic BACKDOOR_ARCH_REGS: OnceLock<EnumMap<BackdoorArgs, Regs>> = OnceLock::new();\n\npub fn get_backdoor_arch_regs() -> &'static EnumMap<BackdoorArgs, Regs> {\n    BACKDOOR_ARCH_REGS.get_or_init(|| {\n        enum_map! {\n            BackdoorArgs::Ret  => Regs::X0,\n            BackdoorArgs::Cmd  => Regs::X0,\n            BackdoorArgs::Arg1 => Regs::X1,\n            BackdoorArgs::Arg2 => Regs::X2,\n            BackdoorArgs::Arg3 => Regs::X3,\n            BackdoorArgs::Arg4 => Regs::X4,\n            BackdoorArgs::Arg5 => Regs::X5,\n            BackdoorArgs::Arg6 => Regs::X6,\n        }\n    })\n}\n\n/// alias registers\n#[allow(non_upper_case_globals)]\nimpl Regs {\n    pub const Fp: Regs = Regs::X29;\n    pub const Lr: Regs = Regs::X30;\n}\n\n/// Return an ARM64 ArchCapstoneBuilder\npub fn capstone() -> capstone::arch::arm64::ArchCapstoneBuilder {\n    capstone::Capstone::new()\n        .arm64()\n        .mode(capstone::arch::arm64::ArchMode::Arm)\n}\n\npub type GuestReg = u64;\n\nimpl crate::ArchExtras for crate::CPU {\n    fn read_return_address<T>(&self) -> Result<T, String>\n    where\n        T: From<GuestReg>,\n    {\n        self.read_reg(Regs::Lr)\n    }\n\n    fn write_return_address<T>(&self, val: T) -> Result<(), String>\n    where\n        T: Into<GuestReg>,\n    {\n        self.write_reg(Regs::Lr, val)\n    }\n\n    fn read_function_argument<T>(&self, conv: CallingConvention, idx: u8) -> Result<T, String>\n    where\n        T: From<GuestReg>,\n    {\n        if conv != CallingConvention::Cdecl {\n            return Err(format!(\"Unsupported calling convention: {conv:#?}\"));\n        }\n\n        let reg_id = match idx {\n            0 => Regs::X0,\n            1 => Regs::X1,\n            2 => Regs::X2,\n            3 => Regs::X3,\n            4 => Regs::X4,\n            5 => Regs::X5,\n            r => return Err(format!(\"Unsupported argument: {r:}\")),\n        };\n\n        self.read_reg(reg_id)\n    }\n\n    fn write_function_argument<T>(\n        &self,\n        conv: CallingConvention,\n        idx: i32,\n        val: T,\n    ) -> Result<(), String>\n    where\n        T: Into<GuestReg>,\n    {\n        if conv != CallingConvention::Cdecl {\n            return Err(format!(\"Unsupported calling convention: {conv:#?}\"));\n        }\n\n        let val: GuestReg = val.into();\n        match idx {\n            0 => self.write_reg(Regs::X0, val),\n            1 => self.write_reg(Regs::X1, val),\n            _ => Err(format!(\"Unsupported argument: {idx:}\")),\n        }\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_7_chunk_0",
        "original_index": 0,
        "content": "use std::sync::OnceLock;\n\nuse capstone::arch::BuildsCapstone;\nuse enum_map::{enum_map, EnumMap};\nuse num_enum::{IntoPrimitive, TryFromPrimitive};\npub use strum_macros::EnumIter;\npub use syscall_numbers::aarch64::*;\n\nuse crate::{sync_backdoor::BackdoorArgs, CallingConvention};\n\n#[derive(IntoPrimitive, TryFromPrimitive, Debug, Clone, Copy, EnumIter)]\n#[repr(i32)]\npub enum Regs {\n    X0 = 0,\n    X1 = 1,\n    X2 = 2,\n    X3 = 3,\n    X4 = 4,\n    X5 = 5,\n    X6 = 6,\n    X7 = 7,\n    X8 = 8,\n    X9 = 9,\n    X10 = 10,\n    X11 = 11,\n    X12 = 12,\n    X13 = 13,\n    X14 = 14,\n    X15 = 15,\n    X16 = 16,\n    X17 = 17,\n    X18 = 18,\n    X19 = 19,\n    X20 = 20,\n    X21 = 21,\n    X22 = 22,\n    X23 = 23,\n    X24 = 24,\n    X25 = 25,\n    X26 = 26,\n    X27 = 27,\n    X28 = 28,\n    X29 = 29,\n    X30 = 30,\n    Sp = 31,\n    Pc = 32,\n    Pstate = 33,\n}\n\n"
      },
      {
        "chunk_id": "doc_7_chunk_1",
        "original_index": 1,
        "content": "static BACKDOOR_ARCH_REGS: OnceLock<EnumMap<BackdoorArgs, Regs>> = OnceLock::new();\n\npub fn get_backdoor_arch_regs() -> &'static EnumMap<BackdoorArgs, Regs> {\n    BACKDOOR_ARCH_REGS.get_or_init(|| {\n        enum_map! {\n            BackdoorArgs::Ret  => Regs::X0,\n            BackdoorArgs::Cmd  => Regs::X0,\n            BackdoorArgs::Arg1 => Regs::X1,\n            BackdoorArgs::Arg2 => Regs::X2,\n            BackdoorArgs::Arg3 => Regs::X3,\n            BackdoorArgs::Arg4 => Regs::X4,\n            BackdoorArgs::Arg5 => Regs::X5,\n            BackdoorArgs::Arg6 => Regs::X6,\n        }\n    })\n}\n\n"
      },
      {
        "chunk_id": "doc_7_chunk_2",
        "original_index": 2,
        "content": "/// alias registers\n#[allow(non_upper_case_globals)]\nimpl Regs {\n    pub const Fp: Regs = Regs::X29;\n    pub const Lr: Regs = Regs::X30;\n}\n\n/// Return an ARM64 ArchCapstoneBuilder\npub fn capstone() -> capstone::arch::arm64::ArchCapstoneBuilder {\n    capstone::Capstone::new()\n        .arm64()\n        .mode(capstone::arch::arm64::ArchMode::Arm)\n}\n\npub type GuestReg = u64;\n\nimpl crate::ArchExtras for crate::CPU {\n    fn read_return_address<T>(&self) -> Result<T, String>\n    where\n        T: From<GuestReg>,\n    {\n        self.read_reg(Regs::Lr)\n    }\n\n    fn write_return_address<T>(&self, val: T) -> Result<(), String>\n    where\n        T: Into<GuestReg>,\n    {\n        self.write_reg(Regs::Lr, val)\n    }\n\n"
      },
      {
        "chunk_id": "doc_7_chunk_3",
        "original_index": 3,
        "content": "    fn read_function_argument<T>(&self, conv: CallingConvention, idx: u8) -> Result<T, String>\n    where\n        T: From<GuestReg>,\n    {\n        if conv != CallingConvention::Cdecl {\n            return Err(format!(\"Unsupported calling convention: {conv:#?}\"));\n        }\n\n        let reg_id = match idx {\n            0 => Regs::X0,\n            1 => Regs::X1,\n            2 => Regs::X2,\n            3 => Regs::X3,\n            4 => Regs::X4,\n            5 => Regs::X5,\n            r => return Err(format!(\"Unsupported argument: {r:}\")),\n        };\n\n        self.read_reg(reg_id)\n    }\n\n"
      },
      {
        "chunk_id": "doc_7_chunk_4",
        "original_index": 4,
        "content": "    fn write_function_argument<T>(\n        &self,\n        conv: CallingConvention,\n        idx: i32,\n        val: T,\n    ) -> Result<(), String>\n    where\n        T: Into<GuestReg>,\n    {\n        if conv != CallingConvention::Cdecl {\n            return Err(format!(\"Unsupported calling convention: {conv:#?}\"));\n        }\n\n        let val: GuestReg = val.into();\n        match idx {\n            0 => self.write_reg(Regs::X0, val),\n            1 => self.write_reg(Regs::X1, val),\n            _ => Err(format!(\"Unsupported argument: {idx:}\")),\n        }\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_8",
    "original_uuid": "86e39b19ca47c979baa00968bc37f96da0b379d1e2a30e8407738bdce8e98748",
    "content": "use std::{mem::size_of, sync::OnceLock};\n\nuse capstone::arch::BuildsCapstone;\nuse enum_map::{enum_map, EnumMap};\nuse num_enum::{IntoPrimitive, TryFromPrimitive};\npub use strum_macros::EnumIter;\npub use syscall_numbers::x86_64::*;\n\nuse crate::{sync_backdoor::BackdoorArgs, CallingConvention};\n\n#[derive(IntoPrimitive, TryFromPrimitive, Debug, Clone, Copy, EnumIter)]\n#[repr(i32)]\npub enum Regs {\n    Rax = 0,\n    Rbx = 1,\n    Rcx = 2,\n    Rdx = 3,\n    Rsi = 4,\n    Rdi = 5,\n    Rbp = 6,\n    Rsp = 7,\n    R8 = 8,\n    R9 = 9,\n    R10 = 10,\n    R11 = 11,\n    R12 = 12,\n    R13 = 13,\n    R14 = 14,\n    R15 = 15,\n    Rip = 16,\n    Rflags = 17,\n}\n\nstatic BACKDOOR_ARCH_REGS: OnceLock<EnumMap<BackdoorArgs, Regs>> = OnceLock::new();\n\npub fn get_backdoor_arch_regs() -> &'static EnumMap<BackdoorArgs, Regs> {\n    BACKDOOR_ARCH_REGS.get_or_init(|| {\n        enum_map! {\n            BackdoorArgs::Ret  => Regs::Rax,\n            BackdoorArgs::Cmd  => Regs::Rax,\n            BackdoorArgs::Arg1 => Regs::Rdi,\n            BackdoorArgs::Arg2 => Regs::Rsi,\n            BackdoorArgs::Arg3 => Regs::Rdx,\n            BackdoorArgs::Arg4 => Regs::R10,\n            BackdoorArgs::Arg5 => Regs::R8,\n            BackdoorArgs::Arg6 => Regs::R9,\n        }\n    })\n}\n\n/// alias registers\n#[allow(non_upper_case_globals)]\nimpl Regs {\n    pub const Sp: Regs = Regs::Rsp;\n    pub const Pc: Regs = Regs::Rip;\n}\n\n/// Return an X86 `ArchCapstoneBuilder`\n#[must_use]\npub fn capstone() -> capstone::arch::x86::ArchCapstoneBuilder {\n    capstone::Capstone::new()\n        .x86()\n        .mode(capstone::arch::x86::ArchMode::Mode64)\n}\n\npub type GuestReg = u64;\n\nimpl crate::ArchExtras for crate::CPU {\n    fn read_return_address<T>(&self) -> Result<T, String>\n    where\n        T: From<GuestReg>,\n    {\n        let stack_ptr: GuestReg = self.read_reg(Regs::Rsp)?;\n        let mut ret_addr = [0; size_of::<GuestReg>()];\n        unsafe { self.read_mem(stack_ptr, &mut ret_addr) };\n        Ok(GuestReg::from_le_bytes(ret_addr).into())\n    }\n\n    fn write_return_address<T>(&self, val: T) -> Result<(), String>\n    where\n        T: Into<GuestReg>,\n    {\n        let stack_ptr: GuestReg = self.read_reg(Regs::Rsp)?;\n        let val: GuestReg = val.into();\n        let ret_addr = val.to_le_bytes();\n        unsafe { self.write_mem(stack_ptr, &ret_addr) };\n        Ok(())\n    }\n\n    fn read_function_argument<T>(&self, conv: CallingConvention, idx: u8) -> Result<T, String>\n    where\n        T: From<GuestReg>,\n    {\n        if conv != CallingConvention::Cdecl {\n            return Err(format!(\"Unsupported calling convention: {conv:#?}\"));\n        }\n\n        let reg_id = match idx {\n            0 => Regs::Rdi,\n            1 => Regs::Rsi,\n            2 => Regs::Rdx,\n            3 => Regs::Rcx,\n            4 => Regs::R8,\n            5 => Regs::R9,\n            r => return Err(format!(\"Unsupported argument: {r:}\")),\n        };\n\n        self.read_reg(reg_id)\n    }\n\n    fn write_function_argument<T>(\n        &self,\n        conv: CallingConvention,\n        idx: i32,\n        val: T,\n    ) -> Result<(), String>\n    where\n        T: Into<GuestReg>,\n    {\n        if conv != CallingConvention::Cdecl {\n            return Err(format!(\"Unsupported calling convention: {conv:#?}\"));\n        }\n\n        let val: GuestReg = val.into();\n        match idx {\n            0 => self.write_reg(Regs::Rdi, val),\n            1 => self.write_reg(Regs::Rsi, val),\n            _ => Err(format!(\"Unsupported argument: {idx:}\")),\n        }\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_8_chunk_0",
        "original_index": 0,
        "content": "use std::{mem::size_of, sync::OnceLock};\n\nuse capstone::arch::BuildsCapstone;\nuse enum_map::{enum_map, EnumMap};\nuse num_enum::{IntoPrimitive, TryFromPrimitive};\npub use strum_macros::EnumIter;\npub use syscall_numbers::x86_64::*;\n\nuse crate::{sync_backdoor::BackdoorArgs, CallingConvention};\n\n#[derive(IntoPrimitive, TryFromPrimitive, Debug, Clone, Copy, EnumIter)]\n#[repr(i32)]\npub enum Regs {\n    Rax = 0,\n    Rbx = 1,\n    Rcx = 2,\n    Rdx = 3,\n    Rsi = 4,\n    Rdi = 5,\n    Rbp = 6,\n    Rsp = 7,\n    R8 = 8,\n    R9 = 9,\n    R10 = 10,\n    R11 = 11,\n    R12 = 12,\n    R13 = 13,\n    R14 = 14,\n    R15 = 15,\n    Rip = 16,\n    Rflags = 17,\n}\n\nstatic BACKDOOR_ARCH_REGS: OnceLock<EnumMap<BackdoorArgs, Regs>> = OnceLock::new();\n\n"
      },
      {
        "chunk_id": "doc_8_chunk_1",
        "original_index": 1,
        "content": "pub fn get_backdoor_arch_regs() -> &'static EnumMap<BackdoorArgs, Regs> {\n    BACKDOOR_ARCH_REGS.get_or_init(|| {\n        enum_map! {\n            BackdoorArgs::Ret  => Regs::Rax,\n            BackdoorArgs::Cmd  => Regs::Rax,\n            BackdoorArgs::Arg1 => Regs::Rdi,\n            BackdoorArgs::Arg2 => Regs::Rsi,\n            BackdoorArgs::Arg3 => Regs::Rdx,\n            BackdoorArgs::Arg4 => Regs::R10,\n            BackdoorArgs::Arg5 => Regs::R8,\n            BackdoorArgs::Arg6 => Regs::R9,\n        }\n    })\n}\n\n/// alias registers\n#[allow(non_upper_case_globals)]\nimpl Regs {\n    pub const Sp: Regs = Regs::Rsp;\n    pub const Pc: Regs = Regs::Rip;\n}\n\n/// Return an X86 `ArchCapstoneBuilder`\n#[must_use]\npub fn capstone() -> capstone::arch::x86::ArchCapstoneBuilder {\n    capstone::Capstone::new()\n        .x86()\n        .mode(capstone::arch::x86::ArchMode::Mode64)\n}\n\npub type GuestReg = u64;\n\n"
      },
      {
        "chunk_id": "doc_8_chunk_2",
        "original_index": 2,
        "content": "impl crate::ArchExtras for crate::CPU {\n    fn read_return_address<T>(&self) -> Result<T, String>\n    where\n        T: From<GuestReg>,\n    {\n        let stack_ptr: GuestReg = self.read_reg(Regs::Rsp)?;\n        let mut ret_addr = [0; size_of::<GuestReg>()];\n        unsafe { self.read_mem(stack_ptr, &mut ret_addr) };\n        Ok(GuestReg::from_le_bytes(ret_addr).into())\n    }\n\n    fn write_return_address<T>(&self, val: T) -> Result<(), String>\n    where\n        T: Into<GuestReg>,\n    {\n        let stack_ptr: GuestReg = self.read_reg(Regs::Rsp)?;\n        let val: GuestReg = val.into();\n        let ret_addr = val.to_le_bytes();\n        unsafe { self.write_mem(stack_ptr, &ret_addr) };\n        Ok(())\n    }\n\n"
      },
      {
        "chunk_id": "doc_8_chunk_3",
        "original_index": 3,
        "content": "    fn read_function_argument<T>(&self, conv: CallingConvention, idx: u8) -> Result<T, String>\n    where\n        T: From<GuestReg>,\n    {\n        if conv != CallingConvention::Cdecl {\n            return Err(format!(\"Unsupported calling convention: {conv:#?}\"));\n        }\n\n        let reg_id = match idx {\n            0 => Regs::Rdi,\n            1 => Regs::Rsi,\n            2 => Regs::Rdx,\n            3 => Regs::Rcx,\n            4 => Regs::R8,\n            5 => Regs::R9,\n            r => return Err(format!(\"Unsupported argument: {r:}\")),\n        };\n\n        self.read_reg(reg_id)\n    }\n\n"
      },
      {
        "chunk_id": "doc_8_chunk_4",
        "original_index": 4,
        "content": "    fn write_function_argument<T>(\n        &self,\n        conv: CallingConvention,\n        idx: i32,\n        val: T,\n    ) -> Result<(), String>\n    where\n        T: Into<GuestReg>,\n    {\n        if conv != CallingConvention::Cdecl {\n            return Err(format!(\"Unsupported calling convention: {conv:#?}\"));\n        }\n\n        let val: GuestReg = val.into();\n        match idx {\n            0 => self.write_reg(Regs::Rdi, val),\n            1 => self.write_reg(Regs::Rsi, val),\n            _ => Err(format!(\"Unsupported argument: {idx:}\")),\n        }\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_9",
    "original_uuid": "f53f33e3403059a8fa7d21b3037c33c6a797fa43c38bca3e16adedee20780642",
    "content": "//! Input for the [`Nautilus`](https://github.com/RUB-SysSec/nautilus) grammar fuzzer methods\n//!\n\n//use ahash::AHasher;\n//use core::hash::Hasher;\n\nuse alloc::{rc::Rc, string::String, vec::Vec};\nuse core::cell::RefCell;\nuse std::hash::{Hash, Hasher};\n\nuse grammartec::{\n    newtypes::NodeID,\n    rule::RuleIDOrCustom,\n    tree::{Tree, TreeLike},\n};\nuse libafl_bolts::HasLen;\nuse serde::{Deserialize, Serialize};\n\nuse crate::{\n    generators::nautilus::NautilusContext,\n    inputs::{BytesInput, Input, InputConverter},\n    Error,\n};\n\n/// An [`Input`] implementation for `Nautilus` grammar.\n#[derive(Serialize, Deserialize, Clone, Debug)]\npub struct NautilusInput {\n    /// The input representation as Tree\n    pub tree: Tree,\n}\n\nimpl Input for NautilusInput {\n    /// Generate a name for this input\n    #[must_use]\n    fn generate_name(&self, idx: usize) -> String {\n        /*let mut hasher = AHasher::new_with_keys(0, 0);\n        for term in &self.terms {\n            hasher.write(term.symbol.as_bytes());\n        }\n        format!(\"{:016x}\", hasher.finish())*/\n        format!(\"id:{idx}\")\n    }\n}\n\n/// Rc Ref-cell from Input\nimpl From<NautilusInput> for Rc<RefCell<NautilusInput>> {\n    fn from(input: NautilusInput) -> Self {\n        Rc::new(RefCell::new(input))\n    }\n}\n\nimpl HasLen for NautilusInput {\n    #[inline]\n    fn len(&self) -> usize {\n        self.tree.size()\n    }\n}\n\nimpl NautilusInput {\n    /// Creates a new codes input using the given terminals\n    #[must_use]\n    pub fn new(tree: Tree) -> Self {\n        Self { tree }\n    }\n\n    /// Create an empty [`Input`]\n    #[must_use]\n    pub fn empty() -> Self {\n        Self {\n            tree: Tree {\n                rules: vec![],\n                sizes: vec![],\n                paren: vec![],\n            },\n        }\n    }\n\n    /// Generate a `Nautilus` input from the given bytes\n    pub fn unparse(&self, context: &NautilusContext, bytes: &mut Vec<u8>) {\n        bytes.clear();\n        self.tree.unparse(NodeID::from(0), &context.ctx, bytes);\n    }\n\n    /// Get the tree representation of this input\n    #[must_use]\n    pub fn tree(&self) -> &Tree {\n        &self.tree\n    }\n\n    /// Get the tree representation of this input, as a mutable reference\n    #[must_use]\n    pub fn tree_mut(&mut self) -> &mut Tree {\n        &mut self.tree\n    }\n}\n\nimpl Hash for NautilusInput {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        self.tree().paren.hash(state);\n        for r in &self.tree().rules {\n            match r {\n                RuleIDOrCustom::Custom(a, b) => {\n                    a.hash(state);\n                    b.hash(state);\n                }\n                RuleIDOrCustom::Rule(a) => a.hash(state),\n            }\n        }\n        self.tree().sizes.hash(state);\n    }\n}\n\n/// `InputConverter` to convert from `NautilusInput` to `BytesInput`\n#[derive(Debug)]\npub struct NautilusToBytesInputConverter<'a> {\n    ctx: &'a NautilusContext,\n}\n\nimpl<'a> NautilusToBytesInputConverter<'a> {\n    #[must_use]\n    /// Create a new `NautilusToBytesInputConverter` from a context\n    pub fn new(ctx: &'a NautilusContext) -> Self {\n        Self { ctx }\n    }\n}\n\nimpl<'a> InputConverter for NautilusToBytesInputConverter<'a> {\n    type From = NautilusInput;\n    type To = BytesInput;\n\n    fn convert(&mut self, input: Self::From) -> Result<Self::To, Error> {\n        let mut bytes = vec![];\n        input.unparse(self.ctx, &mut bytes);\n        Ok(BytesInput::new(bytes))\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_9_chunk_0",
        "original_index": 0,
        "content": "//! Input for the [`Nautilus`](https://github.com/RUB-SysSec/nautilus) grammar fuzzer methods\n//!\n\n//use ahash::AHasher;\n//use core::hash::Hasher;\n\nuse alloc::{rc::Rc, string::String, vec::Vec};\nuse core::cell::RefCell;\nuse std::hash::{Hash, Hasher};\n\nuse grammartec::{\n    newtypes::NodeID,\n    rule::RuleIDOrCustom,\n    tree::{Tree, TreeLike},\n};\nuse libafl_bolts::HasLen;\nuse serde::{Deserialize, Serialize};\n\nuse crate::{\n    generators::nautilus::NautilusContext,\n    inputs::{BytesInput, Input, InputConverter},\n    Error,\n};\n\n/// An [`Input`] implementation for `Nautilus` grammar.\n#[derive(Serialize, Deserialize, Clone, Debug)]\npub struct NautilusInput {\n    /// The input representation as Tree\n    pub tree: Tree,\n}\n\n"
      },
      {
        "chunk_id": "doc_9_chunk_1",
        "original_index": 1,
        "content": "impl Input for NautilusInput {\n    /// Generate a name for this input\n    #[must_use]\n    fn generate_name(&self, idx: usize) -> String {\n        /*let mut hasher = AHasher::new_with_keys(0, 0);\n        for term in &self.terms {\n            hasher.write(term.symbol.as_bytes());\n        }\n        format!(\"{:016x}\", hasher.finish())*/\n        format!(\"id:{idx}\")\n    }\n}\n\n/// Rc Ref-cell from Input\nimpl From<NautilusInput> for Rc<RefCell<NautilusInput>> {\n    fn from(input: NautilusInput) -> Self {\n        Rc::new(RefCell::new(input))\n    }\n}\n\nimpl HasLen for NautilusInput {\n    #[inline]\n    fn len(&self) -> usize {\n        self.tree.size()\n    }\n}\n\nimpl NautilusInput {\n    /// Creates a new codes input using the given terminals\n    #[must_use]\n    pub fn new(tree: Tree) -> Self {\n        Self { tree }\n    }\n\n"
      },
      {
        "chunk_id": "doc_9_chunk_2",
        "original_index": 2,
        "content": "    /// Create an empty [`Input`]\n    #[must_use]\n    pub fn empty() -> Self {\n        Self {\n            tree: Tree {\n                rules: vec![],\n                sizes: vec![],\n                paren: vec![],\n            },\n        }\n    }\n\n    /// Generate a `Nautilus` input from the given bytes\n    pub fn unparse(&self, context: &NautilusContext, bytes: &mut Vec<u8>) {\n        bytes.clear();\n        self.tree.unparse(NodeID::from(0), &context.ctx, bytes);\n    }\n\n"
      },
      {
        "chunk_id": "doc_9_chunk_3",
        "original_index": 3,
        "content": "    /// Get the tree representation of this input\n    #[must_use]\n    pub fn tree(&self) -> &Tree {\n        &self.tree\n    }\n\n    /// Get the tree representation of this input, as a mutable reference\n    #[must_use]\n    pub fn tree_mut(&mut self) -> &mut Tree {\n        &mut self.tree\n    }\n}\n\nimpl Hash for NautilusInput {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        self.tree().paren.hash(state);\n        for r in &self.tree().rules {\n            match r {\n                RuleIDOrCustom::Custom(a, b) => {\n                    a.hash(state);\n                    b.hash(state);\n                }\n                RuleIDOrCustom::Rule(a) => a.hash(state),\n            }\n        }\n        self.tree().sizes.hash(state);\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_9_chunk_4",
        "original_index": 4,
        "content": "/// `InputConverter` to convert from `NautilusInput` to `BytesInput`\n#[derive(Debug)]\npub struct NautilusToBytesInputConverter<'a> {\n    ctx: &'a NautilusContext,\n}\n\nimpl<'a> NautilusToBytesInputConverter<'a> {\n    #[must_use]\n    /// Create a new `NautilusToBytesInputConverter` from a context\n    pub fn new(ctx: &'a NautilusContext) -> Self {\n        Self { ctx }\n    }\n}\n\nimpl<'a> InputConverter for NautilusToBytesInputConverter<'a> {\n    type From = NautilusInput;\n    type To = BytesInput;\n\n    fn convert(&mut self, input: Self::From) -> Result<Self::To, Error> {\n        let mut bytes = vec![];\n        input.unparse(self.ctx, &mut bytes);\n        Ok(BytesInput::new(bytes))\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_10",
    "original_uuid": "17f3b912090b0ab395e7ceed8c88c38cea8c99bc292e3d94feec7a7dcbdf3ee2",
    "content": "use {\n    crate::args::LogArgs,\n    anyhow::{anyhow, Result},\n    simplelog::{Config, LevelFilter, WriteLogger},\n    std::fs::File,\n};\n\npub struct Logger;\n\nimpl Logger {\n    pub fn init(args: &impl LogArgs) -> Result<()> {\n        let filter: LevelFilter = args.log_level().into();\n        if filter != LevelFilter::Off {\n            let logfile = File::create(args.log_file())\n                .map_err(|e| anyhow!(\"Failed to open log file: {e:}\"))?;\n            WriteLogger::init(filter, Config::default(), logfile)\n                .map_err(|e| anyhow!(\"Failed to initalize logger: {e:}\"))?;\n        }\n        Ok(())\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_10_chunk_0",
        "original_index": 0,
        "content": "use {\n    crate::args::LogArgs,\n    anyhow::{anyhow, Result},\n    simplelog::{Config, LevelFilter, WriteLogger},\n    std::fs::File,\n};\n\npub struct Logger;\n\nimpl Logger {\n    pub fn init(args: &impl LogArgs) -> Result<()> {\n        let filter: LevelFilter = args.log_level().into();\n        if filter != LevelFilter::Off {\n            let logfile = File::create(args.log_file())\n                .map_err(|e| anyhow!(\"Failed to open log file: {e:}\"))?;\n            WriteLogger::init(filter, Config::default(), logfile)\n                .map_err(|e| anyhow!(\"Failed to initalize logger: {e:}\"))?;\n        }\n        Ok(())\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_11",
    "original_uuid": "db4820f398227726bb49a455d49677d8b6cce93fd915b4632ce34ca39c1684f4",
    "content": "from typing import Any, Dict, List, Optional, Set, Tuple, Type, Union\n\ntry:\n    from typing import get_args, get_origin\nexcept ImportError:\n    from typing_inspect import get_origin, get_args\n\nfrom . import _fwd\nfrom ._modules import *\n\n\nclass Registry:\n    # I was planning on using __init_subclass__, but that is incompatible with dynamic type creation when we have\n    # generic keys\n\n    RegElem = Union[List[Type], Dict[Type, \"RegElem\"]]\n\n    _reg: Dict[Type, RegElem] = {}\n    _names: Dict[str, Tuple[Type, Set[Type]]] = {}\n    _targets: Dict[str, Dict[Type, List[Type]]] = {}\n    _modules = {Checker, Cracker, Decoder, ResourceLoader, Searcher, PolymorphicChecker}\n\n    def _register_one(self, input_type, module_base, module_args):\n        if len(module_args) == 0:\n            self._reg.setdefault(module_base, []).append(input_type)\n            return\n\n        target_reg = self._reg.setdefault(module_base, {})\n        # Seek to the given type\n        for subtype in module_args[0:-1]:\n            target_reg = target_reg.setdefault(subtype, {})\n        target_reg.setdefault(module_args[-1], []).append(input_type)\n\n    def _real_register(self, input_type: type, *args) -> Type:\n        name = input_type.__name__.lower()\n        name_target = self._names[name] = (input_type, set())\n\n        if issubclass(input_type, Targeted):\n            target = input_type.getTarget()\n        else:\n            target = None\n\n        if issubclass(input_type, Searcher):\n            module_type = module_base = Searcher\n            module_args = ()\n        else:\n            module_type: Optional[Type] = None\n            module_base = None\n\n            # Work out what module type this is\n            if len(args) == 0 and hasattr(input_type, \"__orig_bases__\"):\n                for i in input_type.__orig_bases__:\n                    if module_type is not None:\n                        raise TypeError(\n                            f\"Type derived from multiple registrable base classes {i} and {module_type}\"\n                        )\n                    module_base = get_origin(i)\n                    if module_base not in self._modules:\n                        continue\n                    module_type = i\n            else:\n                for i in self._modules:\n                    if not issubclass(input_type, i):\n                        continue\n                    if module_type is not None:\n                        raise TypeError(\n                            f\"Type derived from multiple registrable base classes {i} and {module_type}\"\n                        )\n                    module_type = i\n            if module_type is None:\n                raise TypeError(\"No registrable base class\")\n\n            # Replace input type with polymorphic checker if required\n            if issubclass(input_type, Checker):\n                if len(args) == 0:\n                    arg = [\n                        get_args(i)\n                        for i in input_type.__orig_bases__\n                        if get_origin(i) == Checker\n                    ][0]\n                    if len(arg) != 1:\n                        raise TypeError(\"No argument for Checker\")\n                    input_type = input_type.convert({arg[0]})\n                else:\n                    input_type = input_type.convert(set(args))\n                self._register_one(input_type, PolymorphicChecker, [])\n                # Refresh the names with the new type\n                name_target = self._names[name] = (input_type, {PolymorphicChecker})\n\n            # Now handle the difference between register and register_multi\n            if len(args) == 0:\n                if module_type is PolymorphicChecker:\n                    module_base = PolymorphicChecker\n                elif module_base is None:\n                    raise TypeError(\"No type argument given\")\n                self._register_one(input_type, module_base, get_args(module_type))\n                name_target[1].add(module_base)\n            else:\n                if module_base is not None:\n                    raise TypeError(f\"Redundant type argument for {module_type}\")\n                module_base = module_type\n                for module_args in args:\n                    # Correct missing brackets\n                    if not isinstance(module_args, tuple):\n                        module_args = (module_args,)\n\n                    self._register_one(input_type, module_base, module_args)\n                    name_target[1].add(module_type[module_args])\n\n        name_target[1].add(module_type)\n\n        if target is not None and issubclass(module_base, Targeted):\n            self._targets.setdefault(target, {}).setdefault(module_type, []).append(\n                input_type\n            )\n\n        return input_type\n\n    def register(self, input_type):\n        return self._real_register(input_type)\n\n    def register_multi(self, *x):\n        return lambda input_type: self._real_register(input_type, *x)\n\n    def __getitem__(self, i: type) -> Optional[Any]:\n        target_type = get_origin(i)\n        # Check if this is a non-generic type, and return the whole dict if it is\n        if target_type is None:\n            return self._reg[i]\n\n        target_subtypes = get_args(i)\n        target_list = self._reg.setdefault(target_type, {})\n        for subtype in target_subtypes:\n            target_list = target_list.setdefault(subtype, {})\n        return target_list\n\n    def get_named(self, name: str, type_constraint: Type = None) -> Any:\n        ret = self._names[name.lower()]\n        if type_constraint and type_constraint not in ret[1]:\n            raise TypeError(f\"Type mismatch: wanted {type_constraint}, got {ret[1]}\")\n        return ret[0]\n\n    def get_targeted(\n        self, target: str, type_constraint: Type = None\n    ) -> Optional[Union[Dict[Type, Set[Type]], Set[Type]]]:\n        x = self._targets.get(target)\n        if x is None or type_constraint is None:\n            return x\n        return x.get(type_constraint)\n\n    def get_all_names(self) -> List[str]:\n        return list(self._names.keys())\n\n    def __str__(self):\n        return f\"ciphey.iface.Registry {{_reg: {self._reg}, _names: {self._names}, _targets: {self._targets}}}\"\n\n\n_fwd.registry = Registry()\n",
    "chunks": [
      {
        "chunk_id": "doc_11_chunk_0",
        "original_index": 0,
        "content": "from typing import Any, Dict, List, Optional, Set, Tuple, Type, Union\n\ntry:\n    from typing import get_args, get_origin\nexcept ImportError:\n    from typing_inspect import get_origin, get_args\n\nfrom . import _fwd\nfrom ._modules import *\n\n\nclass Registry:\n    # I was planning on using __init_subclass__, but that is incompatible with dynamic type creation when we have\n    # generic keys\n\n    RegElem = Union[List[Type], Dict[Type, \"RegElem\"]]\n\n"
      },
      {
        "chunk_id": "doc_11_chunk_1",
        "original_index": 1,
        "content": "    _reg: Dict[Type, RegElem] = {}\n    _names: Dict[str, Tuple[Type, Set[Type]]] = {}\n    _targets: Dict[str, Dict[Type, List[Type]]] = {}\n    _modules = {Checker, Cracker, Decoder, ResourceLoader, Searcher, PolymorphicChecker}\n\n    def _register_one(self, input_type, module_base, module_args):\n        if len(module_args) == 0:\n            self._reg.setdefault(module_base, []).append(input_type)\n            return\n\n        target_reg = self._reg.setdefault(module_base, {})\n        # Seek to the given type\n        for subtype in module_args[0:-1]:\n            target_reg = target_reg.setdefault(subtype, {})\n        target_reg.setdefault(module_args[-1], []).append(input_type)\n\n"
      },
      {
        "chunk_id": "doc_11_chunk_2",
        "original_index": 2,
        "content": "    def _real_register(self, input_type: type, *args) -> Type:\n        name = input_type.__name__.lower()\n        name_target = self._names[name] = (input_type, set())\n\n        if issubclass(input_type, Targeted):\n            target = input_type.getTarget()\n        else:\n            target = None\n\n        if issubclass(input_type, Searcher):\n            module_type = module_base = Searcher\n            module_args = ()\n        else:\n            module_type: Optional[Type] = None\n            module_base = None\n\n"
      },
      {
        "chunk_id": "doc_11_chunk_3",
        "original_index": 3,
        "content": "            # Work out what module type this is\n            if len(args) == 0 and hasattr(input_type, \"__orig_bases__\"):\n                for i in input_type.__orig_bases__:\n                    if module_type is not None:\n                        raise TypeError(\n                            f\"Type derived from multiple registrable base classes {i} and {module_type}\"\n                        )\n                    module_base = get_origin(i)\n                    if module_base not in self._modules:\n                        continue\n                    module_type = i\n            else:\n                for i in self._modules:\n                    if not issubclass(input_type, i):\n"
      },
      {
        "chunk_id": "doc_11_chunk_4",
        "original_index": 4,
        "content": "                        continue\n                    if module_type is not None:\n                        raise TypeError(\n                            f\"Type derived from multiple registrable base classes {i} and {module_type}\"\n                        )\n                    module_type = i\n            if module_type is None:\n                raise TypeError(\"No registrable base class\")\n\n"
      },
      {
        "chunk_id": "doc_11_chunk_5",
        "original_index": 5,
        "content": "            # Replace input type with polymorphic checker if required\n            if issubclass(input_type, Checker):\n                if len(args) == 0:\n                    arg = [\n                        get_args(i)\n                        for i in input_type.__orig_bases__\n                        if get_origin(i) == Checker\n                    ][0]\n                    if len(arg) != 1:\n                        raise TypeError(\"No argument for Checker\")\n                    input_type = input_type.convert({arg[0]})\n                else:\n                    input_type = input_type.convert(set(args))\n                self._register_one(input_type, PolymorphicChecker, [])\n                # Refresh the names with the new type\n                name_target = self._names[name] = (input_type, {PolymorphicChecker})\n\n"
      },
      {
        "chunk_id": "doc_11_chunk_6",
        "original_index": 6,
        "content": "            # Now handle the difference between register and register_multi\n            if len(args) == 0:\n                if module_type is PolymorphicChecker:\n                    module_base = PolymorphicChecker\n                elif module_base is None:\n                    raise TypeError(\"No type argument given\")\n                self._register_one(input_type, module_base, get_args(module_type))\n                name_target[1].add(module_base)\n            else:\n                if module_base is not None:\n                    raise TypeError(f\"Redundant type argument for {module_type}\")\n                module_base = module_type\n                for module_args in args:\n                    # Correct missing brackets\n                    if not isinstance(module_args, tuple):\n                        module_args = (module_args,)\n\n"
      },
      {
        "chunk_id": "doc_11_chunk_7",
        "original_index": 7,
        "content": "                    self._register_one(input_type, module_base, module_args)\n                    name_target[1].add(module_type[module_args])\n\n        name_target[1].add(module_type)\n\n        if target is not None and issubclass(module_base, Targeted):\n            self._targets.setdefault(target, {}).setdefault(module_type, []).append(\n                input_type\n            )\n\n        return input_type\n\n    def register(self, input_type):\n        return self._real_register(input_type)\n\n    def register_multi(self, *x):\n        return lambda input_type: self._real_register(input_type, *x)\n\n    def __getitem__(self, i: type) -> Optional[Any]:\n        target_type = get_origin(i)\n        # Check if this is a non-generic type, and return the whole dict if it is\n        if target_type is None:\n            return self._reg[i]\n\n"
      },
      {
        "chunk_id": "doc_11_chunk_8",
        "original_index": 8,
        "content": "        target_subtypes = get_args(i)\n        target_list = self._reg.setdefault(target_type, {})\n        for subtype in target_subtypes:\n            target_list = target_list.setdefault(subtype, {})\n        return target_list\n\n    def get_named(self, name: str, type_constraint: Type = None) -> Any:\n        ret = self._names[name.lower()]\n        if type_constraint and type_constraint not in ret[1]:\n            raise TypeError(f\"Type mismatch: wanted {type_constraint}, got {ret[1]}\")\n        return ret[0]\n\n"
      },
      {
        "chunk_id": "doc_11_chunk_9",
        "original_index": 9,
        "content": "    def get_targeted(\n        self, target: str, type_constraint: Type = None\n    ) -> Optional[Union[Dict[Type, Set[Type]], Set[Type]]]:\n        x = self._targets.get(target)\n        if x is None or type_constraint is None:\n            return x\n        return x.get(type_constraint)\n\n    def get_all_names(self) -> List[str]:\n        return list(self._names.keys())\n\n    def __str__(self):\n        return f\"ciphey.iface.Registry {{_reg: {self._reg}, _names: {self._names}, _targets: {self._targets}}}\"\n\n\n_fwd.registry = Registry()\n"
      }
    ]
  },
  {
    "doc_id": "doc_12",
    "original_uuid": "ea58fee353c3cce2856ea3e5cba5cad31eb25bef27af6a2828000a99cca9d947",
    "content": "from typing import Dict, Optional\n\nimport logging\nfrom rich.logging import RichHandler\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, U, registry\n\n\n@registry.register\nclass Octal(Decoder[str]):\n    def decode(self, ctext: T) -> Optional[U]:\n        \"\"\"\n        Performs Octal decoding\n        \"\"\"\n        str_converted = []\n        octal_seq = ctext.split(\" \")\n        if len(octal_seq) == 1:\n            # Concatted octal must be formed of octal triplets\n            if len(ctext) % 3 != 0:\n                return None\n            octal_seq = [ctext[i : i + 3] for i in range(0, len(ctext), 3)]\n            logging.debug(f\"Trying chunked octal {octal_seq}\")\n        try:\n            for octal_char in octal_seq:\n                if len(octal_char) > 3:\n                    logging.debug(\"Octal subseq too long\")\n                    return None\n                n = int(octal_char, 8)\n                if (\n                    n < 0\n                ):  # n cannot be greater than 255, as we checked that with the earlier length check\n                    logging.debug(f\"Non octal char {octal_char}\")\n                    return None\n                str_converted.append(n)\n\n            return bytes(str_converted)\n        # Catch bad octal chars\n        except ValueError:\n            return None\n\n    @staticmethod\n    def priority() -> float:\n        return 0.025\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return None\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"octal\"\n",
    "chunks": [
      {
        "chunk_id": "doc_12_chunk_0",
        "original_index": 0,
        "content": "from typing import Dict, Optional\n\nimport logging\nfrom rich.logging import RichHandler\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, U, registry\n\n\n@registry.register\nclass Octal(Decoder[str]):\n    def decode(self, ctext: T) -> Optional[U]:\n        \"\"\"\n        Performs Octal decoding\n        \"\"\"\n        str_converted = []\n        octal_seq = ctext.split(\" \")\n        if len(octal_seq) == 1:\n            # Concatted octal must be formed of octal triplets\n            if len(ctext) % 3 != 0:\n                return None\n            octal_seq = [ctext[i : i + 3] for i in range(0, len(ctext), 3)]\n            logging.debug(f\"Trying chunked octal {octal_seq}\")\n        try:\n            for octal_char in octal_seq:\n                if len(octal_char) > 3:\n                    logging.debug(\"Octal subseq too long\")\n"
      },
      {
        "chunk_id": "doc_12_chunk_1",
        "original_index": 1,
        "content": "                    return None\n                n = int(octal_char, 8)\n                if (\n                    n < 0\n                ):  # n cannot be greater than 255, as we checked that with the earlier length check\n                    logging.debug(f\"Non octal char {octal_char}\")\n                    return None\n                str_converted.append(n)\n\n            return bytes(str_converted)\n        # Catch bad octal chars\n        except ValueError:\n            return None\n\n    @staticmethod\n    def priority() -> float:\n        return 0.025\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return None\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"octal\"\n"
      }
    ]
  },
  {
    "doc_id": "doc_13",
    "original_uuid": "3990e75dcaf5a10f72ca64cdf4ac7c3cbeb3e0e9c643269d774222d0b105bb7b",
    "content": "import re\nfrom typing import Dict, Optional\n\nimport logging\nfrom rich.logging import RichHandler\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, U, registry\n\n\n@registry.register\nclass A1z26(Decoder[str]):\n    def decode(self, ctext: T) -> Optional[U]:\n        \"\"\"\n        Performs A1Z26 decoding\n        \"\"\"\n        logging.debug(\"Attempting A1Z26\")\n        ctext_converted = []\n        ctext_split = re.split(r\"[ ,;:\\-\\n]\", ctext)\n        delimiters = set(sorted(re.sub(r\"[^ ,;:\\-\\n]\", \"\", ctext)))\n        ctext_num = re.sub(r\"[,;:\\-\\s]\", \"\", ctext)\n        ctext_decoded = \"\"\n        if ctext_num.isnumeric() is False:\n            logging.debug(\"Failed to decode A1Z26 due to non numeric character(s)\")\n            return None\n        try:\n            for i in ctext_split:\n                val = int(i)\n                if val > 26 or val < 1:\n                    logging.debug(\n                        f\"Failed to decode A1Z26 due to invalid number '{val}'\"\n                    )\n                    return None\n                val2 = int(i) + 96\n                ctext_converted.append(chr(val2))\n            ctext_decoded = \"\".join(ctext_converted)\n            logging.info(\n                f\"A1Z26 successful, returning '{ctext_decoded}' with delimiter(s) {delimiters}\"\n            )\n            return ctext_decoded\n        except Exception:\n            return None\n\n    @staticmethod\n    def priority() -> float:\n        return 0.05\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return None\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"a1z26\"\n",
    "chunks": [
      {
        "chunk_id": "doc_13_chunk_0",
        "original_index": 0,
        "content": "import re\nfrom typing import Dict, Optional\n\nimport logging\nfrom rich.logging import RichHandler\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, U, registry\n\n\n@registry.register\nclass A1z26(Decoder[str]):\n    def decode(self, ctext: T) -> Optional[U]:\n        \"\"\"\n        Performs A1Z26 decoding\n        \"\"\"\n        logging.debug(\"Attempting A1Z26\")\n        ctext_converted = []\n        ctext_split = re.split(r\"[ ,;:\\-\\n]\", ctext)\n        delimiters = set(sorted(re.sub(r\"[^ ,;:\\-\\n]\", \"\", ctext)))\n        ctext_num = re.sub(r\"[,;:\\-\\s]\", \"\", ctext)\n        ctext_decoded = \"\"\n        if ctext_num.isnumeric() is False:\n            logging.debug(\"Failed to decode A1Z26 due to non numeric character(s)\")\n            return None\n        try:\n            for i in ctext_split:\n                val = int(i)\n                if val > 26 or val < 1:\n                    logging.debug(\n"
      },
      {
        "chunk_id": "doc_13_chunk_1",
        "original_index": 1,
        "content": "                        f\"Failed to decode A1Z26 due to invalid number '{val}'\"\n                    )\n                    return None\n                val2 = int(i) + 96\n                ctext_converted.append(chr(val2))\n            ctext_decoded = \"\".join(ctext_converted)\n            logging.info(\n                f\"A1Z26 successful, returning '{ctext_decoded}' with delimiter(s) {delimiters}\"\n            )\n            return ctext_decoded\n        except Exception:\n            return None\n\n    @staticmethod\n    def priority() -> float:\n        return 0.05\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return None\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"a1z26\"\n"
      }
    ]
  },
  {
    "doc_id": "doc_14",
    "original_uuid": "b9849c2091e8c45fe2589066b6c8ac5d95127a61895c7482b37250e853ab8aad",
    "content": "from typing import Dict, Optional\n\nimport base58\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, U, registry\n\n\n@registry.register\nclass Base58_ripple(Decoder[str]):\n    def decode(self, ctext: T) -> Optional[U]:\n        \"\"\"\n        Performs Base58 (Ripple) decoding\n        \"\"\"\n        try:\n            return base58.b58decode(ctext, alphabet=base58.RIPPLE_ALPHABET).decode(\n                \"utf-8\"\n            )\n        except Exception:\n            return None\n\n    @staticmethod\n    def priority() -> float:\n        # Not expected to show up often, but also very fast to check.\n        return 0.05\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return None\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"base58_ripple\"\n",
    "chunks": [
      {
        "chunk_id": "doc_14_chunk_0",
        "original_index": 0,
        "content": "from typing import Dict, Optional\n\nimport base58\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, U, registry\n\n\n@registry.register\nclass Base58_ripple(Decoder[str]):\n    def decode(self, ctext: T) -> Optional[U]:\n        \"\"\"\n        Performs Base58 (Ripple) decoding\n        \"\"\"\n        try:\n            return base58.b58decode(ctext, alphabet=base58.RIPPLE_ALPHABET).decode(\n                \"utf-8\"\n            )\n        except Exception:\n            return None\n\n    @staticmethod\n    def priority() -> float:\n        # Not expected to show up often, but also very fast to check.\n        return 0.05\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return None\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"base58_ripple\"\n"
      }
    ]
  },
  {
    "doc_id": "doc_15",
    "original_uuid": "d4bc89992e119e8c40738b830e03e9586e1cb958d4e30c96f935e7385841364f",
    "content": "from typing import Dict, Optional\n\nimport logging\nfrom rich.logging import RichHandler\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, Translation, U, registry\n\n\n@registry.register\nclass Morse_code(Decoder[str]):\n    # A priority list for char/word boundaries\n    BOUNDARIES = {\" \": 1, \"/\": 2, \"\\n\": 3}\n    PURGE = {ord(c): None for c in BOUNDARIES.keys()}\n    MAX_PRIORITY = 3\n    ALLOWED = {\".\", \"-\", \" \", \"/\", \"\\n\"}\n    MORSE_CODE_DICT: Dict[str, str]\n    MORSE_CODE_DICT_INV: Dict[str, str]\n\n    def decode(self, ctext: T) -> Optional[U]:\n        logging.debug(\"Attempting Morse code decoder\")\n\n        char_boundary = word_boundary = None\n\n        char_boundary = word_boundary = None\n        char_priority = word_priority = 0\n        # Custom loop allows early break\n        for i in ctext:\n            i_priority = self.BOUNDARIES.get(i)\n            if i_priority is None:\n                if i in self.ALLOWED:\n                    continue\n                logging.debug(f\"Non-morse char '{i}' found\")\n                return None\n\n            if i_priority <= char_priority or i == char_boundary or i == word_boundary:\n                continue\n            # Default to having a char boundary over a word boundary\n            if (\n                i_priority > word_priority\n                and word_boundary is None\n                and char_boundary is not None\n            ):\n                word_priority = i_priority\n                word_boundary = i\n                continue\n            char_priority = i_priority\n            char_boundary = i\n\n        logging.debug(\n            f\"Char boundary is unicode {ord(char_boundary)}, and word boundary is unicode {ord(word_boundary) if word_boundary is not None else None}\"\n        )\n\n        result = \"\"\n\n        for word in ctext.split(word_boundary) if word_boundary else [ctext]:\n            logging.debug(f\"Attempting to decode word {word}\")\n            for char in word.split(char_boundary):\n                char = char.translate(self.PURGE)\n                if len(char) == 0:\n                    continue\n                try:\n                    m = self.MORSE_CODE_DICT_INV[char]\n                except KeyError:\n                    logging.debug(f\"Invalid codeword '{char}' found\")\n                    return None\n                result = result + m\n            # after every word add a space\n            result = result + \" \"\n        if len(result) == 0:\n            logging.debug(\"Morse code failed to match\")\n            return None\n        # Remove trailing space\n        result = result[:-1]\n        logging.info(f\"Morse code successful, returning {result}\")\n        return result.strip().upper()\n\n    @staticmethod\n    def priority() -> float:\n        return 0.05\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n        self.MORSE_CODE_DICT = config.get_resource(self._params()[\"dict\"], Translation)\n        self.MORSE_CODE_DICT_INV = {v: k for k, v in self.MORSE_CODE_DICT.items()}\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return {\n            \"dict\": ParamSpec(\n                desc=\"The morse code dictionary to use\",\n                req=False,\n                default=\"cipheydists::translate::morse\",\n            )\n        }\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"morse_code\"\n",
    "chunks": [
      {
        "chunk_id": "doc_15_chunk_0",
        "original_index": 0,
        "content": "from typing import Dict, Optional\n\nimport logging\nfrom rich.logging import RichHandler\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, Translation, U, registry\n\n\n@registry.register\nclass Morse_code(Decoder[str]):\n    # A priority list for char/word boundaries\n    BOUNDARIES = {\" \": 1, \"/\": 2, \"\\n\": 3}\n    PURGE = {ord(c): None for c in BOUNDARIES.keys()}\n    MAX_PRIORITY = 3\n    ALLOWED = {\".\", \"-\", \" \", \"/\", \"\\n\"}\n    MORSE_CODE_DICT: Dict[str, str]\n    MORSE_CODE_DICT_INV: Dict[str, str]\n\n    def decode(self, ctext: T) -> Optional[U]:\n        logging.debug(\"Attempting Morse code decoder\")\n\n        char_boundary = word_boundary = None\n\n"
      },
      {
        "chunk_id": "doc_15_chunk_1",
        "original_index": 1,
        "content": "        char_boundary = word_boundary = None\n        char_priority = word_priority = 0\n        # Custom loop allows early break\n        for i in ctext:\n            i_priority = self.BOUNDARIES.get(i)\n            if i_priority is None:\n                if i in self.ALLOWED:\n                    continue\n                logging.debug(f\"Non-morse char '{i}' found\")\n                return None\n\n"
      },
      {
        "chunk_id": "doc_15_chunk_2",
        "original_index": 2,
        "content": "            if i_priority <= char_priority or i == char_boundary or i == word_boundary:\n                continue\n            # Default to having a char boundary over a word boundary\n            if (\n                i_priority > word_priority\n                and word_boundary is None\n                and char_boundary is not None\n            ):\n                word_priority = i_priority\n                word_boundary = i\n                continue\n            char_priority = i_priority\n            char_boundary = i\n\n        logging.debug(\n            f\"Char boundary is unicode {ord(char_boundary)}, and word boundary is unicode {ord(word_boundary) if word_boundary is not None else None}\"\n        )\n\n        result = \"\"\n\n"
      },
      {
        "chunk_id": "doc_15_chunk_3",
        "original_index": 3,
        "content": "        for word in ctext.split(word_boundary) if word_boundary else [ctext]:\n            logging.debug(f\"Attempting to decode word {word}\")\n            for char in word.split(char_boundary):\n                char = char.translate(self.PURGE)\n                if len(char) == 0:\n                    continue\n                try:\n                    m = self.MORSE_CODE_DICT_INV[char]\n                except KeyError:\n                    logging.debug(f\"Invalid codeword '{char}' found\")\n                    return None\n                result = result + m\n            # after every word add a space\n            result = result + \" \"\n        if len(result) == 0:\n            logging.debug(\"Morse code failed to match\")\n            return None\n        # Remove trailing space\n        result = result[:-1]\n        logging.info(f\"Morse code successful, returning {result}\")\n        return result.strip().upper()\n\n"
      },
      {
        "chunk_id": "doc_15_chunk_4",
        "original_index": 4,
        "content": "    @staticmethod\n    def priority() -> float:\n        return 0.05\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n        self.MORSE_CODE_DICT = config.get_resource(self._params()[\"dict\"], Translation)\n        self.MORSE_CODE_DICT_INV = {v: k for k, v in self.MORSE_CODE_DICT.items()}\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return {\n            \"dict\": ParamSpec(\n                desc=\"The morse code dictionary to use\",\n                req=False,\n                default=\"cipheydists::translate::morse\",\n            )\n        }\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"morse_code\"\n"
      }
    ]
  },
  {
    "doc_id": "doc_16",
    "original_uuid": "fd3a6d5d6a5a1ab1afaae8810c2d2141ea1707b7eb7bfd5b883947d078519c31",
    "content": "import re\nfrom typing import Dict, List, Optional\n\nimport logging\nfrom rich.logging import RichHandler\n\nfrom ciphey.iface import (\n    Config,\n    Cracker,\n    CrackInfo,\n    CrackResult,\n    ParamSpec,\n    Translation,\n    registry,\n)\n\n\n@registry.register\nclass Soundex(Cracker[str]):\n    def getInfo(self, ctext: str) -> CrackInfo:\n        return CrackInfo(\n            success_likelihood=0.1,\n            success_runtime=1e-5,\n            failure_runtime=1e-5,\n        )\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"soundex\"\n\n    def attemptCrack(self, ctext: str) -> List[CrackResult]:\n        \"\"\"\n        Attempts to crack Soundex by generating all possible combinations.\n        \"\"\"\n        logging.debug(\"Attempting Soundex cracker\")\n        word_list = []\n        sentences = []\n        result = []\n\n        # Convert to uppercase and replace delimiters and whitespace with nothing\n        ctext = re.sub(r\"[,;:\\-\\s]\", \"\", ctext.upper())\n\n        # Make sure ctext contains only A-Z and 0-9\n        if bool(re.search(r\"[^A-Z0-9]\", ctext)) is True:\n            logging.debug(\"Failed to crack soundex due to non soundex character(s)\")\n            return None\n\n        # Make sure ctext is divisible by 4\n        ctext_len = len(ctext)\n        if ctext_len % 4:\n            logging.debug(\n                f\"Failed to decode Soundex because length must be a multiple of 4, not '{ctext_len}'\"\n            )\n            return None\n\n        # Split ctext into groups of 4\n        ctext = \" \".join(ctext[i : i + 4] for i in range(0, len(ctext), 4))\n        ctext_split = ctext.split(\" \")\n        soundex_keys = self.SOUNDEX_DICT.keys()\n\n        # Find all words that correspond to each given soundex code\n        for code in ctext_split:\n            if code in soundex_keys:\n                word_list.append(self.SOUNDEX_DICT[code])\n\n        logging.info(f\"Possible words for given encoded text: {word_list}\")\n\n        # Find all possible sentences\n        self.getSentenceCombo(\n            word_list,\n            sentences,\n            self.frequency_dict,\n            self.sentence_freq,\n            self.word_freq,\n        )\n\n        sorted_sentences = self.sortlistwithdict(sentences, self.frequency_dict)\n\n        for sentence in sorted_sentences:\n            result.append(CrackResult(value=sentence))\n\n        logging.debug(f\"Soundex cracker - Returning results: {result}\")\n        return result\n\n    def sortlistwithdict(self, listtosort, hashes):\n        \"\"\"\n        This function uses the sum of ranks (based on frequency) of each word in each\n        sentence and sorts them according to it.\n        \"\"\"\n        return sorted(listtosort, key=lambda x: hashes[x])\n\n    def getSentenceCombo(\n        self, A, sentences, frequency_dict, sentence_freq, word_freq, result=\"\", n=0\n    ):\n        \"\"\"\n        This function uses recursion to generate a list of sentences from all possible\n        words for a given set of soundex codes.\n        \"\"\"\n        logging.debug(\"Creating all possible sentences from Soundex\")\n        if n == len(A):\n            sentences.append(result[1:])\n            for word in result[1:].split():\n                # Adding the rank of each word to find out the sentence's net frequency\n                if word in word_freq:\n                    sentence_freq += word_freq.index(word)\n                # If the word isn't in the frequency list then it's a very uncommon word\n                # so we add a large number (5000)\n                else:\n                    sentence_freq += 5000\n            frequency_dict[result[1:]] = sentence_freq\n            sentence_freq = 0\n            return\n\n        for word in A[n]:\n            out = result + \" \" + word\n            self.getSentenceCombo(\n                A, sentences, frequency_dict, sentence_freq, word_freq, out, n + 1\n            )\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return {\n            \"dict\": ParamSpec(\n                desc=\"The Soundex dictionary to use\",\n                req=False,\n                default=\"cipheydists::translate::soundex\",\n            ),\n            \"freq\": ParamSpec(\n                desc=\"The word frequency dictionary to use\",\n                req=False,\n                default=\"cipheydists::list::English5000Freq\",\n            ),\n        }\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n        self.SOUNDEX_DICT = config.get_resource(self._params()[\"dict\"], Translation)\n        self.word_freq = config.get_resource(self._params()[\"freq\"], Translation)\n        self.frequency_dict = {}\n        self.sentence_freq = 0\n",
    "chunks": [
      {
        "chunk_id": "doc_16_chunk_0",
        "original_index": 0,
        "content": "import re\nfrom typing import Dict, List, Optional\n\nimport logging\nfrom rich.logging import RichHandler\n\nfrom ciphey.iface import (\n    Config,\n    Cracker,\n    CrackInfo,\n    CrackResult,\n    ParamSpec,\n    Translation,\n    registry,\n)\n\n\n@registry.register\nclass Soundex(Cracker[str]):\n    def getInfo(self, ctext: str) -> CrackInfo:\n        return CrackInfo(\n            success_likelihood=0.1,\n            success_runtime=1e-5,\n            failure_runtime=1e-5,\n        )\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"soundex\"\n\n"
      },
      {
        "chunk_id": "doc_16_chunk_1",
        "original_index": 1,
        "content": "    def attemptCrack(self, ctext: str) -> List[CrackResult]:\n        \"\"\"\n        Attempts to crack Soundex by generating all possible combinations.\n        \"\"\"\n        logging.debug(\"Attempting Soundex cracker\")\n        word_list = []\n        sentences = []\n        result = []\n\n        # Convert to uppercase and replace delimiters and whitespace with nothing\n        ctext = re.sub(r\"[,;:\\-\\s]\", \"\", ctext.upper())\n\n        # Make sure ctext contains only A-Z and 0-9\n        if bool(re.search(r\"[^A-Z0-9]\", ctext)) is True:\n            logging.debug(\"Failed to crack soundex due to non soundex character(s)\")\n            return None\n\n"
      },
      {
        "chunk_id": "doc_16_chunk_2",
        "original_index": 2,
        "content": "        # Make sure ctext is divisible by 4\n        ctext_len = len(ctext)\n        if ctext_len % 4:\n            logging.debug(\n                f\"Failed to decode Soundex because length must be a multiple of 4, not '{ctext_len}'\"\n            )\n            return None\n\n        # Split ctext into groups of 4\n        ctext = \" \".join(ctext[i : i + 4] for i in range(0, len(ctext), 4))\n        ctext_split = ctext.split(\" \")\n        soundex_keys = self.SOUNDEX_DICT.keys()\n\n        # Find all words that correspond to each given soundex code\n        for code in ctext_split:\n            if code in soundex_keys:\n                word_list.append(self.SOUNDEX_DICT[code])\n\n        logging.info(f\"Possible words for given encoded text: {word_list}\")\n\n        # Find all possible sentences\n        self.getSentenceCombo(\n            word_list,\n            sentences,\n            self.frequency_dict,\n            self.sentence_freq,\n            self.word_freq,\n        )\n\n"
      },
      {
        "chunk_id": "doc_16_chunk_3",
        "original_index": 3,
        "content": "        sorted_sentences = self.sortlistwithdict(sentences, self.frequency_dict)\n\n        for sentence in sorted_sentences:\n            result.append(CrackResult(value=sentence))\n\n        logging.debug(f\"Soundex cracker - Returning results: {result}\")\n        return result\n\n    def sortlistwithdict(self, listtosort, hashes):\n        \"\"\"\n        This function uses the sum of ranks (based on frequency) of each word in each\n        sentence and sorts them according to it.\n        \"\"\"\n        return sorted(listtosort, key=lambda x: hashes[x])\n\n"
      },
      {
        "chunk_id": "doc_16_chunk_4",
        "original_index": 4,
        "content": "    def getSentenceCombo(\n        self, A, sentences, frequency_dict, sentence_freq, word_freq, result=\"\", n=0\n    ):\n        \"\"\"\n        This function uses recursion to generate a list of sentences from all possible\n        words for a given set of soundex codes.\n        \"\"\"\n        logging.debug(\"Creating all possible sentences from Soundex\")\n        if n == len(A):\n            sentences.append(result[1:])\n            for word in result[1:].split():\n                # Adding the rank of each word to find out the sentence's net frequency\n                if word in word_freq:\n                    sentence_freq += word_freq.index(word)\n                # If the word isn't in the frequency list then it's a very uncommon word\n                # so we add a large number (5000)\n                else:\n                    sentence_freq += 5000\n            frequency_dict[result[1:]] = sentence_freq\n            sentence_freq = 0\n            return\n\n"
      },
      {
        "chunk_id": "doc_16_chunk_5",
        "original_index": 5,
        "content": "        for word in A[n]:\n            out = result + \" \" + word\n            self.getSentenceCombo(\n                A, sentences, frequency_dict, sentence_freq, word_freq, out, n + 1\n            )\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return {\n            \"dict\": ParamSpec(\n                desc=\"The Soundex dictionary to use\",\n                req=False,\n                default=\"cipheydists::translate::soundex\",\n            ),\n            \"freq\": ParamSpec(\n                desc=\"The word frequency dictionary to use\",\n                req=False,\n                default=\"cipheydists::list::English5000Freq\",\n            ),\n        }\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n        self.SOUNDEX_DICT = config.get_resource(self._params()[\"dict\"], Translation)\n        self.word_freq = config.get_resource(self._params()[\"freq\"], Translation)\n        self.frequency_dict = {}\n        self.sentence_freq = 0\n"
      }
    ]
  },
  {
    "doc_id": "doc_17",
    "original_uuid": "44f12a4ef079daf871dc6a95ed7af4ff2ec55b48ca3b004dfc954bf4c9b05ba3",
    "content": "# by https://github.com/RustyDucky and https://github.com/lukasgabriel\n\nfrom typing import Dict, Optional\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, Translation, U, registry\n\n\n@registry.register\nclass Tap_code(Decoder[str]):\n    def decode(self, ctext: T) -> Optional[U]:\n        \"\"\"\n        Performs Tap code decoding\n        \"\"\"\n        try:\n            result = \"\"\n            combinations = ctext.split(\" \")\n            for fragment in combinations:\n                result += self.TABLE.get(fragment)\n            return result\n        except Exception:\n            return None\n\n    @staticmethod\n    def priority() -> float:\n        return 0.06\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n        self.TABLE = config.get_resource(self._params()[\"dict\"], Translation)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return {\n            \"dict\": ParamSpec(\n                desc=\"The table of letters used for the tap code interpretation.\",\n                req=False,\n                default=\"cipheydists::translate::tap_code\",\n            )\n        }\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"tap_code\"\n",
    "chunks": [
      {
        "chunk_id": "doc_17_chunk_0",
        "original_index": 0,
        "content": "# by https://github.com/RustyDucky and https://github.com/lukasgabriel\n\nfrom typing import Dict, Optional\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, Translation, U, registry\n\n\n@registry.register\nclass Tap_code(Decoder[str]):\n    def decode(self, ctext: T) -> Optional[U]:\n        \"\"\"\n        Performs Tap code decoding\n        \"\"\"\n        try:\n            result = \"\"\n            combinations = ctext.split(\" \")\n            for fragment in combinations:\n                result += self.TABLE.get(fragment)\n            return result\n        except Exception:\n            return None\n\n"
      },
      {
        "chunk_id": "doc_17_chunk_1",
        "original_index": 1,
        "content": "    @staticmethod\n    def priority() -> float:\n        return 0.06\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n        self.TABLE = config.get_resource(self._params()[\"dict\"], Translation)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return {\n            \"dict\": ParamSpec(\n                desc=\"The table of letters used for the tap code interpretation.\",\n                req=False,\n                default=\"cipheydists::translate::tap_code\",\n            )\n        }\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"tap_code\"\n"
      }
    ]
  },
  {
    "doc_id": "doc_18",
    "original_uuid": "bfc6250497ea53318a31782941f86e13660430636fa5ac61fbda86e2ffb94ea2",
    "content": "from functools import lru_cache\nfrom typing import Any, Dict, Optional, Set\n\nimport cipheydists\nimport logging\n\nfrom ciphey.iface import (\n    Config,\n    Distribution,\n    ParamSpec,\n    ResourceLoader,\n    Translation,\n    WordList,\n    registry,\n)\n\n\n@registry.register_multi(WordList, Distribution, Translation)\nclass CipheyDists(ResourceLoader):\n    # _wordlists: Set[str] = frozenset({\"english\", \"english1000\", \"englishStopWords\"})\n    # _brandons: Set[str] = frozenset({\"english\"})\n    # _dists: Set[str] = frozenset({\"twist\"})\n    # _translates: Set[str] = frozenset({\"morse\"})\n    _getters = {\n        \"list\": cipheydists.get_list,\n        \"dist\": cipheydists.get_dist,\n        \"brandon\": cipheydists.get_brandon,\n        \"translate\": cipheydists.get_translate,\n    }\n\n    def whatResources(self) -> Optional[Set[str]]:\n        pass\n\n    @lru_cache()\n    def getResource(self, name: str) -> Any:\n        logging.debug(f\"Loading cipheydists resource {name}\")\n        prefix, name = name.split(\"::\", 1)\n        return self._getters[prefix](name)\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return None\n",
    "chunks": [
      {
        "chunk_id": "doc_18_chunk_0",
        "original_index": 0,
        "content": "from functools import lru_cache\nfrom typing import Any, Dict, Optional, Set\n\nimport cipheydists\nimport logging\n\nfrom ciphey.iface import (\n    Config,\n    Distribution,\n    ParamSpec,\n    ResourceLoader,\n    Translation,\n    WordList,\n    registry,\n)\n\n\n@registry.register_multi(WordList, Distribution, Translation)\nclass CipheyDists(ResourceLoader):\n    # _wordlists: Set[str] = frozenset({\"english\", \"english1000\", \"englishStopWords\"})\n    # _brandons: Set[str] = frozenset({\"english\"})\n    # _dists: Set[str] = frozenset({\"twist\"})\n    # _translates: Set[str] = frozenset({\"morse\"})\n    _getters = {\n        \"list\": cipheydists.get_list,\n        \"dist\": cipheydists.get_dist,\n        \"brandon\": cipheydists.get_brandon,\n        \"translate\": cipheydists.get_translate,\n    }\n\n"
      },
      {
        "chunk_id": "doc_18_chunk_1",
        "original_index": 1,
        "content": "    def whatResources(self) -> Optional[Set[str]]:\n        pass\n\n    @lru_cache()\n    def getResource(self, name: str) -> Any:\n        logging.debug(f\"Loading cipheydists resource {name}\")\n        prefix, name = name.split(\"::\", 1)\n        return self._getters[prefix](name)\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return None\n"
      }
    ]
  },
  {
    "doc_id": "doc_19",
    "original_uuid": "2da927c1c66089a8d0af2c7edd199977cc56933b1ba803439d7f2f7f7592f3a3",
    "content": "# Translated to Python and adapted for Ciphey from the JS original at https://github.com/pshihn/base69\n\n\nimport re\nfrom math import ceil\nfrom typing import Dict, Optional\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, U, WordList, registry\n\n\n@registry.register\nclass Base69(Decoder[str]):\n    def decode(self, ctext: T) -> Optional[U]:\n        \"\"\"\n        Performs Base69 decoding\n        \"\"\"\n        # Remove whitespace\n        try:\n            ctext = re.sub(r\"\\s+\", \"\", ctext, flags=re.UNICODE)\n            extra_bytes = 0\n            clen = len(ctext)\n\n            if ctext[:-1] == \"=\":\n                extra_bytes = int(ctext[clen - 2])\n\n            CHUNK_COUNT = ceil(clen / 16)\n            result = [0 for _ in range(CHUNK_COUNT * 7 - extra_bytes)]\n\n            for i in range(CHUNK_COUNT):\n                chunk_string = ctext[i * 16 : (i + 1) * 16]\n                if extra_bytes and (i == CHUNK_COUNT - 1):\n                    insert = self.decode_chunk(chunk_string)\n                    for n, elem in enumerate(insert[0 : 7 - extra_bytes]):\n                        result[n + i * 7] = elem\n                else:\n                    insert = self.decode_chunk(chunk_string)\n                    for n, elem in enumerate(insert):\n                        result[n + i * 7] = elem % 256\n            return bytearray(result).decode().strip(\"\\x00\")\n        except Exception:\n            return None\n\n    def decode_chunk(self, s: str):\n        padded_bytes = s.endswith(\"=\")\n\n        decoded = [0 for _ in range(8)]\n        for i in range(8):\n            decoded[i] = (\n                0\n                if i == 7 and padded_bytes\n                else self.chars_to_byte(s[i * 2 : i * 2 + 2])\n            )\n\n        result = [0 for _ in range(7)]\n        for i in range(7):\n            t1 = decoded[i] << (i + 1)\n            t2 = decoded[i + 1] >> (7 - i - 1)\n            result[i] = t1 | t2\n        return result\n\n    def chars_to_byte(self, s: str):\n        return (69 * self.CHARS.index(s[1])) + (self.CHARS.index(s[0]))\n\n    @staticmethod\n    def priority() -> float:\n        # If this becomes lower or equal to the reverse, it breaks.\n        # So I'll set it to 0.2 for now since it is very fast anyways.\n        return 0.2\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n        self.CHARS = config.get_resource(self._params()[\"dict\"], WordList)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return {\n            \"dict\": ParamSpec(\n                desc=\"The charset used for the decoder.\",\n                req=False,\n                default=\"cipheydists::list::base69\",\n            )\n        }\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"base69\"\n",
    "chunks": [
      {
        "chunk_id": "doc_19_chunk_0",
        "original_index": 0,
        "content": "# Translated to Python and adapted for Ciphey from the JS original at https://github.com/pshihn/base69\n\n\nimport re\nfrom math import ceil\nfrom typing import Dict, Optional\n\nfrom ciphey.iface import Config, Decoder, ParamSpec, T, U, WordList, registry\n\n\n@registry.register\nclass Base69(Decoder[str]):\n    def decode(self, ctext: T) -> Optional[U]:\n        \"\"\"\n        Performs Base69 decoding\n        \"\"\"\n        # Remove whitespace\n        try:\n            ctext = re.sub(r\"\\s+\", \"\", ctext, flags=re.UNICODE)\n            extra_bytes = 0\n            clen = len(ctext)\n\n            if ctext[:-1] == \"=\":\n                extra_bytes = int(ctext[clen - 2])\n\n            CHUNK_COUNT = ceil(clen / 16)\n            result = [0 for _ in range(CHUNK_COUNT * 7 - extra_bytes)]\n\n"
      },
      {
        "chunk_id": "doc_19_chunk_1",
        "original_index": 1,
        "content": "            for i in range(CHUNK_COUNT):\n                chunk_string = ctext[i * 16 : (i + 1) * 16]\n                if extra_bytes and (i == CHUNK_COUNT - 1):\n                    insert = self.decode_chunk(chunk_string)\n                    for n, elem in enumerate(insert[0 : 7 - extra_bytes]):\n                        result[n + i * 7] = elem\n                else:\n                    insert = self.decode_chunk(chunk_string)\n                    for n, elem in enumerate(insert):\n                        result[n + i * 7] = elem % 256\n            return bytearray(result).decode().strip(\"\\x00\")\n        except Exception:\n            return None\n\n"
      },
      {
        "chunk_id": "doc_19_chunk_2",
        "original_index": 2,
        "content": "    def decode_chunk(self, s: str):\n        padded_bytes = s.endswith(\"=\")\n\n        decoded = [0 for _ in range(8)]\n        for i in range(8):\n            decoded[i] = (\n                0\n                if i == 7 and padded_bytes\n                else self.chars_to_byte(s[i * 2 : i * 2 + 2])\n            )\n\n        result = [0 for _ in range(7)]\n        for i in range(7):\n            t1 = decoded[i] << (i + 1)\n            t2 = decoded[i + 1] >> (7 - i - 1)\n            result[i] = t1 | t2\n        return result\n\n"
      },
      {
        "chunk_id": "doc_19_chunk_3",
        "original_index": 3,
        "content": "    def chars_to_byte(self, s: str):\n        return (69 * self.CHARS.index(s[1])) + (self.CHARS.index(s[0]))\n\n    @staticmethod\n    def priority() -> float:\n        # If this becomes lower or equal to the reverse, it breaks.\n        # So I'll set it to 0.2 for now since it is very fast anyways.\n        return 0.2\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n        self.CHARS = config.get_resource(self._params()[\"dict\"], WordList)\n\n    @staticmethod\n    def getParams() -> Optional[Dict[str, ParamSpec]]:\n        return {\n            \"dict\": ParamSpec(\n                desc=\"The charset used for the decoder.\",\n                req=False,\n                default=\"cipheydists::list::base69\",\n            )\n        }\n\n    @staticmethod\n    def getTarget() -> str:\n        return \"base69\"\n"
      }
    ]
  },
  {
    "doc_id": "doc_20",
    "original_uuid": "1cb2aa7099194a80d66547995e291634a603cb89864add10e5fa54c0a6656c74",
    "content": "import pytest\n\nfrom ciphey import decrypt\nfrom ciphey.iface import Config\n\nanswer_str = \"Hello my name is bee and I like dog and apple and tree\"\n\n\ndef test_a1z26():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"8 5 12 12 15 13 25 14 1 13 5 9 19 2 5 5 1 14 4 9 12 9 11 5 4 15 7 1 14 4 1 16 16 12 5 1 14 4 20 18 5 5\",\n    )\n    assert res == \"hellomynameisbeeandilikedogandappleandtree\"\n\n\ndef test_affine():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"Ihsst bf kxbh rd ghh xky R srjh ytz xky xccsh xky muhh\",\n    )\n    assert res == answer_str\n\n\ndef test_ascii_shift():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        '\"?FFIzGSzH;G?zCMz<??z;H>z#zFCE?z>IAz;H>z;JJF?z;H>zNL??',\n    )\n    assert res == answer_str\n\n\ndef test_atbash():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"Svool nb mznv rh yvv zmw R orpv wlt zmw zkkov zmw givv\",\n    )\n    assert res == answer_str\n\n\ndef test_baconian_complete_variant():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"AABBB AABAA ABABB ABABB ABBBA ABBAA BBAAA ABBAB AAAAA ABBAA AABAA ABAAA BAABA AAAAB AABAA AABAA AAAAA ABBAB AAABB ABAAA ABABB ABAAA ABABA AABAA AAABB ABBBA AABBA AAAAA ABBAB AAABB AAAAA ABBBB ABBBB ABABB AABAA AAAAA ABBAB AAABB BAABB BAAAB AABAA AABAA\",\n    )\n    assert res == \"HELLOMYNAMEISBEEANDILIKEDOGANDAPPLEANDTREE\"\n\n\ndef test_baconian_standard_variant():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"AABBB AABAA ABABA ABABA ABBAB ABABB BABBA ABBAA AAAAA ABABB AABAA ABAAA BAAAB AAAAB AABAA AABAA AAAAA ABBAA AAABB ABAAA ABABA ABAAA ABAAB AABAA AAABB ABBAB AABBA AAAAA ABBAA AAABB AAAAA ABBBA ABBBA ABABA AABAA AAAAA ABBAA AAABB BAABA BAAAA AABAA AABAA\",\n    )\n    assert res == \"HELLOMYNAMEISBEEANDILIKEDOGANDAPPLEANDTREE\"\n\n\ndef test_base32():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"JBSWY3DPEBWXSIDOMFWWKIDJOMQGEZLFEBQW4ZBAJEQGY2LLMUQGI33HEBQW4ZBAMFYHA3DFEBQW4ZBAORZGKZI=\",\n    )\n    assert res == answer_str\n\n\ndef test_base58_bitcoin():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"6qYhNwsP46Mn4gy6gyANfsMm2icAxGFA6gnFjVm9phYHeby7PZm3vthiXxSU77teQgTFGbHETn\",\n    )\n    assert res == answer_str\n\n\ndef test_base58_ripple():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"aqY64A1PhaM8hgyagyw4C1Mmp5cwxGEwag8EjVm9F6YHebyfPZmsvt65XxS7ffteQgTEGbHNT8\",\n    )\n    assert res == answer_str\n\n\ndef test_base62():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"2mQvnz9Yevvb7DRCuyDltsP31vJLToR5pjE9orWkzHMUsht2kbC96PLbZ1sdIocsGHENrzC2n\",\n    )\n    assert res == answer_str\n\n\ndef test_base64():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"SGVsbG8gbXkgbmFtZSBpcyBiZWUgYW5kIEkgbGlrZSBkb2cgYW5kIGFwcGxlIGFuZCB0cmVl\",\n    )\n\n    assert res == answer_str\n\n\ndef test_base69():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"kAZAtABBeB8A-AoB8ADBNAhBLA1AFBgA0AXBfBGATAVAFBgAwAWBHB<ACAkA-AnB0AVBnBNBDARAZBiBQAYAtAhBhABA<ArB4AbAMANBDAFAXBfBQAdAOAmArAUAAA2=\",\n    )\n    assert res == answer_str\n\n\ndef test_base85():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"87cURD]inB+DtV)AKY].+C\\\\nn+CT.u+A!\\\\lBkq9&A8c*'@;]Tu@;p1%AKYE!A0>u7ARt\",\n    )\n    assert res == answer_str\n\n\ndef test_base91():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \">OwJh>=/fV@$x88j9ZNKB*ge$yV%lE%ZKi,<d,TX2$0t,,cjPD@JY<UCHRWznuWoQPD\",\n    )\n    assert res == answer_str\n\n\ndef test_baudot():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"10100 00001 10010 10010 11000 00100 11100 10101 00100 01100 00011 11100 00001 00100 00110 00101 00100 11001 00001 00001 00100 00011 01100 01001 00100 00110 00100 10010 00110 01111 00001 00100 01001 11000 11010 00100 00011 01100 01001 00100 00011 10110 10110 10010 00001 00100 00011 01100 01001 00100 10000 01010 00001 00001\",\n    )\n    assert res == answer_str.upper()\n\n\ndef test_binary():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"01001000 01100101 01101100 01101100 01101111 00100000 01101101 01111001 00100000 01101110 01100001 01101101 01100101 00100000 01101001 01110011 00100000 01100010 01100101 01100101 00100000 01100001 01101110 01100100 00100000 01001001 00100000 01101100 01101001 01101011 01100101 00100000 01100100 01101111 01100111 00100000 01100001 01101110 01100100 00100000 01100001 01110000 01110000 01101100 01100101 00100000 01100001 01101110 01100100 00100000 01110100 01110010 01100101 01100101\",\n    )\n\n    assert res == answer_str\n\n\n@pytest.mark.skip(\n    \"Can't decode base64 + caesar https://github.com/Ciphey/Ciphey/issues/606\"\n)\ndef test_binary_base64_caesar():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"01010110 01011000 01001010 00110101 01100101 01010111 01001001 01100111 01100101 01101101 01110111 01100111 01011001 01010111 00110101 00110110 01100011 01101001 01000010 00110010 01011010 01101001 01000010 01110110 01100011 01101110 01001001 01100111 01100010 01101101 01000110 01111000 01001001 01000110 01011001 01100111 01100101 01011000 01011010 00110100 01100011 01101001 01000010 01111000 01011001 01101110 01010001 01100111 01100010 01101101 01000110 01111000 01001001 01000111 00110101 01101010 01011001 00110011 01101100 01111001 01001001 01000111 00110101 01101000 01100011 01010011 01000010 01101110 01011010 01011000 01001010 01111001 00001010\",\n    )\n\n    assert res == answer_str\n\n\ndef test_braille():\n    res = decrypt(\n        Config.library_default().complete_config(),\n        \"\u2813\u2811\u2807\u2807\u2815\u2800\u280d\u283d\u2800\u281d\u2801\u280d\u2811\u2800\u280a\u280e\u2800\u2803\u2811\u2811\u2800\u2801\u281d\u2819\u2800\u280a\u2800\u2807\u280a\u2805\u2811\u2800\u2819\u2815\u281b\u2800\u2801\u281d\u2819\u2800\u2801\u280f\u280f\u2807\u2811\u2800\u2801\u281d\u2819\u2800\u281e\u2817\u2811\u2811\",\n    )\n    assert res == answer_str.lower()\n\n\ndef test_brainfuck():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"+[+++++++>+<]>-.-[+>-----<]>++.+++++++..+++.+[+>++<]>.[++>+<]>---.--[+++>-<]>.-[+>++++<]>.[++>+<]>--.-[+++>++<]>-.+[-->---<]>.--------.[+++++>+<]>+.-[+++>--<]>-.++++++++++.---[+>++<]>.[+++>-<]>++.+++..[+++++>+<]>+.[+++>-<]>+.+[-->---<]>+.----------.-[+++>-<]>-.-[+++>+<]>--.-[+>----<]>.++[+++>--<]>.---.++.------.[+++++>+<]>+.+[+>---<]>+.+++++++++++.--------.-[+++>-<]>--.[+++>-<]>+.+[-->---<]>+.----------.-[+++>-<]>-.[+++>-<]>+.-[-->---<]>..----.-------.[+++++>+<]>+.[+++>-<]>+.+[-->---<]>+.----------.-[+++>-<]>-.[++>+<]>++++.--.-------------..\",\n    )\n    assert res == answer_str\n\n\ndef test_brandon():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"R hvv blf tzgsvi yvuliv nv...sfmtib...gviirurvw... Xofgxsrmt blfi yzyvh gl blfi yivzhg. Vnkvili Vnsbi srh nzixsvw srh ovtrlmh rmgl lfi ozmwh... Ozrw hrvtv gl vevib uligivhh uiln sviv gl gsv Yofv Nlfmgzrmh. Izyrw zmw izevmlfh, sv yrgvh zmw yrgvh zdzb. Nvm lu gsv Mligs, blf hgzmw zg gsv kivxrkrxv. Blfi prmth szev uzrovw blf, hl mld blf gfim gl gsv tlwh! Zmw bvg blf wl mlg kovzw? Blf wl mlg pmvvo gl wfhg blfi svzwh drgs zhs? Rmhgvzw blf dzro,  Dsb szev gsv tlwh ulihzpvm fh?  Dv nfhg ollp rmgl gsv girzoh dv uzrovw olmt ztl! Rm z grnv kzhhvw, lfi dliow rmgvigdrmvw drgs zmlgsvi gsilfts zm fksvzezo hxslozih xzoo gsv Xlmqfmxgrlm lu gsv Hksvivh... Gsv tlwh zooldvw fmslob ulixvh gl hork rmgl lfi wlnzrm. Gsv luuhkirmt lu gszg xzgzxobhn dzh gsv mvuvirlfh ulixv xzoovw nztrx... Bvg dv wrw mlg yzmrhs rg, rmhgvzw hgfwbrmt gsv erov zixzmv uli lfi kldvi zmw dvzogs! Zmw gsv nlmhgvih zg lfi wlli...gsv fmslob ivorxgh lu gsrh Xlmqfmxgrlm? ...gsv gilooh...gsv xlikhv vzgvih...gsv dvivdloevh? Wrw dv izrhv lfi hdliwh ztzrmhg gsvn? Li szev dv ozrw gsrh yfiwvm lm lgsvih? Lm hl-xzoovw drgxsvih? Hgizb xsrowivm gzftsg gsv dzbh lu ulfo hlixvib, gsvri ylwrvh nfgzgvw gsilfts yozhksvnlfh irgfzo. Hvmg gl urtsg nlmhgvih gslfts gsvb xlfow mlg wrhgrmtfrhs tllw uiln vero. Gsv uorxpvi lu sfnzmrgb olmt vcgrmtfrhsvw drgsrm gsvn. Bvh, gsvri mfnyvih szev wdrmwovw gsilfts gsv bvzih. Yfg z uvd hgroo ilzn lfi ozmwh, luuvirmt gsvri yollwb dlip uli xlrm. Gl gsrh wzb gsvb hsznv fh drgs gsvri evib vcrhgvmxv! Gsv Mligs yovvwh, uolttvw yb dzi. Gsv yzggovh ziv gsv tlwh' dsrk, xszhgrhvnvmg uli lfi hrmh! Zmw ovg fh mlg ulitvg gsv gviilih, gsv hxlfitvh uiln yvblmw lfi dliow! Gsv Drow Sfmg irwvh gsv hpb drgs vevib ufoo nllm! Gsv wzip izrwvih zywfxg lfi xsrowivm rmgl ozmwh fmpmldm! Hlnv hzb gsvb svizow z hvxlmw Xlmqfmxgrlm! Xzm dv xszig z xlfihv yzxp rmgl gsv ortsg? Droo dv urmw gsv hgivmtgs gl yzmrhs gsv nztvh uiln lfi prmtwlnh? Fmrgv zilfmw gsv dzings lu gsv Vgvimzo Uriv? Mrts rh gsv Grnv lu gsv Hdliw zmw gsv Zcv! Mlmv droo urtsg gsrh dzi rm lfi hgvzw! Mrts rh gsv Grnv lu Nzwmvhh zmw Wrhwzrm!\",\n    )\n    assert bool(res) is True\n\n\ndef test_caesar():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"Uryyb zl anzr vf orr naq V yvxr qbt naq nccyr naq gerr\",\n    )\n    assert res == answer_str\n\n\ndef test_decimal():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"72 101 108 108 111 32 109 121 32 110 97 109 101 32 105 115 32 98 101 101 32 97 110 100 32 73 32 108 105 107 101 32 100 111 103 32 97 110 100 32 97 112 112 108 101 32 97 110 100 32 116 114 101 101\",\n    )\n    assert res == answer_str\n\n\ndef test_dna():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"GAT AAT GCT ATT TCT ATT AAT ACT GAA CGT GAA TCT ACT ATT AAT GGT\",\n    )\n    assert res == \"DNAISINTERESTING\"\n\n\ndef test_dtmf():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1209-697 1336-941 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697\",\n    )\n    assert res == answer_str\n\n\ndef test_galactic():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"\u2351\u14b7\ua58e\ua58e\ud835\ude79 \u14b2|| \u30ea\u1511\u14b2\u14b7 \u254e\u14ed \u0296\u14b7\u14b7 \u1511\u30ea\u21b8 i \ua58e\u254e\ua58c\u14b7 \u21b8\ud835\ude79\u22a3 \u1511\u30ea\u21b8 \u1511!\u00a1!\u00a1\ua58e\u14b7 \u1511\u30ea\u21b8 \u2138 \u0323 \u2237\u14b7\u14b7\",\n    )\n    assert res == answer_str.lower()\n\n\ndef test_galactic_Xproblem():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"\u2351\u1511\ua58e\u254e\u2393\u1511 \u0307/,  \u0307/||\ua58e\ud835\ude79!\u00a1\u2351\ud835\ude79\u30ea\u14b7, \u1511  \u0307/ \u1511\ua58e\ud835\ude79\u30ea\u14b7 \u1511\u30ea\u21b8  \u0307/\u14b7\u2237\ud835\ude79 \u0307/ \u2393\u2237\ud835\ude79\u14b2 \ud835\ude79 \u0307/\u2393\ud835\ude79\u2237\u21b8\",\n    )\n    assert res == \"halifax, xylophone, a x alone and xerox from oxford\"\n\n\ndef test_gzip():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"H4sIAAzul18A/yXJzQmAMBSEwVa+ckwZT7LIw80P6sXuA3ocZpM9aC89msibXSJ6peA8RR3Hx5jTfzyXtAAbQvCyNgAAAA==\",\n    )\n    assert res == answer_str\n\n\ndef test_hexadecimal():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"48 65 6c 6c 6f 20 6d 79 20 6e 61 6d 65 20 69 73 20 62 65 65 20 61 6e 64 20 49 20 6c 69 6b 65 20 64 6f 67 20 61 6e 64 20 61 70 70 6c 65 20 61 6e 64 20 74 72 65 65\",\n    )\n\n    assert res == answer_str\n\n\ndef test_json_problem():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"0110100001100101011011000110110001101111\",\n    )\n    assert res != \"0110100001100101011011000110110001101111\"\n\n\ndef test_leetspeak():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"|-|3ll0 my n4m3 1s 833 4nd 1 l1k3 D06 4ND 4ppl3 4nd 7R33\",\n    )\n    assert res.lower() == answer_str.lower()\n\n\ndef test_morse_code():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \".... . .-.. .-.. ---/-- -.--/-. .- -- ./.. .../-... . ./.- -. -../../.-.. .. -.- ./-.. --- --./.- -. -../.- .--. .--. .-.. ./.- -. -../- .-. . .\",\n    )\n    assert res == answer_str.upper()\n\n\ndef test_multi_tap():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"44 33 555 555 666 0 6 999 0 66 2 6 33 0 444 7777 0 22 33 33 0 2 66 3 0 444 0 555 444 55 33 0 3 666 4 0 2 66 3 0 2 7 7 555 33 0 2 66 3 0 8 777 33 33\",\n    )\n    assert res == answer_str.upper()\n\n\ndef test_new_line_at_start_returns():\n    # Language Checker should return True by stripping new line\n    # but the new line should be returned to the user as new lines are important\n    res = decrypt(Config().library_default().complete_config(), \"\\npass\\n\")\n\n    assert res == \"\\npass\\n\"\n\n\ndef test_new_line_strip_and_return():\n    # Language Checker should return True by stripping new line\n    # but the new line should be returned to the user as new lines are important\n    res = decrypt(Config().library_default().complete_config(), \"pass\\n\")\n\n    assert res == \"pass\\n\"\n\n\ndef test_octal():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"110 145 154 154 157 40 155 171 40 156 141 155 145 40 151 163 40 142 145 145 40 141 156 144 40 111 40 154 151 153 145 40 144 157 147 40 141 156 144 40 141 160 160 154 145 40 141 156 144 40 164 162 145 145\",\n    )\n    assert res == answer_str\n\n\ndef test_plaintext():\n    res = decrypt(Config().library_default().complete_config(), answer_str)\n    assert res == answer_str\n\n\ndef test_quadgrams_messed_up_spacing():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"H ello m y na m e is b ee an d I l ik e do g a n d ap pl e a nd tr e e\",\n    )\n    assert (\n        res == \"H ello m y na m e is b ee an d I l ik e do g a n d ap pl e a nd tr e e\"\n    )\n\n\ndef test_quadgrams_no_spaces():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"HellomynameisbeeandIlikedogandappleandtree\",\n    )\n    assert res == \"HellomynameisbeeandIlikedogandappleandtree\"\n\n\ndef test_quadgrams_space_between_every_letter():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"H e l l o m y n a m e i s b e e a n d I l i k e d o g a n d a p p l e a n d t r e e\",\n    )\n    assert (\n        res\n        == \"H e l l o m y n a m e i s b e e a n d I l i k e d o g a n d a p p l e a n d t r e e\"\n    )\n\n\ndef test_reversed_text():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"eert dna elppa dna god ekil I dna eeb si eman ym olleH\",\n    )\n    assert res == answer_str\n\n\ndef test_rot47():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"$A9:?I @7 3=24< BF2CEK[ ;F586 >J G@H\",\n    )\n    assert res == \"Sphinx of black quartz, judge my vow\"\n\n\ndef test_soundex():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"H236 I200 I500 T000 P230\",\n    )\n    assert res.lower() == \"history is in the past\"\n\n\ndef test_tap_code():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"4,4 1,5 4,3 4,4  3,4 3,3 1,5  4,4 5,2 3,4  4,4 2,3 4,2 1,5 1,5\",\n    )\n    assert res == \"test one two three\".upper()\n\n\ndef test_url():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"https%3A%2F%2Fwww%2Egoogle%2Ecom%2Fsearch%3Fq%3Dciphey\",\n    )\n    assert res == \"https://www.google.com/search?q=ciphey\"\n\n\ndef test_uuencode():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        'begin 644 /dev/stdout\\nM2&5L;&\\\\@;7D@;F%M92!I<R!B964@86YD($D@;&EK92!D;V<@86YD(&%P<&QE\\n)(&%N9\"!T<F5E\\n`\\nend\\n',\n    )\n    assert res == answer_str\n    res = decrypt(\n        Config().library_default().complete_config(),\n        'M2&5L;&\\\\@;7D@;F%M92!I<R!B964@86YD($D@;&EK92!D;V<@86YD(&%P<&QE\\n)(&%N9\"!T<F5E\\n',\n    )\n    assert res == answer_str\n\n\ndef test_vigenere():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"Rijvs ki rywi gc fco eln M jsoc nse krb ktnvi yxh rbic\",\n    )\n\n    assert res == answer_str\n\n\ndef test_xandy():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"xDxxDxxx xDDxxDxD xDDxDDxx xDDxDDxx xDDxDDDD xxDxxxxx xDDxDDxD xDDDDxxD xxDxxxxx xDDxDDDx xDDxxxxD xDDxDDxD xDDxxDxD xxDxxxxx xDDxDxxD xDDDxxDD xxDxxxxx xDDxxxDx xDDxxDxD xDDxxDxD xxDxxxxx xDDxxxxD xDDxDDDx xDDxxDxx xxDxxxxx xDxxDxxD xxDxxxxx xDDxDDxx xDDxDxxD xDDxDxDD xDDxxDxD xxDxxxxx xDDxxDxx xDDxDDDD xDDxxDDD xxDxxxxx xDDxxxxD xDDxDDDx xDDxxDxx xxDxxxxx xDDxxxxD xDDDxxxx xDDDxxxx xDDxDDxx xDDxxDxD xxDxxxxx xDDxxxxD xDDxDDDx xDDxxDxx xxDxxxxx xDDDxDxx xDDDxxDx xDDxxDxD xDDxxDxD\",\n    )\n    assert res == answer_str\n",
    "chunks": [
      {
        "chunk_id": "doc_20_chunk_0",
        "original_index": 0,
        "content": "import pytest\n\nfrom ciphey import decrypt\nfrom ciphey.iface import Config\n\nanswer_str = \"Hello my name is bee and I like dog and apple and tree\"\n\n\ndef test_a1z26():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"8 5 12 12 15 13 25 14 1 13 5 9 19 2 5 5 1 14 4 9 12 9 11 5 4 15 7 1 14 4 1 16 16 12 5 1 14 4 20 18 5 5\",\n    )\n    assert res == \"hellomynameisbeeandilikedogandappleandtree\"\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_1",
        "original_index": 1,
        "content": "\ndef test_affine():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"Ihsst bf kxbh rd ghh xky R srjh ytz xky xccsh xky muhh\",\n    )\n    assert res == answer_str\n\n\ndef test_ascii_shift():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        '\"?FFIzGSzH;G?zCMz<??z;H>z#zFCE?z>IAz;H>z;JJF?z;H>zNL??',\n    )\n    assert res == answer_str\n\n\ndef test_atbash():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"Svool nb mznv rh yvv zmw R orpv wlt zmw zkkov zmw givv\",\n    )\n    assert res == answer_str\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_2",
        "original_index": 2,
        "content": "\ndef test_baconian_complete_variant():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"AABBB AABAA ABABB ABABB ABBBA ABBAA BBAAA ABBAB AAAAA ABBAA AABAA ABAAA BAABA AAAAB AABAA AABAA AAAAA ABBAB AAABB ABAAA ABABB ABAAA ABABA AABAA AAABB ABBBA AABBA AAAAA ABBAB AAABB AAAAA ABBBB ABBBB ABABB AABAA AAAAA ABBAB AAABB BAABB BAAAB AABAA AABAA\",\n    )\n    assert res == \"HELLOMYNAMEISBEEANDILIKEDOGANDAPPLEANDTREE\"\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_3",
        "original_index": 3,
        "content": "\ndef test_baconian_standard_variant():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"AABBB AABAA ABABA ABABA ABBAB ABABB BABBA ABBAA AAAAA ABABB AABAA ABAAA BAAAB AAAAB AABAA AABAA AAAAA ABBAA AAABB ABAAA ABABA ABAAA ABAAB AABAA AAABB ABBAB AABBA AAAAA ABBAA AAABB AAAAA ABBBA ABBBA ABABA AABAA AAAAA ABBAA AAABB BAABA BAAAA AABAA AABAA\",\n    )\n    assert res == \"HELLOMYNAMEISBEEANDILIKEDOGANDAPPLEANDTREE\"\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_4",
        "original_index": 4,
        "content": "\ndef test_base32():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"JBSWY3DPEBWXSIDOMFWWKIDJOMQGEZLFEBQW4ZBAJEQGY2LLMUQGI33HEBQW4ZBAMFYHA3DFEBQW4ZBAORZGKZI=\",\n    )\n    assert res == answer_str\n\n\ndef test_base58_bitcoin():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"6qYhNwsP46Mn4gy6gyANfsMm2icAxGFA6gnFjVm9phYHeby7PZm3vthiXxSU77teQgTFGbHETn\",\n    )\n    assert res == answer_str\n\n\ndef test_base58_ripple():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"aqY64A1PhaM8hgyagyw4C1Mmp5cwxGEwag8EjVm9F6YHebyfPZmsvt65XxS7ffteQgTEGbHNT8\",\n    )\n    assert res == answer_str\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_5",
        "original_index": 5,
        "content": "\ndef test_base62():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"2mQvnz9Yevvb7DRCuyDltsP31vJLToR5pjE9orWkzHMUsht2kbC96PLbZ1sdIocsGHENrzC2n\",\n    )\n    assert res == answer_str\n\n\ndef test_base64():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"SGVsbG8gbXkgbmFtZSBpcyBiZWUgYW5kIEkgbGlrZSBkb2cgYW5kIGFwcGxlIGFuZCB0cmVl\",\n    )\n\n    assert res == answer_str\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_6",
        "original_index": 6,
        "content": "\ndef test_base69():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"kAZAtABBeB8A-AoB8ADBNAhBLA1AFBgA0AXBfBGATAVAFBgAwAWBHB<ACAkA-AnB0AVBnBNBDARAZBiBQAYAtAhBhABA<ArB4AbAMANBDAFAXBfBQAdAOAmArAUAAA2=\",\n    )\n    assert res == answer_str\n\n\ndef test_base85():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"87cURD]inB+DtV)AKY].+C\\\\nn+CT.u+A!\\\\lBkq9&A8c*'@;]Tu@;p1%AKYE!A0>u7ARt\",\n    )\n    assert res == answer_str\n\n\ndef test_base91():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \">OwJh>=/fV@$x88j9ZNKB*ge$yV%lE%ZKi,<d,TX2$0t,,cjPD@JY<UCHRWznuWoQPD\",\n    )\n    assert res == answer_str\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_7",
        "original_index": 7,
        "content": "\ndef test_baudot():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"10100 00001 10010 10010 11000 00100 11100 10101 00100 01100 00011 11100 00001 00100 00110 00101 00100 11001 00001 00001 00100 00011 01100 01001 00100 00110 00100 10010 00110 01111 00001 00100 01001 11000 11010 00100 00011 01100 01001 00100 00011 10110 10110 10010 00001 00100 00011 01100 01001 00100 10000 01010 00001 00001\",\n    )\n    assert res == answer_str.upper()\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_8",
        "original_index": 8,
        "content": "\ndef test_binary():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"01001000 01100101 01101100 01101100 01101111 00100000 01101101 01111001 00100000 01101110 01100001 01101101 01100101 00100000 01101001 01110011 00100000 01100010 01100101 01100101 00100000 01100001 01101110 01100100 00100000 01001001 00100000 01101100 01101001 01101011 01100101 00100000 01100100 01101111 01100111 00100000 01100001 01101110 01100100 00100000 01100001 01110000 01110000 01101100 01100101 00100000 01100001 01101110 01100100 00100000 01110100 01110010 01100101 01100101\",\n    )\n\n    assert res == answer_str\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_9",
        "original_index": 9,
        "content": "\n@pytest.mark.skip(\n    \"Can't decode base64 + caesar https://github.com/Ciphey/Ciphey/issues/606\"\n)\ndef test_binary_base64_caesar():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"01010110 01011000 01001010 00110101 01100101 01010111 01001001 01100111 01100101 01101101 01110111 01100111 01011001 01010111 00110101 00110110 01100011 01101001 01000010 00110010 01011010 01101001 01000010 01110110 01100011 01101110 01001001 01100111 01100010 01101101 01000110 01111000 01001001 01000110 01011001 01100111 01100101 01011000 01011010 00110100 01100011 01101001 01000010 01111000 01011001 01101110 01010001 01100111 01100010 01101101 01000110 01111000 01001001 01000111 00110101 01101010 01011001 00110011 01101100 01111001 01001001 01000111 00110101 01101000 01100011 01010011 01000010 01101110 01011010 01011000 01001010 01111001 00001010\",\n    )\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_10",
        "original_index": 10,
        "content": "    assert res == answer_str\n\n\ndef test_braille():\n    res = decrypt(\n        Config.library_default().complete_config(),\n        \"\u2813\u2811\u2807\u2807\u2815\u2800\u280d\u283d\u2800\u281d\u2801\u280d\u2811\u2800\u280a\u280e\u2800\u2803\u2811\u2811\u2800\u2801\u281d\u2819\u2800\u280a\u2800\u2807\u280a\u2805\u2811\u2800\u2819\u2815\u281b\u2800\u2801\u281d\u2819\u2800\u2801\u280f\u280f\u2807\u2811\u2800\u2801\u281d\u2819\u2800\u281e\u2817\u2811\u2811\",\n    )\n    assert res == answer_str.lower()\n\n\ndef test_brainfuck():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"+[+++++++>+<]>-.-[+>-----<]>++.+++++++..+++.+[+>++<]>.[++>+<]>---.--[+++>-<]>.-[+>++++<]>.[++>+<]>--.-[+++>++<]>-.+[-->---<]>.--------.[+++++>+<]>+.-[+++>--<]>-.++++++++++.---[+>++<]>.[+++>-<]>++.+++..[+++++>+<]>+.[+++>-<]>+.+[-->---<]>+.----------.-[+++>-<]>-.-[+++>+<]>--.-[+>----<]>.++[+++>--<]>.---.++.------.[+++++>+<]>+.+[+>---<]>+.+++++++++++.--------.-[+++>-<]>--.[+++>-<]>+.+[-->---<]>+.----------.-[+++>-<]>-.[+++>-<]>+.-[-->---<]>..----.-------.[+++++>+<]>+.[+++>-<]>+.+[-->---<]>+.----------.-[+++>-<]>-.[++>+<]>++++.--.-------------..\",\n    )\n    assert res == answer_str\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_11",
        "original_index": 11,
        "content": "\ndef test_brandon():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"R hvv blf tzgsvi yvuliv nv...sfmtib...gviirurvw... Xofgxsrmt blfi yzyvh gl blfi yivzhg. Vnkvili Vnsbi srh nzixsvw srh ovtrlmh rmgl lfi ozmwh... Ozrw hrvtv gl vevib uligivhh uiln sviv gl gsv Yofv Nlfmgzrmh. Izyrw zmw izevmlfh, sv yrgvh zmw yrgvh zdzb. Nvm lu gsv Mligs, blf hgzmw zg gsv kivxrkrxv. Blfi prmth szev uzrovw blf, hl mld blf gfim gl gsv tlwh! Zmw bvg blf wl mlg kovzw? Blf wl mlg pmvvo gl wfhg blfi svzwh drgs zhs? Rmhgvzw blf dzro,  Dsb szev gsv tlwh ulihzpvm fh?  Dv nfhg ollp rmgl gsv girzoh dv uzrovw olmt ztl! Rm z grnv kzhhvw, "
      },
      {
        "chunk_id": "doc_20_chunk_12",
        "original_index": 12,
        "content": "lfi dliow rmgvigdrmvw drgs zmlgsvi gsilfts zm fksvzezo hxslozih xzoo gsv Xlmqfmxgrlm lu gsv Hksvivh... Gsv tlwh zooldvw fmslob ulixvh gl hork rmgl lfi wlnzrm. Gsv luuhkirmt lu gszg xzgzxobhn dzh gsv mvuvirlfh ulixv xzoovw nztrx... Bvg dv wrw mlg yzmrhs rg, rmhgvzw hgfwbrmt gsv erov zixzmv uli lfi kldvi zmw dvzogs! Zmw gsv nlmhgvih zg lfi wlli...gsv fmslob ivorxgh lu gsrh Xlmqfmxgrlm? ...gsv gilooh...gsv xlikhv vzgvih...gsv dvivdloevh? Wrw dv izrhv lfi hdliwh ztzrmhg gsvn? Li szev dv ozrw gsrh yfiwvm lm lgsvih? Lm hl-xzoovw drgxsvih? Hgizb xsrowivm gzftsg gsv dzbh lu ulfo hlixvib, "
      },
      {
        "chunk_id": "doc_20_chunk_13",
        "original_index": 13,
        "content": "gsvri ylwrvh nfgzgvw gsilfts yozhksvnlfh irgfzo. Hvmg gl urtsg nlmhgvih gslfts gsvb xlfow mlg wrhgrmtfrhs tllw uiln vero. Gsv uorxpvi lu sfnzmrgb olmt vcgrmtfrhsvw drgsrm gsvn. Bvh, gsvri mfnyvih szev wdrmwovw gsilfts gsv bvzih. Yfg z uvd hgroo ilzn lfi ozmwh, luuvirmt gsvri yollwb dlip uli xlrm. Gl gsrh wzb gsvb hsznv fh drgs gsvri evib vcrhgvmxv! Gsv Mligs yovvwh, uolttvw yb dzi. Gsv yzggovh ziv gsv tlwh' dsrk, xszhgrhvnvmg uli lfi hrmh! Zmw ovg fh mlg ulitvg gsv gviilih, gsv hxlfitvh uiln yvblmw lfi dliow! Gsv Drow Sfmg irwvh gsv hpb drgs vevib ufoo nllm! Gsv wzip izrwvih zywfxg lfi xsrowivm rmgl ozmwh fmpmldm! Hlnv hzb gsvb svizow z hvxlmw Xlmqfmxgrlm! Xzm dv xszig z xlfihv yzxp rmgl gsv ortsg? Droo dv urmw gsv hgivmtgs gl yzmrhs gsv nztvh uiln lfi prmtwlnh? Fmrgv zilfmw gsv dzings lu gsv Vgvimzo Uriv? Mrts rh gsv Grnv lu gsv Hdliw zmw gsv Zcv! Mlmv droo urtsg gsrh dzi rm lfi hgvzw! Mrts rh gsv Grnv lu Nzwmvhh zmw Wrhwzrm!\",\n    )\n    assert bool(res) is True\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_14",
        "original_index": 14,
        "content": "\ndef test_caesar():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"Uryyb zl anzr vf orr naq V yvxr qbt naq nccyr naq gerr\",\n    )\n    assert res == answer_str\n\n\ndef test_decimal():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"72 101 108 108 111 32 109 121 32 110 97 109 101 32 105 115 32 98 101 101 32 97 110 100 32 73 32 108 105 107 101 32 100 111 103 32 97 110 100 32 97 112 112 108 101 32 97 110 100 32 116 114 101 101\",\n    )\n    assert res == answer_str\n\n\ndef test_dna():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"GAT AAT GCT ATT TCT ATT AAT ACT GAA CGT GAA TCT ACT ATT AAT GGT\",\n    )\n    assert res == \"DNAISINTERESTING\"\n\n\ndef test_dtmf():\n    res = decrypt(\n        Config().library_default().complete_config(),\n"
      },
      {
        "chunk_id": "doc_20_chunk_15",
        "original_index": 15,
        "content": "        \"1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1209-697 1336-941 1336-941 1336-941 1336-941 1336-941 1336-941 1209-697 1209-697 1209-697 1336-941 1209-697 1336-941 1336-941 1336-941 1209-697 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697 1336-941 1209-697 1209-697 1336-941 1336-941 1209-697 1336-941 1209-697\","
      },
      {
        "chunk_id": "doc_20_chunk_16",
        "original_index": 16,
        "content": "\n    )\n    assert res == answer_str\n\n\ndef test_galactic():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"\u2351\u14b7\ua58e\ua58e\ud835\ude79 \u14b2|| \u30ea\u1511\u14b2\u14b7 \u254e\u14ed \u0296\u14b7\u14b7 \u1511\u30ea\u21b8 i \ua58e\u254e\ua58c\u14b7 \u21b8\ud835\ude79\u22a3 \u1511\u30ea\u21b8 \u1511!\u00a1!\u00a1\ua58e\u14b7 \u1511\u30ea\u21b8 \u2138 \u0323 \u2237\u14b7\u14b7\",\n    )\n    assert res == answer_str.lower()\n\n\ndef test_galactic_Xproblem():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"\u2351\u1511\ua58e\u254e\u2393\u1511 \u0307/,  \u0307/||\ua58e\ud835\ude79!\u00a1\u2351\ud835\ude79\u30ea\u14b7, \u1511  \u0307/ \u1511\ua58e\ud835\ude79\u30ea\u14b7 \u1511\u30ea\u21b8  \u0307/\u14b7\u2237\ud835\ude79 \u0307/ \u2393\u2237\ud835\ude79\u14b2 \ud835\ude79 \u0307/\u2393\ud835\ude79\u2237\u21b8\",\n    )\n    assert res == \"halifax, xylophone, a x alone and xerox from oxford\"\n\n\ndef test_gzip():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"H4sIAAzul18A/yXJzQmAMBSEwVa+ckwZT7LIw80P6sXuA3ocZpM9aC89msibXSJ6peA8RR3Hx5jTfzyXtAAbQvCyNgAAAA==\",\n    )\n    assert res == answer_str\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_17",
        "original_index": 17,
        "content": "\ndef test_hexadecimal():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"48 65 6c 6c 6f 20 6d 79 20 6e 61 6d 65 20 69 73 20 62 65 65 20 61 6e 64 20 49 20 6c 69 6b 65 20 64 6f 67 20 61 6e 64 20 61 70 70 6c 65 20 61 6e 64 20 74 72 65 65\",\n    )\n\n    assert res == answer_str\n\n\ndef test_json_problem():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"0110100001100101011011000110110001101111\",\n    )\n    assert res != \"0110100001100101011011000110110001101111\"\n\n\ndef test_leetspeak():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"|-|3ll0 my n4m3 1s 833 4nd 1 l1k3 D06 4ND 4ppl3 4nd 7R33\",\n    )\n    assert res.lower() == answer_str.lower()\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_18",
        "original_index": 18,
        "content": "\ndef test_morse_code():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \".... . .-.. .-.. ---/-- -.--/-. .- -- ./.. .../-... . ./.- -. -../../.-.. .. -.- ./-.. --- --./.- -. -../.- .--. .--. .-.. ./.- -. -../- .-. . .\",\n    )\n    assert res == answer_str.upper()\n\n\ndef test_multi_tap():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"44 33 555 555 666 0 6 999 0 66 2 6 33 0 444 7777 0 22 33 33 0 2 66 3 0 444 0 555 444 55 33 0 3 666 4 0 2 66 3 0 2 7 7 555 33 0 2 66 3 0 8 777 33 33\",\n    )\n    assert res == answer_str.upper()\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_19",
        "original_index": 19,
        "content": "\ndef test_new_line_at_start_returns():\n    # Language Checker should return True by stripping new line\n    # but the new line should be returned to the user as new lines are important\n    res = decrypt(Config().library_default().complete_config(), \"\\npass\\n\")\n\n    assert res == \"\\npass\\n\"\n\n\ndef test_new_line_strip_and_return():\n    # Language Checker should return True by stripping new line\n    # but the new line should be returned to the user as new lines are important\n    res = decrypt(Config().library_default().complete_config(), \"pass\\n\")\n\n    assert res == \"pass\\n\"\n\n\ndef test_octal():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"110 145 154 154 157 40 155 171 40 156 141 155 145 40 151 163 40 142 145 145 40 141 156 144 40 111 40 154 151 153 145 40 144 157 147 40 141 156 144 40 141 160 160 154 145 40 141 156 144 40 164 162 145 145\",\n    )\n    assert res == answer_str\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_20",
        "original_index": 20,
        "content": "\ndef test_plaintext():\n    res = decrypt(Config().library_default().complete_config(), answer_str)\n    assert res == answer_str\n\n\ndef test_quadgrams_messed_up_spacing():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"H ello m y na m e is b ee an d I l ik e do g a n d ap pl e a nd tr e e\",\n    )\n    assert (\n        res == \"H ello m y na m e is b ee an d I l ik e do g a n d ap pl e a nd tr e e\"\n    )\n\n\ndef test_quadgrams_no_spaces():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"HellomynameisbeeandIlikedogandappleandtree\",\n    )\n    assert res == \"HellomynameisbeeandIlikedogandappleandtree\"\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_21",
        "original_index": 21,
        "content": "\ndef test_quadgrams_space_between_every_letter():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"H e l l o m y n a m e i s b e e a n d I l i k e d o g a n d a p p l e a n d t r e e\",\n    )\n    assert (\n        res\n        == \"H e l l o m y n a m e i s b e e a n d I l i k e d o g a n d a p p l e a n d t r e e\"\n    )\n\n\ndef test_reversed_text():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"eert dna elppa dna god ekil I dna eeb si eman ym olleH\",\n    )\n    assert res == answer_str\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_22",
        "original_index": 22,
        "content": "\ndef test_rot47():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"$A9:?I @7 3=24< BF2CEK[ ;F586 >J G@H\",\n    )\n    assert res == \"Sphinx of black quartz, judge my vow\"\n\n\ndef test_soundex():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"H236 I200 I500 T000 P230\",\n    )\n    assert res.lower() == \"history is in the past\"\n\n\ndef test_tap_code():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"4,4 1,5 4,3 4,4  3,4 3,3 1,5  4,4 5,2 3,4  4,4 2,3 4,2 1,5 1,5\",\n    )\n    assert res == \"test one two three\".upper()\n\n\ndef test_url():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"https%3A%2F%2Fwww%2Egoogle%2Ecom%2Fsearch%3Fq%3Dciphey\",\n    )\n    assert res == \"https://www.google.com/search?q=ciphey\"\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_23",
        "original_index": 23,
        "content": "\ndef test_uuencode():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        'begin 644 /dev/stdout\\nM2&5L;&\\\\@;7D@;F%M92!I<R!B964@86YD($D@;&EK92!D;V<@86YD(&%P<&QE\\n)(&%N9\"!T<F5E\\n`\\nend\\n',\n    )\n    assert res == answer_str\n    res = decrypt(\n        Config().library_default().complete_config(),\n        'M2&5L;&\\\\@;7D@;F%M92!I<R!B964@86YD($D@;&EK92!D;V<@86YD(&%P<&QE\\n)(&%N9\"!T<F5E\\n',\n    )\n    assert res == answer_str\n\n\ndef test_vigenere():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"Rijvs ki rywi gc fco eln M jsoc nse krb ktnvi yxh rbic\",\n    )\n\n    assert res == answer_str\n\n"
      },
      {
        "chunk_id": "doc_20_chunk_24",
        "original_index": 24,
        "content": "\ndef test_xandy():\n    res = decrypt(\n        Config().library_default().complete_config(),\n        \"xDxxDxxx xDDxxDxD xDDxDDxx xDDxDDxx xDDxDDDD xxDxxxxx xDDxDDxD xDDDDxxD xxDxxxxx xDDxDDDx xDDxxxxD xDDxDDxD xDDxxDxD xxDxxxxx xDDxDxxD xDDDxxDD xxDxxxxx xDDxxxDx xDDxxDxD xDDxxDxD xxDxxxxx xDDxxxxD xDDxDDDx xDDxxDxx xxDxxxxx xDxxDxxD xxDxxxxx xDDxDDxx xDDxDxxD xDDxDxDD xDDxxDxD xxDxxxxx xDDxxDxx xDDxDDDD xDDxxDDD xxDxxxxx xDDxxxxD xDDxDDDx xDDxxDxx xxDxxxxx xDDxxxxD xDDDxxxx xDDDxxxx xDDxDDxx xDDxxDxD xxDxxxxx xDDxxxxD xDDxDDDx xDDxxDxx xxDxxxxx xDDDxDxx xDDDxxDx xDDxxDxD xDDxxDxD\",\n    )\n    assert res == answer_str\n"
      }
    ]
  },
  {
    "doc_id": "doc_21",
    "original_uuid": "538e985a1d85e0fc67ab55f40ee6dade761bf959d5e8f3daca45b722935ba6a5",
    "content": "#include \"value_generators.h\"\n\n#include <algorithm>\n#include <type_traits>\n#include <math.h>\n\nnamespace {\nusing namespace clickhouse;\n}\n\nstd::vector<uint32_t> MakeNumbers() {\n    return std::vector<uint32_t> {1, 2, 3, 7, 11, 13, 17, 19, 23, 29, 31};\n}\n\nstd::vector<uint8_t> MakeBools() {\n    return std::vector<uint8_t> {1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0};\n}\n\nstd::vector<std::string> MakeFixedStrings(size_t string_size) {\n    std::vector<std::string> result = MakeStrings();\n\n    std::for_each(result.begin(), result.end(), [string_size](auto& value) {\n        value.resize(string_size, '\\0');\n    });\n\n    return result;\n}\n\nstd::vector<std::string> MakeStrings() {\n    return {\n        \"a\", \"ab\", \"abc\", \"abcd\",\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n    };\n}\n\nstd::vector<UUID> MakeUUIDs() {\n    return {\n        UUID(0llu, 0llu),\n        UUID(0xbb6a8c699ab2414cllu, 0x86697b7fd27f0825llu),\n        UUID(0x84b9f24bc26b49c6llu, 0xa03b4ab723341951llu),\n        UUID(0x3507213c178649f9llu, 0x9faf035d662f60aellu)\n    };\n}\n\nstd::vector<Int64> MakeDateTime64s(size_t scale, size_t values_size) {\n    const auto seconds_multiplier = static_cast<size_t>(std::pow(10, scale));\n    const auto year = 86400ull * 365 * seconds_multiplier; // ~approx, but this doesn't matter here.\n\n    // Approximatelly +/- 200 years around epoch (and value of epoch itself)\n    // with non zero seconds and sub-seconds.\n    // Please note there are values outside of DateTime (32-bit) range that might\n    // not have correct string representation in CH yet,\n    // but still are supported as Int64 values.\n    return GenerateVector(values_size,\n        [seconds_multiplier, year] (size_t i )-> Int64 {\n            return (i - 100) * year * 2 + (i * 10) * seconds_multiplier + i;\n        });\n}\n\nstd::vector<int32_t> MakeDates32() {\n    // in CH Date32 internally a UInt32 and stores a day number\n    // ColumnDate expects values to be seconds, which is then\n    // converted to day number internally, hence the `* 86400`.\n    // 114634 * 86400 is 2282-11-10, last integer that fits into DateTime32 range\n    // (max is 2283-11-11)\n    std::vector<int32_t> result = MakeDates<int32_t>();\n\n    // add corresponding negative values, since pre-epoch date are supported too.\n    const auto size = result.size();\n    for (size_t i = 0; i < size; ++i) {\n        result.push_back(result[i] * -1);\n    }\n\n    return result;\n}\n\nstd::vector<clickhouse::Int64> MakeDateTimes() {\n    // in CH DateTime internally a UInt32\n    return {\n        0, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536,\n        131072, 262144, 524288, 1048576, 2097152, 4194304, 8388608, 16777216, 33554432, 67108864,\n        134217728, 268435456, 536870912, 1073741824, 2147483648, 4294967296 - 1\n    };\n}\n\nstd::vector<clickhouse::Int128> MakeInt128s() {\n    return {\n        absl::MakeInt128(0xffffffffffffffffll, 0xffffffffffffffffll), // -1\n        absl::MakeInt128(0, 0xffffffffffffffffll),  // 2^64\n        absl::MakeInt128(0xffffffffffffffffll, 0),\n        absl::MakeInt128(0x8000000000000000ll, 0),\n        Int128(0)\n    };\n}\n\nstd::vector<clickhouse::Int128> MakeDecimals(size_t /*precision*/, size_t scale) {\n    const auto scale_multiplier = static_cast<size_t>(std::pow(10, scale));\n    const long long int rhs_value = 12345678910;\n\n    const std::vector<long long int> vals {0, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536 - 1};\n\n    std::vector<clickhouse::Int128> result;\n    result.reserve(vals.size());\n\n    std::transform(vals.begin(), vals.end(), std::back_inserter(result), [scale_multiplier, rhs_value](const auto& value) {\n        return value * scale_multiplier + rhs_value % scale_multiplier;\n    });\n\n    return result;\n}\n\nstd::string FooBarGenerator(size_t i) {\n    std::string result;\n    if (i % 3 == 0)\n        result += \"Foo\";\n    if (i % 5 == 0)\n        result += \"Bar\";\n    if (result.empty())\n        result = std::to_string(i);\n\n    return result;\n}\n\nstd::vector<in_addr> MakeIPv4s() {\n    return {\n        MakeIPv4(0x12345678), // 255.255.255.255\n        MakeIPv4(0x0100007f), // 127.0.0.1\n        MakeIPv4(3585395774),\n        MakeIPv4(0),\n        MakeIPv4(0x12345678),\n    };\n}\n\nstd::vector<in6_addr> MakeIPv6s() {\n    return {\n        MakeIPv6(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), // 1:203:405:607:809:a0b:c0d:e0f\n        MakeIPv6(0, 0, 0, 0, 0, 1),                                     // ::1\n        MakeIPv6(0, 0, 0, 0, 0, 0),                                     // ::\n        MakeIPv6(0xff, 0xff, 204, 152, 189, 116),                       // ::ffff:204.152.189.116\n    };\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_21_chunk_0",
        "original_index": 0,
        "content": "#include \"value_generators.h\"\n\n#include <algorithm>\n#include <type_traits>\n#include <math.h>\n\nnamespace {\nusing namespace clickhouse;\n}\n\nstd::vector<uint32_t> MakeNumbers() {\n    return std::vector<uint32_t> {1, 2, 3, 7, 11, 13, 17, 19, 23, 29, 31};\n}\n\nstd::vector<uint8_t> MakeBools() {\n    return std::vector<uint8_t> {1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0};\n}\n\nstd::vector<std::string> MakeFixedStrings(size_t string_size) {\n    std::vector<std::string> result = MakeStrings();\n\n    std::for_each(result.begin(), result.end(), [string_size](auto& value) {\n        value.resize(string_size, '\\0');\n    });\n\n    return result;\n}\n\n"
      },
      {
        "chunk_id": "doc_21_chunk_1",
        "original_index": 1,
        "content": "std::vector<std::string> MakeStrings() {\n    return {\n        \"a\", \"ab\", \"abc\", \"abcd\",\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n"
      },
      {
        "chunk_id": "doc_21_chunk_2",
        "original_index": 2,
        "content": "        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n        \"long string to test how those are handled. Here goes more text. \"\n    };\n}\n\n"
      },
      {
        "chunk_id": "doc_21_chunk_3",
        "original_index": 3,
        "content": "std::vector<UUID> MakeUUIDs() {\n    return {\n        UUID(0llu, 0llu),\n        UUID(0xbb6a8c699ab2414cllu, 0x86697b7fd27f0825llu),\n        UUID(0x84b9f24bc26b49c6llu, 0xa03b4ab723341951llu),\n        UUID(0x3507213c178649f9llu, 0x9faf035d662f60aellu)\n    };\n}\n\nstd::vector<Int64> MakeDateTime64s(size_t scale, size_t values_size) {\n    const auto seconds_multiplier = static_cast<size_t>(std::pow(10, scale));\n    const auto year = 86400ull * 365 * seconds_multiplier; // ~approx, but this doesn't matter here.\n\n"
      },
      {
        "chunk_id": "doc_21_chunk_4",
        "original_index": 4,
        "content": "    // Approximatelly +/- 200 years around epoch (and value of epoch itself)\n    // with non zero seconds and sub-seconds.\n    // Please note there are values outside of DateTime (32-bit) range that might\n    // not have correct string representation in CH yet,\n    // but still are supported as Int64 values.\n    return GenerateVector(values_size,\n        [seconds_multiplier, year] (size_t i )-> Int64 {\n            return (i - 100) * year * 2 + (i * 10) * seconds_multiplier + i;\n        });\n}\n\nstd::vector<int32_t> MakeDates32() {\n    // in CH Date32 internally a UInt32 and stores a day number\n    // ColumnDate expects values to be seconds, which is then\n    // converted to day number internally, hence the `* 86400`.\n    // 114634 * 86400 is 2282-11-10, last integer that fits into DateTime32 range\n    // (max is 2283-11-11)\n    std::vector<int32_t> result = MakeDates<int32_t>();\n\n"
      },
      {
        "chunk_id": "doc_21_chunk_5",
        "original_index": 5,
        "content": "    // add corresponding negative values, since pre-epoch date are supported too.\n    const auto size = result.size();\n    for (size_t i = 0; i < size; ++i) {\n        result.push_back(result[i] * -1);\n    }\n\n    return result;\n}\n\nstd::vector<clickhouse::Int64> MakeDateTimes() {\n    // in CH DateTime internally a UInt32\n    return {\n        0, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536,\n        131072, 262144, 524288, 1048576, 2097152, 4194304, 8388608, 16777216, 33554432, 67108864,\n        134217728, 268435456, 536870912, 1073741824, 2147483648, 4294967296 - 1\n    };\n}\n\n"
      },
      {
        "chunk_id": "doc_21_chunk_6",
        "original_index": 6,
        "content": "std::vector<clickhouse::Int128> MakeInt128s() {\n    return {\n        absl::MakeInt128(0xffffffffffffffffll, 0xffffffffffffffffll), // -1\n        absl::MakeInt128(0, 0xffffffffffffffffll),  // 2^64\n        absl::MakeInt128(0xffffffffffffffffll, 0),\n        absl::MakeInt128(0x8000000000000000ll, 0),\n        Int128(0)\n    };\n}\n\nstd::vector<clickhouse::Int128> MakeDecimals(size_t /*precision*/, size_t scale) {\n    const auto scale_multiplier = static_cast<size_t>(std::pow(10, scale));\n    const long long int rhs_value = 12345678910;\n\n    const std::vector<long long int> vals {0, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536 - 1};\n\n    std::vector<clickhouse::Int128> result;\n    result.reserve(vals.size());\n\n"
      },
      {
        "chunk_id": "doc_21_chunk_7",
        "original_index": 7,
        "content": "    std::transform(vals.begin(), vals.end(), std::back_inserter(result), [scale_multiplier, rhs_value](const auto& value) {\n        return value * scale_multiplier + rhs_value % scale_multiplier;\n    });\n\n    return result;\n}\n\nstd::string FooBarGenerator(size_t i) {\n    std::string result;\n    if (i % 3 == 0)\n        result += \"Foo\";\n    if (i % 5 == 0)\n        result += \"Bar\";\n    if (result.empty())\n        result = std::to_string(i);\n\n    return result;\n}\n\n"
      },
      {
        "chunk_id": "doc_21_chunk_8",
        "original_index": 8,
        "content": "std::vector<in_addr> MakeIPv4s() {\n    return {\n        MakeIPv4(0x12345678), // 255.255.255.255\n        MakeIPv4(0x0100007f), // 127.0.0.1\n        MakeIPv4(3585395774),\n        MakeIPv4(0),\n        MakeIPv4(0x12345678),\n    };\n}\n\nstd::vector<in6_addr> MakeIPv6s() {\n    return {\n        MakeIPv6(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), // 1:203:405:607:809:a0b:c0d:e0f\n        MakeIPv6(0, 0, 0, 0, 0, 1),                                     // ::1\n        MakeIPv6(0, 0, 0, 0, 0, 0),                                     // ::\n        MakeIPv6(0xff, 0xff, 204, 152, 189, 116),                       // ::ffff:204.152.189.116\n    };\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_22",
    "original_uuid": "6ffb0cf236934c884639effc308d9cb67a7cd33d849153664bd70cc5b7dc6787",
    "content": "#pragma once\n\n#include \"column.h\"\n#include \"utils.h\"\n\n#include <vector>\n\nnamespace clickhouse {\n\n/**\n * Represents column of Tuple([T]).\n */\nclass ColumnTuple : public Column {\npublic:\n    ColumnTuple(const std::vector<ColumnRef>& columns);\n\n    /// Returns count of columns in the tuple.\n    size_t TupleSize() const;\n\n    inline ColumnRef operator [] (size_t n) const {\n        return columns_[n];\n    }\n\n    inline ColumnRef At(size_t n) const {\n        return columns_[n];\n    }\n\npublic:\n    /// Increase the capacity of the column for large block insertion.\n    void Reserve(size_t new_cap) override;\n\n    /// Appends content of given column to the end of current one.\n    void Append(ColumnRef column) override;\n\n    /// Loads column prefix from input stream.\n    bool LoadPrefix(InputStream* input, size_t rows) override;\n\n    /// Loads column data from input stream.\n    bool LoadBody(InputStream* input, size_t rows) override;\n\n    /// Saves column prefix to output stream.\n    void SavePrefix(OutputStream* output) override;\n\n    /// Saves column data to output stream.\n    void SaveBody(OutputStream* output) override;\n\n    /// Clear column data .\n    void Clear() override;\n\n    /// Returns count of rows in the column.\n    size_t Size() const override;\n\n    /// Makes slice of the current column.\n    ColumnRef Slice(size_t, size_t) const override;\n    ColumnRef CloneEmpty() const override;\n    void Swap(Column& other) override;\n\nprivate:\n    std::vector<ColumnRef> columns_;\n};\n\ntemplate <typename... Columns>\nclass ColumnTupleT : public ColumnTuple {\npublic:\n    using TupleOfColumns = std::tuple<std::shared_ptr<Columns>...>;\n\n    using ValueType = std::tuple<std::decay_t<decltype(std::declval<Columns>().At(0))>...>;\n\n    ColumnTupleT(std::tuple<std::shared_ptr<Columns>...> columns)\n        : ColumnTuple(TupleToVector(columns)), typed_columns_(std::move(columns)) {}\n\n    ColumnTupleT(std::vector<ColumnRef> columns)\n        : ColumnTuple(columns), typed_columns_(VectorToTuple(std::move(columns))) {}\n\n    ColumnTupleT(const std::initializer_list<ColumnRef> columns)\n        : ColumnTuple(columns), typed_columns_(VectorToTuple(std::move(columns))) {}\n\n    inline ValueType At(size_t index) const { return GetTupleOfValues(index); }\n\n    inline ValueType operator[](size_t index) const { return GetTupleOfValues(index); }\n\n    using ColumnTuple::Append;\n\n    template <typename... T>\n    inline void Append(std::tuple<T...> value) {\n        AppendTuple(std::move(value));\n    }\n\n    /** Create a ColumnTupleT from a ColumnTuple, without copying data and offsets, but by\n     * 'stealing' those from `col`.\n     *\n     *  Ownership of column internals is transferred to returned object, original (argument) object\n     *  MUST NOT BE USED IN ANY WAY, it is only safe to dispose it.\n     *\n     *  Throws an exception if `col` is of wrong type, it is safe to use original col in this case.\n     *  This is a static method to make such conversion verbose.\n     */\n    static auto Wrap(ColumnTuple&& col) {\n        if (col.TupleSize() != std::tuple_size_v<TupleOfColumns>) {\n            throw ValidationError(\"Can't wrap from \" + col.GetType().GetName());\n        }\n        return std::make_shared<ColumnTupleT<Columns...>>(VectorToTuple(std::move(col)));\n    }\n\n    static auto Wrap(Column&& col) { return Wrap(std::move(dynamic_cast<ColumnTuple&&>(col))); }\n\n    // Helper to simplify integration with other APIs\n    static auto Wrap(ColumnRef&& col) { return Wrap(std::move(*col->AsStrict<ColumnTuple>())); }\n\n    ColumnRef Slice(size_t begin, size_t size) const override {\n        return Wrap(ColumnTuple::Slice(begin, size));\n    }\n\n    ColumnRef CloneEmpty() const override { return Wrap(ColumnTuple::CloneEmpty()); }\n\n    void Swap(Column& other) override {\n        auto& col = dynamic_cast<ColumnTupleT<Columns...>&>(other);\n        typed_columns_.swap(col.typed_columns_);\n        ColumnTuple::Swap(other);\n    }\n\nprivate:\n    template <typename T, size_t index = std::tuple_size_v<T>>\n    inline void AppendTuple([[maybe_unused]] T value) {\n        static_assert(index <= std::tuple_size_v<T>);\n        static_assert(std::tuple_size_v<TupleOfColumns> == std::tuple_size_v<T>);\n        if constexpr (index == 0) {\n            return;\n        } else {\n            std::get<index - 1>(typed_columns_)->Append(std::move(std::get<index - 1>(value)));\n            AppendTuple<T, index - 1>(std::move(value));\n        }\n    }\n\n    template <typename T, size_t index = std::tuple_size_v<T>>\n    inline static std::vector<ColumnRef> TupleToVector([[maybe_unused]] const T& value) {\n        static_assert(index <= std::tuple_size_v<T>);\n        if constexpr (index == 0) {\n            std::vector<ColumnRef> result;\n            result.reserve(std::tuple_size_v<T>);\n            return result;\n        } else {\n            auto result = TupleToVector<T, index - 1>(value);\n            result.push_back(std::get<index - 1>(value));\n            return result;\n        }\n    }\n\n    template <typename T, size_t column_index = std::tuple_size_v<TupleOfColumns>>\n    inline static auto VectorToTuple([[maybe_unused]] T columns) {\n        static_assert(column_index <= std::tuple_size_v<TupleOfColumns>);\n        if constexpr (column_index == 0) {\n            return std::make_tuple();\n        } else {\n            using ColumnType =\n                typename std::tuple_element<column_index - 1, TupleOfColumns>::type::element_type;\n            auto column = WrapColumn<ColumnType>(columns[column_index - 1]);\n            return std::tuple_cat(std::move(VectorToTuple<T, column_index - 1>(std::move(columns))),\n                                  std::make_tuple(std::move(column)));\n        }\n    }\n\n    template <size_t column_index = std::tuple_size_v<TupleOfColumns>>\n    inline auto GetTupleOfValues([[maybe_unused]]size_t index) const {\n        static_assert(column_index <= std::tuple_size_v<TupleOfColumns>);\n        if constexpr (column_index == 0) {\n            return std::make_tuple();\n        } else {\n            return std::tuple_cat(\n                std::move(GetTupleOfValues<column_index - 1>(index)),\n                std::move(std::make_tuple(std::get<column_index - 1>(typed_columns_)->At(index))));\n        }\n    }\n\n    TupleOfColumns typed_columns_;\n};\n\n}  // namespace clickhouse\n",
    "chunks": [
      {
        "chunk_id": "doc_22_chunk_0",
        "original_index": 0,
        "content": "#pragma once\n\n#include \"column.h\"\n#include \"utils.h\"\n\n#include <vector>\n\nnamespace clickhouse {\n\n/**\n * Represents column of Tuple([T]).\n */\nclass ColumnTuple : public Column {\npublic:\n    ColumnTuple(const std::vector<ColumnRef>& columns);\n\n    /// Returns count of columns in the tuple.\n    size_t TupleSize() const;\n\n    inline ColumnRef operator [] (size_t n) const {\n        return columns_[n];\n    }\n\n    inline ColumnRef At(size_t n) const {\n        return columns_[n];\n    }\n\npublic:\n    /// Increase the capacity of the column for large block insertion.\n    void Reserve(size_t new_cap) override;\n\n    /// Appends content of given column to the end of current one.\n    void Append(ColumnRef column) override;\n\n"
      },
      {
        "chunk_id": "doc_22_chunk_1",
        "original_index": 1,
        "content": "    /// Loads column prefix from input stream.\n    bool LoadPrefix(InputStream* input, size_t rows) override;\n\n    /// Loads column data from input stream.\n    bool LoadBody(InputStream* input, size_t rows) override;\n\n    /// Saves column prefix to output stream.\n    void SavePrefix(OutputStream* output) override;\n\n    /// Saves column data to output stream.\n    void SaveBody(OutputStream* output) override;\n\n    /// Clear column data .\n    void Clear() override;\n\n    /// Returns count of rows in the column.\n    size_t Size() const override;\n\n    /// Makes slice of the current column.\n    ColumnRef Slice(size_t, size_t) const override;\n    ColumnRef CloneEmpty() const override;\n    void Swap(Column& other) override;\n\n"
      },
      {
        "chunk_id": "doc_22_chunk_2",
        "original_index": 2,
        "content": "private:\n    std::vector<ColumnRef> columns_;\n};\n\ntemplate <typename... Columns>\nclass ColumnTupleT : public ColumnTuple {\npublic:\n    using TupleOfColumns = std::tuple<std::shared_ptr<Columns>...>;\n\n    using ValueType = std::tuple<std::decay_t<decltype(std::declval<Columns>().At(0))>...>;\n\n    ColumnTupleT(std::tuple<std::shared_ptr<Columns>...> columns)\n        : ColumnTuple(TupleToVector(columns)), typed_columns_(std::move(columns)) {}\n\n"
      },
      {
        "chunk_id": "doc_22_chunk_3",
        "original_index": 3,
        "content": "    ColumnTupleT(std::vector<ColumnRef> columns)\n        : ColumnTuple(columns), typed_columns_(VectorToTuple(std::move(columns))) {}\n\n    ColumnTupleT(const std::initializer_list<ColumnRef> columns)\n        : ColumnTuple(columns), typed_columns_(VectorToTuple(std::move(columns))) {}\n\n    inline ValueType At(size_t index) const { return GetTupleOfValues(index); }\n\n    inline ValueType operator[](size_t index) const { return GetTupleOfValues(index); }\n\n    using ColumnTuple::Append;\n\n    template <typename... T>\n    inline void Append(std::tuple<T...> value) {\n        AppendTuple(std::move(value));\n    }\n\n"
      },
      {
        "chunk_id": "doc_22_chunk_4",
        "original_index": 4,
        "content": "    /** Create a ColumnTupleT from a ColumnTuple, without copying data and offsets, but by\n     * 'stealing' those from `col`.\n     *\n     *  Ownership of column internals is transferred to returned object, original (argument) object\n     *  MUST NOT BE USED IN ANY WAY, it is only safe to dispose it.\n     *\n     *  Throws an exception if `col` is of wrong type, it is safe to use original col in this case.\n     *  This is a static method to make such conversion verbose.\n     */\n    static auto Wrap(ColumnTuple&& col) {\n        if (col.TupleSize() != std::tuple_size_v<TupleOfColumns>) {\n            throw ValidationError(\"Can't wrap from \" + col.GetType().GetName());\n        }\n        return std::make_shared<ColumnTupleT<Columns...>>(VectorToTuple(std::move(col)));\n    }\n\n"
      },
      {
        "chunk_id": "doc_22_chunk_5",
        "original_index": 5,
        "content": "    static auto Wrap(Column&& col) { return Wrap(std::move(dynamic_cast<ColumnTuple&&>(col))); }\n\n    // Helper to simplify integration with other APIs\n    static auto Wrap(ColumnRef&& col) { return Wrap(std::move(*col->AsStrict<ColumnTuple>())); }\n\n    ColumnRef Slice(size_t begin, size_t size) const override {\n        return Wrap(ColumnTuple::Slice(begin, size));\n    }\n\n    ColumnRef CloneEmpty() const override { return Wrap(ColumnTuple::CloneEmpty()); }\n\n    void Swap(Column& other) override {\n        auto& col = dynamic_cast<ColumnTupleT<Columns...>&>(other);\n        typed_columns_.swap(col.typed_columns_);\n        ColumnTuple::Swap(other);\n    }\n\n"
      },
      {
        "chunk_id": "doc_22_chunk_6",
        "original_index": 6,
        "content": "private:\n    template <typename T, size_t index = std::tuple_size_v<T>>\n    inline void AppendTuple([[maybe_unused]] T value) {\n        static_assert(index <= std::tuple_size_v<T>);\n        static_assert(std::tuple_size_v<TupleOfColumns> == std::tuple_size_v<T>);\n        if constexpr (index == 0) {\n            return;\n        } else {\n            std::get<index - 1>(typed_columns_)->Append(std::move(std::get<index - 1>(value)));\n            AppendTuple<T, index - 1>(std::move(value));\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_22_chunk_7",
        "original_index": 7,
        "content": "    template <typename T, size_t index = std::tuple_size_v<T>>\n    inline static std::vector<ColumnRef> TupleToVector([[maybe_unused]] const T& value) {\n        static_assert(index <= std::tuple_size_v<T>);\n        if constexpr (index == 0) {\n            std::vector<ColumnRef> result;\n            result.reserve(std::tuple_size_v<T>);\n            return result;\n        } else {\n            auto result = TupleToVector<T, index - 1>(value);\n            result.push_back(std::get<index - 1>(value));\n            return result;\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_22_chunk_8",
        "original_index": 8,
        "content": "    template <typename T, size_t column_index = std::tuple_size_v<TupleOfColumns>>\n    inline static auto VectorToTuple([[maybe_unused]] T columns) {\n        static_assert(column_index <= std::tuple_size_v<TupleOfColumns>);\n        if constexpr (column_index == 0) {\n            return std::make_tuple();\n        } else {\n            using ColumnType =\n                typename std::tuple_element<column_index - 1, TupleOfColumns>::type::element_type;\n            auto column = WrapColumn<ColumnType>(columns[column_index - 1]);\n            return std::tuple_cat(std::move(VectorToTuple<T, column_index - 1>(std::move(columns))),\n                                  std::make_tuple(std::move(column)));\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_22_chunk_9",
        "original_index": 9,
        "content": "    template <size_t column_index = std::tuple_size_v<TupleOfColumns>>\n    inline auto GetTupleOfValues([[maybe_unused]]size_t index) const {\n        static_assert(column_index <= std::tuple_size_v<TupleOfColumns>);\n        if constexpr (column_index == 0) {\n            return std::make_tuple();\n        } else {\n            return std::tuple_cat(\n                std::move(GetTupleOfValues<column_index - 1>(index)),\n                std::move(std::make_tuple(std::get<column_index - 1>(typed_columns_)->At(index))));\n        }\n    }\n\n    TupleOfColumns typed_columns_;\n};\n\n}  // namespace clickhouse\n"
      }
    ]
  },
  {
    "doc_id": "doc_23",
    "original_uuid": "68689866af92461ae59fa9f0bc3064ba012e1482bce9a48fc44e1b25a26ac50c",
    "content": "#pragma once\n\n#include \"numeric.h\"\n\nstruct in_addr;\n\nnamespace clickhouse {\n\nclass ColumnIPv4 : public Column {\npublic:\n    using DataType = in_addr;\n    using ValueType = in_addr;\n\n    ColumnIPv4();\n    /** Takes ownership of the data, expects ColumnUInt32.\n     * Modifying memory pointed by `data` from outside is UB.\n     *\n     * TODO: deprecate and remove as it is too dangerous and error-prone.\n     */\n    explicit ColumnIPv4(ColumnRef data);\n\n    explicit ColumnIPv4(std::vector<uint32_t>&& data);\n\n    /// Appends one element to the column.\n    void Append(const std::string& ip);\n\n    /// @params ip numeric value with host byte order.\n    void Append(uint32_t ip);\n\n    ///\n    void Append(in_addr ip);\n\n    /// Returns element at given row number.\n    in_addr At(size_t n) const;\n\n    /// Returns element at given row number.\n    in_addr operator [] (size_t n) const;\n\n    std::string AsString(size_t n) const;\n\npublic:\n    /// Increase the capacity of the column for large block insertion.\n    void Reserve(size_t new_cap) override;\n\n    /// Appends content of given column to the end of current one.\n    void Append(ColumnRef column) override;\n\n    /// Loads column data from input stream.\n    bool LoadBody(InputStream* input, size_t rows) override;\n\n    /// Saves column data to output stream.\n    void SaveBody(OutputStream* output) override;\n\n    /// Clear column data .\n    void Clear() override;\n\n    /// Returns count of rows in the column.\n    size_t Size() const override;\n\n    /// Makes slice of the current column.\n    ColumnRef Slice(size_t begin, size_t len) const override;\n    ColumnRef CloneEmpty() const override;\n    void Swap(Column& other) override;\n\n    ItemView GetItem(size_t index) const override;\n\nprivate:\n    std::shared_ptr<ColumnUInt32> data_;\n};\n\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_23_chunk_0",
        "original_index": 0,
        "content": "#pragma once\n\n#include \"numeric.h\"\n\nstruct in_addr;\n\nnamespace clickhouse {\n\nclass ColumnIPv4 : public Column {\npublic:\n    using DataType = in_addr;\n    using ValueType = in_addr;\n\n    ColumnIPv4();\n    /** Takes ownership of the data, expects ColumnUInt32.\n     * Modifying memory pointed by `data` from outside is UB.\n     *\n     * TODO: deprecate and remove as it is too dangerous and error-prone.\n     */\n    explicit ColumnIPv4(ColumnRef data);\n\n    explicit ColumnIPv4(std::vector<uint32_t>&& data);\n\n    /// Appends one element to the column.\n    void Append(const std::string& ip);\n\n"
      },
      {
        "chunk_id": "doc_23_chunk_1",
        "original_index": 1,
        "content": "    /// @params ip numeric value with host byte order.\n    void Append(uint32_t ip);\n\n    ///\n    void Append(in_addr ip);\n\n    /// Returns element at given row number.\n    in_addr At(size_t n) const;\n\n    /// Returns element at given row number.\n    in_addr operator [] (size_t n) const;\n\n    std::string AsString(size_t n) const;\n\npublic:\n    /// Increase the capacity of the column for large block insertion.\n    void Reserve(size_t new_cap) override;\n\n    /// Appends content of given column to the end of current one.\n    void Append(ColumnRef column) override;\n\n"
      },
      {
        "chunk_id": "doc_23_chunk_2",
        "original_index": 2,
        "content": "    /// Loads column data from input stream.\n    bool LoadBody(InputStream* input, size_t rows) override;\n\n    /// Saves column data to output stream.\n    void SaveBody(OutputStream* output) override;\n\n    /// Clear column data .\n    void Clear() override;\n\n    /// Returns count of rows in the column.\n    size_t Size() const override;\n\n    /// Makes slice of the current column.\n    ColumnRef Slice(size_t begin, size_t len) const override;\n    ColumnRef CloneEmpty() const override;\n    void Swap(Column& other) override;\n\n    ItemView GetItem(size_t index) const override;\n\nprivate:\n    std::shared_ptr<ColumnUInt32> data_;\n};\n\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_24",
    "original_uuid": "8001dcf16ed7af29411a65852c128e572d3ca6697c0f70ae4e1018147047ea69",
    "content": "#include \"type_parser.h\"\n\n#include \"clickhouse/exceptions.h\"\n#include \"clickhouse/base/platform.h\" // for _win_\n\n#include <algorithm>\n#include <cmath>\n#include <map>\n#include <mutex>\n#include <unordered_map>\n\n#if defined _win_\n#include <string.h>\n#else\n#include <strings.h>\n#endif\n\n\nnamespace clickhouse {\n\nbool TypeAst::operator==(const TypeAst & other) const {\n    return meta == other.meta\n        && code == other.code\n        && name == other.name\n        && value == other.value\n        && std::equal(elements.begin(), elements.end(), other.elements.begin(), other.elements.end());\n}\n\nstatic const std::unordered_map<std::string, Type::Code> kTypeCode = {\n    { \"Void\",        Type::Void },\n    { \"Int8\",        Type::Int8 },\n    { \"Int16\",       Type::Int16 },\n    { \"Int32\",       Type::Int32 },\n    { \"Int64\",       Type::Int64 },\n    { \"Bool\",        Type::UInt8 },\n    { \"UInt8\",       Type::UInt8 },\n    { \"UInt16\",      Type::UInt16 },\n    { \"UInt32\",      Type::UInt32 },\n    { \"UInt64\",      Type::UInt64 },\n    { \"Float32\",     Type::Float32 },\n    { \"Float64\",     Type::Float64 },\n    { \"String\",      Type::String },\n    { \"FixedString\", Type::FixedString },\n    { \"DateTime\",    Type::DateTime },\n    { \"DateTime64\",  Type::DateTime64 },\n    { \"Date\",        Type::Date },\n    { \"Date32\",      Type::Date32 },\n    { \"Array\",       Type::Array },\n    { \"Nullable\",    Type::Nullable },\n    { \"Tuple\",       Type::Tuple },\n    { \"Enum8\",       Type::Enum8 },\n    { \"Enum16\",      Type::Enum16 },\n    { \"UUID\",        Type::UUID },\n    { \"IPv4\",        Type::IPv4 },\n    { \"IPv6\",        Type::IPv6 },\n    { \"Int128\",      Type::Int128 },\n//    { \"UInt128\",      Type::UInt128 },\n    { \"Decimal\",     Type::Decimal },\n    { \"Decimal32\",   Type::Decimal32 },\n    { \"Decimal64\",   Type::Decimal64 },\n    { \"Decimal128\",  Type::Decimal128 },\n    { \"LowCardinality\", Type::LowCardinality },\n    { \"Map\",         Type::Map },\n    { \"Point\",       Type::Point },\n    { \"Ring\",        Type::Ring },\n    { \"Polygon\",     Type::Polygon },\n    { \"MultiPolygon\", Type::MultiPolygon },\n};\n\ntemplate <typename L, typename R>\ninline int CompateStringsCaseInsensitive(const L& left, const R& right) {\n    int64_t size_diff = left.size() - right.size();\n    if (size_diff != 0)\n        return size_diff > 0 ? 1 : -1;\n\n#if defined _win_\n    return _strnicmp(left.data(), right.data(), left.size());\n#else\n    return strncasecmp(left.data(), right.data(), left.size());\n#endif\n}\n\nstatic Type::Code GetTypeCode(const std::string& name) {\n    auto it = kTypeCode.find(name);\n    if (it != kTypeCode.end()) {\n        return it->second;\n    }\n\n    return Type::Void;\n}\n\nstatic TypeAst::Meta GetTypeMeta(const StringView& name) {\n    if (name == \"Array\") {\n        return TypeAst::Array;\n    }\n\n    if (name == \"Null\") {\n        return TypeAst::Null;\n    }\n\n    if (name == \"Nullable\") {\n        return TypeAst::Nullable;\n    }\n\n    if (name == \"Tuple\") {\n        return TypeAst::Tuple;\n    }\n\n    if (name == \"Enum8\" || name == \"Enum16\") {\n        return TypeAst::Enum;\n    }\n\n    if (name == \"LowCardinality\") {\n        return TypeAst::LowCardinality;\n    }\n\n    if (name == \"SimpleAggregateFunction\") {\n        return TypeAst::SimpleAggregateFunction;\n    }\n\n    if (name == \"Map\") {\n        return TypeAst::Map;\n    }\n\n    return TypeAst::Terminal;\n}\n\nbool ValidateAST(const TypeAst& ast) {\n    // Void terminal that is not actually \"void\" produced when unknown type is encountered.\n    if (ast.meta == TypeAst::Terminal\n            && ast.code == Type::Void\n            && CompateStringsCaseInsensitive(ast.name, std::string_view(\"void\")) != 0)\n        //throw UnimplementedError(\"Unsupported type: \" + ast.name);\n        return false;\n\n    return true;\n}\n\n\nTypeParser::TypeParser(const StringView& name)\n    : cur_(name.data())\n    , end_(name.data() + name.size())\n    , type_(nullptr)\n{\n}\n\nTypeParser::~TypeParser() = default;\n\nbool TypeParser::Parse(TypeAst* type) {\n    type_ = type;\n    open_elements_.push(type_);\n\n    size_t processed_tokens = 0;\n    do {\n        const Token & token = NextToken();\n        switch (token.type) {\n            case Token::QuotedString:\n            {\n                type_->meta = TypeAst::Terminal;\n                if (token.value.length() < 1)\n                    type_->value_string = {};\n                else\n                    type_->value_string = token.value.substr(1, token.value.length() - 2).to_string();\n                type_->code = Type::String;\n                break;\n            }\n            case Token::Name:\n                type_->meta = GetTypeMeta(token.value);\n                type_->name = token.value.to_string();\n                type_->code = GetTypeCode(type_->name);\n                break;\n            case Token::Number:\n                type_->meta = TypeAst::Number;\n                type_->value = std::stol(token.value.to_string());\n                break;\n            case Token::String:\n                type_->meta = TypeAst::String;\n                type_->value_string = std::string(token.value);\n                break;\n            case Token::LPar:\n                type_->elements.emplace_back(TypeAst());\n                open_elements_.push(type_);\n                type_ = &type_->elements.back();\n                break;\n            case Token::RPar:\n                type_ = open_elements_.top();\n                open_elements_.pop();\n                break;\n            case Token::Assign:\n            case Token::Comma:\n                type_ = open_elements_.top();\n                open_elements_.pop();\n                type_->elements.emplace_back(TypeAst());\n                open_elements_.push(type_);\n                type_ = &type_->elements.back();\n                break;\n            case Token::EOS:\n            {\n                // Ubalanced braces, brackets, etc is an error.\n                if (open_elements_.size() != 1)\n                    return false;\n\n                // Empty input string, no tokens produced\n                if (processed_tokens == 0)\n                    return false;\n\n                return ValidateAST(*type);\n            }\n            case Token::Invalid:\n                return false;\n        }\n        ++processed_tokens;\n    } while (true);\n}\n\nTypeParser::Token TypeParser::NextToken() {\n    for (; cur_ < end_; ++cur_) {\n        switch (*cur_) {\n            case ' ':\n            case '\\n':\n            case '\\t':\n            case '\\0':\n                continue;\n            case '=':\n                return Token{Token::Assign, StringView(cur_++, 1)};\n            case '(':\n                return Token{Token::LPar, StringView(cur_++, 1)};\n            case ')':\n                return Token{Token::RPar, StringView(cur_++, 1)};\n            case ',':\n                return Token{Token::Comma, StringView(cur_++, 1)};\n            case '\\'':\n            {\n                const auto end_quote_length = 1;\n                const StringView end_quote{cur_, end_quote_length};\n                // Fast forward to the closing quote.\n                const auto start = cur_++;\n                for (; cur_ < end_ - end_quote_length; ++cur_) {\n                    // TODO (nemkov): handle escaping ?\n                    if (end_quote == StringView{cur_, end_quote_length}) {\n                        cur_ += end_quote_length;\n\n                        return Token{Token::QuotedString, StringView{start, cur_}};\n                    }\n                }\n                return Token{Token::QuotedString, StringView(cur_++, 1)};\n            }\n\n            default: {\n                const char* st = cur_;\n\n                if (*cur_ == '\\'') {\n                    for (st = ++cur_; cur_ < end_; ++cur_) {\n                        if (*cur_ == '\\'') {\n                            return Token{Token::String, StringView(st, cur_++ - st)};\n                        }\n                    }\n\n                    return Token{Token::Invalid, StringView()};\n                }\n\n                if (isalpha(*cur_) || *cur_ == '_') {\n                    for (; cur_ < end_; ++cur_) {\n                        if (!isalpha(*cur_) && !isdigit(*cur_) && *cur_ != '_') {\n                            break;\n                        }\n                    }\n\n                    return Token{Token::Name, StringView(st, cur_)};\n                }\n\n                if (isdigit(*cur_) || *cur_ == '-') {\n                    for (++cur_; cur_ < end_; ++cur_) {\n                        if (!isdigit(*cur_)) {\n                            break;\n                        }\n                    }\n\n                    return Token{Token::Number, StringView(st, cur_)};\n                }\n\n                return Token{Token::Invalid, StringView()};\n            }\n        }\n    }\n\n    return Token{Token::EOS, StringView()};\n}\n\n\nconst TypeAst* ParseTypeName(const std::string& type_name) {\n    // Cache for type_name.\n    // Usually we won't have too many type names in the cache, so do not try to\n    // limit cache size.\n    static std::map<std::string, TypeAst> ast_cache;\n    static std::mutex lock;\n\n    std::lock_guard<std::mutex> guard(lock);\n    auto it = ast_cache.find(type_name);\n    if (it != ast_cache.end()) {\n        return &it->second;\n    }\n\n    auto& ast = ast_cache[type_name];\n    if (TypeParser(type_name).Parse(&ast)) {\n        return &ast;\n    }\n    ast_cache.erase(type_name);\n    return nullptr;\n}\n\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_24_chunk_0",
        "original_index": 0,
        "content": "#include \"type_parser.h\"\n\n#include \"clickhouse/exceptions.h\"\n#include \"clickhouse/base/platform.h\" // for _win_\n\n#include <algorithm>\n#include <cmath>\n#include <map>\n#include <mutex>\n#include <unordered_map>\n\n#if defined _win_\n#include <string.h>\n#else\n#include <strings.h>\n#endif\n\n\nnamespace clickhouse {\n\nbool TypeAst::operator==(const TypeAst & other) const {\n    return meta == other.meta\n        && code == other.code\n        && name == other.name\n        && value == other.value\n        && std::equal(elements.begin(), elements.end(), other.elements.begin(), other.elements.end());\n}\n\n"
      },
      {
        "chunk_id": "doc_24_chunk_1",
        "original_index": 1,
        "content": "static const std::unordered_map<std::string, Type::Code> kTypeCode = {\n    { \"Void\",        Type::Void },\n    { \"Int8\",        Type::Int8 },\n    { \"Int16\",       Type::Int16 },\n    { \"Int32\",       Type::Int32 },\n    { \"Int64\",       Type::Int64 },\n    { \"Bool\",        Type::UInt8 },\n    { \"UInt8\",       Type::UInt8 },\n    { \"UInt16\",      Type::UInt16 },\n    { \"UInt32\",      Type::UInt32 },\n    { \"UInt64\",      Type::UInt64 },\n    { \"Float32\",     Type::Float32 },\n    { \"Float64\",     Type::Float64 },\n    { \"String\",      Type::String },\n    { \"FixedString\", Type::FixedString },\n    { \"DateTime\",    Type::DateTime },\n    { \"DateTime64\",  Type::DateTime64 },\n"
      },
      {
        "chunk_id": "doc_24_chunk_2",
        "original_index": 2,
        "content": "    { \"Date\",        Type::Date },\n    { \"Date32\",      Type::Date32 },\n    { \"Array\",       Type::Array },\n    { \"Nullable\",    Type::Nullable },\n    { \"Tuple\",       Type::Tuple },\n    { \"Enum8\",       Type::Enum8 },\n    { \"Enum16\",      Type::Enum16 },\n    { \"UUID\",        Type::UUID },\n    { \"IPv4\",        Type::IPv4 },\n    { \"IPv6\",        Type::IPv6 },\n    { \"Int128\",      Type::Int128 },\n//    { \"UInt128\",      Type::UInt128 },\n    { \"Decimal\",     Type::Decimal },\n    { \"Decimal32\",   Type::Decimal32 },\n    { \"Decimal64\",   Type::Decimal64 },\n    { \"Decimal128\",  Type::Decimal128 },\n    { \"LowCardinality\", Type::LowCardinality },\n    { \"Map\",         Type::Map },\n    { \"Point\",       Type::Point },\n    { \"Ring\",        Type::Ring },\n    { \"Polygon\",     Type::Polygon },\n    { \"MultiPolygon\", Type::MultiPolygon },\n};\n\n"
      },
      {
        "chunk_id": "doc_24_chunk_3",
        "original_index": 3,
        "content": "template <typename L, typename R>\ninline int CompateStringsCaseInsensitive(const L& left, const R& right) {\n    int64_t size_diff = left.size() - right.size();\n    if (size_diff != 0)\n        return size_diff > 0 ? 1 : -1;\n\n#if defined _win_\n    return _strnicmp(left.data(), right.data(), left.size());\n#else\n    return strncasecmp(left.data(), right.data(), left.size());\n#endif\n}\n\nstatic Type::Code GetTypeCode(const std::string& name) {\n    auto it = kTypeCode.find(name);\n    if (it != kTypeCode.end()) {\n        return it->second;\n    }\n\n    return Type::Void;\n}\n\nstatic TypeAst::Meta GetTypeMeta(const StringView& name) {\n    if (name == \"Array\") {\n        return TypeAst::Array;\n    }\n\n"
      },
      {
        "chunk_id": "doc_24_chunk_4",
        "original_index": 4,
        "content": "    if (name == \"Null\") {\n        return TypeAst::Null;\n    }\n\n    if (name == \"Nullable\") {\n        return TypeAst::Nullable;\n    }\n\n    if (name == \"Tuple\") {\n        return TypeAst::Tuple;\n    }\n\n    if (name == \"Enum8\" || name == \"Enum16\") {\n        return TypeAst::Enum;\n    }\n\n    if (name == \"LowCardinality\") {\n        return TypeAst::LowCardinality;\n    }\n\n    if (name == \"SimpleAggregateFunction\") {\n        return TypeAst::SimpleAggregateFunction;\n    }\n\n    if (name == \"Map\") {\n        return TypeAst::Map;\n    }\n\n    return TypeAst::Terminal;\n}\n\n"
      },
      {
        "chunk_id": "doc_24_chunk_5",
        "original_index": 5,
        "content": "bool ValidateAST(const TypeAst& ast) {\n    // Void terminal that is not actually \"void\" produced when unknown type is encountered.\n    if (ast.meta == TypeAst::Terminal\n            && ast.code == Type::Void\n            && CompateStringsCaseInsensitive(ast.name, std::string_view(\"void\")) != 0)\n        //throw UnimplementedError(\"Unsupported type: \" + ast.name);\n        return false;\n\n    return true;\n}\n\n\nTypeParser::TypeParser(const StringView& name)\n    : cur_(name.data())\n    , end_(name.data() + name.size())\n    , type_(nullptr)\n{\n}\n\nTypeParser::~TypeParser() = default;\n\nbool TypeParser::Parse(TypeAst* type) {\n    type_ = type;\n    open_elements_.push(type_);\n\n"
      },
      {
        "chunk_id": "doc_24_chunk_6",
        "original_index": 6,
        "content": "    size_t processed_tokens = 0;\n    do {\n        const Token & token = NextToken();\n        switch (token.type) {\n            case Token::QuotedString:\n            {\n                type_->meta = TypeAst::Terminal;\n                if (token.value.length() < 1)\n                    type_->value_string = {};\n                else\n                    type_->value_string = token.value.substr(1, token.value.length() - 2).to_string();\n"
      },
      {
        "chunk_id": "doc_24_chunk_7",
        "original_index": 7,
        "content": "                type_->code = Type::String;\n                break;\n            }\n            case Token::Name:\n                type_->meta = GetTypeMeta(token.value);\n                type_->name = token.value.to_string();\n                type_->code = GetTypeCode(type_->name);\n                break;\n            case Token::Number:\n                type_->meta = TypeAst::Number;\n                type_->value = std::stol(token.value.to_string());\n                break;\n            case Token::String:\n                type_->meta = TypeAst::String;\n                type_->value_string = std::string(token.value);\n"
      },
      {
        "chunk_id": "doc_24_chunk_8",
        "original_index": 8,
        "content": "                break;\n            case Token::LPar:\n                type_->elements.emplace_back(TypeAst());\n                open_elements_.push(type_);\n                type_ = &type_->elements.back();\n                break;\n            case Token::RPar:\n                type_ = open_elements_.top();\n                open_elements_.pop();\n                break;\n            case Token::Assign:\n            case Token::Comma:\n                type_ = open_elements_.top();\n                open_elements_.pop();\n                type_->elements.emplace_back(TypeAst());\n                open_elements_.push(type_);\n                type_ = &type_->elements.back();\n                break;\n            case Token::EOS:\n            {\n                // Ubalanced braces, brackets, etc is an error.\n                if (open_elements_.size() != 1)\n                    return false;\n\n"
      },
      {
        "chunk_id": "doc_24_chunk_9",
        "original_index": 9,
        "content": "                // Empty input string, no tokens produced\n                if (processed_tokens == 0)\n                    return false;\n\n                return ValidateAST(*type);\n            }\n            case Token::Invalid:\n                return false;\n        }\n        ++processed_tokens;\n    } while (true);\n}\n\nTypeParser::Token TypeParser::NextToken() {\n    for (; cur_ < end_; ++cur_) {\n        switch (*cur_) {\n            case ' ':\n            case '\\n':\n            case '\\t':\n            case '\\0':\n                continue;\n            case '=':\n                return Token{Token::Assign, StringView(cur_++, 1)};\n            case '(':\n                return Token{Token::LPar, StringView(cur_++, 1)};\n            case ')':\n                return Token{Token::RPar, StringView(cur_++, 1)};\n"
      },
      {
        "chunk_id": "doc_24_chunk_10",
        "original_index": 10,
        "content": "            case ',':\n                return Token{Token::Comma, StringView(cur_++, 1)};\n            case '\\'':\n            {\n                const auto end_quote_length = 1;\n                const StringView end_quote{cur_, end_quote_length};\n                // Fast forward to the closing quote.\n                const auto start = cur_++;\n                for (; cur_ < end_ - end_quote_length; ++cur_) {\n                    // TODO (nemkov): handle escaping ?\n                    if (end_quote == StringView{cur_, end_quote_length}) {\n                        cur_ += end_quote_length;\n\n"
      },
      {
        "chunk_id": "doc_24_chunk_11",
        "original_index": 11,
        "content": "                        return Token{Token::QuotedString, StringView{start, cur_}};\n                    }\n                }\n                return Token{Token::QuotedString, StringView(cur_++, 1)};\n            }\n\n            default: {\n                const char* st = cur_;\n\n                if (*cur_ == '\\'') {\n                    for (st = ++cur_; cur_ < end_; ++cur_) {\n                        if (*cur_ == '\\'') {\n                            return Token{Token::String, StringView(st, cur_++ - st)};\n                        }\n                    }\n\n"
      },
      {
        "chunk_id": "doc_24_chunk_12",
        "original_index": 12,
        "content": "                    return Token{Token::Invalid, StringView()};\n                }\n\n                if (isalpha(*cur_) || *cur_ == '_') {\n                    for (; cur_ < end_; ++cur_) {\n                        if (!isalpha(*cur_) && !isdigit(*cur_) && *cur_ != '_') {\n                            break;\n                        }\n                    }\n\n                    return Token{Token::Name, StringView(st, cur_)};\n                }\n\n                if (isdigit(*cur_) || *cur_ == '-') {\n                    for (++cur_; cur_ < end_; ++cur_) {\n                        if (!isdigit(*cur_)) {\n                            break;\n                        }\n                    }\n\n"
      },
      {
        "chunk_id": "doc_24_chunk_13",
        "original_index": 13,
        "content": "                    return Token{Token::Number, StringView(st, cur_)};\n                }\n\n                return Token{Token::Invalid, StringView()};\n            }\n        }\n    }\n\n    return Token{Token::EOS, StringView()};\n}\n\n\nconst TypeAst* ParseTypeName(const std::string& type_name) {\n    // Cache for type_name.\n    // Usually we won't have too many type names in the cache, so do not try to\n    // limit cache size.\n    static std::map<std::string, TypeAst> ast_cache;\n    static std::mutex lock;\n\n    std::lock_guard<std::mutex> guard(lock);\n    auto it = ast_cache.find(type_name);\n    if (it != ast_cache.end()) {\n        return &it->second;\n    }\n\n    auto& ast = ast_cache[type_name];\n    if (TypeParser(type_name).Parse(&ast)) {\n        return &ast;\n    }\n    ast_cache.erase(type_name);\n    return nullptr;\n}\n\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_25",
    "original_uuid": "e3d478567bc2bb9f55952c093a97847b3dc538cdcdd9d8b74b855857cf238bd1",
    "content": "// Copyright 2005, Google Inc.\n// All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions are\n// met:\n//\n//     * Redistributions of source code must retain the above copyright\n// notice, this list of conditions and the following disclaimer.\n//     * Redistributions in binary form must reproduce the above\n// copyright notice, this list of conditions and the following disclaimer\n// in the documentation and/or other materials provided with the\n// distribution.\n//     * Neither the name of Google Inc. nor the names of its\n// contributors may be used to endorse or promote products derived from\n// this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n//\n// The Google C++ Testing and Mocking Framework (Google Test)\n//\n// This header file defines the public API for death tests.  It is\n// #included by gtest.h so a user doesn't need to include this\n// directly.\n// GOOGLETEST_CM0001 DO NOT DELETE\n\n#ifndef GOOGLETEST_INCLUDE_GTEST_GTEST_DEATH_TEST_H_\n#define GOOGLETEST_INCLUDE_GTEST_GTEST_DEATH_TEST_H_\n\n#include \"gtest/internal/gtest-death-test-internal.h\"\n\nnamespace testing {\n\n// This flag controls the style of death tests.  Valid values are \"threadsafe\",\n// meaning that the death test child process will re-execute the test binary\n// from the start, running only a single death test, or \"fast\",\n// meaning that the child process will execute the test logic immediately\n// after forking.\nGTEST_DECLARE_string_(death_test_style);\n\n#if GTEST_HAS_DEATH_TEST\n\nnamespace internal {\n\n// Returns a Boolean value indicating whether the caller is currently\n// executing in the context of the death test child process.  Tools such as\n// Valgrind heap checkers may need this to modify their behavior in death\n// tests.  IMPORTANT: This is an internal utility.  Using it may break the\n// implementation of death tests.  User code MUST NOT use it.\nGTEST_API_ bool InDeathTestChild();\n\n}  // namespace internal\n\n// The following macros are useful for writing death tests.\n\n// Here's what happens when an ASSERT_DEATH* or EXPECT_DEATH* is\n// executed:\n//\n//   1. It generates a warning if there is more than one active\n//   thread.  This is because it's safe to fork() or clone() only\n//   when there is a single thread.\n//\n//   2. The parent process clone()s a sub-process and runs the death\n//   test in it; the sub-process exits with code 0 at the end of the\n//   death test, if it hasn't exited already.\n//\n//   3. The parent process waits for the sub-process to terminate.\n//\n//   4. The parent process checks the exit code and error message of\n//   the sub-process.\n//\n// Examples:\n//\n//   ASSERT_DEATH(server.SendMessage(56, \"Hello\"), \"Invalid port number\");\n//   for (int i = 0; i < 5; i++) {\n//     EXPECT_DEATH(server.ProcessRequest(i),\n//                  \"Invalid request .* in ProcessRequest()\")\n//                  << \"Failed to die on request \" << i;\n//   }\n//\n//   ASSERT_EXIT(server.ExitNow(), ::testing::ExitedWithCode(0), \"Exiting\");\n//\n//   bool KilledBySIGHUP(int exit_code) {\n//     return WIFSIGNALED(exit_code) && WTERMSIG(exit_code) == SIGHUP;\n//   }\n//\n//   ASSERT_EXIT(client.HangUpServer(), KilledBySIGHUP, \"Hanging up!\");\n//\n// The final parameter to each of these macros is a matcher applied to any data\n// the sub-process wrote to stderr.  For compatibility with existing tests, a\n// bare string is interpreted as a regular expression matcher.\n//\n// On the regular expressions used in death tests:\n//\n//   GOOGLETEST_CM0005 DO NOT DELETE\n//   On POSIX-compliant systems (*nix), we use the <regex.h> library,\n//   which uses the POSIX extended regex syntax.\n//\n//   On other platforms (e.g. Windows or Mac), we only support a simple regex\n//   syntax implemented as part of Google Test.  This limited\n//   implementation should be enough most of the time when writing\n//   death tests; though it lacks many features you can find in PCRE\n//   or POSIX extended regex syntax.  For example, we don't support\n//   union (\"x|y\"), grouping (\"(xy)\"), brackets (\"[xy]\"), and\n//   repetition count (\"x{5,7}\"), among others.\n//\n//   Below is the syntax that we do support.  We chose it to be a\n//   subset of both PCRE and POSIX extended regex, so it's easy to\n//   learn wherever you come from.  In the following: 'A' denotes a\n//   literal character, period (.), or a single \\\\ escape sequence;\n//   'x' and 'y' denote regular expressions; 'm' and 'n' are for\n//   natural numbers.\n//\n//     c     matches any literal character c\n//     \\\\d   matches any decimal digit\n//     \\\\D   matches any character that's not a decimal digit\n//     \\\\f   matches \\f\n//     \\\\n   matches \\n\n//     \\\\r   matches \\r\n//     \\\\s   matches any ASCII whitespace, including \\n\n//     \\\\S   matches any character that's not a whitespace\n//     \\\\t   matches \\t\n//     \\\\v   matches \\v\n//     \\\\w   matches any letter, _, or decimal digit\n//     \\\\W   matches any character that \\\\w doesn't match\n//     \\\\c   matches any literal character c, which must be a punctuation\n//     .     matches any single character except \\n\n//     A?    matches 0 or 1 occurrences of A\n//     A*    matches 0 or many occurrences of A\n//     A+    matches 1 or many occurrences of A\n//     ^     matches the beginning of a string (not that of each line)\n//     $     matches the end of a string (not that of each line)\n//     xy    matches x followed by y\n//\n//   If you accidentally use PCRE or POSIX extended regex features\n//   not implemented by us, you will get a run-time failure.  In that\n//   case, please try to rewrite your regular expression within the\n//   above syntax.\n//\n//   This implementation is *not* meant to be as highly tuned or robust\n//   as a compiled regex library, but should perform well enough for a\n//   death test, which already incurs significant overhead by launching\n//   a child process.\n//\n// Known caveats:\n//\n//   A \"threadsafe\" style death test obtains the path to the test\n//   program from argv[0] and re-executes it in the sub-process.  For\n//   simplicity, the current implementation doesn't search the PATH\n//   when launching the sub-process.  This means that the user must\n//   invoke the test program via a path that contains at least one\n//   path separator (e.g. path/to/foo_test and\n//   /absolute/path/to/bar_test are fine, but foo_test is not).  This\n//   is rarely a problem as people usually don't put the test binary\n//   directory in PATH.\n//\n\n// Asserts that a given `statement` causes the program to exit, with an\n// integer exit status that satisfies `predicate`, and emitting error output\n// that matches `matcher`.\n# define ASSERT_EXIT(statement, predicate, matcher) \\\n    GTEST_DEATH_TEST_(statement, predicate, matcher, GTEST_FATAL_FAILURE_)\n\n// Like `ASSERT_EXIT`, but continues on to successive tests in the\n// test suite, if any:\n# define EXPECT_EXIT(statement, predicate, matcher) \\\n    GTEST_DEATH_TEST_(statement, predicate, matcher, GTEST_NONFATAL_FAILURE_)\n\n// Asserts that a given `statement` causes the program to exit, either by\n// explicitly exiting with a nonzero exit code or being killed by a\n// signal, and emitting error output that matches `matcher`.\n# define ASSERT_DEATH(statement, matcher) \\\n    ASSERT_EXIT(statement, ::testing::internal::ExitedUnsuccessfully, matcher)\n\n// Like `ASSERT_DEATH`, but continues on to successive tests in the\n// test suite, if any:\n# define EXPECT_DEATH(statement, matcher) \\\n    EXPECT_EXIT(statement, ::testing::internal::ExitedUnsuccessfully, matcher)\n\n// Two predicate classes that can be used in {ASSERT,EXPECT}_EXIT*:\n\n// Tests that an exit code describes a normal exit with a given exit code.\nclass GTEST_API_ ExitedWithCode {\n public:\n  explicit ExitedWithCode(int exit_code);\n  ExitedWithCode(const ExitedWithCode&) = default;\n  void operator=(const ExitedWithCode& other) = delete;\n  bool operator()(int exit_status) const;\n private:\n  const int exit_code_;\n};\n\n# if !GTEST_OS_WINDOWS && !GTEST_OS_FUCHSIA\n// Tests that an exit code describes an exit due to termination by a\n// given signal.\n// GOOGLETEST_CM0006 DO NOT DELETE\nclass GTEST_API_ KilledBySignal {\n public:\n  explicit KilledBySignal(int signum);\n  bool operator()(int exit_status) const;\n private:\n  const int signum_;\n};\n# endif  // !GTEST_OS_WINDOWS\n\n// EXPECT_DEBUG_DEATH asserts that the given statements die in debug mode.\n// The death testing framework causes this to have interesting semantics,\n// since the sideeffects of the call are only visible in opt mode, and not\n// in debug mode.\n//\n// In practice, this can be used to test functions that utilize the\n// LOG(DFATAL) macro using the following style:\n//\n// int DieInDebugOr12(int* sideeffect) {\n//   if (sideeffect) {\n//     *sideeffect = 12;\n//   }\n//   LOG(DFATAL) << \"death\";\n//   return 12;\n// }\n//\n// TEST(TestSuite, TestDieOr12WorksInDgbAndOpt) {\n//   int sideeffect = 0;\n//   // Only asserts in dbg.\n//   EXPECT_DEBUG_DEATH(DieInDebugOr12(&sideeffect), \"death\");\n//\n// #ifdef NDEBUG\n//   // opt-mode has sideeffect visible.\n//   EXPECT_EQ(12, sideeffect);\n// #else\n//   // dbg-mode no visible sideeffect.\n//   EXPECT_EQ(0, sideeffect);\n// #endif\n// }\n//\n// This will assert that DieInDebugReturn12InOpt() crashes in debug\n// mode, usually due to a DCHECK or LOG(DFATAL), but returns the\n// appropriate fallback value (12 in this case) in opt mode. If you\n// need to test that a function has appropriate side-effects in opt\n// mode, include assertions against the side-effects.  A general\n// pattern for this is:\n//\n// EXPECT_DEBUG_DEATH({\n//   // Side-effects here will have an effect after this statement in\n//   // opt mode, but none in debug mode.\n//   EXPECT_EQ(12, DieInDebugOr12(&sideeffect));\n// }, \"death\");\n//\n# ifdef NDEBUG\n\n#  define EXPECT_DEBUG_DEATH(statement, regex) \\\n  GTEST_EXECUTE_STATEMENT_(statement, regex)\n\n#  define ASSERT_DEBUG_DEATH(statement, regex) \\\n  GTEST_EXECUTE_STATEMENT_(statement, regex)\n\n# else\n\n#  define EXPECT_DEBUG_DEATH(statement, regex) \\\n  EXPECT_DEATH(statement, regex)\n\n#  define ASSERT_DEBUG_DEATH(statement, regex) \\\n  ASSERT_DEATH(statement, regex)\n\n# endif  // NDEBUG for EXPECT_DEBUG_DEATH\n#endif  // GTEST_HAS_DEATH_TEST\n\n// This macro is used for implementing macros such as\n// EXPECT_DEATH_IF_SUPPORTED and ASSERT_DEATH_IF_SUPPORTED on systems where\n// death tests are not supported. Those macros must compile on such systems\n// if and only if EXPECT_DEATH and ASSERT_DEATH compile with the same parameters\n// on systems that support death tests. This allows one to write such a macro on\n// a system that does not support death tests and be sure that it will compile\n// on a death-test supporting system. It is exposed publicly so that systems\n// that have death-tests with stricter requirements than GTEST_HAS_DEATH_TEST\n// can write their own equivalent of EXPECT_DEATH_IF_SUPPORTED and\n// ASSERT_DEATH_IF_SUPPORTED.\n//\n// Parameters:\n//   statement -  A statement that a macro such as EXPECT_DEATH would test\n//                for program termination. This macro has to make sure this\n//                statement is compiled but not executed, to ensure that\n//                EXPECT_DEATH_IF_SUPPORTED compiles with a certain\n//                parameter if and only if EXPECT_DEATH compiles with it.\n//   regex     -  A regex that a macro such as EXPECT_DEATH would use to test\n//                the output of statement.  This parameter has to be\n//                compiled but not evaluated by this macro, to ensure that\n//                this macro only accepts expressions that a macro such as\n//                EXPECT_DEATH would accept.\n//   terminator - Must be an empty statement for EXPECT_DEATH_IF_SUPPORTED\n//                and a return statement for ASSERT_DEATH_IF_SUPPORTED.\n//                This ensures that ASSERT_DEATH_IF_SUPPORTED will not\n//                compile inside functions where ASSERT_DEATH doesn't\n//                compile.\n//\n//  The branch that has an always false condition is used to ensure that\n//  statement and regex are compiled (and thus syntactically correct) but\n//  never executed. The unreachable code macro protects the terminator\n//  statement from generating an 'unreachable code' warning in case\n//  statement unconditionally returns or throws. The Message constructor at\n//  the end allows the syntax of streaming additional messages into the\n//  macro, for compilational compatibility with EXPECT_DEATH/ASSERT_DEATH.\n# define GTEST_UNSUPPORTED_DEATH_TEST(statement, regex, terminator) \\\n    GTEST_AMBIGUOUS_ELSE_BLOCKER_ \\\n    if (::testing::internal::AlwaysTrue()) { \\\n      GTEST_LOG_(WARNING) \\\n          << \"Death tests are not supported on this platform.\\n\" \\\n          << \"Statement '\" #statement \"' cannot be verified.\"; \\\n    } else if (::testing::internal::AlwaysFalse()) { \\\n      ::testing::internal::RE::PartialMatch(\".*\", (regex)); \\\n      GTEST_SUPPRESS_UNREACHABLE_CODE_WARNING_BELOW_(statement); \\\n      terminator; \\\n    } else \\\n      ::testing::Message()\n\n// EXPECT_DEATH_IF_SUPPORTED(statement, regex) and\n// ASSERT_DEATH_IF_SUPPORTED(statement, regex) expand to real death tests if\n// death tests are supported; otherwise they just issue a warning.  This is\n// useful when you are combining death test assertions with normal test\n// assertions in one test.\n#if GTEST_HAS_DEATH_TEST\n# define EXPECT_DEATH_IF_SUPPORTED(statement, regex) \\\n    EXPECT_DEATH(statement, regex)\n# define ASSERT_DEATH_IF_SUPPORTED(statement, regex) \\\n    ASSERT_DEATH(statement, regex)\n#else\n# define EXPECT_DEATH_IF_SUPPORTED(statement, regex) \\\n    GTEST_UNSUPPORTED_DEATH_TEST(statement, regex, )\n# define ASSERT_DEATH_IF_SUPPORTED(statement, regex) \\\n    GTEST_UNSUPPORTED_DEATH_TEST(statement, regex, return)\n#endif\n\n}  // namespace testing\n\n#endif  // GOOGLETEST_INCLUDE_GTEST_GTEST_DEATH_TEST_H_\n",
    "chunks": [
      {
        "chunk_id": "doc_25_chunk_0",
        "original_index": 0,
        "content": "// Copyright 2005, Google Inc.\n// All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions are\n// met:\n//\n//     * Redistributions of source code must retain the above copyright\n// notice, this list of conditions and the following disclaimer.\n//     * Redistributions in binary form must reproduce the above\n// copyright notice, this list of conditions and the following disclaimer\n// in the documentation and/or other materials provided with the\n// distribution.\n//     * Neither the name of Google Inc. nor the names of its\n// contributors may be used to endorse or promote products derived from\n// this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n"
      },
      {
        "chunk_id": "doc_25_chunk_1",
        "original_index": 1,
        "content": "// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n"
      },
      {
        "chunk_id": "doc_25_chunk_2",
        "original_index": 2,
        "content": "//\n// The Google C++ Testing and Mocking Framework (Google Test)\n//\n// This header file defines the public API for death tests.  It is\n// #included by gtest.h so a user doesn't need to include this\n// directly.\n// GOOGLETEST_CM0001 DO NOT DELETE\n\n#ifndef GOOGLETEST_INCLUDE_GTEST_GTEST_DEATH_TEST_H_\n#define GOOGLETEST_INCLUDE_GTEST_GTEST_DEATH_TEST_H_\n\n#include \"gtest/internal/gtest-death-test-internal.h\"\n\nnamespace testing {\n\n// This flag controls the style of death tests.  Valid values are \"threadsafe\",\n// meaning that the death test child process will re-execute the test binary\n// from the start, running only a single death test, or \"fast\",\n// meaning that the child process will execute the test logic immediately\n// after forking.\nGTEST_DECLARE_string_(death_test_style);\n\n#if GTEST_HAS_DEATH_TEST\n\nnamespace internal {\n\n"
      },
      {
        "chunk_id": "doc_25_chunk_3",
        "original_index": 3,
        "content": "// Returns a Boolean value indicating whether the caller is currently\n// executing in the context of the death test child process.  Tools such as\n// Valgrind heap checkers may need this to modify their behavior in death\n// tests.  IMPORTANT: This is an internal utility.  Using it may break the\n// implementation of death tests.  User code MUST NOT use it.\nGTEST_API_ bool InDeathTestChild();\n\n}  // namespace internal\n\n// The following macros are useful for writing death tests.\n\n// Here's what happens when an ASSERT_DEATH* or EXPECT_DEATH* is\n// executed:\n//\n//   1. It generates a warning if there is more than one active\n//   thread.  This is because it's safe to fork() or clone() only\n//   when there is a single thread.\n//\n//   2. The parent process clone()s a sub-process and runs the death\n//   test in it; the sub-process exits with code 0 at the end of the\n//   death test, if it hasn't exited already.\n//\n"
      },
      {
        "chunk_id": "doc_25_chunk_4",
        "original_index": 4,
        "content": "//   3. The parent process waits for the sub-process to terminate.\n//\n//   4. The parent process checks the exit code and error message of\n//   the sub-process.\n//\n// Examples:\n//\n//   ASSERT_DEATH(server.SendMessage(56, \"Hello\"), \"Invalid port number\");\n//   for (int i = 0; i < 5; i++) {\n//     EXPECT_DEATH(server.ProcessRequest(i),\n//                  \"Invalid request .* in ProcessRequest()\")\n//                  << \"Failed to die on request \" << i;\n//   }\n//\n//   ASSERT_EXIT(server.ExitNow(), ::testing::ExitedWithCode(0), \"Exiting\");\n//\n//   bool KilledBySIGHUP(int exit_code) {\n//     return WIFSIGNALED(exit_code) && WTERMSIG(exit_code) == SIGHUP;\n//   }\n//\n//   ASSERT_EXIT(client.HangUpServer(), KilledBySIGHUP, \"Hanging up!\");\n//\n// The final parameter to each of these macros is a matcher applied to any data\n"
      },
      {
        "chunk_id": "doc_25_chunk_5",
        "original_index": 5,
        "content": "// the sub-process wrote to stderr.  For compatibility with existing tests, a\n// bare string is interpreted as a regular expression matcher.\n//\n// On the regular expressions used in death tests:\n//\n//   GOOGLETEST_CM0005 DO NOT DELETE\n//   On POSIX-compliant systems (*nix), we use the <regex.h> library,\n//   which uses the POSIX extended regex syntax.\n//\n//   On other platforms (e.g. Windows or Mac), we only support a simple regex\n//   syntax implemented as part of Google Test.  This limited\n//   implementation should be enough most of the time when writing\n//   death tests; though it lacks many features you can find in PCRE\n//   or POSIX extended regex syntax.  For example, we don't support\n"
      },
      {
        "chunk_id": "doc_25_chunk_6",
        "original_index": 6,
        "content": "//   union (\"x|y\"), grouping (\"(xy)\"), brackets (\"[xy]\"), and\n//   repetition count (\"x{5,7}\"), among others.\n//\n//   Below is the syntax that we do support.  We chose it to be a\n//   subset of both PCRE and POSIX extended regex, so it's easy to\n//   learn wherever you come from.  In the following: 'A' denotes a\n//   literal character, period (.), or a single \\\\ escape sequence;\n//   'x' and 'y' denote regular expressions; 'm' and 'n' are for\n"
      },
      {
        "chunk_id": "doc_25_chunk_7",
        "original_index": 7,
        "content": "//   natural numbers.\n//\n//     c     matches any literal character c\n//     \\\\d   matches any decimal digit\n//     \\\\D   matches any character that's not a decimal digit\n//     \\\\f   matches \\f\n//     \\\\n   matches \\n\n//     \\\\r   matches \\r\n//     \\\\s   matches any ASCII whitespace, including \\n\n//     \\\\S   matches any character that's not a whitespace\n//     \\\\t   matches \\t\n//     \\\\v   matches \\v\n//     \\\\w   matches any letter, _, or decimal digit\n//     \\\\W   matches any character that \\\\w doesn't match\n//     \\\\c   matches any literal character c, which must be a punctuation\n//     .     matches any single character except \\n\n"
      },
      {
        "chunk_id": "doc_25_chunk_8",
        "original_index": 8,
        "content": "//     A?    matches 0 or 1 occurrences of A\n//     A*    matches 0 or many occurrences of A\n//     A+    matches 1 or many occurrences of A\n//     ^     matches the beginning of a string (not that of each line)\n//     $     matches the end of a string (not that of each line)\n//     xy    matches x followed by y\n//\n//   If you accidentally use PCRE or POSIX extended regex features\n//   not implemented by us, you will get a run-time failure.  In that\n"
      },
      {
        "chunk_id": "doc_25_chunk_9",
        "original_index": 9,
        "content": "//   case, please try to rewrite your regular expression within the\n//   above syntax.\n//\n//   This implementation is *not* meant to be as highly tuned or robust\n//   as a compiled regex library, but should perform well enough for a\n//   death test, which already incurs significant overhead by launching\n//   a child process.\n//\n// Known caveats:\n//\n//   A \"threadsafe\" style death test obtains the path to the test\n//   program from argv[0] and re-executes it in the sub-process.  For\n//   simplicity, the current implementation doesn't search the PATH\n//   when launching the sub-process.  This means that the user must\n//   invoke the test program via a path that contains at least one\n//   path separator (e.g. path/to/foo_test and\n//   /absolute/path/to/bar_test are fine, but foo_test is not).  This\n//   is rarely a problem as people usually don't put the test binary\n//   directory in PATH.\n//\n\n"
      },
      {
        "chunk_id": "doc_25_chunk_10",
        "original_index": 10,
        "content": "// Asserts that a given `statement` causes the program to exit, with an\n// integer exit status that satisfies `predicate`, and emitting error output\n// that matches `matcher`.\n# define ASSERT_EXIT(statement, predicate, matcher) \\\n    GTEST_DEATH_TEST_(statement, predicate, matcher, GTEST_FATAL_FAILURE_)\n\n// Like `ASSERT_EXIT`, but continues on to successive tests in the\n// test suite, if any:\n# define EXPECT_EXIT(statement, predicate, matcher) \\\n    GTEST_DEATH_TEST_(statement, predicate, matcher, GTEST_NONFATAL_FAILURE_)\n\n"
      },
      {
        "chunk_id": "doc_25_chunk_11",
        "original_index": 11,
        "content": "// Asserts that a given `statement` causes the program to exit, either by\n// explicitly exiting with a nonzero exit code or being killed by a\n// signal, and emitting error output that matches `matcher`.\n# define ASSERT_DEATH(statement, matcher) \\\n    ASSERT_EXIT(statement, ::testing::internal::ExitedUnsuccessfully, matcher)\n\n// Like `ASSERT_DEATH`, but continues on to successive tests in the\n// test suite, if any:\n# define EXPECT_DEATH(statement, matcher) \\\n    EXPECT_EXIT(statement, ::testing::internal::ExitedUnsuccessfully, matcher)\n\n// Two predicate classes that can be used in {ASSERT,EXPECT}_EXIT*:\n\n"
      },
      {
        "chunk_id": "doc_25_chunk_12",
        "original_index": 12,
        "content": "// Tests that an exit code describes a normal exit with a given exit code.\nclass GTEST_API_ ExitedWithCode {\n public:\n  explicit ExitedWithCode(int exit_code);\n  ExitedWithCode(const ExitedWithCode&) = default;\n  void operator=(const ExitedWithCode& other) = delete;\n  bool operator()(int exit_status) const;\n private:\n  const int exit_code_;\n};\n\n# if !GTEST_OS_WINDOWS && !GTEST_OS_FUCHSIA\n// Tests that an exit code describes an exit due to termination by a\n// given signal.\n// GOOGLETEST_CM0006 DO NOT DELETE\nclass GTEST_API_ KilledBySignal {\n public:\n  explicit KilledBySignal(int signum);\n  bool operator()(int exit_status) const;\n private:\n  const int signum_;\n};\n# endif  // !GTEST_OS_WINDOWS\n\n"
      },
      {
        "chunk_id": "doc_25_chunk_13",
        "original_index": 13,
        "content": "// EXPECT_DEBUG_DEATH asserts that the given statements die in debug mode.\n// The death testing framework causes this to have interesting semantics,\n// since the sideeffects of the call are only visible in opt mode, and not\n// in debug mode.\n//\n// In practice, this can be used to test functions that utilize the\n// LOG(DFATAL) macro using the following style:\n//\n// int DieInDebugOr12(int* sideeffect) {\n//   if (sideeffect) {\n//     *sideeffect = 12;\n//   }\n"
      },
      {
        "chunk_id": "doc_25_chunk_14",
        "original_index": 14,
        "content": "//   LOG(DFATAL) << \"death\";\n//   return 12;\n// }\n//\n// TEST(TestSuite, TestDieOr12WorksInDgbAndOpt) {\n//   int sideeffect = 0;\n//   // Only asserts in dbg.\n//   EXPECT_DEBUG_DEATH(DieInDebugOr12(&sideeffect), \"death\");\n//\n// #ifdef NDEBUG\n//   // opt-mode has sideeffect visible.\n//   EXPECT_EQ(12, sideeffect);\n// #else\n//   // dbg-mode no visible sideeffect.\n//   EXPECT_EQ(0, sideeffect);\n// #endif\n// }\n//\n// This will assert that DieInDebugReturn12InOpt() crashes in debug\n// mode, usually due to a DCHECK or LOG(DFATAL), but returns the\n// appropriate fallback value (12 in this case) in opt mode. If you\n// need to test that a function has appropriate side-effects in opt\n// mode, include assertions against the side-effects.  A general\n// pattern for this is:\n//\n// EXPECT_DEBUG_DEATH({\n//   // Side-effects here will have an effect after this statement in\n//   // opt mode, but none in debug mode.\n//   EXPECT_EQ(12, DieInDebugOr12(&sideeffect));\n// }, \"death\");\n//\n# ifdef NDEBUG\n\n"
      },
      {
        "chunk_id": "doc_25_chunk_15",
        "original_index": 15,
        "content": "#  define EXPECT_DEBUG_DEATH(statement, regex) \\\n  GTEST_EXECUTE_STATEMENT_(statement, regex)\n\n#  define ASSERT_DEBUG_DEATH(statement, regex) \\\n  GTEST_EXECUTE_STATEMENT_(statement, regex)\n\n# else\n\n#  define EXPECT_DEBUG_DEATH(statement, regex) \\\n  EXPECT_DEATH(statement, regex)\n\n#  define ASSERT_DEBUG_DEATH(statement, regex) \\\n  ASSERT_DEATH(statement, regex)\n\n# endif  // NDEBUG for EXPECT_DEBUG_DEATH\n#endif  // GTEST_HAS_DEATH_TEST\n\n"
      },
      {
        "chunk_id": "doc_25_chunk_16",
        "original_index": 16,
        "content": "// This macro is used for implementing macros such as\n// EXPECT_DEATH_IF_SUPPORTED and ASSERT_DEATH_IF_SUPPORTED on systems where\n// death tests are not supported. Those macros must compile on such systems\n// if and only if EXPECT_DEATH and ASSERT_DEATH compile with the same parameters\n// on systems that support death tests. This allows one to write such a macro on\n// a system that does not support death tests and be sure that it will compile\n// on a death-test supporting system. It is exposed publicly so that systems\n// that have death-tests with stricter requirements than GTEST_HAS_DEATH_TEST\n"
      },
      {
        "chunk_id": "doc_25_chunk_17",
        "original_index": 17,
        "content": "// can write their own equivalent of EXPECT_DEATH_IF_SUPPORTED and\n// ASSERT_DEATH_IF_SUPPORTED.\n//\n// Parameters:\n//   statement -  A statement that a macro such as EXPECT_DEATH would test\n//                for program termination. This macro has to make sure this\n//                statement is compiled but not executed, to ensure that\n//                EXPECT_DEATH_IF_SUPPORTED compiles with a certain\n//                parameter if and only if EXPECT_DEATH compiles with it.\n//   regex     -  A regex that a macro such as EXPECT_DEATH would use to test\n"
      },
      {
        "chunk_id": "doc_25_chunk_18",
        "original_index": 18,
        "content": "//                the output of statement.  This parameter has to be\n//                compiled but not evaluated by this macro, to ensure that\n//                this macro only accepts expressions that a macro such as\n//                EXPECT_DEATH would accept.\n//   terminator - Must be an empty statement for EXPECT_DEATH_IF_SUPPORTED\n//                and a return statement for ASSERT_DEATH_IF_SUPPORTED.\n//                This ensures that ASSERT_DEATH_IF_SUPPORTED will not\n//                compile inside functions where ASSERT_DEATH doesn't\n//                compile.\n//\n//  The branch that has an always false condition is used to ensure that\n//  statement and regex are compiled (and thus syntactically correct) but\n//  never executed. The unreachable code macro protects the terminator\n//  statement from generating an 'unreachable code' warning in case\n//  statement unconditionally returns or throws. The Message constructor at\n"
      },
      {
        "chunk_id": "doc_25_chunk_19",
        "original_index": 19,
        "content": "//  the end allows the syntax of streaming additional messages into the\n//  macro, for compilational compatibility with EXPECT_DEATH/ASSERT_DEATH.\n# define GTEST_UNSUPPORTED_DEATH_TEST(statement, regex, terminator) \\\n    GTEST_AMBIGUOUS_ELSE_BLOCKER_ \\\n    if (::testing::internal::AlwaysTrue()) { \\\n      GTEST_LOG_(WARNING) \\\n          << \"Death tests are not supported on this platform.\\n\" \\\n          << \"Statement '\" #statement \"' cannot be verified.\"; \\\n    } else if (::testing::internal::AlwaysFalse()) { \\\n      ::testing::internal::RE::PartialMatch(\".*\", (regex)); \\\n      GTEST_SUPPRESS_UNREACHABLE_CODE_WARNING_BELOW_(statement); \\\n      terminator; \\\n    } else \\\n      ::testing::Message()\n\n"
      },
      {
        "chunk_id": "doc_25_chunk_20",
        "original_index": 20,
        "content": "// EXPECT_DEATH_IF_SUPPORTED(statement, regex) and\n// ASSERT_DEATH_IF_SUPPORTED(statement, regex) expand to real death tests if\n// death tests are supported; otherwise they just issue a warning.  This is\n// useful when you are combining death test assertions with normal test\n// assertions in one test.\n#if GTEST_HAS_DEATH_TEST\n# define EXPECT_DEATH_IF_SUPPORTED(statement, regex) \\\n    EXPECT_DEATH(statement, regex)\n# define ASSERT_DEATH_IF_SUPPORTED(statement, regex) \\\n    ASSERT_DEATH(statement, regex)\n#else\n# define EXPECT_DEATH_IF_SUPPORTED(statement, regex) \\\n    GTEST_UNSUPPORTED_DEATH_TEST(statement, regex, )\n# define ASSERT_DEATH_IF_SUPPORTED(statement, regex) \\\n    GTEST_UNSUPPORTED_DEATH_TEST(statement, regex, return)\n#endif\n\n}  // namespace testing\n\n#endif  // GOOGLETEST_INCLUDE_GTEST_GTEST_DEATH_TEST_H_\n"
      }
    ]
  },
  {
    "doc_id": "doc_26",
    "original_uuid": "b55a4b2aefbbe30b355c360d7f1f24bd114d9699fdd21c2e4eae3f693ab5ef36",
    "content": "#pragma once\n\n#include <string>\n#include <cstdint>\n\nnamespace clickhouse {\n\nclass InputStream;\nclass OutputStream;\n\nclass WireFormat {\npublic:\n    template <typename T>\n    static bool ReadFixed(InputStream& input, T* value);\n    static bool ReadString(InputStream& input, std::string* value);\n    static bool SkipString(InputStream& input);\n    static bool ReadBytes(InputStream& input, void* buf, size_t len);\n    static bool ReadUInt64(InputStream& input, uint64_t* value);\n    static bool ReadVarint64(InputStream& output, uint64_t* value);\n\n    template <typename T>\n    static void WriteFixed(OutputStream& output, const T& value);\n    static void WriteBytes(OutputStream& output, const void* buf, size_t len);\n    static void WriteString(OutputStream& output, std::string_view value);\n    static void WriteUInt64(OutputStream& output, const uint64_t value);\n    static void WriteVarint64(OutputStream& output, uint64_t value);\n\nprivate:\n    static bool ReadAll(InputStream& input, void* buf, size_t len);\n    static void WriteAll(OutputStream& output, const void* buf, size_t len);\n};\n\ntemplate <typename T>\ninline bool WireFormat::ReadFixed(InputStream& input, T* value) {\n    return ReadAll(input, value, sizeof(T));\n}\n\ninline bool WireFormat::ReadString(InputStream& input, std::string* value) {\n    uint64_t len = 0;\n    if (ReadVarint64(input, &len)) {\n        if (len > 0x00FFFFFFULL) {\n            return false;\n        }\n        value->resize((size_t)len);\n        return ReadAll(input, value->data(), (size_t)len);\n    }\n\n    return false;\n}\n\ninline bool WireFormat::ReadBytes(InputStream& input, void* buf, size_t len) {\n    return ReadAll(input, buf, len);\n}\n\ninline bool WireFormat::ReadUInt64(InputStream& input, uint64_t* value) {\n    return ReadVarint64(input, value);\n}\n\ntemplate <typename T>\ninline void WireFormat::WriteFixed(OutputStream& output, const T& value) {\n    WriteAll(output, &value, sizeof(T));\n}\n\ninline void WireFormat::WriteBytes(OutputStream& output, const void* buf, size_t len) {\n    WriteAll(output, buf, len);\n}\n\ninline void WireFormat::WriteString(OutputStream& output, std::string_view value) {\n    WriteVarint64(output, value.size());\n    WriteAll(output, value.data(), value.size());\n}\n\ninline void WireFormat::WriteUInt64(OutputStream& output, const uint64_t value) {\n    WriteVarint64(output, value);\n}\n\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_26_chunk_0",
        "original_index": 0,
        "content": "#pragma once\n\n#include <string>\n#include <cstdint>\n\nnamespace clickhouse {\n\nclass InputStream;\nclass OutputStream;\n\nclass WireFormat {\npublic:\n    template <typename T>\n    static bool ReadFixed(InputStream& input, T* value);\n    static bool ReadString(InputStream& input, std::string* value);\n    static bool SkipString(InputStream& input);\n    static bool ReadBytes(InputStream& input, void* buf, size_t len);\n    static bool ReadUInt64(InputStream& input, uint64_t* value);\n    static bool ReadVarint64(InputStream& output, uint64_t* value);\n\n    template <typename T>\n    static void WriteFixed(OutputStream& output, const T& value);\n    static void WriteBytes(OutputStream& output, const void* buf, size_t len);\n    static void WriteString(OutputStream& output, std::string_view value);\n    static void WriteUInt64(OutputStream& output, const uint64_t value);\n    static void WriteVarint64(OutputStream& output, uint64_t value);\n\n"
      },
      {
        "chunk_id": "doc_26_chunk_1",
        "original_index": 1,
        "content": "private:\n    static bool ReadAll(InputStream& input, void* buf, size_t len);\n    static void WriteAll(OutputStream& output, const void* buf, size_t len);\n};\n\ntemplate <typename T>\ninline bool WireFormat::ReadFixed(InputStream& input, T* value) {\n    return ReadAll(input, value, sizeof(T));\n}\n\ninline bool WireFormat::ReadString(InputStream& input, std::string* value) {\n    uint64_t len = 0;\n    if (ReadVarint64(input, &len)) {\n        if (len > 0x00FFFFFFULL) {\n            return false;\n        }\n        value->resize((size_t)len);\n        return ReadAll(input, value->data(), (size_t)len);\n    }\n\n"
      },
      {
        "chunk_id": "doc_26_chunk_2",
        "original_index": 2,
        "content": "    return false;\n}\n\ninline bool WireFormat::ReadBytes(InputStream& input, void* buf, size_t len) {\n    return ReadAll(input, buf, len);\n}\n\ninline bool WireFormat::ReadUInt64(InputStream& input, uint64_t* value) {\n    return ReadVarint64(input, value);\n}\n\ntemplate <typename T>\ninline void WireFormat::WriteFixed(OutputStream& output, const T& value) {\n    WriteAll(output, &value, sizeof(T));\n}\n\ninline void WireFormat::WriteBytes(OutputStream& output, const void* buf, size_t len) {\n    WriteAll(output, buf, len);\n}\n\ninline void WireFormat::WriteString(OutputStream& output, std::string_view value) {\n    WriteVarint64(output, value.size());\n    WriteAll(output, value.data(), value.size());\n}\n\ninline void WireFormat::WriteUInt64(OutputStream& output, const uint64_t value) {\n    WriteVarint64(output, value);\n}\n\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_27",
    "original_uuid": "f08b70253a31ba96a0e3e873e3f53393786ceb5fb150ea3878551b32ccf3914d",
    "content": "#include \"column.h\"\n\nnamespace clickhouse {\n\nbool Column::LoadPrefix(InputStream*, size_t) {\n    /// does nothing by default\n    return true;\n}\n\nbool Column::Load(InputStream* input, size_t rows) {\n    return LoadPrefix(input, rows) && LoadBody(input, rows);\n}\n\nvoid Column::SavePrefix(OutputStream*) {\n    /// does nothing by default\n}\n\n/// Saves column data to output stream.\nvoid Column::Save(OutputStream* output) {\n    SavePrefix(output);\n    SaveBody(output);\n}\n\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_27_chunk_0",
        "original_index": 0,
        "content": "#include \"column.h\"\n\nnamespace clickhouse {\n\nbool Column::LoadPrefix(InputStream*, size_t) {\n    /// does nothing by default\n    return true;\n}\n\nbool Column::Load(InputStream* input, size_t rows) {\n    return LoadPrefix(input, rows) && LoadBody(input, rows);\n}\n\nvoid Column::SavePrefix(OutputStream*) {\n    /// does nothing by default\n}\n\n/// Saves column data to output stream.\nvoid Column::Save(OutputStream* output) {\n    SavePrefix(output);\n    SaveBody(output);\n}\n\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_28",
    "original_uuid": "087c7915a5df0e768bca07ed728ccdebfa8bfd6d5eeb03a815ad219ead305e6a",
    "content": "#pragma once\n\n#include \"column.h\"\n#include \"numeric.h\"\n#include \"nullable.h\"\n\n#include <functional>\n#include <string>\n#include <unordered_map>\n#include <utility>\n\nnamespace clickhouse {\n\ntemplate <typename NestedColumnType>\nclass ColumnLowCardinalityT;\n\nnamespace details {\n\n/** LowCardinalityHashKey used as key in unique items hashmap to abstract away key value\n * (type of which depends on dictionary column) and to reduce likelehood of collisions.\n *\n * In order to dramatically reduce collision rate, we use 2 different hashes from 2 different hash functions.\n * First hash is used in hashtable (to calculate item position).\n * Second one is used as part of key value and accessed via `operator==()` upon collision resolution/detection.\n */\nusing LowCardinalityHashKey = std::pair<std::uint64_t, std::uint64_t>;\n\nstruct LowCardinalityHashKeyHash {\n    inline std::size_t operator()(const LowCardinalityHashKey &hash_key) const noexcept {\n        return hash_key.first;\n    }\n};\n\n}\n\n/*\n * LC column contains an \"invisible\" default item at the beginning of the collection. [default, ...]\n * If the nested type is Nullable, it contains a null-item at the beginning and a default item at the second position. [null, default, ...]\n * Null map is not serialized in LC columns. Instead, nulls are tracked by having an index of 0.\n * */\nclass ColumnLowCardinality : public Column {\npublic:\n    using UniqueItems = std::unordered_map<details::LowCardinalityHashKey, size_t /*dictionary index*/, details::LowCardinalityHashKeyHash>;\n\n    template <typename T>\n    friend class ColumnLowCardinalityT;\n\nprivate:\n    // IMPLEMENTATION NOTE: ColumnLowCardinalityT takes reference to underlying dictionary column object,\n    // so make sure to NOT change address of the dictionary object (with reset(), swap()) or with anything else.\n    ColumnRef dictionary_column_;\n    ColumnRef index_column_;\n    UniqueItems unique_items_map_;\n\npublic:\n    ColumnLowCardinality(ColumnLowCardinality&& col) = default;\n    // c-tor makes a deep copy of the dictionary_column.\n    explicit ColumnLowCardinality(ColumnRef dictionary_column);\n    explicit ColumnLowCardinality(std::shared_ptr<ColumnNullable> dictionary_column);\n\n    template <typename T>\n    explicit ColumnLowCardinality(std::shared_ptr<ColumnNullableT<T>> dictionary_column)\n        : ColumnLowCardinality(dictionary_column->template As<ColumnNullable>())\n    {}\n\n    ~ColumnLowCardinality();\n\n    /// Increase the capacity of the column for large block insertion.\n    void Reserve(size_t new_cap) override;\n\n    /// Appends another LowCardinality column to the end of this one, updating dictionary.\n    void Append(ColumnRef /*column*/) override;\n\n    bool LoadPrefix(InputStream* input, size_t rows) override;\n\n    /// Loads column data from input stream.\n    bool LoadBody(InputStream* input, size_t rows) override;\n\n    /// Saves column prefix to output stream.\n    void SavePrefix(OutputStream* output) override;\n\n    /// Saves column data to output stream.\n    void SaveBody(OutputStream* output) override;\n\n    /// Clear column data.\n    void Clear() override;\n\n    /// Returns count of rows in the column.\n    size_t Size() const override;\n\n    /// Makes slice of current column, with compacted dictionary\n    ColumnRef Slice(size_t begin, size_t len) const override;\n    ColumnRef CloneEmpty() const override;\n    void Swap(Column& other) override;\n    ItemView GetItem(size_t index) const override;\n\n    size_t GetDictionarySize() const;\n    TypeRef GetNestedType() const;\n\nprotected:\n    std::uint64_t getDictionaryIndex(std::uint64_t item_index) const;\n    void appendIndex(std::uint64_t item_index);\n    void removeLastIndex();\n    ColumnRef GetDictionary();\n\n    void AppendUnsafe(const ItemView &);\n\nprivate:\n    void Setup(ColumnRef dictionary_column);\n    void AppendNullItem();\n    void AppendDefaultItem();\n\npublic:\n    static details::LowCardinalityHashKey computeHashKey(const ItemView &);\n};\n\n/** Type-aware wrapper that provides simple convenience interface for accessing/appending individual items.\n */\ntemplate <typename DictionaryColumnType>\nclass ColumnLowCardinalityT : public ColumnLowCardinality {\n\n    DictionaryColumnType& typed_dictionary_;\n    const Type::Code type_;\n\npublic:\n    using WrappedColumnType = DictionaryColumnType;\n    // Type this column takes as argument of Append and returns with At() and operator[]\n    using ValueType = typename DictionaryColumnType::ValueType;\n\n    explicit ColumnLowCardinalityT(ColumnLowCardinality&& col)\n        : ColumnLowCardinality(std::move(col))\n        ,  typed_dictionary_(dynamic_cast<DictionaryColumnType &>(*GetDictionary()))\n        ,  type_(GetTypeCode(typed_dictionary_))\n    {\n    }\n\n    template <typename ...Args>\n    explicit ColumnLowCardinalityT(Args &&... args)\n        : ColumnLowCardinalityT(std::make_shared<DictionaryColumnType>(std::forward<Args>(args)...))\n    {}\n\n    // Create LC<T> column from existing T-column, making a deep copy of all contents.\n    explicit ColumnLowCardinalityT(std::shared_ptr<DictionaryColumnType> dictionary_col)\n        : ColumnLowCardinality(dictionary_col)\n        , typed_dictionary_(dynamic_cast<DictionaryColumnType &>(*GetDictionary()))\n        , type_(GetTypeCode(typed_dictionary_))\n    {}\n\n    /// Extended interface to simplify reading/adding individual items.\n\n    /// Returns element at given row number.\n    inline ValueType At(size_t n) const {\n        return typed_dictionary_.At(getDictionaryIndex(n));\n    }\n\n    /// Returns element at given row number.\n    inline ValueType operator [] (size_t n) const {\n        return typed_dictionary_[getDictionaryIndex(n)];\n    }\n\n    // so the non-virtual Append below doesn't shadow Append() from base class when compiled with older compilers.\n    using ColumnLowCardinality::Append;\n\n    inline void Append(const ValueType & value) {\n        if constexpr (IsNullable<WrappedColumnType>) {\n            if (value.has_value()) {\n                AppendUnsafe(ItemView{type_, *value});\n            } else {\n                AppendUnsafe(ItemView{});\n            }\n        } else {\n            AppendUnsafe(ItemView{type_, value});\n        }\n    }\n\n    template <typename T>\n    inline void AppendMany(const T& container) {\n        for (const auto & item : container) {\n            Append(item);\n        }\n    }\n\n    /** Create a ColumnLowCardinalityT from a ColumnLowCardinality, without copying data and offsets, but by\n     * 'stealing' those from `col`.\n     *\n     *  Ownership of column internals is transferred to returned object, original (argument) object\n     *  MUST NOT BE USED IN ANY WAY, it is only safe to dispose it.\n     *\n     *  Throws an exception if `col` is of wrong type, it is safe to use original col in this case.\n     *  This is a static method to make such conversion verbose.\n     */\n    static auto Wrap(ColumnLowCardinality&& col) {\n        return std::make_shared<ColumnLowCardinalityT<WrappedColumnType>>(std::move(col));\n    }\n\n    static auto Wrap(Column&& col) { return Wrap(std::move(dynamic_cast<ColumnLowCardinality&&>(col))); }\n\n    // Helper to simplify integration with other APIs\n    static auto Wrap(ColumnRef&& col) { return Wrap(std::move(*col->AsStrict<ColumnLowCardinality>())); }\n\n    ColumnRef Slice(size_t begin, size_t size) const override {\n        return Wrap(ColumnLowCardinality::Slice(begin, size));\n    }\n\n    ColumnRef CloneEmpty() const override { return Wrap(ColumnLowCardinality::CloneEmpty()); }\n\nprivate:\n\n    template <typename T>\n    static auto GetTypeCode(T& column) {\n        if constexpr (IsNullable<T>) {\n            return GetTypeCode(*column.Nested()->template AsStrict<typename T::NestedColumnType>());\n        } else {\n            return column.Type()->GetCode();\n        }\n    }\n};\n\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_28_chunk_0",
        "original_index": 0,
        "content": "#pragma once\n\n#include \"column.h\"\n#include \"numeric.h\"\n#include \"nullable.h\"\n\n#include <functional>\n#include <string>\n#include <unordered_map>\n#include <utility>\n\nnamespace clickhouse {\n\ntemplate <typename NestedColumnType>\nclass ColumnLowCardinalityT;\n\nnamespace details {\n\n/** LowCardinalityHashKey used as key in unique items hashmap to abstract away key value\n * (type of which depends on dictionary column) and to reduce likelehood of collisions.\n *\n * In order to dramatically reduce collision rate, we use 2 different hashes from 2 different hash functions.\n * First hash is used in hashtable (to calculate item position).\n * Second one is used as part of key value and accessed via `operator==()` upon collision resolution/detection.\n */\nusing LowCardinalityHashKey = std::pair<std::uint64_t, std::uint64_t>;\n\n"
      },
      {
        "chunk_id": "doc_28_chunk_1",
        "original_index": 1,
        "content": "struct LowCardinalityHashKeyHash {\n    inline std::size_t operator()(const LowCardinalityHashKey &hash_key) const noexcept {\n        return hash_key.first;\n    }\n};\n\n}\n\n/*\n * LC column contains an \"invisible\" default item at the beginning of the collection. [default, ...]\n * If the nested type is Nullable, it contains a null-item at the beginning and a default item at the second position. [null, default, ...]\n * Null map is not serialized in LC columns. Instead, nulls are tracked by having an index of 0.\n * */\nclass ColumnLowCardinality : public Column {\npublic:\n    using UniqueItems = std::unordered_map<details::LowCardinalityHashKey, size_t /*dictionary index*/, details::LowCardinalityHashKeyHash>;\n\n"
      },
      {
        "chunk_id": "doc_28_chunk_2",
        "original_index": 2,
        "content": "    template <typename T>\n    friend class ColumnLowCardinalityT;\n\nprivate:\n    // IMPLEMENTATION NOTE: ColumnLowCardinalityT takes reference to underlying dictionary column object,\n    // so make sure to NOT change address of the dictionary object (with reset(), swap()) or with anything else.\n    ColumnRef dictionary_column_;\n    ColumnRef index_column_;\n    UniqueItems unique_items_map_;\n\npublic:\n    ColumnLowCardinality(ColumnLowCardinality&& col) = default;\n    // c-tor makes a deep copy of the dictionary_column.\n    explicit ColumnLowCardinality(ColumnRef dictionary_column);\n    explicit ColumnLowCardinality(std::shared_ptr<ColumnNullable> dictionary_column);\n\n    template <typename T>\n    explicit ColumnLowCardinality(std::shared_ptr<ColumnNullableT<T>> dictionary_column)\n        : ColumnLowCardinality(dictionary_column->template As<ColumnNullable>())\n    {}\n\n"
      },
      {
        "chunk_id": "doc_28_chunk_3",
        "original_index": 3,
        "content": "    ~ColumnLowCardinality();\n\n    /// Increase the capacity of the column for large block insertion.\n    void Reserve(size_t new_cap) override;\n\n    /// Appends another LowCardinality column to the end of this one, updating dictionary.\n    void Append(ColumnRef /*column*/) override;\n\n    bool LoadPrefix(InputStream* input, size_t rows) override;\n\n    /// Loads column data from input stream.\n    bool LoadBody(InputStream* input, size_t rows) override;\n\n    /// Saves column prefix to output stream.\n    void SavePrefix(OutputStream* output) override;\n\n    /// Saves column data to output stream.\n    void SaveBody(OutputStream* output) override;\n\n    /// Clear column data.\n    void Clear() override;\n\n    /// Returns count of rows in the column.\n    size_t Size() const override;\n\n"
      },
      {
        "chunk_id": "doc_28_chunk_4",
        "original_index": 4,
        "content": "    /// Makes slice of current column, with compacted dictionary\n    ColumnRef Slice(size_t begin, size_t len) const override;\n    ColumnRef CloneEmpty() const override;\n    void Swap(Column& other) override;\n    ItemView GetItem(size_t index) const override;\n\n    size_t GetDictionarySize() const;\n    TypeRef GetNestedType() const;\n\nprotected:\n    std::uint64_t getDictionaryIndex(std::uint64_t item_index) const;\n    void appendIndex(std::uint64_t item_index);\n    void removeLastIndex();\n    ColumnRef GetDictionary();\n\n    void AppendUnsafe(const ItemView &);\n\nprivate:\n    void Setup(ColumnRef dictionary_column);\n    void AppendNullItem();\n    void AppendDefaultItem();\n\npublic:\n    static details::LowCardinalityHashKey computeHashKey(const ItemView &);\n};\n\n/** Type-aware wrapper that provides simple convenience interface for accessing/appending individual items.\n */\ntemplate <typename DictionaryColumnType>\nclass ColumnLowCardinalityT : public ColumnLowCardinality {\n\n"
      },
      {
        "chunk_id": "doc_28_chunk_5",
        "original_index": 5,
        "content": "    DictionaryColumnType& typed_dictionary_;\n    const Type::Code type_;\n\npublic:\n    using WrappedColumnType = DictionaryColumnType;\n    // Type this column takes as argument of Append and returns with At() and operator[]\n    using ValueType = typename DictionaryColumnType::ValueType;\n\n    explicit ColumnLowCardinalityT(ColumnLowCardinality&& col)\n        : ColumnLowCardinality(std::move(col))\n        ,  typed_dictionary_(dynamic_cast<DictionaryColumnType &>(*GetDictionary()))\n        ,  type_(GetTypeCode(typed_dictionary_))\n    {\n    }\n\n    template <typename ...Args>\n    explicit ColumnLowCardinalityT(Args &&... args)\n        : ColumnLowCardinalityT(std::make_shared<DictionaryColumnType>(std::forward<Args>(args)...))\n    {}\n\n"
      },
      {
        "chunk_id": "doc_28_chunk_6",
        "original_index": 6,
        "content": "    // Create LC<T> column from existing T-column, making a deep copy of all contents.\n    explicit ColumnLowCardinalityT(std::shared_ptr<DictionaryColumnType> dictionary_col)\n        : ColumnLowCardinality(dictionary_col)\n        , typed_dictionary_(dynamic_cast<DictionaryColumnType &>(*GetDictionary()))\n        , type_(GetTypeCode(typed_dictionary_))\n    {}\n\n    /// Extended interface to simplify reading/adding individual items.\n\n    /// Returns element at given row number.\n    inline ValueType At(size_t n) const {\n        return typed_dictionary_.At(getDictionaryIndex(n));\n    }\n\n    /// Returns element at given row number.\n    inline ValueType operator [] (size_t n) const {\n        return typed_dictionary_[getDictionaryIndex(n)];\n    }\n\n    // so the non-virtual Append below doesn't shadow Append() from base class when compiled with older compilers.\n    using ColumnLowCardinality::Append;\n\n"
      },
      {
        "chunk_id": "doc_28_chunk_7",
        "original_index": 7,
        "content": "    inline void Append(const ValueType & value) {\n        if constexpr (IsNullable<WrappedColumnType>) {\n            if (value.has_value()) {\n                AppendUnsafe(ItemView{type_, *value});\n            } else {\n                AppendUnsafe(ItemView{});\n            }\n        } else {\n            AppendUnsafe(ItemView{type_, value});\n        }\n    }\n\n    template <typename T>\n    inline void AppendMany(const T& container) {\n        for (const auto & item : container) {\n            Append(item);\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_28_chunk_8",
        "original_index": 8,
        "content": "    /** Create a ColumnLowCardinalityT from a ColumnLowCardinality, without copying data and offsets, but by\n     * 'stealing' those from `col`.\n     *\n     *  Ownership of column internals is transferred to returned object, original (argument) object\n     *  MUST NOT BE USED IN ANY WAY, it is only safe to dispose it.\n     *\n     *  Throws an exception if `col` is of wrong type, it is safe to use original col in this case.\n     *  This is a static method to make such conversion verbose.\n     */\n    static auto Wrap(ColumnLowCardinality&& col) {\n        return std::make_shared<ColumnLowCardinalityT<WrappedColumnType>>(std::move(col));\n    }\n\n"
      },
      {
        "chunk_id": "doc_28_chunk_9",
        "original_index": 9,
        "content": "    static auto Wrap(Column&& col) { return Wrap(std::move(dynamic_cast<ColumnLowCardinality&&>(col))); }\n\n    // Helper to simplify integration with other APIs\n    static auto Wrap(ColumnRef&& col) { return Wrap(std::move(*col->AsStrict<ColumnLowCardinality>())); }\n\n    ColumnRef Slice(size_t begin, size_t size) const override {\n        return Wrap(ColumnLowCardinality::Slice(begin, size));\n    }\n\n    ColumnRef CloneEmpty() const override { return Wrap(ColumnLowCardinality::CloneEmpty()); }\n\nprivate:\n\n    template <typename T>\n    static auto GetTypeCode(T& column) {\n        if constexpr (IsNullable<T>) {\n            return GetTypeCode(*column.Nested()->template AsStrict<typename T::NestedColumnType>());\n        } else {\n            return column.Type()->GetCode();\n        }\n    }\n};\n\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_29",
    "original_uuid": "130da0aba10d9e75238c693ee9b6ea2494f8eca2a10e29fa834efe3729ee5bd6",
    "content": "#pragma once\n\n#include \"array.h\"\n#include \"column.h\"\n#include \"numeric.h\"\n#include \"tuple.h\"\n\nnamespace clickhouse {\n\ntemplate <typename NestedColumnType, Type::Code type_code>\nclass ColumnGeo : public Column {\npublic:\n    using ValueType = typename NestedColumnType::ValueType;\n\n    ColumnGeo();\n\n    explicit ColumnGeo(ColumnRef data);\n\n    /// Appends one element to the end of column.\n    template <typename T = ValueType>\n    void Append(const T& value) {\n        data_->Append(value);\n    }\n\n    /// Returns element at given row number.\n    const ValueType At(size_t n) const;\n\n    /// Returns element at given row number.\n    inline const ValueType operator[](size_t n) const { return At(n); }\n\npublic:\n    /// Increase the capacity of the column for large block insertion.\n    void Reserve(size_t new_cap) override;\n\n    /// Appends content of given column to the end of current one.\n    void Append(ColumnRef column) override;\n\n    /// Loads column data from input stream.\n    bool LoadBody(InputStream* input, size_t rows) override;\n\n    /// Saves column data to output stream.\n    void SaveBody(OutputStream* output) override;\n\n    /// Clear column data .\n    void Clear() override;\n\n    /// Returns count of rows in the column.\n    size_t Size() const override;\n\n    /// Makes slice of the current column.\n    ColumnRef Slice(size_t begin, size_t len) const override;\n    ColumnRef CloneEmpty() const override;\n    void Swap(Column& other) override;\n\nprivate:\n    std::shared_ptr<NestedColumnType> data_;\n};\n\n// /**\n//  * Represents a Point column.\n//  */\nusing ColumnPoint = ColumnGeo<ColumnTupleT<ColumnFloat64, ColumnFloat64>, Type::Code::Point>;\n\n/**\n * Represents a Ring column.\n */\nusing ColumnRing = ColumnGeo<ColumnArrayT<ColumnPoint>, Type::Code::Ring>;\n\n/**\n * Represents a Polygon column.\n */\nusing ColumnPolygon = ColumnGeo<ColumnArrayT<ColumnRing>, Type::Code::Polygon>;\n\n/**\n * Represents a MultiPolygon column.\n */\nusing ColumnMultiPolygon = ColumnGeo<ColumnArrayT<ColumnPolygon>, Type::Code::MultiPolygon>;\n\n}  // namespace clickhouse\n",
    "chunks": [
      {
        "chunk_id": "doc_29_chunk_0",
        "original_index": 0,
        "content": "#pragma once\n\n#include \"array.h\"\n#include \"column.h\"\n#include \"numeric.h\"\n#include \"tuple.h\"\n\nnamespace clickhouse {\n\ntemplate <typename NestedColumnType, Type::Code type_code>\nclass ColumnGeo : public Column {\npublic:\n    using ValueType = typename NestedColumnType::ValueType;\n\n    ColumnGeo();\n\n    explicit ColumnGeo(ColumnRef data);\n\n    /// Appends one element to the end of column.\n    template <typename T = ValueType>\n    void Append(const T& value) {\n        data_->Append(value);\n    }\n\n    /// Returns element at given row number.\n    const ValueType At(size_t n) const;\n\n    /// Returns element at given row number.\n    inline const ValueType operator[](size_t n) const { return At(n); }\n\n"
      },
      {
        "chunk_id": "doc_29_chunk_1",
        "original_index": 1,
        "content": "public:\n    /// Increase the capacity of the column for large block insertion.\n    void Reserve(size_t new_cap) override;\n\n    /// Appends content of given column to the end of current one.\n    void Append(ColumnRef column) override;\n\n    /// Loads column data from input stream.\n    bool LoadBody(InputStream* input, size_t rows) override;\n\n    /// Saves column data to output stream.\n    void SaveBody(OutputStream* output) override;\n\n"
      },
      {
        "chunk_id": "doc_29_chunk_2",
        "original_index": 2,
        "content": "    /// Clear column data .\n    void Clear() override;\n\n    /// Returns count of rows in the column.\n    size_t Size() const override;\n\n    /// Makes slice of the current column.\n    ColumnRef Slice(size_t begin, size_t len) const override;\n    ColumnRef CloneEmpty() const override;\n    void Swap(Column& other) override;\n\nprivate:\n    std::shared_ptr<NestedColumnType> data_;\n};\n\n// /**\n//  * Represents a Point column.\n//  */\nusing ColumnPoint = ColumnGeo<ColumnTupleT<ColumnFloat64, ColumnFloat64>, Type::Code::Point>;\n\n/**\n * Represents a Ring column.\n */\nusing ColumnRing = ColumnGeo<ColumnArrayT<ColumnPoint>, Type::Code::Ring>;\n\n/**\n * Represents a Polygon column.\n */\nusing ColumnPolygon = ColumnGeo<ColumnArrayT<ColumnRing>, Type::Code::Polygon>;\n\n/**\n * Represents a MultiPolygon column.\n */\nusing ColumnMultiPolygon = ColumnGeo<ColumnArrayT<ColumnPolygon>, Type::Code::MultiPolygon>;\n\n}  // namespace clickhouse\n"
      }
    ]
  },
  {
    "doc_id": "doc_30",
    "original_uuid": "43bd45ab839500606044476e58992df90d6c72471777260327776df9c3f3d4bd",
    "content": "#pragma once\n\n#include <iterator>\n#include <type_traits>\n#include <utility>\n\nnamespace clickhouse {\n\ntemplate <typename UnaryFunction, typename Iterator, typename Reference = decltype(std::declval<UnaryFunction>()(std::declval<Iterator>())),\n          typename Value = std::decay_t<Reference>>\nclass ProjectedIterator {\npublic:\n    using value_type        = Value;\n    using reference         = Reference;\n    using pointer           = Reference;\n    using difference_type   = typename std::iterator_traits<Iterator>::difference_type;\n    using iterator_category = typename std::iterator_traits<Iterator>::iterator_category;\n\n    ProjectedIterator() = default;\n\n    inline ProjectedIterator(Iterator const& iterator, UnaryFunction functor)\n        : iterator_(iterator)\n        , functor_(std::move(functor)) {\n    }\n\n    inline UnaryFunction functor() const { return functor; }\n\n    inline Iterator const& base() const { return iterator_; }\n\n    inline reference operator*() const { return functor_(iterator_); }\n\n    inline ProjectedIterator& operator++() {\n        ++iterator_;\n        return *this;\n    }\n\n    inline ProjectedIterator& operator--() {\n        --iterator_;\n        return *this;\n    }\n\n    inline bool operator==(const ProjectedIterator& other) const {\n        return this->iterator_ == other.iterator_;\n    }\n\n    inline bool operator!=(const ProjectedIterator& other) const {\n        return !(*this == other);\n    }\n\nprivate:\n    Iterator iterator_;\n    UnaryFunction functor_;\n};\n\n}  // namespace clickhouse\n",
    "chunks": [
      {
        "chunk_id": "doc_30_chunk_0",
        "original_index": 0,
        "content": "#pragma once\n\n#include <iterator>\n#include <type_traits>\n#include <utility>\n\nnamespace clickhouse {\n\ntemplate <typename UnaryFunction, typename Iterator, typename Reference = decltype(std::declval<UnaryFunction>()(std::declval<Iterator>())),\n          typename Value = std::decay_t<Reference>>\nclass ProjectedIterator {\npublic:\n    using value_type        = Value;\n    using reference         = Reference;\n    using pointer           = Reference;\n    using difference_type   = typename std::iterator_traits<Iterator>::difference_type;\n    using iterator_category = typename std::iterator_traits<Iterator>::iterator_category;\n\n"
      },
      {
        "chunk_id": "doc_30_chunk_1",
        "original_index": 1,
        "content": "    ProjectedIterator() = default;\n\n    inline ProjectedIterator(Iterator const& iterator, UnaryFunction functor)\n        : iterator_(iterator)\n        , functor_(std::move(functor)) {\n    }\n\n    inline UnaryFunction functor() const { return functor; }\n\n    inline Iterator const& base() const { return iterator_; }\n\n    inline reference operator*() const { return functor_(iterator_); }\n\n    inline ProjectedIterator& operator++() {\n        ++iterator_;\n        return *this;\n    }\n\n    inline ProjectedIterator& operator--() {\n        --iterator_;\n        return *this;\n    }\n\n    inline bool operator==(const ProjectedIterator& other) const {\n        return this->iterator_ == other.iterator_;\n    }\n\n    inline bool operator!=(const ProjectedIterator& other) const {\n        return !(*this == other);\n    }\n\nprivate:\n    Iterator iterator_;\n    UnaryFunction functor_;\n};\n\n}  // namespace clickhouse\n"
      }
    ]
  },
  {
    "doc_id": "doc_31",
    "original_uuid": "4969d098eff293d66a67d63d1c2d7c785a7b09666272510b9e0c6324e8246dc8",
    "content": "/*\n * Copyright 2020 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.cli.logging;\n\npublic enum ConsoleOutput {\n  auto,\n  rich,\n  plain\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_31_chunk_0",
        "original_index": 0,
        "content": "/*\n * Copyright 2020 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.cli.logging;\n\npublic enum ConsoleOutput {\n  auto,\n  rich,\n  plain\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_32",
    "original_uuid": "e154c2b27db3036da0a3ae9e88f7445ec748ea9d2d1c24b14460801801705c66",
    "content": "/*\n * Copyright 2020 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.plugins.common;\n\nimport com.fasterxml.jackson.annotation.JsonIgnoreProperties;\nimport com.google.cloud.tools.jib.api.LogEvent;\nimport com.google.cloud.tools.jib.http.FailoverHttpClient;\nimport com.google.cloud.tools.jib.http.Request;\nimport com.google.cloud.tools.jib.http.Response;\nimport com.google.cloud.tools.jib.json.JsonTemplate;\nimport com.google.cloud.tools.jib.json.JsonTemplateMapper;\nimport com.google.cloud.tools.jib.plugins.common.globalconfig.GlobalConfig;\nimport com.google.common.annotations.VisibleForTesting;\nimport java.io.IOException;\nimport java.net.URL;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.StandardCopyOption;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.time.format.DateTimeParseException;\nimport java.util.Optional;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Future;\nimport java.util.function.Consumer;\n\n/** Checks if Jib is up-to-date. */\npublic class UpdateChecker {\n\n  private static final String LAST_UPDATE_CHECK_FILENAME = \"lastUpdateCheck\";\n\n  /** JSON template for content downloaded during version check. */\n  @JsonIgnoreProperties(ignoreUnknown = true)\n  private static class VersionJsonTemplate implements JsonTemplate {\n    private String latest = \"\";\n  }\n\n  /**\n   * Begins checking for an update in a separate thread.\n   *\n   * @param executorService the {@link ExecutorService}\n   * @param versionUrl the location to check for the latest version\n   * @param toolName the tool name\n   * @param toolVersion the tool version\n   * @param log {@link Consumer} used to log messages\n   * @return a new {@link UpdateChecker}\n   */\n  public static Future<Optional<String>> checkForUpdate(\n      ExecutorService executorService,\n      String versionUrl,\n      String toolName,\n      String toolVersion,\n      Consumer<LogEvent> log) {\n    return executorService.submit(\n        () ->\n            performUpdateCheck(\n                GlobalConfig.getConfigDir(), toolVersion, versionUrl, toolName, log));\n  }\n\n  @VisibleForTesting\n  static Optional<String> performUpdateCheck(\n      Path configDir,\n      String currentVersion,\n      String versionUrl,\n      String toolName,\n      Consumer<LogEvent> log) {\n    Path lastUpdateCheck = configDir.resolve(LAST_UPDATE_CHECK_FILENAME);\n\n    try {\n      // Check time of last update check\n      if (Files.exists(lastUpdateCheck)) {\n        try {\n          String fileContents =\n              new String(Files.readAllBytes(lastUpdateCheck), StandardCharsets.UTF_8);\n          Instant modifiedTime = Instant.parse(fileContents);\n          if (modifiedTime.plus(Duration.ofDays(1)).isAfter(Instant.now())) {\n            return Optional.empty();\n          }\n        } catch (DateTimeParseException | IOException ex) {\n          // If reading update time failed, file might be corrupt, so delete it\n          log.accept(LogEvent.debug(\"Failed to read lastUpdateCheck; \" + ex.getMessage()));\n          Files.delete(lastUpdateCheck);\n        }\n      }\n\n      // Check for update\n      FailoverHttpClient httpClient = new FailoverHttpClient(true, false, ignored -> {});\n      try {\n        Response response =\n            httpClient.get(\n                new URL(versionUrl),\n                Request.builder()\n                    .setHttpTimeout(3000)\n                    .setUserAgent(\"jib \" + currentVersion + \" \" + toolName)\n                    .build());\n        VersionJsonTemplate version =\n            JsonTemplateMapper.readJson(response.getBody(), VersionJsonTemplate.class);\n\n        Path lastUpdateCheckTemp =\n            Files.createTempFile(configDir, LAST_UPDATE_CHECK_FILENAME, null);\n        lastUpdateCheckTemp.toFile().deleteOnExit();\n        Files.write(lastUpdateCheckTemp, Instant.now().toString().getBytes(StandardCharsets.UTF_8));\n        Files.move(lastUpdateCheckTemp, lastUpdateCheck, StandardCopyOption.REPLACE_EXISTING);\n\n        if (currentVersion.equals(version.latest)) {\n          return Optional.empty();\n        }\n        return Optional.of(version.latest);\n      } finally {\n        httpClient.shutDown();\n      }\n\n    } catch (IOException ex) {\n      log.accept(LogEvent.debug(\"Update check failed; \" + ex.getMessage()));\n    }\n\n    return Optional.empty();\n  }\n\n  /**\n   * Returns the latest Jib version available if the check succeeded and the current version is\n   * outdated, or returns {@code Optional.empty()} if the check was interrupted or did not determine\n   * that a later version was available.\n   *\n   * @param updateMessageFuture the {@link Future} returned by {@link UpdateChecker#checkForUpdate}\n   * @return the latest version, if found, else {@code Optional.empty()}.\n   */\n  public static Optional<String> finishUpdateCheck(Future<Optional<String>> updateMessageFuture) {\n    if (updateMessageFuture.isDone()) {\n      try {\n        return updateMessageFuture.get();\n      } catch (InterruptedException | ExecutionException ex) {\n        // No need to restore the interrupted status. The intention here is to silently consume any\n        // kind of error\n      }\n    }\n    updateMessageFuture.cancel(true);\n    return Optional.empty();\n  }\n\n  private UpdateChecker() {}\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_32_chunk_0",
        "original_index": 0,
        "content": "/*\n * Copyright 2020 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.plugins.common;\n\n"
      },
      {
        "chunk_id": "doc_32_chunk_1",
        "original_index": 1,
        "content": "import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\nimport com.google.cloud.tools.jib.api.LogEvent;\nimport com.google.cloud.tools.jib.http.FailoverHttpClient;\nimport com.google.cloud.tools.jib.http.Request;\nimport com.google.cloud.tools.jib.http.Response;\nimport com.google.cloud.tools.jib.json.JsonTemplate;\nimport com.google.cloud.tools.jib.json.JsonTemplateMapper;\nimport com.google.cloud.tools.jib.plugins.common.globalconfig.GlobalConfig;\nimport com.google.common.annotations.VisibleForTesting;\nimport java.io.IOException;\nimport java.net.URL;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.StandardCopyOption;\nimport java.time.Duration;\nimport java.time.Instant;\nimport java.time.format.DateTimeParseException;\nimport java.util.Optional;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Future;\nimport java.util.function.Consumer;\n\n"
      },
      {
        "chunk_id": "doc_32_chunk_2",
        "original_index": 2,
        "content": "/** Checks if Jib is up-to-date. */\npublic class UpdateChecker {\n\n  private static final String LAST_UPDATE_CHECK_FILENAME = \"lastUpdateCheck\";\n\n  /** JSON template for content downloaded during version check. */\n  @JsonIgnoreProperties(ignoreUnknown = true)\n  private static class VersionJsonTemplate implements JsonTemplate {\n    private String latest = \"\";\n  }\n\n"
      },
      {
        "chunk_id": "doc_32_chunk_3",
        "original_index": 3,
        "content": "  /**\n   * Begins checking for an update in a separate thread.\n   *\n   * @param executorService the {@link ExecutorService}\n   * @param versionUrl the location to check for the latest version\n   * @param toolName the tool name\n   * @param toolVersion the tool version\n   * @param log {@link Consumer} used to log messages\n   * @return a new {@link UpdateChecker}\n   */\n  public static Future<Optional<String>> checkForUpdate(\n      ExecutorService executorService,\n      String versionUrl,\n      String toolName,\n      String toolVersion,\n      Consumer<LogEvent> log) {\n    return executorService.submit(\n        () ->\n            performUpdateCheck(\n                GlobalConfig.getConfigDir(), toolVersion, versionUrl, toolName, log));\n  }\n\n"
      },
      {
        "chunk_id": "doc_32_chunk_4",
        "original_index": 4,
        "content": "  @VisibleForTesting\n  static Optional<String> performUpdateCheck(\n      Path configDir,\n      String currentVersion,\n      String versionUrl,\n      String toolName,\n      Consumer<LogEvent> log) {\n    Path lastUpdateCheck = configDir.resolve(LAST_UPDATE_CHECK_FILENAME);\n\n    try {\n      // Check time of last update check\n      if (Files.exists(lastUpdateCheck)) {\n        try {\n          String fileContents =\n              new String(Files.readAllBytes(lastUpdateCheck), StandardCharsets.UTF_8);\n          Instant modifiedTime = Instant.parse(fileContents);\n          if (modifiedTime.plus(Duration.ofDays(1)).isAfter(Instant.now())) {\n            return Optional.empty();\n          }\n        } catch (DateTimeParseException | IOException ex) {\n          // If reading update time failed, file might be corrupt, so delete it\n          log.accept(LogEvent.debug(\"Failed to read lastUpdateCheck; \" + ex.getMessage()));\n          Files.delete(lastUpdateCheck);\n        }\n      }\n\n"
      },
      {
        "chunk_id": "doc_32_chunk_5",
        "original_index": 5,
        "content": "      // Check for update\n      FailoverHttpClient httpClient = new FailoverHttpClient(true, false, ignored -> {});\n      try {\n        Response response =\n            httpClient.get(\n                new URL(versionUrl),\n                Request.builder()\n                    .setHttpTimeout(3000)\n                    .setUserAgent(\"jib \" + currentVersion + \" \" + toolName)\n                    .build());\n        VersionJsonTemplate version =\n            JsonTemplateMapper.readJson(response.getBody(), VersionJsonTemplate.class);\n\n"
      },
      {
        "chunk_id": "doc_32_chunk_6",
        "original_index": 6,
        "content": "        Path lastUpdateCheckTemp =\n            Files.createTempFile(configDir, LAST_UPDATE_CHECK_FILENAME, null);\n        lastUpdateCheckTemp.toFile().deleteOnExit();\n        Files.write(lastUpdateCheckTemp, Instant.now().toString().getBytes(StandardCharsets.UTF_8));\n        Files.move(lastUpdateCheckTemp, lastUpdateCheck, StandardCopyOption.REPLACE_EXISTING);\n\n        if (currentVersion.equals(version.latest)) {\n          return Optional.empty();\n        }\n        return Optional.of(version.latest);\n      } finally {\n        httpClient.shutDown();\n      }\n\n    } catch (IOException ex) {\n      log.accept(LogEvent.debug(\"Update check failed; \" + ex.getMessage()));\n    }\n\n    return Optional.empty();\n  }\n\n"
      },
      {
        "chunk_id": "doc_32_chunk_7",
        "original_index": 7,
        "content": "  /**\n   * Returns the latest Jib version available if the check succeeded and the current version is\n   * outdated, or returns {@code Optional.empty()} if the check was interrupted or did not determine\n   * that a later version was available.\n   *\n   * @param updateMessageFuture the {@link Future} returned by {@link UpdateChecker#checkForUpdate}\n   * @return the latest version, if found, else {@code Optional.empty()}.\n   */\n  public static Optional<String> finishUpdateCheck(Future<Optional<String>> updateMessageFuture) {\n    if (updateMessageFuture.isDone()) {\n      try {\n        return updateMessageFuture.get();\n      } catch (InterruptedException | ExecutionException ex) {\n        // No need to restore the interrupted status. The intention here is to silently consume any\n        // kind of error\n      }\n    }\n    updateMessageFuture.cancel(true);\n    return Optional.empty();\n  }\n\n  private UpdateChecker() {}\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_33",
    "original_uuid": "f8dd24de0db395aa7cff1e4c804eb1d10f916c9b4765d7c790b1dedfa339f913",
    "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.plugins.common;\n\nimport static com.google.common.truth.Truth.assertThat;\nimport static com.google.common.truth.Truth8.assertThat;\nimport static org.junit.Assert.assertThrows;\nimport static org.mockito.ArgumentMatchers.anyString;\nimport static org.mockito.Mockito.verify;\nimport static org.mockito.Mockito.when;\n\nimport com.google.cloud.tools.jib.api.Credential;\nimport com.google.cloud.tools.jib.api.CredentialRetriever;\nimport com.google.cloud.tools.jib.frontend.CredentialRetrieverFactory;\nimport com.google.common.collect.ImmutableMap;\nimport java.io.FileNotFoundException;\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Properties;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.TemporaryFolder;\nimport org.junit.runner.RunWith;\nimport org.mockito.Mock;\nimport org.mockito.junit.MockitoJUnitRunner;\n\n/** Tests for {@link DefaultCredentialRetrievers}. */\n@RunWith(MockitoJUnitRunner.class)\npublic class DefaultCredentialRetrieversTest {\n\n  @Rule public final TemporaryFolder temporaryFolder = new TemporaryFolder();\n\n  @Mock private CredentialRetrieverFactory mockCredentialRetrieverFactory;\n  @Mock private CredentialRetriever mockDockerCredentialHelperCredentialRetriever;\n  @Mock private CredentialRetriever mockKnownCredentialRetriever;\n  @Mock private CredentialRetriever mockInferredCredentialRetriever;\n  @Mock private CredentialRetriever mockWellKnownCredentialHelpersCredentialRetriever;\n  @Mock private CredentialRetriever mockXdgPrimaryCredentialRetriever;\n  @Mock private CredentialRetriever mockEnvHomeXdgCredentialRetriever;\n  @Mock private CredentialRetriever mockSystemHomeXdgCredentialRetriever;\n  @Mock private CredentialRetriever mockDockerConfigEnvDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockDockerConfigEnvLegacyDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockSystemHomeDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockSystemHomeKubernetesDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockSystemHomeLegacyDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockEnvHomeDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockEnvHomeKubernetesDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockEnvHomeLegacyDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockApplicationDefaultCredentialRetriever;\n\n  private Properties properties;\n  private Map<String, String> environment;\n\n  private final Credential knownCredential = Credential.from(\"username\", \"password\");\n  private final Credential inferredCredential = Credential.from(\"username2\", \"password2\");\n\n  @Before\n  public void setUp() {\n    properties = new Properties();\n    properties.setProperty(\"os.name\", \"unknown\");\n    properties.setProperty(\"user.home\", Paths.get(\"/system/home\").toString());\n    environment =\n        ImmutableMap.of(\n            \"HOME\",\n            Paths.get(\"/env/home\").toString(),\n            \"DOCKER_CONFIG\",\n            Paths.get(\"/docker_config\").toString(),\n            \"XDG_RUNTIME_DIR\",\n            Paths.get(\"/run/user/1000\").toString(),\n            \"XDG_CONFIG_HOME\",\n            Paths.get(\"/env/home/.config\").toString());\n\n    when(mockCredentialRetrieverFactory.dockerCredentialHelper(anyString()))\n        .thenReturn(mockDockerCredentialHelperCredentialRetriever);\n    when(mockCredentialRetrieverFactory.known(knownCredential, \"credentialSource\"))\n        .thenReturn(mockKnownCredentialRetriever);\n    when(mockCredentialRetrieverFactory.known(inferredCredential, \"inferredCredentialSource\"))\n        .thenReturn(mockInferredCredentialRetriever);\n    when(mockCredentialRetrieverFactory.wellKnownCredentialHelpers())\n        .thenReturn(mockWellKnownCredentialHelpersCredentialRetriever);\n\n    when(mockCredentialRetrieverFactory.dockerConfig(\n            Paths.get(\"/run/user/1000/containers/auth.json\")))\n        .thenReturn(mockXdgPrimaryCredentialRetriever);\n    when(mockCredentialRetrieverFactory.dockerConfig(\n            Paths.get(\"/env/home/.config/containers/auth.json\")))\n        .thenReturn(mockEnvHomeXdgCredentialRetriever);\n\n    when(mockCredentialRetrieverFactory.dockerConfig(\n            Paths.get(\"/system/home/.config/containers/auth.json\")))\n        .thenReturn(mockSystemHomeXdgCredentialRetriever);\n\n    when(mockCredentialRetrieverFactory.dockerConfig(Paths.get(\"/docker_config/config.json\")))\n        .thenReturn(mockDockerConfigEnvDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.dockerConfig(Paths.get(\"/docker_config/.dockerconfigjson\")))\n        .thenReturn(mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.legacyDockerConfig(Paths.get(\"/docker_config/.dockercfg\")))\n        .thenReturn(mockDockerConfigEnvLegacyDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.dockerConfig(Paths.get(\"/system/home/.docker/config.json\")))\n        .thenReturn(mockSystemHomeDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.dockerConfig(\n            Paths.get(\"/system/home/.docker/.dockerconfigjson\")))\n        .thenReturn(mockSystemHomeKubernetesDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.legacyDockerConfig(\n            Paths.get(\"/system/home/.docker/.dockercfg\")))\n        .thenReturn(mockSystemHomeLegacyDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.dockerConfig(Paths.get(\"/env/home/.docker/config.json\")))\n        .thenReturn(mockEnvHomeDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.dockerConfig(\n            Paths.get(\"/env/home/.docker/.dockerconfigjson\")))\n        .thenReturn(mockEnvHomeKubernetesDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.legacyDockerConfig(\n            Paths.get(\"/env/home/.docker/.dockercfg\")))\n        .thenReturn(mockEnvHomeLegacyDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.googleApplicationDefaultCredentials())\n        .thenReturn(mockApplicationDefaultCredentialRetriever);\n  }\n\n  @Test\n  public void testAsList() throws FileNotFoundException {\n    List<CredentialRetriever> retriever =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .asList();\n    assertThat(retriever)\n        .containsExactly(\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockSystemHomeXdgCredentialRetriever,\n            mockDockerConfigEnvDockerConfigCredentialRetriever,\n            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockSystemHomeDockerConfigCredentialRetriever,\n            mockSystemHomeKubernetesDockerConfigCredentialRetriever,\n            mockSystemHomeLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n  }\n\n  @Test\n  public void testAsList_all() throws FileNotFoundException {\n    List<CredentialRetriever> retrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setKnownCredential(knownCredential, \"credentialSource\")\n            .setInferredCredential(inferredCredential, \"inferredCredentialSource\")\n            .setCredentialHelper(\"credentialHelperSuffix\")\n            .asList();\n    assertThat(retrievers)\n        .containsExactly(\n            mockKnownCredentialRetriever,\n            mockDockerCredentialHelperCredentialRetriever,\n            mockInferredCredentialRetriever,\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockSystemHomeXdgCredentialRetriever,\n            mockDockerConfigEnvDockerConfigCredentialRetriever,\n            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockSystemHomeDockerConfigCredentialRetriever,\n            mockSystemHomeKubernetesDockerConfigCredentialRetriever,\n            mockSystemHomeLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n\n    verify(mockCredentialRetrieverFactory).known(knownCredential, \"credentialSource\");\n    verify(mockCredentialRetrieverFactory).known(inferredCredential, \"inferredCredentialSource\");\n    verify(mockCredentialRetrieverFactory)\n        .dockerCredentialHelper(\"docker-credential-credentialHelperSuffix\");\n  }\n\n  @Test\n  public void testAsList_credentialHelperPath() throws IOException {\n    Path fakeCredentialHelperPath = temporaryFolder.newFile(\"fake-credHelper\").toPath();\n    DefaultCredentialRetrievers credentialRetrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setCredentialHelper(fakeCredentialHelperPath.toString());\n\n    List<CredentialRetriever> retrievers = credentialRetrievers.asList();\n    assertThat(retrievers)\n        .containsExactly(\n            mockDockerCredentialHelperCredentialRetriever,\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockSystemHomeXdgCredentialRetriever,\n            mockDockerConfigEnvDockerConfigCredentialRetriever,\n            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockSystemHomeDockerConfigCredentialRetriever,\n            mockSystemHomeKubernetesDockerConfigCredentialRetriever,\n            mockSystemHomeLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n    verify(mockCredentialRetrieverFactory)\n        .dockerCredentialHelper(fakeCredentialHelperPath.toString());\n\n    Files.delete(fakeCredentialHelperPath);\n    Exception ex = assertThrows(FileNotFoundException.class, credentialRetrievers::asList);\n    assertThat(ex)\n        .hasMessageThat()\n        .isEqualTo(\"Specified credential helper was not found: \" + fakeCredentialHelperPath);\n  }\n\n  @Test\n  public void testDockerConfigRetrievers_undefinedHome() throws FileNotFoundException {\n    List<CredentialRetriever> retrievers =\n        new DefaultCredentialRetrievers(\n                mockCredentialRetrieverFactory, new Properties(), new HashMap<>())\n            .asList();\n    assertThat(retrievers)\n        .containsExactly(\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n  }\n\n  @Test\n  public void testDockerConfigRetrievers_noDuplicateRetrievers() throws FileNotFoundException {\n    properties.setProperty(\"user.home\", Paths.get(\"/env/home\").toString());\n    List<CredentialRetriever> retrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .asList();\n    assertThat(retrievers)\n        .containsExactly(\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockDockerConfigEnvDockerConfigCredentialRetriever,\n            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n\n    environment =\n        ImmutableMap.of(\n            \"HOME\",\n            Paths.get(\"/env/home\").toString(),\n            \"DOCKER_CONFIG\",\n            Paths.get(\"/env/home/.docker\").toString());\n    retrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .asList();\n    assertThat(retrievers)\n        .containsExactly(\n            mockEnvHomeXdgCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n  }\n\n  @Test\n  public void testCredentialHelper_cmdExtension() throws IOException {\n    Path credHelper = temporaryFolder.newFile(\"foo.cmd\").toPath();\n    Path pathWithoutCmd = credHelper.getParent().resolve(\"foo\");\n    assertThat(credHelper).isEqualTo(pathWithoutCmd.getParent().resolve(\"foo.cmd\"));\n\n    DefaultCredentialRetrievers credentialRetrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setCredentialHelper(pathWithoutCmd.toString());\n    Exception ex = assertThrows(FileNotFoundException.class, credentialRetrievers::asList);\n    assertThat(ex).hasMessageThat().startsWith(\"Specified credential helper was not found:\");\n    assertThat(ex).hasMessageThat().endsWith(\"foo\");\n\n    properties.setProperty(\"os.name\", \"winDOWs\");\n    List<CredentialRetriever> retrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setCredentialHelper(pathWithoutCmd.toString())\n            .asList();\n\n    assertThat(retrievers)\n        .containsExactly(\n            mockDockerCredentialHelperCredentialRetriever,\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockSystemHomeXdgCredentialRetriever,\n            mockDockerConfigEnvDockerConfigCredentialRetriever,\n            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockSystemHomeDockerConfigCredentialRetriever,\n            mockSystemHomeKubernetesDockerConfigCredentialRetriever,\n            mockSystemHomeLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n  }\n\n  @Test\n  public void testCredentialHelper_exeExtension() throws IOException {\n    Path credHelper = temporaryFolder.newFile(\"foo.exe\").toPath();\n    Path pathWithoutExe = credHelper.getParent().resolve(\"foo\");\n    assertThat(credHelper).isEqualTo(pathWithoutExe.getParent().resolve(\"foo.exe\"));\n\n    DefaultCredentialRetrievers credentialRetrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setCredentialHelper(pathWithoutExe.toString());\n    Exception ex = assertThrows(FileNotFoundException.class, credentialRetrievers::asList);\n    assertThat(ex).hasMessageThat().startsWith(\"Specified credential helper was not found:\");\n    assertThat(ex).hasMessageThat().endsWith(\"foo\");\n\n    properties.setProperty(\"os.name\", \"winDOWs\");\n    List<CredentialRetriever> retrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setCredentialHelper(pathWithoutExe.toString())\n            .asList();\n\n    assertThat(retrievers)\n        .containsExactly(\n            mockDockerCredentialHelperCredentialRetriever,\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockSystemHomeXdgCredentialRetriever,\n            mockDockerConfigEnvDockerConfigCredentialRetriever,\n            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockSystemHomeDockerConfigCredentialRetriever,\n            mockSystemHomeKubernetesDockerConfigCredentialRetriever,\n            mockSystemHomeLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n  }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_33_chunk_0",
        "original_index": 0,
        "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_1",
        "original_index": 1,
        "content": "package com.google.cloud.tools.jib.plugins.common;\n\nimport static com.google.common.truth.Truth.assertThat;\nimport static com.google.common.truth.Truth8.assertThat;\nimport static org.junit.Assert.assertThrows;\nimport static org.mockito.ArgumentMatchers.anyString;\nimport static org.mockito.Mockito.verify;\nimport static org.mockito.Mockito.when;\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_2",
        "original_index": 2,
        "content": "import com.google.cloud.tools.jib.api.Credential;\nimport com.google.cloud.tools.jib.api.CredentialRetriever;\nimport com.google.cloud.tools.jib.frontend.CredentialRetrieverFactory;\nimport com.google.common.collect.ImmutableMap;\nimport java.io.FileNotFoundException;\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Properties;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.TemporaryFolder;\nimport org.junit.runner.RunWith;\nimport org.mockito.Mock;\nimport org.mockito.junit.MockitoJUnitRunner;\n\n/** Tests for {@link DefaultCredentialRetrievers}. */\n@RunWith(MockitoJUnitRunner.class)\npublic class DefaultCredentialRetrieversTest {\n\n  @Rule public final TemporaryFolder temporaryFolder = new TemporaryFolder();\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_3",
        "original_index": 3,
        "content": "  @Mock private CredentialRetrieverFactory mockCredentialRetrieverFactory;\n  @Mock private CredentialRetriever mockDockerCredentialHelperCredentialRetriever;\n  @Mock private CredentialRetriever mockKnownCredentialRetriever;\n  @Mock private CredentialRetriever mockInferredCredentialRetriever;\n  @Mock private CredentialRetriever mockWellKnownCredentialHelpersCredentialRetriever;\n  @Mock private CredentialRetriever mockXdgPrimaryCredentialRetriever;\n  @Mock private CredentialRetriever mockEnvHomeXdgCredentialRetriever;\n  @Mock private CredentialRetriever mockSystemHomeXdgCredentialRetriever;\n  @Mock private CredentialRetriever mockDockerConfigEnvDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockDockerConfigEnvLegacyDockerConfigCredentialRetriever;\n"
      },
      {
        "chunk_id": "doc_33_chunk_4",
        "original_index": 4,
        "content": "  @Mock private CredentialRetriever mockSystemHomeDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockSystemHomeKubernetesDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockSystemHomeLegacyDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockEnvHomeDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockEnvHomeKubernetesDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockEnvHomeLegacyDockerConfigCredentialRetriever;\n  @Mock private CredentialRetriever mockApplicationDefaultCredentialRetriever;\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_5",
        "original_index": 5,
        "content": "  private Properties properties;\n  private Map<String, String> environment;\n\n  private final Credential knownCredential = Credential.from(\"username\", \"password\");\n  private final Credential inferredCredential = Credential.from(\"username2\", \"password2\");\n\n  @Before\n  public void setUp() {\n    properties = new Properties();\n    properties.setProperty(\"os.name\", \"unknown\");\n    properties.setProperty(\"user.home\", Paths.get(\"/system/home\").toString());\n    environment =\n        ImmutableMap.of(\n            \"HOME\",\n            Paths.get(\"/env/home\").toString(),\n            \"DOCKER_CONFIG\",\n            Paths.get(\"/docker_config\").toString(),\n            \"XDG_RUNTIME_DIR\",\n            Paths.get(\"/run/user/1000\").toString(),\n            \"XDG_CONFIG_HOME\",\n            Paths.get(\"/env/home/.config\").toString());\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_6",
        "original_index": 6,
        "content": "    when(mockCredentialRetrieverFactory.dockerCredentialHelper(anyString()))\n        .thenReturn(mockDockerCredentialHelperCredentialRetriever);\n    when(mockCredentialRetrieverFactory.known(knownCredential, \"credentialSource\"))\n        .thenReturn(mockKnownCredentialRetriever);\n    when(mockCredentialRetrieverFactory.known(inferredCredential, \"inferredCredentialSource\"))\n        .thenReturn(mockInferredCredentialRetriever);\n    when(mockCredentialRetrieverFactory.wellKnownCredentialHelpers())\n        .thenReturn(mockWellKnownCredentialHelpersCredentialRetriever);\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_7",
        "original_index": 7,
        "content": "    when(mockCredentialRetrieverFactory.dockerConfig(\n            Paths.get(\"/run/user/1000/containers/auth.json\")))\n        .thenReturn(mockXdgPrimaryCredentialRetriever);\n    when(mockCredentialRetrieverFactory.dockerConfig(\n            Paths.get(\"/env/home/.config/containers/auth.json\")))\n        .thenReturn(mockEnvHomeXdgCredentialRetriever);\n\n    when(mockCredentialRetrieverFactory.dockerConfig(\n            Paths.get(\"/system/home/.config/containers/auth.json\")))\n        .thenReturn(mockSystemHomeXdgCredentialRetriever);\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_8",
        "original_index": 8,
        "content": "    when(mockCredentialRetrieverFactory.dockerConfig(Paths.get(\"/docker_config/config.json\")))\n        .thenReturn(mockDockerConfigEnvDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.dockerConfig(Paths.get(\"/docker_config/.dockerconfigjson\")))\n        .thenReturn(mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.legacyDockerConfig(Paths.get(\"/docker_config/.dockercfg\")))\n        .thenReturn(mockDockerConfigEnvLegacyDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.dockerConfig(Paths.get(\"/system/home/.docker/config.json\")))\n        .thenReturn(mockSystemHomeDockerConfigCredentialRetriever);\n"
      },
      {
        "chunk_id": "doc_33_chunk_9",
        "original_index": 9,
        "content": "    when(mockCredentialRetrieverFactory.dockerConfig(\n            Paths.get(\"/system/home/.docker/.dockerconfigjson\")))\n        .thenReturn(mockSystemHomeKubernetesDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.legacyDockerConfig(\n            Paths.get(\"/system/home/.docker/.dockercfg\")))\n        .thenReturn(mockSystemHomeLegacyDockerConfigCredentialRetriever);\n"
      },
      {
        "chunk_id": "doc_33_chunk_10",
        "original_index": 10,
        "content": "    when(mockCredentialRetrieverFactory.dockerConfig(Paths.get(\"/env/home/.docker/config.json\")))\n        .thenReturn(mockEnvHomeDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.dockerConfig(\n            Paths.get(\"/env/home/.docker/.dockerconfigjson\")))\n        .thenReturn(mockEnvHomeKubernetesDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.legacyDockerConfig(\n            Paths.get(\"/env/home/.docker/.dockercfg\")))\n        .thenReturn(mockEnvHomeLegacyDockerConfigCredentialRetriever);\n    when(mockCredentialRetrieverFactory.googleApplicationDefaultCredentials())\n        .thenReturn(mockApplicationDefaultCredentialRetriever);\n  }\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_11",
        "original_index": 11,
        "content": "  @Test\n  public void testAsList() throws FileNotFoundException {\n    List<CredentialRetriever> retriever =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .asList();\n    assertThat(retriever)\n        .containsExactly(\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockSystemHomeXdgCredentialRetriever,\n"
      },
      {
        "chunk_id": "doc_33_chunk_12",
        "original_index": 12,
        "content": "            mockDockerConfigEnvDockerConfigCredentialRetriever,\n            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockSystemHomeDockerConfigCredentialRetriever,\n            mockSystemHomeKubernetesDockerConfigCredentialRetriever,\n            mockSystemHomeLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n  }\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_13",
        "original_index": 13,
        "content": "  @Test\n  public void testAsList_all() throws FileNotFoundException {\n    List<CredentialRetriever> retrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setKnownCredential(knownCredential, \"credentialSource\")\n            .setInferredCredential(inferredCredential, \"inferredCredentialSource\")\n            .setCredentialHelper(\"credentialHelperSuffix\")\n            .asList();\n    assertThat(retrievers)\n        .containsExactly(\n            mockKnownCredentialRetriever,\n            mockDockerCredentialHelperCredentialRetriever,\n            mockInferredCredentialRetriever,\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockSystemHomeXdgCredentialRetriever,\n            mockDockerConfigEnvDockerConfigCredentialRetriever,\n            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n"
      },
      {
        "chunk_id": "doc_33_chunk_14",
        "original_index": 14,
        "content": "            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockSystemHomeDockerConfigCredentialRetriever,\n            mockSystemHomeKubernetesDockerConfigCredentialRetriever,\n            mockSystemHomeLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_15",
        "original_index": 15,
        "content": "    verify(mockCredentialRetrieverFactory).known(knownCredential, \"credentialSource\");\n    verify(mockCredentialRetrieverFactory).known(inferredCredential, \"inferredCredentialSource\");\n    verify(mockCredentialRetrieverFactory)\n        .dockerCredentialHelper(\"docker-credential-credentialHelperSuffix\");\n  }\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_16",
        "original_index": 16,
        "content": "  @Test\n  public void testAsList_credentialHelperPath() throws IOException {\n    Path fakeCredentialHelperPath = temporaryFolder.newFile(\"fake-credHelper\").toPath();\n    DefaultCredentialRetrievers credentialRetrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setCredentialHelper(fakeCredentialHelperPath.toString());\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_17",
        "original_index": 17,
        "content": "    List<CredentialRetriever> retrievers = credentialRetrievers.asList();\n    assertThat(retrievers)\n        .containsExactly(\n            mockDockerCredentialHelperCredentialRetriever,\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockSystemHomeXdgCredentialRetriever,\n            mockDockerConfigEnvDockerConfigCredentialRetriever,\n"
      },
      {
        "chunk_id": "doc_33_chunk_18",
        "original_index": 18,
        "content": "            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockSystemHomeDockerConfigCredentialRetriever,\n            mockSystemHomeKubernetesDockerConfigCredentialRetriever,\n            mockSystemHomeLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n    verify(mockCredentialRetrieverFactory)\n        .dockerCredentialHelper(fakeCredentialHelperPath.toString());\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_19",
        "original_index": 19,
        "content": "    Files.delete(fakeCredentialHelperPath);\n    Exception ex = assertThrows(FileNotFoundException.class, credentialRetrievers::asList);\n    assertThat(ex)\n        .hasMessageThat()\n        .isEqualTo(\"Specified credential helper was not found: \" + fakeCredentialHelperPath);\n  }\n\n  @Test\n  public void testDockerConfigRetrievers_undefinedHome() throws FileNotFoundException {\n    List<CredentialRetriever> retrievers =\n        new DefaultCredentialRetrievers(\n                mockCredentialRetrieverFactory, new Properties(), new HashMap<>())\n            .asList();\n    assertThat(retrievers)\n        .containsExactly(\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n  }\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_20",
        "original_index": 20,
        "content": "  @Test\n  public void testDockerConfigRetrievers_noDuplicateRetrievers() throws FileNotFoundException {\n    properties.setProperty(\"user.home\", Paths.get(\"/env/home\").toString());\n    List<CredentialRetriever> retrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .asList();\n    assertThat(retrievers)\n        .containsExactly(\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockDockerConfigEnvDockerConfigCredentialRetriever,\n"
      },
      {
        "chunk_id": "doc_33_chunk_21",
        "original_index": 21,
        "content": "            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_22",
        "original_index": 22,
        "content": "    environment =\n        ImmutableMap.of(\n            \"HOME\",\n            Paths.get(\"/env/home\").toString(),\n            \"DOCKER_CONFIG\",\n            Paths.get(\"/env/home/.docker\").toString());\n    retrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .asList();\n    assertThat(retrievers)\n        .containsExactly(\n            mockEnvHomeXdgCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n  }\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_23",
        "original_index": 23,
        "content": "  @Test\n  public void testCredentialHelper_cmdExtension() throws IOException {\n    Path credHelper = temporaryFolder.newFile(\"foo.cmd\").toPath();\n    Path pathWithoutCmd = credHelper.getParent().resolve(\"foo\");\n    assertThat(credHelper).isEqualTo(pathWithoutCmd.getParent().resolve(\"foo.cmd\"));\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_24",
        "original_index": 24,
        "content": "    DefaultCredentialRetrievers credentialRetrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setCredentialHelper(pathWithoutCmd.toString());\n    Exception ex = assertThrows(FileNotFoundException.class, credentialRetrievers::asList);\n    assertThat(ex).hasMessageThat().startsWith(\"Specified credential helper was not found:\");\n    assertThat(ex).hasMessageThat().endsWith(\"foo\");\n\n    properties.setProperty(\"os.name\", \"winDOWs\");\n    List<CredentialRetriever> retrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setCredentialHelper(pathWithoutCmd.toString())\n            .asList();\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_25",
        "original_index": 25,
        "content": "    assertThat(retrievers)\n        .containsExactly(\n            mockDockerCredentialHelperCredentialRetriever,\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockSystemHomeXdgCredentialRetriever,\n            mockDockerConfigEnvDockerConfigCredentialRetriever,\n            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockSystemHomeDockerConfigCredentialRetriever,\n            mockSystemHomeKubernetesDockerConfigCredentialRetriever,\n            mockSystemHomeLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n  }\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_26",
        "original_index": 26,
        "content": "  @Test\n  public void testCredentialHelper_exeExtension() throws IOException {\n    Path credHelper = temporaryFolder.newFile(\"foo.exe\").toPath();\n    Path pathWithoutExe = credHelper.getParent().resolve(\"foo\");\n    assertThat(credHelper).isEqualTo(pathWithoutExe.getParent().resolve(\"foo.exe\"));\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_27",
        "original_index": 27,
        "content": "    DefaultCredentialRetrievers credentialRetrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setCredentialHelper(pathWithoutExe.toString());\n    Exception ex = assertThrows(FileNotFoundException.class, credentialRetrievers::asList);\n    assertThat(ex).hasMessageThat().startsWith(\"Specified credential helper was not found:\");\n    assertThat(ex).hasMessageThat().endsWith(\"foo\");\n\n    properties.setProperty(\"os.name\", \"winDOWs\");\n    List<CredentialRetriever> retrievers =\n        new DefaultCredentialRetrievers(mockCredentialRetrieverFactory, properties, environment)\n            .setCredentialHelper(pathWithoutExe.toString())\n            .asList();\n\n"
      },
      {
        "chunk_id": "doc_33_chunk_28",
        "original_index": 28,
        "content": "    assertThat(retrievers)\n        .containsExactly(\n            mockDockerCredentialHelperCredentialRetriever,\n            mockXdgPrimaryCredentialRetriever,\n            mockEnvHomeXdgCredentialRetriever,\n            mockSystemHomeXdgCredentialRetriever,\n            mockDockerConfigEnvDockerConfigCredentialRetriever,\n            mockDockerConfigEnvKubernetesDockerConfigCredentialRetriever,\n            mockDockerConfigEnvLegacyDockerConfigCredentialRetriever,\n            mockSystemHomeDockerConfigCredentialRetriever,\n            mockSystemHomeKubernetesDockerConfigCredentialRetriever,\n            mockSystemHomeLegacyDockerConfigCredentialRetriever,\n            mockEnvHomeDockerConfigCredentialRetriever,\n            mockEnvHomeKubernetesDockerConfigCredentialRetriever,\n            mockEnvHomeLegacyDockerConfigCredentialRetriever,\n            mockWellKnownCredentialHelpersCredentialRetriever,\n            mockApplicationDefaultCredentialRetriever)\n        .inOrder();\n  }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_34",
    "original_uuid": "bd642f9c2a6fa3b4643bf66c82f214dd6cea1dcff7f20ce8cad864503b7f40ee",
    "content": "/*\n * Copyright 2019 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.api;\n\nimport static com.google.common.truth.Truth.assertThat;\n\nimport com.google.cloud.tools.jib.api.buildplan.AbsoluteUnixPath;\nimport com.google.cloud.tools.jib.api.buildplan.FileEntriesLayer;\nimport com.google.cloud.tools.jib.api.buildplan.FilePermissions;\nimport com.google.common.collect.ArrayListMultimap;\nimport com.google.common.collect.ImmutableList;\nimport com.google.common.collect.Multimap;\nimport com.google.common.io.CharStreams;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.time.Instant;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Set;\nimport java.util.concurrent.ExecutionException;\nimport java.util.function.BiConsumer;\nimport java.util.zip.GZIPInputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveEntry;\nimport org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\nimport org.junit.BeforeClass;\nimport org.junit.ClassRule;\nimport org.junit.Test;\nimport org.junit.rules.TemporaryFolder;\n\n/**\n * Verify that created image has explicit directory structures, default timestamps, permissions, and\n * file orderings.\n */\npublic class ReproducibleImageTest {\n\n  @ClassRule public static final TemporaryFolder imageLocation = new TemporaryFolder();\n\n  private static File imageTar;\n\n  @BeforeClass\n  public static void createImage()\n      throws InvalidImageReferenceException, InterruptedException, CacheDirectoryCreationException,\n          IOException, RegistryException, ExecutionException {\n\n    Path root = imageLocation.getRoot().toPath();\n    Path fileA = Files.createFile(root.resolve(\"fileA.txt\"));\n    Path fileB = Files.createFile(root.resolve(\"fileB.txt\"));\n    Path fileC = Files.createFile(root.resolve(\"fileC.txt\"));\n    Path subdir = Files.createDirectory(root.resolve(\"dir\"));\n    Path subsubdir = Files.createDirectory(subdir.resolve(\"subdir\"));\n    Files.createFile(subdir.resolve(\"fileD.txt\"));\n    Files.createFile(subsubdir.resolve(\"fileE.txt\"));\n\n    imageTar = new File(imageLocation.getRoot(), \"image.tar\");\n    Containerizer containerizer =\n        Containerizer.to(TarImage.at(imageTar.toPath()).named(\"jib-core/reproducible\"));\n\n    Jib.fromScratch()\n        .setEntrypoint(\"echo\", \"Hello World\")\n        .addLayer(ImmutableList.of(fileA), AbsoluteUnixPath.get(\"/app\"))\n        // layer with out-of-order files\n        .addLayer(ImmutableList.of(fileC, fileB), \"/app\")\n        .addFileEntriesLayer(\n            FileEntriesLayer.builder()\n                .addEntryRecursive(subdir, AbsoluteUnixPath.get(\"/app\"))\n                .build())\n        .containerize(containerizer);\n  }\n\n  @Test\n  public void testTarballStructure() throws IOException {\n    // known content should produce known results\n    List<String> actual = new ArrayList<>();\n    try (TarArchiveInputStream input =\n        new TarArchiveInputStream(Files.newInputStream(imageTar.toPath()))) {\n      TarArchiveEntry imageEntry;\n      while ((imageEntry = input.getNextTarEntry()) != null) {\n        actual.add(imageEntry.getName());\n      }\n    }\n\n    assertThat(actual)\n        .containsExactly(\n            \"c46572ef74f58d95e44dd36c1fbdfebd3752e8b56a794a13c11cfed35a1a6e1c.tar.gz\",\n            \"6d2763b0f3940d324ea6b55386429e5b173899608abf7d1bff62e25dd2e4dcea.tar.gz\",\n            \"530c1954a2b087d0b989895ea56435c9dc739a973f2d2b6cb9bb98e55bbea7ac.tar.gz\",\n            \"config.json\",\n            \"manifest.json\")\n        .inOrder();\n  }\n\n  @Test\n  public void testManifest() throws IOException {\n    String expectedManifest =\n        \"[{\\\"Config\\\":\\\"config.json\\\",\\\"RepoTags\\\":[\\\"jib-core/reproducible:latest\\\"],\"\n            + \"\\\"Layers\\\":[\\\"c46572ef74f58d95e44dd36c1fbdfebd3752e8b56a794a13c11cfed35a1a6e1c.tar.gz\\\",\\\"6d2763b0f3940d324ea6b55386429e5b173899608abf7d1bff62e25dd2e4dcea.tar.gz\\\",\\\"530c1954a2b087d0b989895ea56435c9dc739a973f2d2b6cb9bb98e55bbea7ac.tar.gz\\\"]}]\";\n    String generatedManifest = extractFromTarFileAsString(imageTar, \"manifest.json\");\n    assertThat(generatedManifest).isEqualTo(expectedManifest);\n  }\n\n  @Test\n  public void testConfiguration() throws IOException {\n    String expectedConfig =\n        \"{\\\"created\\\":\\\"1970-01-01T00:00:00Z\\\",\\\"architecture\\\":\\\"amd64\\\",\\\"os\\\":\\\"linux\\\",\"\n            + \"\\\"config\\\":{\\\"Env\\\":[],\\\"Entrypoint\\\":[\\\"echo\\\",\\\"Hello World\\\"],\\\"ExposedPorts\\\":{},\\\"Labels\\\":{},\\\"Volumes\\\":{}},\"\n            + \"\\\"history\\\":[{\\\"created\\\":\\\"1970-01-01T00:00:00Z\\\",\\\"author\\\":\\\"Jib\\\",\\\"created_by\\\":\\\"jib-core:null\\\",\\\"comment\\\":\\\"\\\"},{\\\"created\\\":\\\"1970-01-01T00:00:00Z\\\",\\\"author\\\":\\\"Jib\\\",\\\"created_by\\\":\\\"jib-core:null\\\",\\\"comment\\\":\\\"\\\"},{\\\"created\\\":\\\"1970-01-01T00:00:00Z\\\",\\\"author\\\":\\\"Jib\\\",\\\"created_by\\\":\\\"jib-core:null\\\",\\\"comment\\\":\\\"\\\"}],\"\n            + \"\\\"rootfs\\\":{\\\"type\\\":\\\"layers\\\",\\\"diff_ids\\\":[\\\"sha256:18e4f44e6d1835bd968339b166057bd17ab7d4cbb56dc7262a5cafea7cf8d405\\\",\\\"sha256:13369c34f073f2b9c1fa6431e23d925f1a8eac65b1726c8cc8fcc2596c69b414\\\",\\\"sha256:4f92c507112d7880ca0f504ef8272b7fdee107263270125036a260a741565923\\\"]}}\";\n    String generatedConfig = extractFromTarFileAsString(imageTar, \"config.json\");\n    assertThat(generatedConfig).isEqualTo(expectedConfig);\n  }\n\n  @Test\n  public void testImageLayout() throws IOException {\n    Set<String> paths = new HashSet<>();\n    layerEntriesDo(\n        (layerName, layerEntry) -> {\n          if (layerEntry.isFile()) {\n            paths.add(layerEntry.getName());\n          }\n        });\n    assertThat(paths)\n        .containsExactly(\n            \"app/fileA.txt\",\n            \"app/fileB.txt\",\n            \"app/fileC.txt\",\n            \"app/fileD.txt\",\n            \"app/subdir/fileE.txt\");\n  }\n\n  @Test\n  public void testAllFileAndDirectories() throws IOException {\n    layerEntriesDo(\n        (layerName, layerEntry) ->\n            assertThat(layerEntry.isFile() || layerEntry.isDirectory()).isTrue());\n  }\n\n  @Test\n  public void testTimestampsEpochPlus1s() throws IOException {\n    layerEntriesDo(\n        (layerName, layerEntry) -> {\n          Instant modificationTime = layerEntry.getLastModifiedDate().toInstant();\n          assertThat(modificationTime).isEqualTo(Instant.ofEpochSecond(1));\n        });\n  }\n\n  @Test\n  public void testPermissions() throws IOException {\n    assertThat(FilePermissions.DEFAULT_FILE_PERMISSIONS.getPermissionBits()).isEqualTo(0644);\n    assertThat(FilePermissions.DEFAULT_FOLDER_PERMISSIONS.getPermissionBits()).isEqualTo(0755);\n    layerEntriesDo(\n        (layerName, layerEntry) -> {\n          if (layerEntry.isFile()) {\n            assertThat(layerEntry.getMode() & 0777).isEqualTo(0644);\n          } else if (layerEntry.isDirectory()) {\n            assertThat(layerEntry.getMode() & 0777).isEqualTo(0755);\n          }\n        });\n  }\n\n  @Test\n  public void testNoImplicitParentDirectories() throws IOException {\n    Set<String> directories = new HashSet<>();\n    layerEntriesDo(\n        (layerName, layerEntry) -> {\n          String entryPath = layerEntry.getName();\n          if (layerEntry.isDirectory()) {\n            assertThat(entryPath.endsWith(\"/\")).isTrue();\n            entryPath = entryPath.substring(0, entryPath.length() - 1);\n          }\n\n          int lastSlashPosition = entryPath.lastIndexOf('/');\n          String parent = entryPath.substring(0, Math.max(0, lastSlashPosition));\n          if (!parent.isEmpty()) {\n            assertThat(directories.contains(parent)).isTrue();\n          }\n          if (layerEntry.isDirectory()) {\n            directories.add(entryPath);\n          }\n        });\n  }\n\n  @Test\n  public void testFileOrdering() throws IOException {\n    Multimap<String, String> layerPaths = ArrayListMultimap.create();\n    layerEntriesDo((layerName, layerEntry) -> layerPaths.put(layerName, layerEntry.getName()));\n    for (Collection<String> paths : layerPaths.asMap().values()) {\n      List<String> sorted = new ArrayList<>(paths);\n      // ReproducibleLayerBuilder sorts by TarArchiveEntry::getName()\n      Collections.sort(sorted);\n      assertThat(paths).containsExactlyElementsIn(sorted).inOrder();\n    }\n  }\n\n  private void layerEntriesDo(BiConsumer<String, TarArchiveEntry> layerConsumer)\n      throws IOException {\n\n    try (TarArchiveInputStream input =\n        new TarArchiveInputStream(Files.newInputStream(imageTar.toPath()))) {\n      TarArchiveEntry imageEntry;\n      while ((imageEntry = input.getNextTarEntry()) != null) {\n        String imageEntryName = imageEntry.getName();\n        // assume all .tar.gz files are layers\n        if (imageEntry.isFile() && imageEntryName.endsWith(\".tar.gz\")) {\n          @SuppressWarnings(\"resource\") // must not close sub-streams\n          TarArchiveInputStream layer = new TarArchiveInputStream(new GZIPInputStream(input));\n          TarArchiveEntry layerEntry;\n          while ((layerEntry = layer.getNextTarEntry()) != null) {\n            layerConsumer.accept(imageEntryName, layerEntry);\n          }\n        }\n      }\n    }\n  }\n\n  private static String extractFromTarFileAsString(File tarFile, String filename)\n      throws IOException {\n    try (TarArchiveInputStream input =\n        new TarArchiveInputStream(Files.newInputStream(tarFile.toPath()))) {\n      TarArchiveEntry imageEntry;\n      while ((imageEntry = input.getNextTarEntry()) != null) {\n        if (filename.equals(imageEntry.getName())) {\n          return CharStreams.toString(new InputStreamReader(input, StandardCharsets.UTF_8));\n        }\n      }\n    }\n    throw new AssertionError(\"file not found: \" + filename);\n  }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_34_chunk_0",
        "original_index": 0,
        "content": "/*\n * Copyright 2019 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_1",
        "original_index": 1,
        "content": "package com.google.cloud.tools.jib.api;\n\nimport static com.google.common.truth.Truth.assertThat;\n\nimport com.google.cloud.tools.jib.api.buildplan.AbsoluteUnixPath;\nimport com.google.cloud.tools.jib.api.buildplan.FileEntriesLayer;\nimport com.google.cloud.tools.jib.api.buildplan.FilePermissions;\nimport com.google.common.collect.ArrayListMultimap;\nimport com.google.common.collect.ImmutableList;\nimport com.google.common.collect.Multimap;\nimport com.google.common.io.CharStreams;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\n"
      },
      {
        "chunk_id": "doc_34_chunk_2",
        "original_index": 2,
        "content": "import java.nio.file.Path;\nimport java.time.Instant;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Set;\nimport java.util.concurrent.ExecutionException;\nimport java.util.function.BiConsumer;\nimport java.util.zip.GZIPInputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveEntry;\nimport org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\nimport org.junit.BeforeClass;\nimport org.junit.ClassRule;\nimport org.junit.Test;\nimport org.junit.rules.TemporaryFolder;\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_3",
        "original_index": 3,
        "content": "/**\n * Verify that created image has explicit directory structures, default timestamps, permissions, and\n * file orderings.\n */\npublic class ReproducibleImageTest {\n\n  @ClassRule public static final TemporaryFolder imageLocation = new TemporaryFolder();\n\n  private static File imageTar;\n\n  @BeforeClass\n  public static void createImage()\n      throws InvalidImageReferenceException, InterruptedException, CacheDirectoryCreationException,\n          IOException, RegistryException, ExecutionException {\n\n    Path root = imageLocation.getRoot().toPath();\n    Path fileA = Files.createFile(root.resolve(\"fileA.txt\"));\n    Path fileB = Files.createFile(root.resolve(\"fileB.txt\"));\n    Path fileC = Files.createFile(root.resolve(\"fileC.txt\"));\n    Path subdir = Files.createDirectory(root.resolve(\"dir\"));\n    Path subsubdir = Files.createDirectory(subdir.resolve(\"subdir\"));\n    Files.createFile(subdir.resolve(\"fileD.txt\"));\n    Files.createFile(subsubdir.resolve(\"fileE.txt\"));\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_4",
        "original_index": 4,
        "content": "    imageTar = new File(imageLocation.getRoot(), \"image.tar\");\n    Containerizer containerizer =\n        Containerizer.to(TarImage.at(imageTar.toPath()).named(\"jib-core/reproducible\"));\n\n    Jib.fromScratch()\n        .setEntrypoint(\"echo\", \"Hello World\")\n        .addLayer(ImmutableList.of(fileA), AbsoluteUnixPath.get(\"/app\"))\n        // layer with out-of-order files\n        .addLayer(ImmutableList.of(fileC, fileB), \"/app\")\n        .addFileEntriesLayer(\n            FileEntriesLayer.builder()\n                .addEntryRecursive(subdir, AbsoluteUnixPath.get(\"/app\"))\n                .build())\n        .containerize(containerizer);\n  }\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_5",
        "original_index": 5,
        "content": "  @Test\n  public void testTarballStructure() throws IOException {\n    // known content should produce known results\n    List<String> actual = new ArrayList<>();\n    try (TarArchiveInputStream input =\n        new TarArchiveInputStream(Files.newInputStream(imageTar.toPath()))) {\n      TarArchiveEntry imageEntry;\n      while ((imageEntry = input.getNextTarEntry()) != null) {\n        actual.add(imageEntry.getName());\n      }\n    }\n\n    assertThat(actual)\n        .containsExactly(\n            \"c46572ef74f58d95e44dd36c1fbdfebd3752e8b56a794a13c11cfed35a1a6e1c.tar.gz\",\n            \"6d2763b0f3940d324ea6b55386429e5b173899608abf7d1bff62e25dd2e4dcea.tar.gz\",\n            \"530c1954a2b087d0b989895ea56435c9dc739a973f2d2b6cb9bb98e55bbea7ac.tar.gz\",\n            \"config.json\",\n            \"manifest.json\")\n        .inOrder();\n  }\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_6",
        "original_index": 6,
        "content": "  @Test\n  public void testManifest() throws IOException {\n    String expectedManifest =\n        \"[{\\\"Config\\\":\\\"config.json\\\",\\\"RepoTags\\\":[\\\"jib-core/reproducible:latest\\\"],\"\n            + \"\\\"Layers\\\":[\\\"c46572ef74f58d95e44dd36c1fbdfebd3752e8b56a794a13c11cfed35a1a6e1c.tar.gz\\\",\\\"6d2763b0f3940d324ea6b55386429e5b173899608abf7d1bff62e25dd2e4dcea.tar.gz\\\",\\\"530c1954a2b087d0b989895ea56435c9dc739a973f2d2b6cb9bb98e55bbea7ac.tar.gz\\\"]}]\";\n    String generatedManifest = extractFromTarFileAsString(imageTar, \"manifest.json\");\n    assertThat(generatedManifest).isEqualTo(expectedManifest);\n  }\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_7",
        "original_index": 7,
        "content": "  @Test\n  public void testConfiguration() throws IOException {\n    String expectedConfig =\n        \"{\\\"created\\\":\\\"1970-01-01T00:00:00Z\\\",\\\"architecture\\\":\\\"amd64\\\",\\\"os\\\":\\\"linux\\\",\"\n            + \"\\\"config\\\":{\\\"Env\\\":[],\\\"Entrypoint\\\":[\\\"echo\\\",\\\"Hello World\\\"],\\\"ExposedPorts\\\":{},\\\"Labels\\\":{},\\\"Volumes\\\":{}},\"\n            + \"\\\"history\\\":[{\\\"created\\\":\\\"1970-01-01T00:00:00Z\\\",\\\"author\\\":\\\"Jib\\\",\\\"created_by\\\":\\\"jib-core:null\\\",\\\"comment\\\":\\\"\\\"},{\\\"created\\\":\\\"1970-01-01T00:00:00Z\\\",\\\"author\\\":\\\"Jib\\\",\\\"created_by\\\":\\\"jib-core:null\\\",\\\"comment\\\":\\\"\\\"},{\\\"created\\\":\\\"1970-01-01T00:00:00Z\\\",\\\"author\\\":\\\"Jib\\\",\\\"created_by\\\":\\\"jib-core:null\\\",\\\"comment\\\":\\\"\\\"}],\"\n"
      },
      {
        "chunk_id": "doc_34_chunk_8",
        "original_index": 8,
        "content": "            + \"\\\"rootfs\\\":{\\\"type\\\":\\\"layers\\\",\\\"diff_ids\\\":[\\\"sha256:18e4f44e6d1835bd968339b166057bd17ab7d4cbb56dc7262a5cafea7cf8d405\\\",\\\"sha256:13369c34f073f2b9c1fa6431e23d925f1a8eac65b1726c8cc8fcc2596c69b414\\\",\\\"sha256:4f92c507112d7880ca0f504ef8272b7fdee107263270125036a260a741565923\\\"]}}\";\n    String generatedConfig = extractFromTarFileAsString(imageTar, \"config.json\");\n    assertThat(generatedConfig).isEqualTo(expectedConfig);\n  }\n\n  @Test\n  public void testImageLayout() throws IOException {\n    Set<String> paths = new HashSet<>();\n    layerEntriesDo(\n        (layerName, layerEntry) -> {\n          if (layerEntry.isFile()) {\n            paths.add(layerEntry.getName());\n          }\n        });\n    assertThat(paths)\n        .containsExactly(\n            \"app/fileA.txt\",\n            \"app/fileB.txt\",\n            \"app/fileC.txt\",\n            \"app/fileD.txt\",\n            \"app/subdir/fileE.txt\");\n  }\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_9",
        "original_index": 9,
        "content": "  @Test\n  public void testAllFileAndDirectories() throws IOException {\n    layerEntriesDo(\n        (layerName, layerEntry) ->\n            assertThat(layerEntry.isFile() || layerEntry.isDirectory()).isTrue());\n  }\n\n  @Test\n  public void testTimestampsEpochPlus1s() throws IOException {\n    layerEntriesDo(\n        (layerName, layerEntry) -> {\n          Instant modificationTime = layerEntry.getLastModifiedDate().toInstant();\n          assertThat(modificationTime).isEqualTo(Instant.ofEpochSecond(1));\n        });\n  }\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_10",
        "original_index": 10,
        "content": "  @Test\n  public void testPermissions() throws IOException {\n    assertThat(FilePermissions.DEFAULT_FILE_PERMISSIONS.getPermissionBits()).isEqualTo(0644);\n    assertThat(FilePermissions.DEFAULT_FOLDER_PERMISSIONS.getPermissionBits()).isEqualTo(0755);\n    layerEntriesDo(\n        (layerName, layerEntry) -> {\n          if (layerEntry.isFile()) {\n            assertThat(layerEntry.getMode() & 0777).isEqualTo(0644);\n          } else if (layerEntry.isDirectory()) {\n            assertThat(layerEntry.getMode() & 0777).isEqualTo(0755);\n          }\n        });\n  }\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_11",
        "original_index": 11,
        "content": "  @Test\n  public void testNoImplicitParentDirectories() throws IOException {\n    Set<String> directories = new HashSet<>();\n    layerEntriesDo(\n        (layerName, layerEntry) -> {\n          String entryPath = layerEntry.getName();\n          if (layerEntry.isDirectory()) {\n            assertThat(entryPath.endsWith(\"/\")).isTrue();\n            entryPath = entryPath.substring(0, entryPath.length() - 1);\n          }\n\n          int lastSlashPosition = entryPath.lastIndexOf('/');\n          String parent = entryPath.substring(0, Math.max(0, lastSlashPosition));\n          if (!parent.isEmpty()) {\n            assertThat(directories.contains(parent)).isTrue();\n          }\n          if (layerEntry.isDirectory()) {\n            directories.add(entryPath);\n          }\n        });\n  }\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_12",
        "original_index": 12,
        "content": "  @Test\n  public void testFileOrdering() throws IOException {\n    Multimap<String, String> layerPaths = ArrayListMultimap.create();\n    layerEntriesDo((layerName, layerEntry) -> layerPaths.put(layerName, layerEntry.getName()));\n    for (Collection<String> paths : layerPaths.asMap().values()) {\n      List<String> sorted = new ArrayList<>(paths);\n      // ReproducibleLayerBuilder sorts by TarArchiveEntry::getName()\n      Collections.sort(sorted);\n      assertThat(paths).containsExactlyElementsIn(sorted).inOrder();\n    }\n  }\n\n  private void layerEntriesDo(BiConsumer<String, TarArchiveEntry> layerConsumer)\n      throws IOException {\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_13",
        "original_index": 13,
        "content": "    try (TarArchiveInputStream input =\n        new TarArchiveInputStream(Files.newInputStream(imageTar.toPath()))) {\n      TarArchiveEntry imageEntry;\n      while ((imageEntry = input.getNextTarEntry()) != null) {\n        String imageEntryName = imageEntry.getName();\n        // assume all .tar.gz files are layers\n        if (imageEntry.isFile() && imageEntryName.endsWith(\".tar.gz\")) {\n          @SuppressWarnings(\"resource\") // must not close sub-streams\n          TarArchiveInputStream layer = new TarArchiveInputStream(new GZIPInputStream(input));\n          TarArchiveEntry layerEntry;\n          while ((layerEntry = layer.getNextTarEntry()) != null) {\n            layerConsumer.accept(imageEntryName, layerEntry);\n          }\n        }\n      }\n    }\n  }\n\n"
      },
      {
        "chunk_id": "doc_34_chunk_14",
        "original_index": 14,
        "content": "  private static String extractFromTarFileAsString(File tarFile, String filename)\n      throws IOException {\n    try (TarArchiveInputStream input =\n        new TarArchiveInputStream(Files.newInputStream(tarFile.toPath()))) {\n      TarArchiveEntry imageEntry;\n      while ((imageEntry = input.getNextTarEntry()) != null) {\n        if (filename.equals(imageEntry.getName())) {\n          return CharStreams.toString(new InputStreamReader(input, StandardCharsets.UTF_8));\n        }\n      }\n    }\n    throw new AssertionError(\"file not found: \" + filename);\n  }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_35",
    "original_uuid": "f59e2b84517250cd221b201aeac31b98b6174d155ea11255097ffb06702d29b0",
    "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.test;\n\npublic class HelloWorld {\n  public static void main(String[] args) {\n    System.out.println(\"Hello world\");\n  }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_35_chunk_0",
        "original_index": 0,
        "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.test;\n\npublic class HelloWorld {\n  public static void main(String[] args) {\n    System.out.println(\"Hello world\");\n  }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_36",
    "original_uuid": "26dc2c78337411bfcc55ab9e71922005456242e97463ace852147e88984a5f08",
    "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.maven;\n\nimport com.google.cloud.tools.jib.plugins.common.AuthProperty;\nimport com.google.cloud.tools.jib.plugins.common.InferredAuthException;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.Optional;\nimport org.hamcrest.CoreMatchers;\nimport org.hamcrest.MatcherAssert;\nimport org.junit.Assert;\nimport org.junit.Before;\nimport org.junit.Test;\n\n/** Tests for {@link MavenSettingsServerCredentials}. */\npublic class MavenSettingsServerCredentialsTest {\n\n  private MavenSettingsServerCredentials mavenSettingsServerCredentialsNoMasterPassword;\n  private MavenSettingsServerCredentials mavenSettingsServerCredentials;\n  private Path testSettings = Paths.get(\"src/test/resources/maven/settings/settings.xml\");\n  private Path testSettingsSecurity =\n      Paths.get(\"src/test/resources/maven/settings/settings-security.xml\");\n  private Path testSettingsSecurityEmpty =\n      Paths.get(\"src/test/resources/maven/settings/settings-security.empty.xml\");\n\n  @Before\n  public void setUp() {\n    mavenSettingsServerCredentials =\n        new MavenSettingsServerCredentials(\n            SettingsFixture.newSettings(testSettings),\n            SettingsFixture.newSettingsDecrypter(testSettingsSecurity));\n    mavenSettingsServerCredentialsNoMasterPassword =\n        new MavenSettingsServerCredentials(\n            SettingsFixture.newSettings(testSettings),\n            SettingsFixture.newSettingsDecrypter(testSettingsSecurityEmpty));\n  }\n\n  @Test\n  public void testInferredAuth_decrypterFailure() {\n    try {\n      mavenSettingsServerCredentials.inferAuth(\"badServer\");\n      Assert.fail();\n    } catch (InferredAuthException ex) {\n      MatcherAssert.assertThat(\n          ex.getMessage(),\n          CoreMatchers.startsWith(\"Unable to decrypt server(badServer) info from settings.xml:\"));\n    }\n  }\n\n  @Test\n  public void testInferredAuth_successEncrypted() throws InferredAuthException {\n    Optional<AuthProperty> auth = mavenSettingsServerCredentials.inferAuth(\"encryptedServer\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"encryptedUser\", auth.get().getUsername());\n    Assert.assertEquals(\"password1\", auth.get().getPassword());\n  }\n\n  @Test\n  public void testInferredAuth_successUnencrypted() throws InferredAuthException {\n    Optional<AuthProperty> auth = mavenSettingsServerCredentials.inferAuth(\"simpleServer\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"simpleUser\", auth.get().getUsername());\n    Assert.assertEquals(\"password2\", auth.get().getPassword());\n  }\n\n  @Test\n  public void testInferredAuth_successNoPasswordDoesNotBlowUp() throws InferredAuthException {\n    Optional<AuthProperty> auth =\n        mavenSettingsServerCredentialsNoMasterPassword.inferAuth(\"simpleServer\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"simpleUser\", auth.get().getUsername());\n    Assert.assertEquals(\"password2\", auth.get().getPassword());\n  }\n\n  @Test\n  public void testInferredAuth_registryWithHostAndPort() throws InferredAuthException {\n    Optional<AuthProperty> auth =\n        mavenSettingsServerCredentialsNoMasterPassword.inferAuth(\"docker.example.com:8080\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"registryUser\", auth.get().getUsername());\n    Assert.assertEquals(\"registryPassword\", auth.get().getPassword());\n  }\n\n  @Test\n  public void testInferredAuth_registryWithHostWithoutPort() throws InferredAuthException {\n    Optional<AuthProperty> auth =\n        mavenSettingsServerCredentialsNoMasterPassword.inferAuth(\"docker.example.com\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"registryUser\", auth.get().getUsername());\n    Assert.assertEquals(\"registryPassword\", auth.get().getPassword());\n  }\n\n  @Test\n  public void testInferredAuth_registrySettingsWithPort() throws InferredAuthException {\n    // Attempt to resolve WITHOUT the port. Should work as well.\n    Optional<AuthProperty> auth =\n        mavenSettingsServerCredentialsNoMasterPassword.inferAuth(\"docker.example.com:5432\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"registryUser\", auth.get().getUsername());\n    Assert.assertEquals(\"registryPassword\", auth.get().getPassword());\n  }\n\n  @Test\n  public void testInferredAuth_notFound() throws InferredAuthException {\n    Assert.assertFalse(mavenSettingsServerCredentials.inferAuth(\"serverUnknown\").isPresent());\n  }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_36_chunk_0",
        "original_index": 0,
        "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_36_chunk_1",
        "original_index": 1,
        "content": "package com.google.cloud.tools.jib.maven;\n\nimport com.google.cloud.tools.jib.plugins.common.AuthProperty;\nimport com.google.cloud.tools.jib.plugins.common.InferredAuthException;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.Optional;\nimport org.hamcrest.CoreMatchers;\nimport org.hamcrest.MatcherAssert;\nimport org.junit.Assert;\nimport org.junit.Before;\nimport org.junit.Test;\n\n/** Tests for {@link MavenSettingsServerCredentials}. */\npublic class MavenSettingsServerCredentialsTest {\n\n"
      },
      {
        "chunk_id": "doc_36_chunk_2",
        "original_index": 2,
        "content": "  private MavenSettingsServerCredentials mavenSettingsServerCredentialsNoMasterPassword;\n  private MavenSettingsServerCredentials mavenSettingsServerCredentials;\n  private Path testSettings = Paths.get(\"src/test/resources/maven/settings/settings.xml\");\n  private Path testSettingsSecurity =\n      Paths.get(\"src/test/resources/maven/settings/settings-security.xml\");\n  private Path testSettingsSecurityEmpty =\n      Paths.get(\"src/test/resources/maven/settings/settings-security.empty.xml\");\n\n"
      },
      {
        "chunk_id": "doc_36_chunk_3",
        "original_index": 3,
        "content": "  @Before\n  public void setUp() {\n    mavenSettingsServerCredentials =\n        new MavenSettingsServerCredentials(\n            SettingsFixture.newSettings(testSettings),\n            SettingsFixture.newSettingsDecrypter(testSettingsSecurity));\n    mavenSettingsServerCredentialsNoMasterPassword =\n        new MavenSettingsServerCredentials(\n            SettingsFixture.newSettings(testSettings),\n            SettingsFixture.newSettingsDecrypter(testSettingsSecurityEmpty));\n  }\n\n  @Test\n  public void testInferredAuth_decrypterFailure() {\n    try {\n      mavenSettingsServerCredentials.inferAuth(\"badServer\");\n      Assert.fail();\n    } catch (InferredAuthException ex) {\n      MatcherAssert.assertThat(\n          ex.getMessage(),\n          CoreMatchers.startsWith(\"Unable to decrypt server(badServer) info from settings.xml:\"));\n    }\n  }\n\n"
      },
      {
        "chunk_id": "doc_36_chunk_4",
        "original_index": 4,
        "content": "  @Test\n  public void testInferredAuth_successEncrypted() throws InferredAuthException {\n    Optional<AuthProperty> auth = mavenSettingsServerCredentials.inferAuth(\"encryptedServer\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"encryptedUser\", auth.get().getUsername());\n    Assert.assertEquals(\"password1\", auth.get().getPassword());\n  }\n\n  @Test\n  public void testInferredAuth_successUnencrypted() throws InferredAuthException {\n    Optional<AuthProperty> auth = mavenSettingsServerCredentials.inferAuth(\"simpleServer\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"simpleUser\", auth.get().getUsername());\n    Assert.assertEquals(\"password2\", auth.get().getPassword());\n  }\n\n"
      },
      {
        "chunk_id": "doc_36_chunk_5",
        "original_index": 5,
        "content": "  @Test\n  public void testInferredAuth_successNoPasswordDoesNotBlowUp() throws InferredAuthException {\n    Optional<AuthProperty> auth =\n        mavenSettingsServerCredentialsNoMasterPassword.inferAuth(\"simpleServer\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"simpleUser\", auth.get().getUsername());\n    Assert.assertEquals(\"password2\", auth.get().getPassword());\n  }\n\n  @Test\n  public void testInferredAuth_registryWithHostAndPort() throws InferredAuthException {\n    Optional<AuthProperty> auth =\n        mavenSettingsServerCredentialsNoMasterPassword.inferAuth(\"docker.example.com:8080\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"registryUser\", auth.get().getUsername());\n    Assert.assertEquals(\"registryPassword\", auth.get().getPassword());\n  }\n\n"
      },
      {
        "chunk_id": "doc_36_chunk_6",
        "original_index": 6,
        "content": "  @Test\n  public void testInferredAuth_registryWithHostWithoutPort() throws InferredAuthException {\n    Optional<AuthProperty> auth =\n        mavenSettingsServerCredentialsNoMasterPassword.inferAuth(\"docker.example.com\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"registryUser\", auth.get().getUsername());\n    Assert.assertEquals(\"registryPassword\", auth.get().getPassword());\n  }\n\n"
      },
      {
        "chunk_id": "doc_36_chunk_7",
        "original_index": 7,
        "content": "  @Test\n  public void testInferredAuth_registrySettingsWithPort() throws InferredAuthException {\n    // Attempt to resolve WITHOUT the port. Should work as well.\n    Optional<AuthProperty> auth =\n        mavenSettingsServerCredentialsNoMasterPassword.inferAuth(\"docker.example.com:5432\");\n    Assert.assertTrue(auth.isPresent());\n    Assert.assertEquals(\"registryUser\", auth.get().getUsername());\n    Assert.assertEquals(\"registryPassword\", auth.get().getPassword());\n  }\n\n  @Test\n  public void testInferredAuth_notFound() throws InferredAuthException {\n    Assert.assertFalse(mavenSettingsServerCredentials.inferAuth(\"serverUnknown\").isPresent());\n  }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_37",
    "original_uuid": "e23ba17cf99c628afc86f67b22af62848a96d600c7e29bfb7fb12e5cacea7f05",
    "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.registry;\n\nimport com.google.cloud.tools.jib.api.DescriptorDigest;\nimport com.google.cloud.tools.jib.api.RegistryException;\nimport com.google.cloud.tools.jib.blob.Blob;\nimport com.google.cloud.tools.jib.event.EventHandlers;\nimport com.google.cloud.tools.jib.http.FailoverHttpClient;\nimport com.google.cloud.tools.jib.image.json.V22ManifestTemplate;\nimport com.google.common.io.ByteStreams;\nimport java.io.IOException;\nimport java.security.DigestException;\nimport java.util.concurrent.atomic.LongAdder;\nimport org.hamcrest.CoreMatchers;\nimport org.hamcrest.MatcherAssert;\nimport org.junit.Assert;\nimport org.junit.Test;\n\n/** Integration tests for {@link BlobPuller}. */\npublic class BlobPullerIntegrationTest {\n\n  private final FailoverHttpClient httpClient = new FailoverHttpClient(true, false, ignored -> {});\n\n  @Test\n  public void testPull() throws IOException, RegistryException {\n    RegistryClient registryClient =\n        RegistryClient.factory(EventHandlers.NONE, \"gcr.io\", \"distroless/base\", httpClient)\n            .newRegistryClient();\n    V22ManifestTemplate manifestTemplate =\n        registryClient\n            .pullManifest(\n                ManifestPullerIntegrationTest.KNOWN_MANIFEST_V22_SHA, V22ManifestTemplate.class)\n            .getManifest();\n\n    DescriptorDigest realDigest = manifestTemplate.getLayers().get(0).getDigest();\n\n    // Pulls a layer BLOB of the distroless/base image.\n    LongAdder totalByteCount = new LongAdder();\n    LongAdder expectedSize = new LongAdder();\n    Blob pulledBlob =\n        registryClient.pullBlob(\n            realDigest,\n            size -> {\n              Assert.assertEquals(0, expectedSize.sum());\n              expectedSize.add(size);\n            },\n            totalByteCount::add);\n    Assert.assertEquals(realDigest, pulledBlob.writeTo(ByteStreams.nullOutputStream()).getDigest());\n    Assert.assertTrue(expectedSize.sum() > 0);\n    Assert.assertEquals(expectedSize.sum(), totalByteCount.sum());\n  }\n\n  @Test\n  public void testPull_unknownBlob() throws IOException, DigestException {\n    DescriptorDigest nonexistentDigest =\n        DescriptorDigest.fromHash(\n            \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\");\n\n    RegistryClient registryClient =\n        RegistryClient.factory(EventHandlers.NONE, \"gcr.io\", \"distroless/base\", httpClient)\n            .newRegistryClient();\n\n    try {\n      registryClient\n          .pullBlob(nonexistentDigest, ignored -> {}, ignored -> {})\n          .writeTo(ByteStreams.nullOutputStream());\n      Assert.fail(\"Trying to pull nonexistent blob should have errored\");\n\n    } catch (IOException ex) {\n      if (!(ex.getCause() instanceof RegistryErrorException)) {\n        throw ex;\n      }\n      MatcherAssert.assertThat(\n          ex.getMessage(),\n          CoreMatchers.containsString(\n              \"pull BLOB for gcr.io/distroless/base with digest \" + nonexistentDigest));\n    }\n  }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_37_chunk_0",
        "original_index": 0,
        "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.registry;\n\n"
      },
      {
        "chunk_id": "doc_37_chunk_1",
        "original_index": 1,
        "content": "import com.google.cloud.tools.jib.api.DescriptorDigest;\nimport com.google.cloud.tools.jib.api.RegistryException;\nimport com.google.cloud.tools.jib.blob.Blob;\nimport com.google.cloud.tools.jib.event.EventHandlers;\nimport com.google.cloud.tools.jib.http.FailoverHttpClient;\nimport com.google.cloud.tools.jib.image.json.V22ManifestTemplate;\nimport com.google.common.io.ByteStreams;\nimport java.io.IOException;\nimport java.security.DigestException;\nimport java.util.concurrent.atomic.LongAdder;\nimport org.hamcrest.CoreMatchers;\nimport org.hamcrest.MatcherAssert;\nimport org.junit.Assert;\nimport org.junit.Test;\n\n"
      },
      {
        "chunk_id": "doc_37_chunk_2",
        "original_index": 2,
        "content": "/** Integration tests for {@link BlobPuller}. */\npublic class BlobPullerIntegrationTest {\n\n  private final FailoverHttpClient httpClient = new FailoverHttpClient(true, false, ignored -> {});\n\n  @Test\n  public void testPull() throws IOException, RegistryException {\n    RegistryClient registryClient =\n        RegistryClient.factory(EventHandlers.NONE, \"gcr.io\", \"distroless/base\", httpClient)\n            .newRegistryClient();\n    V22ManifestTemplate manifestTemplate =\n        registryClient\n            .pullManifest(\n                ManifestPullerIntegrationTest.KNOWN_MANIFEST_V22_SHA, V22ManifestTemplate.class)\n            .getManifest();\n\n    DescriptorDigest realDigest = manifestTemplate.getLayers().get(0).getDigest();\n\n"
      },
      {
        "chunk_id": "doc_37_chunk_3",
        "original_index": 3,
        "content": "    // Pulls a layer BLOB of the distroless/base image.\n    LongAdder totalByteCount = new LongAdder();\n    LongAdder expectedSize = new LongAdder();\n    Blob pulledBlob =\n        registryClient.pullBlob(\n            realDigest,\n            size -> {\n              Assert.assertEquals(0, expectedSize.sum());\n              expectedSize.add(size);\n            },\n            totalByteCount::add);\n    Assert.assertEquals(realDigest, pulledBlob.writeTo(ByteStreams.nullOutputStream()).getDigest());\n    Assert.assertTrue(expectedSize.sum() > 0);\n    Assert.assertEquals(expectedSize.sum(), totalByteCount.sum());\n  }\n\n"
      },
      {
        "chunk_id": "doc_37_chunk_4",
        "original_index": 4,
        "content": "  @Test\n  public void testPull_unknownBlob() throws IOException, DigestException {\n    DescriptorDigest nonexistentDigest =\n        DescriptorDigest.fromHash(\n            \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\");\n\n    RegistryClient registryClient =\n        RegistryClient.factory(EventHandlers.NONE, \"gcr.io\", \"distroless/base\", httpClient)\n            .newRegistryClient();\n\n    try {\n      registryClient\n          .pullBlob(nonexistentDigest, ignored -> {}, ignored -> {})\n          .writeTo(ByteStreams.nullOutputStream());\n      Assert.fail(\"Trying to pull nonexistent blob should have errored\");\n\n    } catch (IOException ex) {\n      if (!(ex.getCause() instanceof RegistryErrorException)) {\n        throw ex;\n      }\n      MatcherAssert.assertThat(\n          ex.getMessage(),\n          CoreMatchers.containsString(\n              \"pull BLOB for gcr.io/distroless/base with digest \" + nonexistentDigest));\n    }\n  }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_38",
    "original_uuid": "e357fbf7acddc26c61f964891486394c176804f31a319d178f3a4c9b41dd47e0",
    "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.plugins.common;\n\nimport com.google.api.client.http.HttpResponseException;\nimport com.google.api.client.http.HttpStatusCodes;\nimport com.google.cloud.tools.jib.api.CacheDirectoryCreationException;\nimport com.google.cloud.tools.jib.api.Containerizer;\nimport com.google.cloud.tools.jib.api.DescriptorDigest;\nimport com.google.cloud.tools.jib.api.ImageReference;\nimport com.google.cloud.tools.jib.api.InsecureRegistryException;\nimport com.google.cloud.tools.jib.api.JibContainer;\nimport com.google.cloud.tools.jib.api.JibContainerBuilder;\nimport com.google.cloud.tools.jib.api.RegistryException;\nimport com.google.cloud.tools.jib.api.RegistryUnauthorizedException;\nimport com.google.cloud.tools.jib.registry.RegistryCredentialsNotSentException;\nimport com.google.common.collect.ImmutableSet;\nimport java.io.IOException;\nimport java.net.UnknownHostException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.util.Set;\nimport java.util.concurrent.ExecutionException;\nimport org.apache.http.conn.HttpHostConnectException;\nimport org.junit.Assert;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.TemporaryFolder;\nimport org.junit.runner.RunWith;\nimport org.mockito.Mock;\nimport org.mockito.Mockito;\nimport org.mockito.junit.MockitoJUnitRunner;\n\n/** Tests for {@link JibBuildRunner}. */\n@RunWith(MockitoJUnitRunner.class)\npublic class JibBuildRunnerTest {\n\n  private static final HelpfulSuggestions TEST_HELPFUL_SUGGESTIONS =\n      new HelpfulSuggestions(\n          \"messagePrefix\", \"clearCacheCommand\", \"toConfig\", \"toFlag\", \"buildFile\");\n\n  @Rule public TemporaryFolder temporaryFolder = new TemporaryFolder();\n\n  @Mock private JibContainerBuilder mockJibContainerBuilder;\n  @Mock private JibContainer mockJibContainer;\n  @Mock private Containerizer mockContainerizer;\n  @Mock private RegistryUnauthorizedException mockRegistryUnauthorizedException;\n  @Mock private RegistryCredentialsNotSentException mockRegistryCredentialsNotSentException;\n  @Mock private HttpResponseException mockHttpResponseException;\n\n  private JibBuildRunner testJibBuildRunner;\n\n  @Before\n  public void setUpMocks() {\n    testJibBuildRunner =\n        new JibBuildRunner(\n            mockJibContainerBuilder,\n            mockContainerizer,\n            ignored -> {},\n            TEST_HELPFUL_SUGGESTIONS,\n            \"ignored\",\n            \"ignored\");\n  }\n\n  @Test\n  public void testBuildImage_pass()\n      throws BuildStepsExecutionException, IOException, CacheDirectoryCreationException {\n    JibContainer buildResult = testJibBuildRunner.runBuild();\n    Assert.assertNull(buildResult);\n  }\n\n  @Test\n  public void testBuildImage_httpHostConnectException()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    HttpHostConnectException mockHttpHostConnectException =\n        Mockito.mock(HttpHostConnectException.class);\n    Mockito.doThrow(mockHttpHostConnectException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(TEST_HELPFUL_SUGGESTIONS.forHttpHostConnect(), ex.getMessage());\n    }\n  }\n\n  @Test\n  public void testBuildImage_unknownHostException()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    UnknownHostException mockUnknownHostException = Mockito.mock(UnknownHostException.class);\n    Mockito.doThrow(mockUnknownHostException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(TEST_HELPFUL_SUGGESTIONS.forUnknownHost(), ex.getMessage());\n    }\n  }\n\n  @Test\n  public void testBuildImage_insecureRegistryException()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    InsecureRegistryException mockInsecureRegistryException =\n        Mockito.mock(InsecureRegistryException.class);\n    Mockito.doThrow(mockInsecureRegistryException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(TEST_HELPFUL_SUGGESTIONS.forInsecureRegistry(), ex.getMessage());\n    }\n  }\n\n  @Test\n  public void testBuildImage_registryUnauthorizedException_statusCodeForbidden()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    Mockito.when(mockRegistryUnauthorizedException.getHttpResponseException())\n        .thenReturn(mockHttpResponseException);\n    Mockito.when(mockRegistryUnauthorizedException.getImageReference())\n        .thenReturn(\"someregistry/somerepository\");\n    Mockito.when(mockHttpResponseException.getStatusCode())\n        .thenReturn(HttpStatusCodes.STATUS_CODE_FORBIDDEN);\n\n    Mockito.doThrow(mockRegistryUnauthorizedException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(\n          TEST_HELPFUL_SUGGESTIONS.forHttpStatusCodeForbidden(\"someregistry/somerepository\"),\n          ex.getMessage());\n    }\n  }\n\n  @Test\n  public void testBuildImage_registryUnauthorizedException_noCredentials()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    Mockito.when(mockRegistryUnauthorizedException.getHttpResponseException())\n        .thenReturn(mockHttpResponseException);\n    Mockito.when(mockRegistryUnauthorizedException.getImageReference())\n        .thenReturn(\"someregistry/somerepository\");\n    Mockito.when(mockHttpResponseException.getStatusCode()).thenReturn(-1); // Unknown\n\n    Mockito.doThrow(mockRegistryUnauthorizedException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(\n          TEST_HELPFUL_SUGGESTIONS.forNoCredentialsDefined(\"someregistry/somerepository\"),\n          ex.getMessage());\n    }\n  }\n\n  @Test\n  public void testBuildImage_registryCredentialsNotSentException()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    Mockito.doThrow(mockRegistryCredentialsNotSentException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(TEST_HELPFUL_SUGGESTIONS.forCredentialsNotSent(), ex.getMessage());\n    }\n  }\n\n  @Test\n  public void testBuildImage_other()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    Mockito.doThrow(new RegistryException(\"messagePrefix\"))\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(TEST_HELPFUL_SUGGESTIONS.none(), ex.getMessage());\n    }\n  }\n\n  @Test\n  public void testBuildImage_writesImageJson() throws Exception {\n    final ImageReference targetImageReference = ImageReference.parse(\"gcr.io/distroless/java:11\");\n    final String imageId =\n        \"sha256:61bb3ec31a47cb730eb58a38bbfa813761a51dca69d10e39c24c3d00a7b2c7a9\";\n    final String digest = \"sha256:3f1be7e19129edb202c071a659a4db35280ab2bb1a16f223bfd5d1948657b6fc\";\n    final Set<String> tags = ImmutableSet.of(\"latest\", \"0.1.41-69d10e-20200116T101403\");\n\n    final Path outputPath = temporaryFolder.newFile(\"jib-image.json\").toPath();\n\n    Mockito.when(mockJibContainer.getTargetImage()).thenReturn(targetImageReference);\n    Mockito.when(mockJibContainer.getImageId()).thenReturn(DescriptorDigest.fromDigest(imageId));\n    Mockito.when(mockJibContainer.getDigest()).thenReturn(DescriptorDigest.fromDigest(digest));\n    Mockito.when(mockJibContainer.getTags()).thenReturn(tags);\n    Mockito.when(mockJibContainerBuilder.containerize(mockContainerizer))\n        .thenReturn(mockJibContainer);\n    Mockito.when(mockJibContainer.isImagePushed()).thenReturn(true);\n    testJibBuildRunner.writeImageJson(outputPath).runBuild();\n\n    final String outputJson = new String(Files.readAllBytes(outputPath), StandardCharsets.UTF_8);\n    final ImageMetadataOutput metadataOutput = ImageMetadataOutput.fromJson(outputJson);\n    Assert.assertEquals(targetImageReference.toString(), metadataOutput.getImage());\n    Assert.assertEquals(imageId, metadataOutput.getImageId());\n    Assert.assertEquals(digest, metadataOutput.getImageDigest());\n    Assert.assertEquals(tags, ImmutableSet.copyOf(metadataOutput.getTags()));\n    Assert.assertTrue(metadataOutput.isImagePushed());\n  }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_38_chunk_0",
        "original_index": 0,
        "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.plugins.common;\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_1",
        "original_index": 1,
        "content": "import com.google.api.client.http.HttpResponseException;\nimport com.google.api.client.http.HttpStatusCodes;\nimport com.google.cloud.tools.jib.api.CacheDirectoryCreationException;\nimport com.google.cloud.tools.jib.api.Containerizer;\nimport com.google.cloud.tools.jib.api.DescriptorDigest;\nimport com.google.cloud.tools.jib.api.ImageReference;\nimport com.google.cloud.tools.jib.api.InsecureRegistryException;\nimport com.google.cloud.tools.jib.api.JibContainer;\nimport com.google.cloud.tools.jib.api.JibContainerBuilder;\nimport com.google.cloud.tools.jib.api.RegistryException;\nimport com.google.cloud.tools.jib.api.RegistryUnauthorizedException;\nimport com.google.cloud.tools.jib.registry.RegistryCredentialsNotSentException;\nimport com.google.common.collect.ImmutableSet;\nimport java.io.IOException;\nimport java.net.UnknownHostException;\n"
      },
      {
        "chunk_id": "doc_38_chunk_2",
        "original_index": 2,
        "content": "import java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.util.Set;\nimport java.util.concurrent.ExecutionException;\nimport org.apache.http.conn.HttpHostConnectException;\nimport org.junit.Assert;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.TemporaryFolder;\nimport org.junit.runner.RunWith;\nimport org.mockito.Mock;\nimport org.mockito.Mockito;\nimport org.mockito.junit.MockitoJUnitRunner;\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_3",
        "original_index": 3,
        "content": "/** Tests for {@link JibBuildRunner}. */\n@RunWith(MockitoJUnitRunner.class)\npublic class JibBuildRunnerTest {\n\n  private static final HelpfulSuggestions TEST_HELPFUL_SUGGESTIONS =\n      new HelpfulSuggestions(\n          \"messagePrefix\", \"clearCacheCommand\", \"toConfig\", \"toFlag\", \"buildFile\");\n\n  @Rule public TemporaryFolder temporaryFolder = new TemporaryFolder();\n\n  @Mock private JibContainerBuilder mockJibContainerBuilder;\n  @Mock private JibContainer mockJibContainer;\n  @Mock private Containerizer mockContainerizer;\n  @Mock private RegistryUnauthorizedException mockRegistryUnauthorizedException;\n  @Mock private RegistryCredentialsNotSentException mockRegistryCredentialsNotSentException;\n  @Mock private HttpResponseException mockHttpResponseException;\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_4",
        "original_index": 4,
        "content": "  private JibBuildRunner testJibBuildRunner;\n\n  @Before\n  public void setUpMocks() {\n    testJibBuildRunner =\n        new JibBuildRunner(\n            mockJibContainerBuilder,\n            mockContainerizer,\n            ignored -> {},\n            TEST_HELPFUL_SUGGESTIONS,\n            \"ignored\",\n            \"ignored\");\n  }\n\n  @Test\n  public void testBuildImage_pass()\n      throws BuildStepsExecutionException, IOException, CacheDirectoryCreationException {\n    JibContainer buildResult = testJibBuildRunner.runBuild();\n    Assert.assertNull(buildResult);\n  }\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_5",
        "original_index": 5,
        "content": "  @Test\n  public void testBuildImage_httpHostConnectException()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    HttpHostConnectException mockHttpHostConnectException =\n        Mockito.mock(HttpHostConnectException.class);\n    Mockito.doThrow(mockHttpHostConnectException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(TEST_HELPFUL_SUGGESTIONS.forHttpHostConnect(), ex.getMessage());\n    }\n  }\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_6",
        "original_index": 6,
        "content": "  @Test\n  public void testBuildImage_unknownHostException()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    UnknownHostException mockUnknownHostException = Mockito.mock(UnknownHostException.class);\n    Mockito.doThrow(mockUnknownHostException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(TEST_HELPFUL_SUGGESTIONS.forUnknownHost(), ex.getMessage());\n    }\n  }\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_7",
        "original_index": 7,
        "content": "  @Test\n  public void testBuildImage_insecureRegistryException()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    InsecureRegistryException mockInsecureRegistryException =\n        Mockito.mock(InsecureRegistryException.class);\n    Mockito.doThrow(mockInsecureRegistryException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(TEST_HELPFUL_SUGGESTIONS.forInsecureRegistry(), ex.getMessage());\n    }\n  }\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_8",
        "original_index": 8,
        "content": "  @Test\n  public void testBuildImage_registryUnauthorizedException_statusCodeForbidden()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    Mockito.when(mockRegistryUnauthorizedException.getHttpResponseException())\n        .thenReturn(mockHttpResponseException);\n    Mockito.when(mockRegistryUnauthorizedException.getImageReference())\n        .thenReturn(\"someregistry/somerepository\");\n    Mockito.when(mockHttpResponseException.getStatusCode())\n        .thenReturn(HttpStatusCodes.STATUS_CODE_FORBIDDEN);\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_9",
        "original_index": 9,
        "content": "    Mockito.doThrow(mockRegistryUnauthorizedException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(\n          TEST_HELPFUL_SUGGESTIONS.forHttpStatusCodeForbidden(\"someregistry/somerepository\"),\n          ex.getMessage());\n    }\n  }\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_10",
        "original_index": 10,
        "content": "  @Test\n  public void testBuildImage_registryUnauthorizedException_noCredentials()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    Mockito.when(mockRegistryUnauthorizedException.getHttpResponseException())\n        .thenReturn(mockHttpResponseException);\n    Mockito.when(mockRegistryUnauthorizedException.getImageReference())\n        .thenReturn(\"someregistry/somerepository\");\n    Mockito.when(mockHttpResponseException.getStatusCode()).thenReturn(-1); // Unknown\n\n    Mockito.doThrow(mockRegistryUnauthorizedException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(\n          TEST_HELPFUL_SUGGESTIONS.forNoCredentialsDefined(\"someregistry/somerepository\"),\n          ex.getMessage());\n    }\n  }\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_11",
        "original_index": 11,
        "content": "  @Test\n  public void testBuildImage_registryCredentialsNotSentException()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    Mockito.doThrow(mockRegistryCredentialsNotSentException)\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(TEST_HELPFUL_SUGGESTIONS.forCredentialsNotSent(), ex.getMessage());\n    }\n  }\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_12",
        "original_index": 12,
        "content": "  @Test\n  public void testBuildImage_other()\n      throws InterruptedException, IOException, CacheDirectoryCreationException, RegistryException,\n          ExecutionException {\n    Mockito.doThrow(new RegistryException(\"messagePrefix\"))\n        .when(mockJibContainerBuilder)\n        .containerize(mockContainerizer);\n\n    try {\n      testJibBuildRunner.runBuild();\n      Assert.fail();\n\n    } catch (BuildStepsExecutionException ex) {\n      Assert.assertEquals(TEST_HELPFUL_SUGGESTIONS.none(), ex.getMessage());\n    }\n  }\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_13",
        "original_index": 13,
        "content": "  @Test\n  public void testBuildImage_writesImageJson() throws Exception {\n    final ImageReference targetImageReference = ImageReference.parse(\"gcr.io/distroless/java:11\");\n    final String imageId =\n        \"sha256:61bb3ec31a47cb730eb58a38bbfa813761a51dca69d10e39c24c3d00a7b2c7a9\";\n    final String digest = \"sha256:3f1be7e19129edb202c071a659a4db35280ab2bb1a16f223bfd5d1948657b6fc\";\n    final Set<String> tags = ImmutableSet.of(\"latest\", \"0.1.41-69d10e-20200116T101403\");\n\n    final Path outputPath = temporaryFolder.newFile(\"jib-image.json\").toPath();\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_14",
        "original_index": 14,
        "content": "    Mockito.when(mockJibContainer.getTargetImage()).thenReturn(targetImageReference);\n    Mockito.when(mockJibContainer.getImageId()).thenReturn(DescriptorDigest.fromDigest(imageId));\n    Mockito.when(mockJibContainer.getDigest()).thenReturn(DescriptorDigest.fromDigest(digest));\n    Mockito.when(mockJibContainer.getTags()).thenReturn(tags);\n    Mockito.when(mockJibContainerBuilder.containerize(mockContainerizer))\n        .thenReturn(mockJibContainer);\n    Mockito.when(mockJibContainer.isImagePushed()).thenReturn(true);\n    testJibBuildRunner.writeImageJson(outputPath).runBuild();\n\n"
      },
      {
        "chunk_id": "doc_38_chunk_15",
        "original_index": 15,
        "content": "    final String outputJson = new String(Files.readAllBytes(outputPath), StandardCharsets.UTF_8);\n    final ImageMetadataOutput metadataOutput = ImageMetadataOutput.fromJson(outputJson);\n    Assert.assertEquals(targetImageReference.toString(), metadataOutput.getImage());\n    Assert.assertEquals(imageId, metadataOutput.getImageId());\n    Assert.assertEquals(digest, metadataOutput.getImageDigest());\n    Assert.assertEquals(tags, ImmutableSet.copyOf(metadataOutput.getTags()));\n    Assert.assertTrue(metadataOutput.isImagePushed());\n  }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_39",
    "original_uuid": "c5cc0b3e2067eb3f0eec0e111678da31cd242215e7c815420964ca9d607e7ddf",
    "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.maven;\n\nimport static com.google.common.truth.Truth.assertThat;\n\nimport com.google.cloud.tools.jib.Command;\nimport java.io.IOException;\nimport java.security.DigestException;\nimport java.util.Arrays;\nimport org.apache.maven.it.VerificationException;\nimport org.apache.maven.it.Verifier;\nimport org.hamcrest.CoreMatchers;\nimport org.hamcrest.MatcherAssert;\nimport org.junit.Assert;\nimport org.junit.Assume;\nimport org.junit.ClassRule;\nimport org.junit.Test;\n\n/** Integration tests for {@link BuildDockerMojo}. */\npublic class BuildDockerMojoIntegrationTest {\n\n  @ClassRule public static final TestProject simpleTestProject = new TestProject(\"simple\");\n\n  @ClassRule public static final TestProject emptyTestProject = new TestProject(\"empty\");\n\n  @ClassRule\n  public static final TestProject defaultTargetTestProject = new TestProject(\"default-target\");\n\n  private static void buildToDockerDaemon(TestProject project, String imageReference, String pomXml)\n      throws VerificationException, DigestException, IOException {\n    Verifier verifier = new Verifier(project.getProjectRoot().toString());\n    verifier.setSystemProperty(\"jib.useOnlyProjectCache\", \"true\");\n    verifier.setSystemProperty(\"_TARGET_IMAGE\", imageReference);\n    verifier.setAutoclean(false);\n    verifier.addCliOption(\"--file=\" + pomXml);\n    verifier.executeGoal(\"package\");\n\n    verifier.executeGoal(\"jib:dockerBuild\");\n    verifier.verifyErrorFreeLog();\n\n    BuildImageMojoIntegrationTest.readDigestFile(\n        project.getProjectRoot().resolve(\"target/jib-image.digest\"));\n  }\n\n  /**\n   * Builds and runs jib:buildDocker on a project at {@code projectRoot} pushing to {@code\n   * imageReference}.\n   */\n  private static String buildToDockerDaemonAndRun(TestProject project, String imageReference)\n      throws VerificationException, IOException, InterruptedException, DigestException {\n    buildToDockerDaemon(project, imageReference, \"pom.xml\");\n\n    String dockerInspectVolumes =\n        new Command(\"docker\", \"inspect\", \"-f\", \"'{{json .Config.Volumes}}'\", imageReference).run();\n    String dockerInspectExposedPorts =\n        new Command(\"docker\", \"inspect\", \"-f\", \"'{{json .Config.ExposedPorts}}'\", imageReference)\n            .run();\n    String dockerInspectLabels =\n        new Command(\"docker\", \"inspect\", \"-f\", \"'{{json .Config.Labels}}'\", imageReference).run();\n    String history = new Command(\"docker\", \"history\", imageReference).run();\n\n    MatcherAssert.assertThat(\n        dockerInspectVolumes, CoreMatchers.containsString(\"\\\"/var/log\\\":{},\\\"/var/log2\\\":{}\"));\n    MatcherAssert.assertThat(\n        dockerInspectExposedPorts,\n        CoreMatchers.containsString(\n            \"\\\"1000/tcp\\\":{},\\\"2000/udp\\\":{},\\\"2001/udp\\\":{},\\\"2002/udp\\\":{},\\\"2003/udp\\\":{}\"));\n    MatcherAssert.assertThat(\n        dockerInspectLabels,\n        CoreMatchers.containsString(\"\\\"key1\\\":\\\"value1\\\",\\\"key2\\\":\\\"value2\\\"\"));\n\n    return new Command(\"docker\", \"run\", \"--rm\", imageReference).run();\n  }\n\n  @Test\n  public void testExecute_simple()\n      throws VerificationException, IOException, InterruptedException, DigestException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n\n    Assert.assertEquals(\n        \"Hello, world. An argument.\\n1970-01-01T00:00:01Z\\nrw-r--r--\\nrw-r--r--\\nfoo\\ncat\\n\"\n            + \"1970-01-01T00:00:01Z\\n1970-01-01T00:00:01Z\\n\",\n        buildToDockerDaemonAndRun(simpleTestProject, targetImage));\n    Assert.assertEquals(\n        \"1970-01-01T00:00:00Z\",\n        new Command(\"docker\", \"inspect\", \"-f\", \"{{.Created}}\", targetImage).run().trim());\n  }\n\n  @Test\n  public void testExecute_simple_extraDirectoriesFiltering()\n      throws DigestException, IOException, InterruptedException, VerificationException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(simpleTestProject, targetImage, \"pom-extra-dirs-filtering.xml\");\n    String output =\n        new Command(\"docker\", \"run\", \"--rm\", \"--entrypoint=ls\", targetImage, \"-1R\", \"/extras\")\n            .run();\n\n    //   /extras/cat.txt\n    //   /extras/foo\n    //   /extras/sub/\n    //   /extras/sub/a.json\n    assertThat(output).isEqualTo(\"/extras:\\ncat.txt\\nfoo\\nsub\\n\\n/extras/sub:\\na.json\\n\");\n  }\n\n  @Test\n  public void testExecute_dockerClient()\n      throws VerificationException, IOException, InterruptedException {\n    Assume.assumeFalse(System.getProperty(\"os.name\").startsWith(\"Windows\"));\n    new Command(\n            \"chmod\", \"+x\", simpleTestProject.getProjectRoot().resolve(\"mock-docker.sh\").toString())\n        .run();\n\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n    Verifier verifier = new Verifier(simpleTestProject.getProjectRoot().toString());\n    verifier.setSystemProperty(\"jib.useOnlyProjectCache\", \"true\");\n    verifier.setSystemProperty(\"_TARGET_IMAGE\", targetImage);\n    verifier.setAutoclean(false);\n    verifier.addCliOption(\"--file=pom-dockerclient.xml\");\n    verifier.addCliOption(\"--debug\");\n    verifier.executeGoal(\"package\");\n\n    verifier.executeGoal(\"jib:dockerBuild\");\n    verifier.verifyTextInLog(\"Docker load called. value1 value2\");\n    verifier.verifyErrorFreeLog();\n  }\n\n  @Test\n  public void testExecute_empty()\n      throws InterruptedException, IOException, VerificationException, DigestException {\n    String targetImage = \"emptyimage:maven\" + System.nanoTime();\n\n    Assert.assertEquals(\"\", buildToDockerDaemonAndRun(emptyTestProject, targetImage));\n    Assert.assertEquals(\n        \"1970-01-01T00:00:00Z\",\n        new Command(\"docker\", \"inspect\", \"-f\", \"{{.Created}}\", targetImage).run().trim());\n  }\n\n  @Test\n  public void testExecute_defaultTarget()\n      throws VerificationException, IOException, InterruptedException, DigestException {\n    Assert.assertEquals(\n        \"Hello, world. An argument.\\n\",\n        buildToDockerDaemonAndRun(\n            defaultTargetTestProject, \"default-target-name:default-target-version\"));\n  }\n\n  @Test\n  public void testExecute_jibSkip() throws VerificationException, IOException {\n    SkippedGoalVerifier.verifyJibSkip(emptyTestProject, BuildDockerMojo.GOAL_NAME);\n  }\n\n  @Test\n  public void testExecute_jibContainerizeSkips() throws VerificationException, IOException {\n    SkippedGoalVerifier.verifyJibContainerizeSkips(emptyTestProject, BuildDockerMojo.GOAL_NAME);\n  }\n\n  @Test\n  public void testExecute_userNumeric()\n      throws VerificationException, IOException, InterruptedException, DigestException {\n    String targetImage = \"emptyimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(emptyTestProject, targetImage, \"pom.xml\");\n    Assert.assertEquals(\n        \"12345:54321\",\n        new Command(\"docker\", \"inspect\", \"-f\", \"{{.Config.User}}\", targetImage).run().trim());\n  }\n\n  @Test\n  public void testExecute_userNames()\n      throws VerificationException, IOException, InterruptedException, DigestException {\n    String targetImage = \"brokenuserimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(emptyTestProject, targetImage, \"pom-broken-user.xml\");\n    Assert.assertEquals(\n        \"myuser:mygroup\",\n        new Command(\"docker\", \"inspect\", \"-f\", \"{{.Config.User}}\", targetImage).run().trim());\n  }\n\n  @Test\n  public void testExecute_noToImageAndInvalidProjectName()\n      throws DigestException, VerificationException, IOException, InterruptedException {\n    buildToDockerDaemon(simpleTestProject, \"image reference ignored\", \"pom-no-to-image.xml\");\n    Assert.assertEquals(\n        \"Hello, world. \\n1970-01-01T00:00:01Z\\n\",\n        new Command(\"docker\", \"run\", \"--rm\", \"my-artifact-id:1\").run());\n  }\n\n  @Test\n  public void testExecute_jarContainerization()\n      throws DigestException, VerificationException, IOException, InterruptedException {\n    String targetImage = \"jarcontainerizationimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(simpleTestProject, targetImage, \"pom-jar-containerization.xml\");\n    Assert.assertEquals(\n        \"Hello, world. \\nImplementation-Title: hello-world\\nImplementation-Version: 1\\n\",\n        new Command(\"docker\", \"run\", \"--rm\", targetImage).run());\n  }\n\n  @Test\n  public void testExecute_jarContainerizationOnMissingJar() throws IOException {\n    try {\n      Verifier verifier = new Verifier(simpleTestProject.getProjectRoot().toString());\n      verifier.setSystemProperty(\"_TARGET_IMAGE\", \"erroronmissingjar\");\n      verifier.setAutoclean(false);\n      verifier.addCliOption(\"--file=pom-jar-containerization.xml\");\n      verifier.executeGoals(Arrays.asList(\"clean\", \"jib:dockerBuild\"));\n      Assert.fail();\n\n    } catch (VerificationException ex) {\n      MatcherAssert.assertThat(\n          ex.getMessage(),\n          CoreMatchers.containsString(\n              \"Obtaining project build output files failed; make sure you have packaged your \"\n                  + \"project before trying to build the image. (Did you accidentally run \\\"mvn \"\n                  + \"clean jib:build\\\" instead of \\\"mvn clean package jib:build\\\"?)\"));\n    }\n  }\n\n  @Test\n  public void testExecute_jibRequireVersion_ok() throws VerificationException, IOException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n\n    Verifier verifier = new Verifier(simpleTestProject.getProjectRoot().toString());\n    // this plugin should match 1.0\n    verifier.setSystemProperty(\"jib.requiredVersion\", \"1.0\");\n    verifier.setSystemProperty(\"_TARGET_IMAGE\", targetImage);\n    verifier.executeGoals(Arrays.asList(\"package\", \"jib:dockerBuild\"));\n    verifier.verifyErrorFreeLog();\n  }\n\n  @Test\n  public void testExecute_jibRequireVersion_fail() throws IOException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n\n    try {\n      Verifier verifier = new Verifier(simpleTestProject.getProjectRoot().toString());\n      verifier.setSystemProperty(\"jib.requiredVersion\", \"[,1.0]\");\n      verifier.setSystemProperty(\"_TARGET_IMAGE\", targetImage);\n      verifier.executeGoals(Arrays.asList(\"package\", \"jib:dockerBuild\"));\n      Assert.fail();\n    } catch (VerificationException ex) {\n      MatcherAssert.assertThat(\n          ex.getMessage(), CoreMatchers.containsString(\"but is required to be [,1.0]\"));\n    }\n  }\n\n  @Test\n  public void testCredHelperConfigurationSimple()\n      throws DigestException, VerificationException, IOException, InterruptedException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(simpleTestProject, targetImage, \"pom-cred-helper-1.xml\");\n    Assert.assertEquals(\n        \"Hello, world. \\n1970-01-01T00:00:01Z\\n\",\n        new Command(\"docker\", \"run\", \"--rm\", targetImage).run());\n  }\n\n  @Test\n  public void testCredHelperConfigurationComplex()\n      throws DigestException, VerificationException, IOException, InterruptedException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(simpleTestProject, targetImage, \"pom-cred-helper-2.xml\");\n    Assert.assertEquals(\n        \"Hello, world. \\n1970-01-01T00:00:01Z\\n\",\n        new Command(\"docker\", \"run\", \"--rm\", targetImage).run());\n  }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_39_chunk_0",
        "original_index": 0,
        "content": "/*\n * Copyright 2018 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_1",
        "original_index": 1,
        "content": "package com.google.cloud.tools.jib.maven;\n\nimport static com.google.common.truth.Truth.assertThat;\n\nimport com.google.cloud.tools.jib.Command;\nimport java.io.IOException;\nimport java.security.DigestException;\nimport java.util.Arrays;\nimport org.apache.maven.it.VerificationException;\nimport org.apache.maven.it.Verifier;\nimport org.hamcrest.CoreMatchers;\nimport org.hamcrest.MatcherAssert;\nimport org.junit.Assert;\nimport org.junit.Assume;\nimport org.junit.ClassRule;\nimport org.junit.Test;\n\n/** Integration tests for {@link BuildDockerMojo}. */\npublic class BuildDockerMojoIntegrationTest {\n\n  @ClassRule public static final TestProject simpleTestProject = new TestProject(\"simple\");\n\n  @ClassRule public static final TestProject emptyTestProject = new TestProject(\"empty\");\n\n  @ClassRule\n  public static final TestProject defaultTargetTestProject = new TestProject(\"default-target\");\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_2",
        "original_index": 2,
        "content": "  private static void buildToDockerDaemon(TestProject project, String imageReference, String pomXml)\n      throws VerificationException, DigestException, IOException {\n    Verifier verifier = new Verifier(project.getProjectRoot().toString());\n    verifier.setSystemProperty(\"jib.useOnlyProjectCache\", \"true\");\n    verifier.setSystemProperty(\"_TARGET_IMAGE\", imageReference);\n    verifier.setAutoclean(false);\n    verifier.addCliOption(\"--file=\" + pomXml);\n    verifier.executeGoal(\"package\");\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_3",
        "original_index": 3,
        "content": "    verifier.executeGoal(\"jib:dockerBuild\");\n    verifier.verifyErrorFreeLog();\n\n    BuildImageMojoIntegrationTest.readDigestFile(\n        project.getProjectRoot().resolve(\"target/jib-image.digest\"));\n  }\n\n  /**\n   * Builds and runs jib:buildDocker on a project at {@code projectRoot} pushing to {@code\n   * imageReference}.\n   */\n  private static String buildToDockerDaemonAndRun(TestProject project, String imageReference)\n      throws VerificationException, IOException, InterruptedException, DigestException {\n    buildToDockerDaemon(project, imageReference, \"pom.xml\");\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_4",
        "original_index": 4,
        "content": "    String dockerInspectVolumes =\n        new Command(\"docker\", \"inspect\", \"-f\", \"'{{json .Config.Volumes}}'\", imageReference).run();\n    String dockerInspectExposedPorts =\n        new Command(\"docker\", \"inspect\", \"-f\", \"'{{json .Config.ExposedPorts}}'\", imageReference)\n            .run();\n    String dockerInspectLabels =\n        new Command(\"docker\", \"inspect\", \"-f\", \"'{{json .Config.Labels}}'\", imageReference).run();\n    String history = new Command(\"docker\", \"history\", imageReference).run();\n\n    MatcherAssert.assertThat(\n        dockerInspectVolumes, CoreMatchers.containsString(\"\\\"/var/log\\\":{},\\\"/var/log2\\\":{}\"));\n    MatcherAssert.assertThat(\n        dockerInspectExposedPorts,\n        CoreMatchers.containsString(\n            \"\\\"1000/tcp\\\":{},\\\"2000/udp\\\":{},\\\"2001/udp\\\":{},\\\"2002/udp\\\":{},\\\"2003/udp\\\":{}\"));\n    MatcherAssert.assertThat(\n        dockerInspectLabels,\n        CoreMatchers.containsString(\"\\\"key1\\\":\\\"value1\\\",\\\"key2\\\":\\\"value2\\\"\"));\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_5",
        "original_index": 5,
        "content": "    return new Command(\"docker\", \"run\", \"--rm\", imageReference).run();\n  }\n\n  @Test\n  public void testExecute_simple()\n      throws VerificationException, IOException, InterruptedException, DigestException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n\n    Assert.assertEquals(\n        \"Hello, world. An argument.\\n1970-01-01T00:00:01Z\\nrw-r--r--\\nrw-r--r--\\nfoo\\ncat\\n\"\n            + \"1970-01-01T00:00:01Z\\n1970-01-01T00:00:01Z\\n\",\n        buildToDockerDaemonAndRun(simpleTestProject, targetImage));\n    Assert.assertEquals(\n        \"1970-01-01T00:00:00Z\",\n        new Command(\"docker\", \"inspect\", \"-f\", \"{{.Created}}\", targetImage).run().trim());\n  }\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_6",
        "original_index": 6,
        "content": "  @Test\n  public void testExecute_simple_extraDirectoriesFiltering()\n      throws DigestException, IOException, InterruptedException, VerificationException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(simpleTestProject, targetImage, \"pom-extra-dirs-filtering.xml\");\n    String output =\n        new Command(\"docker\", \"run\", \"--rm\", \"--entrypoint=ls\", targetImage, \"-1R\", \"/extras\")\n            .run();\n\n    //   /extras/cat.txt\n    //   /extras/foo\n    //   /extras/sub/\n    //   /extras/sub/a.json\n    assertThat(output).isEqualTo(\"/extras:\\ncat.txt\\nfoo\\nsub\\n\\n/extras/sub:\\na.json\\n\");\n  }\n\n  @Test\n  public void testExecute_dockerClient()\n      throws VerificationException, IOException, InterruptedException {\n    Assume.assumeFalse(System.getProperty(\"os.name\").startsWith(\"Windows\"));\n    new Command(\n            \"chmod\", \"+x\", simpleTestProject.getProjectRoot().resolve(\"mock-docker.sh\").toString())\n        .run();\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_7",
        "original_index": 7,
        "content": "    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n    Verifier verifier = new Verifier(simpleTestProject.getProjectRoot().toString());\n    verifier.setSystemProperty(\"jib.useOnlyProjectCache\", \"true\");\n    verifier.setSystemProperty(\"_TARGET_IMAGE\", targetImage);\n    verifier.setAutoclean(false);\n    verifier.addCliOption(\"--file=pom-dockerclient.xml\");\n    verifier.addCliOption(\"--debug\");\n    verifier.executeGoal(\"package\");\n\n    verifier.executeGoal(\"jib:dockerBuild\");\n    verifier.verifyTextInLog(\"Docker load called. value1 value2\");\n    verifier.verifyErrorFreeLog();\n  }\n\n  @Test\n  public void testExecute_empty()\n      throws InterruptedException, IOException, VerificationException, DigestException {\n    String targetImage = \"emptyimage:maven\" + System.nanoTime();\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_8",
        "original_index": 8,
        "content": "    Assert.assertEquals(\"\", buildToDockerDaemonAndRun(emptyTestProject, targetImage));\n    Assert.assertEquals(\n        \"1970-01-01T00:00:00Z\",\n        new Command(\"docker\", \"inspect\", \"-f\", \"{{.Created}}\", targetImage).run().trim());\n  }\n\n  @Test\n  public void testExecute_defaultTarget()\n      throws VerificationException, IOException, InterruptedException, DigestException {\n    Assert.assertEquals(\n        \"Hello, world. An argument.\\n\",\n        buildToDockerDaemonAndRun(\n            defaultTargetTestProject, \"default-target-name:default-target-version\"));\n  }\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_9",
        "original_index": 9,
        "content": "  @Test\n  public void testExecute_jibSkip() throws VerificationException, IOException {\n    SkippedGoalVerifier.verifyJibSkip(emptyTestProject, BuildDockerMojo.GOAL_NAME);\n  }\n\n  @Test\n  public void testExecute_jibContainerizeSkips() throws VerificationException, IOException {\n    SkippedGoalVerifier.verifyJibContainerizeSkips(emptyTestProject, BuildDockerMojo.GOAL_NAME);\n  }\n\n  @Test\n  public void testExecute_userNumeric()\n      throws VerificationException, IOException, InterruptedException, DigestException {\n    String targetImage = \"emptyimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(emptyTestProject, targetImage, \"pom.xml\");\n    Assert.assertEquals(\n        \"12345:54321\",\n        new Command(\"docker\", \"inspect\", \"-f\", \"{{.Config.User}}\", targetImage).run().trim());\n  }\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_10",
        "original_index": 10,
        "content": "  @Test\n  public void testExecute_userNames()\n      throws VerificationException, IOException, InterruptedException, DigestException {\n    String targetImage = \"brokenuserimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(emptyTestProject, targetImage, \"pom-broken-user.xml\");\n    Assert.assertEquals(\n        \"myuser:mygroup\",\n        new Command(\"docker\", \"inspect\", \"-f\", \"{{.Config.User}}\", targetImage).run().trim());\n  }\n\n  @Test\n  public void testExecute_noToImageAndInvalidProjectName()\n      throws DigestException, VerificationException, IOException, InterruptedException {\n    buildToDockerDaemon(simpleTestProject, \"image reference ignored\", \"pom-no-to-image.xml\");\n    Assert.assertEquals(\n        \"Hello, world. \\n1970-01-01T00:00:01Z\\n\",\n        new Command(\"docker\", \"run\", \"--rm\", \"my-artifact-id:1\").run());\n  }\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_11",
        "original_index": 11,
        "content": "  @Test\n  public void testExecute_jarContainerization()\n      throws DigestException, VerificationException, IOException, InterruptedException {\n    String targetImage = \"jarcontainerizationimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(simpleTestProject, targetImage, \"pom-jar-containerization.xml\");\n    Assert.assertEquals(\n        \"Hello, world. \\nImplementation-Title: hello-world\\nImplementation-Version: 1\\n\",\n        new Command(\"docker\", \"run\", \"--rm\", targetImage).run());\n  }\n\n  @Test\n  public void testExecute_jarContainerizationOnMissingJar() throws IOException {\n    try {\n      Verifier verifier = new Verifier(simpleTestProject.getProjectRoot().toString());\n      verifier.setSystemProperty(\"_TARGET_IMAGE\", \"erroronmissingjar\");\n      verifier.setAutoclean(false);\n      verifier.addCliOption(\"--file=pom-jar-containerization.xml\");\n      verifier.executeGoals(Arrays.asList(\"clean\", \"jib:dockerBuild\"));\n      Assert.fail();\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_12",
        "original_index": 12,
        "content": "    } catch (VerificationException ex) {\n      MatcherAssert.assertThat(\n          ex.getMessage(),\n          CoreMatchers.containsString(\n              \"Obtaining project build output files failed; make sure you have packaged your \"\n                  + \"project before trying to build the image. (Did you accidentally run \\\"mvn \"\n                  + \"clean jib:build\\\" instead of \\\"mvn clean package jib:build\\\"?)\"));\n    }\n  }\n\n  @Test\n  public void testExecute_jibRequireVersion_ok() throws VerificationException, IOException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_13",
        "original_index": 13,
        "content": "    Verifier verifier = new Verifier(simpleTestProject.getProjectRoot().toString());\n    // this plugin should match 1.0\n    verifier.setSystemProperty(\"jib.requiredVersion\", \"1.0\");\n    verifier.setSystemProperty(\"_TARGET_IMAGE\", targetImage);\n    verifier.executeGoals(Arrays.asList(\"package\", \"jib:dockerBuild\"));\n    verifier.verifyErrorFreeLog();\n  }\n\n  @Test\n  public void testExecute_jibRequireVersion_fail() throws IOException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_14",
        "original_index": 14,
        "content": "    try {\n      Verifier verifier = new Verifier(simpleTestProject.getProjectRoot().toString());\n      verifier.setSystemProperty(\"jib.requiredVersion\", \"[,1.0]\");\n      verifier.setSystemProperty(\"_TARGET_IMAGE\", targetImage);\n      verifier.executeGoals(Arrays.asList(\"package\", \"jib:dockerBuild\"));\n      Assert.fail();\n    } catch (VerificationException ex) {\n      MatcherAssert.assertThat(\n          ex.getMessage(), CoreMatchers.containsString(\"but is required to be [,1.0]\"));\n    }\n  }\n\n"
      },
      {
        "chunk_id": "doc_39_chunk_15",
        "original_index": 15,
        "content": "  @Test\n  public void testCredHelperConfigurationSimple()\n      throws DigestException, VerificationException, IOException, InterruptedException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(simpleTestProject, targetImage, \"pom-cred-helper-1.xml\");\n    Assert.assertEquals(\n        \"Hello, world. \\n1970-01-01T00:00:01Z\\n\",\n        new Command(\"docker\", \"run\", \"--rm\", targetImage).run());\n  }\n\n  @Test\n  public void testCredHelperConfigurationComplex()\n      throws DigestException, VerificationException, IOException, InterruptedException {\n    String targetImage = \"simpleimage:maven\" + System.nanoTime();\n    buildToDockerDaemon(simpleTestProject, targetImage, \"pom-cred-helper-2.xml\");\n    Assert.assertEquals(\n        \"Hello, world. \\n1970-01-01T00:00:01Z\\n\",\n        new Command(\"docker\", \"run\", \"--rm\", targetImage).run());\n  }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_40",
    "original_uuid": "eabb6a15874b3744292a5808f64e7a6ddf5b7114f80bad3306c2af61d8799b09",
    "content": "/*\n * Copyright 2017 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\npackage com.google.cloud.tools.jib.api;\n\nimport java.text.MessageFormat;\n\n/** Thrown because registry authentication failed. */\npublic class RegistryAuthenticationFailedException extends RegistryException {\n\n  private static final String REASON = \"Failed to authenticate with registry {0}/{1} because: {2}\";\n  private final String serverUrl;\n  private final String imageName;\n\n  /**\n   * Creates a new exception with a human readable message.\n   *\n   * @param serverUrl the registry server url\n   * @param imageName the image name that requires authentication\n   * @param cause the underlying cause that triggered this exception\n   */\n  public RegistryAuthenticationFailedException(\n      String serverUrl, String imageName, Throwable cause) {\n    super(MessageFormat.format(REASON, serverUrl, imageName, cause.getMessage()), cause);\n    this.serverUrl = serverUrl;\n    this.imageName = imageName;\n  }\n\n  /**\n   * Creates a new exception with a human readable message.\n   *\n   * @param serverUrl the registry server url\n   * @param imageName the image name that requires authentication\n   * @param reason the underlying reason that triggered this exception\n   */\n  public RegistryAuthenticationFailedException(String serverUrl, String imageName, String reason) {\n    super(MessageFormat.format(REASON, serverUrl, imageName, reason));\n    this.serverUrl = serverUrl;\n    this.imageName = imageName;\n  }\n\n  /**\n   * The server being authenticated.\n   *\n   * @return the server being authenticated\n   */\n  public String getServerUrl() {\n    return serverUrl;\n  }\n\n  /**\n   * The image being authenticated.\n   *\n   * @return the image being authenticated\n   */\n  public String getImageName() {\n    return imageName;\n  }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_40_chunk_0",
        "original_index": 0,
        "content": "/*\n * Copyright 2017 Google LLC.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n * use this file except in compliance with the License. You may obtain a copy of\n * the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations under\n * the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_40_chunk_1",
        "original_index": 1,
        "content": "package com.google.cloud.tools.jib.api;\n\nimport java.text.MessageFormat;\n\n/** Thrown because registry authentication failed. */\npublic class RegistryAuthenticationFailedException extends RegistryException {\n\n  private static final String REASON = \"Failed to authenticate with registry {0}/{1} because: {2}\";\n  private final String serverUrl;\n  private final String imageName;\n\n  /**\n   * Creates a new exception with a human readable message.\n   *\n   * @param serverUrl the registry server url\n   * @param imageName the image name that requires authentication\n   * @param cause the underlying cause that triggered this exception\n   */\n  public RegistryAuthenticationFailedException(\n      String serverUrl, String imageName, Throwable cause) {\n    super(MessageFormat.format(REASON, serverUrl, imageName, cause.getMessage()), cause);\n    this.serverUrl = serverUrl;\n    this.imageName = imageName;\n  }\n\n"
      },
      {
        "chunk_id": "doc_40_chunk_2",
        "original_index": 2,
        "content": "  /**\n   * Creates a new exception with a human readable message.\n   *\n   * @param serverUrl the registry server url\n   * @param imageName the image name that requires authentication\n   * @param reason the underlying reason that triggered this exception\n   */\n  public RegistryAuthenticationFailedException(String serverUrl, String imageName, String reason) {\n    super(MessageFormat.format(REASON, serverUrl, imageName, reason));\n    this.serverUrl = serverUrl;\n    this.imageName = imageName;\n  }\n\n  /**\n   * The server being authenticated.\n   *\n   * @return the server being authenticated\n   */\n  public String getServerUrl() {\n    return serverUrl;\n  }\n\n  /**\n   * The image being authenticated.\n   *\n   * @return the image being authenticated\n   */\n  public String getImageName() {\n    return imageName;\n  }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_41",
    "original_uuid": "a7207d085190f179fc2a0f4ed97aece6f033ecdda1104e75dac8fe43844b598b",
    "content": "package com.password4j;\n\nimport org.junit.Assert;\nimport org.junit.Test;\n\n\npublic class PepperGeneratorTest\n{\n\n    @Test\n    public void testSaltLength()\n    {\n        // GIVEN\n        int length = 23;\n\n        // WHEN\n        String pepper = PepperGenerator.generate(length);\n\n        // THEN\n        Assert.assertNotNull(pepper);\n        Assert.assertEquals(length, pepper.length());\n    }\n\n\n    @Test\n    public void testSaltNoLength()\n    {\n        // GIVEN\n\n        // WHEN\n        String pepper = PepperGenerator.generate();\n\n        // THEN\n        Assert.assertNotNull(pepper);\n        Assert.assertEquals(24, pepper.length());\n    }\n\n    @Test(expected = BadParametersException.class)\n    public void testSaltNegativeLength()\n    {\n        // GIVEN\n\n        // WHEN\n        PepperGenerator.generate(-3);\n\n        // THEN\n\n    }\n\n    @Test\n    public void testSaltZeroLength()\n    {\n        // GIVEN\n        int length = 0;\n\n        // WHEN\n        String pepper = PepperGenerator.generate(length);\n\n        // THEN\n        Assert.assertNotNull(pepper);\n        Assert.assertEquals(length, pepper.length());\n    }\n\n    @Test\n    public void testAlice()\n    {\n        // GIVEN\n\n        // WHEN\n        String pepper = PepperGenerator.get();\n\n        // THEN\n        Assert.assertEquals(\"AlicePepper\", pepper);\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_41_chunk_0",
        "original_index": 0,
        "content": "package com.password4j;\n\nimport org.junit.Assert;\nimport org.junit.Test;\n\n\npublic class PepperGeneratorTest\n{\n\n    @Test\n    public void testSaltLength()\n    {\n        // GIVEN\n        int length = 23;\n\n        // WHEN\n        String pepper = PepperGenerator.generate(length);\n\n        // THEN\n        Assert.assertNotNull(pepper);\n        Assert.assertEquals(length, pepper.length());\n    }\n\n\n    @Test\n    public void testSaltNoLength()\n    {\n        // GIVEN\n\n        // WHEN\n        String pepper = PepperGenerator.generate();\n\n        // THEN\n        Assert.assertNotNull(pepper);\n        Assert.assertEquals(24, pepper.length());\n    }\n\n"
      },
      {
        "chunk_id": "doc_41_chunk_1",
        "original_index": 1,
        "content": "    @Test(expected = BadParametersException.class)\n    public void testSaltNegativeLength()\n    {\n        // GIVEN\n\n        // WHEN\n        PepperGenerator.generate(-3);\n\n        // THEN\n\n    }\n\n    @Test\n    public void testSaltZeroLength()\n    {\n        // GIVEN\n        int length = 0;\n\n        // WHEN\n        String pepper = PepperGenerator.generate(length);\n\n        // THEN\n        Assert.assertNotNull(pepper);\n        Assert.assertEquals(length, pepper.length());\n    }\n\n    @Test\n    public void testAlice()\n    {\n        // GIVEN\n\n        // WHEN\n        String pepper = PepperGenerator.get();\n\n        // THEN\n        Assert.assertEquals(\"AlicePepper\", pepper);\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_42",
    "original_uuid": "2c42fa36aa434372ba169a9f7cbfe3a0a0b140342bb70fe07907b93ac23f23e9",
    "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\npackage com.password4j;\n\n/**\n * Class in the hierarchy to avoid code duplication.\n *\n * @author David Bertoldi\n * @since 0.1.0\n */\npublic abstract class AbstractHashingFunction implements HashingFunction\n{\n\n    /**\n     * Compares two {@link CharSequence}s as byte arrays in length-constant time. This comparison method\n     * is used so that password hashes cannot be extracted from an on-line\n     * system using a timing attack and then attacked off-line.\n     *\n     * @param a the first CharSequence\n     * @param b the second CharSequence\n     * @return true if both {@link CharSequence}s are the same, false if not\n     */\n    protected static boolean slowEquals(CharSequence a, CharSequence b)\n    {\n        return slowEquals(Utils.fromCharSequenceToBytes(a), Utils.fromCharSequenceToBytes(b));\n    }\n\n    /**\n     * Compares two byte arrays in length-constant time. This comparison method\n     * is used so that password hashes cannot be extracted from an on-line\n     * system using a timing attack and then attacked off-line.\n     *\n     * @param a the first byte array\n     * @param b the second byte array\n     * @return true if both byte arrays are the same, false if not\n     */\n    protected static boolean slowEquals(byte[] a, byte[] b)\n    {\n        int diff = a.length ^ b.length;\n        for (int i = 0; i < a.length && i < b.length; i++)\n        {\n            diff |= a[i] ^ b[i];\n        }\n        return diff == 0;\n    }\n\n    @Override\n    public Hash hash(CharSequence plainTextPassword, String salt, CharSequence pepper)\n    {\n        CharSequence peppered = Utils.append(pepper, plainTextPassword);\n        Hash result;\n        if (salt == null)\n        {\n            result = hash(peppered);\n        }\n        else\n        {\n            result = hash(peppered, salt);\n        }\n\n        result.setPepper(pepper);\n        return result;\n    }\n\n    @Override\n    public Hash hash(byte[] plainTextPassword, byte[] salt, CharSequence pepper)\n    {\n        byte[] pepperAsBytes = Utils.fromCharSequenceToBytes(pepper);\n        byte[] peppered = Utils.append(pepperAsBytes, plainTextPassword);\n        Hash result;\n        if (salt == null)\n        {\n            result = hash(peppered);\n        }\n        else\n        {\n            result = hash(peppered, salt);\n        }\n\n        result.setPepper(pepper);\n        return result;\n    }\n\n    /**\n     * Just calls {@link #check(CharSequence, String)} without salt\n     * parameter.\n     * <p>\n     * Do not override this if the algorithm doesn't need a manually\n     * provided salt.\n     *\n     * @param plainTextPassword the plaintext password\n     * @param hashed            the hash\n     * @param salt              the salt used to produce the hash\n     * @return true if the hash is generated from the plaintext; false otherwise\n     * @since 0.1.0\n     */\n    @Override\n    public boolean check(CharSequence plainTextPassword, String hashed, String salt)\n    {\n        return check(plainTextPassword, hashed);\n    }\n\n    /**\n     * Just calls {@link #check(CharSequence, String)} without salt\n     * parameter.\n     * <p>\n     * Do not override this if the algorithm doesn't need a manually\n     * provided salt.\n     *\n     * @param plainTextPassword the plaintext password as bytes array\n     * @param hashed            the hash as bytes array\n     * @param salt              the salt as bytes array used to produce the hash\n     * @return true if the hash is generated from the plaintext; false otherwise\n     * @since 1.7.0\n     */\n    @Override\n    public boolean check(byte[] plainTextPassword, byte[] hashed, byte[] salt)\n    {\n        return check(plainTextPassword, hashed);\n    }\n\n    /**\n     * Just calls {@link #check(CharSequence, String, String)}, with a prepended pepper.\n     *\n     * @param plainTextPassword the plaintext password\n     * @param hashed            the hash\n     * @param salt              the salt used to produce the hash\n     * @return true if the hash is generated from the plaintext; false otherwise\n     * @since 1.5.0\n     */\n    @Override\n    public boolean check(CharSequence plainTextPassword, String hashed, String salt, CharSequence pepper)\n    {\n        return check(Utils.append(pepper, plainTextPassword), hashed, salt);\n    }\n\n    /**\n     * Just calls {@link #check(CharSequence, String, String)}, with a prepended pepper.\n     *\n     * @param plainTextPassword the plaintext password\n     * @param hashed            the hash\n     * @param salt              the salt used to produce the hash\n     * @return true if the hash is generated from the plaintext; false otherwise\n     * @since 1.7.0\n     */\n    @Override\n    public boolean check(byte[] plainTextPassword, byte[] hashed, byte[] salt, CharSequence pepper)\n    {\n        byte[] pepperAsBytes = Utils.fromCharSequenceToBytes(pepper);\n        return check(Utils.append(pepperAsBytes, plainTextPassword), hashed, salt);\n    }\n\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_42_chunk_0",
        "original_index": 0,
        "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\n"
      },
      {
        "chunk_id": "doc_42_chunk_1",
        "original_index": 1,
        "content": "package com.password4j;\n\n/**\n * Class in the hierarchy to avoid code duplication.\n *\n * @author David Bertoldi\n * @since 0.1.0\n */\npublic abstract class AbstractHashingFunction implements HashingFunction\n{\n\n    /**\n     * Compares two {@link CharSequence}s as byte arrays in length-constant time. This comparison method\n     * is used so that password hashes cannot be extracted from an on-line\n     * system using a timing attack and then attacked off-line.\n     *\n     * @param a the first CharSequence\n     * @param b the second CharSequence\n     * @return true if both {@link CharSequence}s are the same, false if not\n     */\n    protected static boolean slowEquals(CharSequence a, CharSequence b)\n    {\n        return slowEquals(Utils.fromCharSequenceToBytes(a), Utils.fromCharSequenceToBytes(b));\n    }\n\n"
      },
      {
        "chunk_id": "doc_42_chunk_2",
        "original_index": 2,
        "content": "    /**\n     * Compares two byte arrays in length-constant time. This comparison method\n     * is used so that password hashes cannot be extracted from an on-line\n     * system using a timing attack and then attacked off-line.\n     *\n     * @param a the first byte array\n     * @param b the second byte array\n     * @return true if both byte arrays are the same, false if not\n     */\n    protected static boolean slowEquals(byte[] a, byte[] b)\n    {\n        int diff = a.length ^ b.length;\n        for (int i = 0; i < a.length && i < b.length; i++)\n        {\n            diff |= a[i] ^ b[i];\n        }\n        return diff == 0;\n    }\n\n"
      },
      {
        "chunk_id": "doc_42_chunk_3",
        "original_index": 3,
        "content": "    @Override\n    public Hash hash(CharSequence plainTextPassword, String salt, CharSequence pepper)\n    {\n        CharSequence peppered = Utils.append(pepper, plainTextPassword);\n        Hash result;\n        if (salt == null)\n        {\n            result = hash(peppered);\n        }\n        else\n        {\n            result = hash(peppered, salt);\n        }\n\n        result.setPepper(pepper);\n        return result;\n    }\n\n    @Override\n    public Hash hash(byte[] plainTextPassword, byte[] salt, CharSequence pepper)\n    {\n        byte[] pepperAsBytes = Utils.fromCharSequenceToBytes(pepper);\n        byte[] peppered = Utils.append(pepperAsBytes, plainTextPassword);\n        Hash result;\n        if (salt == null)\n        {\n            result = hash(peppered);\n        }\n        else\n        {\n            result = hash(peppered, salt);\n        }\n\n        result.setPepper(pepper);\n        return result;\n    }\n\n"
      },
      {
        "chunk_id": "doc_42_chunk_4",
        "original_index": 4,
        "content": "    /**\n     * Just calls {@link #check(CharSequence, String)} without salt\n     * parameter.\n     * <p>\n     * Do not override this if the algorithm doesn't need a manually\n     * provided salt.\n     *\n     * @param plainTextPassword the plaintext password\n     * @param hashed            the hash\n     * @param salt              the salt used to produce the hash\n     * @return true if the hash is generated from the plaintext; false otherwise\n     * @since 0.1.0\n     */\n    @Override\n    public boolean check(CharSequence plainTextPassword, String hashed, String salt)\n    {\n        return check(plainTextPassword, hashed);\n    }\n\n"
      },
      {
        "chunk_id": "doc_42_chunk_5",
        "original_index": 5,
        "content": "    /**\n     * Just calls {@link #check(CharSequence, String)} without salt\n     * parameter.\n     * <p>\n     * Do not override this if the algorithm doesn't need a manually\n     * provided salt.\n     *\n     * @param plainTextPassword the plaintext password as bytes array\n     * @param hashed            the hash as bytes array\n     * @param salt              the salt as bytes array used to produce the hash\n     * @return true if the hash is generated from the plaintext; false otherwise\n     * @since 1.7.0\n     */\n    @Override\n    public boolean check(byte[] plainTextPassword, byte[] hashed, byte[] salt)\n    {\n        return check(plainTextPassword, hashed);\n    }\n\n"
      },
      {
        "chunk_id": "doc_42_chunk_6",
        "original_index": 6,
        "content": "    /**\n     * Just calls {@link #check(CharSequence, String, String)}, with a prepended pepper.\n     *\n     * @param plainTextPassword the plaintext password\n     * @param hashed            the hash\n     * @param salt              the salt used to produce the hash\n     * @return true if the hash is generated from the plaintext; false otherwise\n     * @since 1.5.0\n     */\n    @Override\n    public boolean check(CharSequence plainTextPassword, String hashed, String salt, CharSequence pepper)\n    {\n        return check(Utils.append(pepper, plainTextPassword), hashed, salt);\n    }\n\n"
      },
      {
        "chunk_id": "doc_42_chunk_7",
        "original_index": 7,
        "content": "    /**\n     * Just calls {@link #check(CharSequence, String, String)}, with a prepended pepper.\n     *\n     * @param plainTextPassword the plaintext password\n     * @param hashed            the hash\n     * @param salt              the salt used to produce the hash\n     * @return true if the hash is generated from the plaintext; false otherwise\n     * @since 1.7.0\n     */\n    @Override\n    public boolean check(byte[] plainTextPassword, byte[] hashed, byte[] salt, CharSequence pepper)\n    {\n        byte[] pepperAsBytes = Utils.fromCharSequenceToBytes(pepper);\n        return check(Utils.append(pepperAsBytes, plainTextPassword), hashed, salt);\n    }\n\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_43",
    "original_uuid": "b80798210bd12005120f16aa5e3903f550597521ed42ea5f67a050954fbd78ad",
    "content": "/*\n *  (C) Copyright 2023 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\npackage com.password4j;\n\nimport com.password4j.types.Argon2;\nimport com.password4j.types.Bcrypt;\nimport org.junit.Assert;\nimport org.junit.Test;\n\nimport java.nio.charset.StandardCharsets;\nimport java.util.Arrays;\n\npublic class BalloonHashingFunctionTest\n{\n\n    private static final Object[][] TEST_VECTORS = new Object[][]{\n            // Single thread\n            new Object[]{\"hunter42\", \"examplesalt\", \"SHA-256\", 1024, 3, 0, 3, \"716043dff777b44aa7b88dcbab12c078abecfac9d289c5b5195967aa63440dfb\"},\n            new Object[]{\"\", \"salt\", \"SHA-256\", 3, 3, 0, 3, \"5f02f8206f9cd212485c6bdf85527b698956701ad0852106f94b94ee94577378\"},\n            new Object[]{\"password\", \"\", \"SHA-256\", 3, 3, 0, 3, \"20aa99d7fe3f4df4bd98c655c5480ec98b143107a331fd491deda885c4d6a6cc\"},\n            new Object[]{\"\\0\", \"\\0\", \"SHA-256\", 3, 3, 0, 3, \"4fc7e302ffa29ae0eac31166cee7a552d1d71135f4e0da66486fb68a749b73a4\"},\n            new Object[]{\"password\", \"salt\", \"SHA-256\", 1, 1, 0, 3, \"eefda4a8a75b461fa389c1dcfaf3e9dfacbc26f81f22e6f280d15cc18c417545\"},\n\n            // Multiple threads\n            new Object[]{\"hunter42\", \"examplesalt\", \"SHA-256\", 1024, 3, 4, 3, \"1832bd8e5cbeba1cb174a13838095e7e66508e9bf04c40178990adbc8ba9eb6f\"},\n            new Object[]{\"\", \"salt\", \"SHA-256\", 3, 3, 2, 3, \"f8767fe04059cef67b4427cda99bf8bcdd983959dbd399a5e63ea04523716c23\"},\n            new Object[]{\"password\", \"\", \"SHA-256\", 3, 3, 3, 3, \"bcad257eff3d1090b50276514857e60db5d0ec484129013ef3c88f7d36e438d6\"},\n            new Object[]{\"password\", \"\", \"SHA-256\", 3, 3, 1, 3, \"498344ee9d31baf82cc93ebb3874fe0b76e164302c1cefa1b63a90a69afb9b4d\"},\n            new Object[]{\"\\000\", \"\\000\", \"SHA-256\", 3, 3, 4, 3, \"8a665611e40710ba1fd78c181549c750f17c12e423c11930ce997f04c7153e0c\"},\n            new Object[]{\"\\000\", \"\\000\", \"SHA-256\", 3, 3, 1, 3, \"d9e33c683451b21fb3720afbd78bf12518c1d4401fa39f054b052a145c968bb1\"},\n            new Object[]{\"password\", \"salt\", \"SHA-256\", 1, 1, 16, 3, \"a67b383bb88a282aef595d98697f90820adf64582a4b3627c76b7da3d8bae915\"},\n            new Object[]{\"password\", \"salt\", \"SHA-256\", 1, 1, 1, 3, \"97a11df9382a788c781929831d409d3599e0b67ab452ef834718114efdcd1c6d\"},\n\n    };\n\n\n    @Test\n    public void test()\n    {\n\n        BalloonHashingFunction balloonHashingFunction;\n        for (Object[] testVector : TEST_VECTORS)\n        {\n            balloonHashingFunction = new BalloonHashingFunction((String) testVector[2], (Integer) testVector[3], (Integer) testVector[4], (Integer) testVector[5], (Integer) testVector[6]);\n            Assert.assertEquals(testVector[7], balloonHashingFunction.hash((String) testVector[0], (String) testVector[1]).getResult());\n\n            Assert.assertTrue(balloonHashingFunction.check((String) testVector[0], (String) testVector[7], (String) testVector[1]));\n        }\n\n    }\n\n    @Test\n    public void testInstance()\n    {\n\n        BalloonHashingFunction balloonHashingFunction;\n        for (Object[] testVector : TEST_VECTORS)\n        {\n            balloonHashingFunction = BalloonHashingFunction.getInstance((String) testVector[2], (Integer) testVector[3], (Integer) testVector[4], (Integer) testVector[5], (Integer) testVector[6]);\n            Assert.assertEquals(testVector[7], balloonHashingFunction.hash((String) testVector[0], (String) testVector[1]).getResult());\n            Assert.assertEquals(testVector[7], balloonHashingFunction.hash(((String) testVector[0]).getBytes(), ((String) testVector[1]).getBytes()).getResult());\n\n            Assert.assertTrue(balloonHashingFunction.check((String) testVector[0], (String) testVector[7], (String) testVector[1]));\n            Assert.assertTrue(balloonHashingFunction.check(((String) testVector[0]).getBytes(), ((String) testVector[7]).getBytes(), ((String) testVector[1]).getBytes()));\n        }\n\n    }\n\n    @Test\n    public void testEquality()\n    {\n        // GIVEN\n        String m = \"SHA-256\";\n        int i = 2;\n        int p = 3;\n        int l = 4;\n        int v = 5;\n        BalloonHashingFunction balloonHashingFunction = BalloonHashingFunction.getInstance(m, i, p, l, v);\n\n        // THEN\n        boolean eqNull = balloonHashingFunction.equals(null);\n        boolean eqClass = balloonHashingFunction.equals(new BcryptFunction(Bcrypt.A, 10));\n        boolean sameInst = balloonHashingFunction.equals(BalloonHashingFunction.getInstance(m, i, p, l, v));\n        boolean sameInst2 = balloonHashingFunction.equals(new BalloonHashingFunction(m, i, p, l, v));\n        String toString = balloonHashingFunction.toString();\n        int hashCode = balloonHashingFunction.hashCode();\n        boolean notSameInst1 = balloonHashingFunction.equals(new BalloonHashingFunction(\"SHA-512\", i, p, l, v));\n        boolean notSameInst2 = balloonHashingFunction.equals(new BalloonHashingFunction(m, i+1, p, l, v));\n        boolean notSameInst3 = balloonHashingFunction.equals(new BalloonHashingFunction(m, i, p+1, l, v));\n        boolean notSameInst4 = balloonHashingFunction.equals(new BalloonHashingFunction(m, i, p, l+1, v));\n        boolean notSameInst6 = balloonHashingFunction.equals(new BalloonHashingFunction(m, i, p, l,  v+1));\n\n        // END\n        Assert.assertFalse(eqNull);\n        Assert.assertFalse(eqClass);\n        Assert.assertTrue(sameInst);\n        Assert.assertTrue(sameInst2);\n        Assert.assertNotEquals(toString, new BalloonHashingFunction(m, i+1, p, l, v).toString());\n        Assert.assertNotEquals(hashCode, new BalloonHashingFunction(m, i, p, l, v+1).hashCode());\n        Assert.assertFalse(notSameInst1);\n        Assert.assertFalse(notSameInst2);\n        Assert.assertFalse(notSameInst3);\n        Assert.assertFalse(notSameInst4);\n        Assert.assertFalse(notSameInst6);\n    }\n\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_43_chunk_0",
        "original_index": 0,
        "content": "/*\n *  (C) Copyright 2023 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\npackage com.password4j;\n\nimport com.password4j.types.Argon2;\nimport com.password4j.types.Bcrypt;\nimport org.junit.Assert;\nimport org.junit.Test;\n\nimport java.nio.charset.StandardCharsets;\nimport java.util.Arrays;\n\npublic class BalloonHashingFunctionTest\n{\n\n"
      },
      {
        "chunk_id": "doc_43_chunk_1",
        "original_index": 1,
        "content": "    private static final Object[][] TEST_VECTORS = new Object[][]{\n            // Single thread\n            new Object[]{\"hunter42\", \"examplesalt\", \"SHA-256\", 1024, 3, 0, 3, \"716043dff777b44aa7b88dcbab12c078abecfac9d289c5b5195967aa63440dfb\"},\n            new Object[]{\"\", \"salt\", \"SHA-256\", 3, 3, 0, 3, \"5f02f8206f9cd212485c6bdf85527b698956701ad0852106f94b94ee94577378\"},\n            new Object[]{\"password\", \"\", \"SHA-256\", 3, 3, 0, 3, \"20aa99d7fe3f4df4bd98c655c5480ec98b143107a331fd491deda885c4d6a6cc\"},\n            new Object[]{\"\\0\", \"\\0\", \"SHA-256\", 3, 3, 0, 3, \"4fc7e302ffa29ae0eac31166cee7a552d1d71135f4e0da66486fb68a749b73a4\"},\n            new Object[]{\"password\", \"salt\", \"SHA-256\", 1, 1, 0, 3, \"eefda4a8a75b461fa389c1dcfaf3e9dfacbc26f81f22e6f280d15cc18c417545\"},\n\n"
      },
      {
        "chunk_id": "doc_43_chunk_2",
        "original_index": 2,
        "content": "            // Multiple threads\n            new Object[]{\"hunter42\", \"examplesalt\", \"SHA-256\", 1024, 3, 4, 3, \"1832bd8e5cbeba1cb174a13838095e7e66508e9bf04c40178990adbc8ba9eb6f\"},\n            new Object[]{\"\", \"salt\", \"SHA-256\", 3, 3, 2, 3, \"f8767fe04059cef67b4427cda99bf8bcdd983959dbd399a5e63ea04523716c23\"},\n            new Object[]{\"password\", \"\", \"SHA-256\", 3, 3, 3, 3, \"bcad257eff3d1090b50276514857e60db5d0ec484129013ef3c88f7d36e438d6\"},\n"
      },
      {
        "chunk_id": "doc_43_chunk_3",
        "original_index": 3,
        "content": "            new Object[]{\"password\", \"\", \"SHA-256\", 3, 3, 1, 3, \"498344ee9d31baf82cc93ebb3874fe0b76e164302c1cefa1b63a90a69afb9b4d\"},\n            new Object[]{\"\\000\", \"\\000\", \"SHA-256\", 3, 3, 4, 3, \"8a665611e40710ba1fd78c181549c750f17c12e423c11930ce997f04c7153e0c\"},\n            new Object[]{\"\\000\", \"\\000\", \"SHA-256\", 3, 3, 1, 3, \"d9e33c683451b21fb3720afbd78bf12518c1d4401fa39f054b052a145c968bb1\"},\n            new Object[]{\"password\", \"salt\", \"SHA-256\", 1, 1, 16, 3, \"a67b383bb88a282aef595d98697f90820adf64582a4b3627c76b7da3d8bae915\"},\n            new Object[]{\"password\", \"salt\", \"SHA-256\", 1, 1, 1, 3, \"97a11df9382a788c781929831d409d3599e0b67ab452ef834718114efdcd1c6d\"},\n\n"
      },
      {
        "chunk_id": "doc_43_chunk_4",
        "original_index": 4,
        "content": "    };\n\n\n    @Test\n    public void test()\n    {\n\n        BalloonHashingFunction balloonHashingFunction;\n        for (Object[] testVector : TEST_VECTORS)\n        {\n            balloonHashingFunction = new BalloonHashingFunction((String) testVector[2], (Integer) testVector[3], (Integer) testVector[4], (Integer) testVector[5], (Integer) testVector[6]);\n            Assert.assertEquals(testVector[7], balloonHashingFunction.hash((String) testVector[0], (String) testVector[1]).getResult());\n\n            Assert.assertTrue(balloonHashingFunction.check((String) testVector[0], (String) testVector[7], (String) testVector[1]));\n        }\n\n    }\n\n    @Test\n    public void testInstance()\n    {\n\n"
      },
      {
        "chunk_id": "doc_43_chunk_5",
        "original_index": 5,
        "content": "        BalloonHashingFunction balloonHashingFunction;\n        for (Object[] testVector : TEST_VECTORS)\n        {\n            balloonHashingFunction = BalloonHashingFunction.getInstance((String) testVector[2], (Integer) testVector[3], (Integer) testVector[4], (Integer) testVector[5], (Integer) testVector[6]);\n            Assert.assertEquals(testVector[7], balloonHashingFunction.hash((String) testVector[0], (String) testVector[1]).getResult());\n            Assert.assertEquals(testVector[7], balloonHashingFunction.hash(((String) testVector[0]).getBytes(), ((String) testVector[1]).getBytes()).getResult());\n\n"
      },
      {
        "chunk_id": "doc_43_chunk_6",
        "original_index": 6,
        "content": "            Assert.assertTrue(balloonHashingFunction.check((String) testVector[0], (String) testVector[7], (String) testVector[1]));\n            Assert.assertTrue(balloonHashingFunction.check(((String) testVector[0]).getBytes(), ((String) testVector[7]).getBytes(), ((String) testVector[1]).getBytes()));\n        }\n\n    }\n\n    @Test\n    public void testEquality()\n    {\n        // GIVEN\n        String m = \"SHA-256\";\n        int i = 2;\n        int p = 3;\n        int l = 4;\n        int v = 5;\n        BalloonHashingFunction balloonHashingFunction = BalloonHashingFunction.getInstance(m, i, p, l, v);\n\n"
      },
      {
        "chunk_id": "doc_43_chunk_7",
        "original_index": 7,
        "content": "        // THEN\n        boolean eqNull = balloonHashingFunction.equals(null);\n        boolean eqClass = balloonHashingFunction.equals(new BcryptFunction(Bcrypt.A, 10));\n        boolean sameInst = balloonHashingFunction.equals(BalloonHashingFunction.getInstance(m, i, p, l, v));\n        boolean sameInst2 = balloonHashingFunction.equals(new BalloonHashingFunction(m, i, p, l, v));\n        String toString = balloonHashingFunction.toString();\n        int hashCode = balloonHashingFunction.hashCode();\n        boolean notSameInst1 = balloonHashingFunction.equals(new BalloonHashingFunction(\"SHA-512\", i, p, l, v));\n"
      },
      {
        "chunk_id": "doc_43_chunk_8",
        "original_index": 8,
        "content": "        boolean notSameInst2 = balloonHashingFunction.equals(new BalloonHashingFunction(m, i+1, p, l, v));\n        boolean notSameInst3 = balloonHashingFunction.equals(new BalloonHashingFunction(m, i, p+1, l, v));\n        boolean notSameInst4 = balloonHashingFunction.equals(new BalloonHashingFunction(m, i, p, l+1, v));\n        boolean notSameInst6 = balloonHashingFunction.equals(new BalloonHashingFunction(m, i, p, l,  v+1));\n\n"
      },
      {
        "chunk_id": "doc_43_chunk_9",
        "original_index": 9,
        "content": "        // END\n        Assert.assertFalse(eqNull);\n        Assert.assertFalse(eqClass);\n        Assert.assertTrue(sameInst);\n        Assert.assertTrue(sameInst2);\n        Assert.assertNotEquals(toString, new BalloonHashingFunction(m, i+1, p, l, v).toString());\n        Assert.assertNotEquals(hashCode, new BalloonHashingFunction(m, i, p, l, v+1).hashCode());\n        Assert.assertFalse(notSameInst1);\n        Assert.assertFalse(notSameInst2);\n        Assert.assertFalse(notSameInst3);\n        Assert.assertFalse(notSameInst4);\n        Assert.assertFalse(notSameInst6);\n    }\n\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_44",
    "original_uuid": "cf29d0f1b0d00030546c50e9c15f1fc432ba590aaa270f7c6dcfa2591c386f25",
    "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j;\n\nimport java.util.Arrays;\n\n\nclass Blake2b\n{\n    private static final long[] IV = { 0x6a09e667f3bcc908L, 0xbb67ae8584caa73bL, 0x3c6ef372fe94f82bL, 0xa54ff53a5f1d36f1L,\n            0x510e527fade682d1L, 0x9b05688c2b3e6c1fL, 0x1f83d9abfb41bd6bL, 0x5be0cd19137e2179L };\n\n    private static final byte[][] SIGMA = { { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 },\n            { 14, 10, 4, 8, 9, 15, 13, 6, 1, 12, 0, 2, 11, 7, 5, 3 }, { 11, 8, 12, 0, 5, 2, 15, 13, 10, 14, 3, 6, 7, 1, 9, 4 },\n            { 7, 9, 3, 1, 13, 12, 11, 14, 2, 6, 5, 10, 4, 0, 15, 8 }, { 9, 0, 5, 7, 2, 4, 10, 15, 14, 1, 11, 12, 6, 8, 3, 13 },\n            { 2, 12, 6, 10, 0, 11, 8, 3, 4, 13, 7, 5, 15, 14, 1, 9 }, { 12, 5, 1, 15, 14, 13, 4, 10, 0, 7, 6, 3, 9, 2, 8, 11 },\n            { 13, 11, 7, 14, 12, 1, 3, 9, 5, 0, 15, 4, 8, 6, 2, 10 }, { 6, 15, 14, 9, 11, 3, 0, 8, 12, 2, 13, 7, 1, 4, 10, 5 },\n            { 10, 2, 8, 4, 7, 6, 1, 5, 15, 11, 9, 14, 3, 12, 13, 0 }, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 },\n            { 14, 10, 4, 8, 9, 15, 13, 6, 1, 12, 0, 2, 11, 7, 5, 3 } };\n\n    private static final int ROUNDS = 12;\n\n    private static final int BLOCK_LENGTH_BYTES = 128;\n\n    private final int digestLength;\n\n    private final int keyLength;\n\n    private final byte[] buffer;\n\n    private final long[] internalState = new long[16];\n\n    private int bufferPos = 0;\n\n    private long[] chainValue = null;\n\n    private long t0 = 0L;\n\n    private long t1 = 0L;\n\n    private long f0 = 0L;\n\n    /**\n     * Basic sized constructor - size in bytes.\n     *\n     * @param digestSize size of the digest in bytes\n     */\n    Blake2b(int digestSize)\n    {\n        if (digestSize < 1 || digestSize > 64)\n        {\n            throw new BadParametersException(\"BLAKE2b digest bytes length must be not greater than 64\");\n        }\n\n        buffer = new byte[BLOCK_LENGTH_BYTES];\n        keyLength = 0;\n        this.digestLength = digestSize;\n        init();\n    }\n\n    // initialize chainValue\n    private void init()\n    {\n        chainValue = new long[8];\n        chainValue[0] = IV[0] ^ (digestLength | ((long) keyLength << 8) | 0x1010000);\n        chainValue[1] = IV[1];\n        chainValue[2] = IV[2];\n        chainValue[3] = IV[3];\n        chainValue[4] = IV[4];\n        chainValue[5] = IV[5];\n        chainValue[6] = IV[6];\n        chainValue[7] = IV[7];\n    }\n\n    private void initializeInternalState()\n    {\n        System.arraycopy(chainValue, 0, internalState, 0, chainValue.length);\n        System.arraycopy(IV, 0, internalState, chainValue.length, 4);\n        internalState[12] = t0 ^ IV[4];\n        internalState[13] = t1 ^ IV[5];\n        internalState[14] = f0 ^ IV[6];\n        internalState[15] = IV[7];// ^ f1 with f1 = 0\n    }\n\n    void update(byte[] message)\n    {\n        if (message == null)\n        {\n            return;\n        }\n        update(message, 0, message.length);\n    }\n\n    /**\n     * update the message digest with a block of bytes.\n     *\n     * @param message the byte array containing the data.\n     * @param offset  the offset into the byte array where the data starts.\n     * @param len     the length of the data.\n     */\n    void update(byte[] message, int offset, int len)\n    {\n        int remainingLength = 0;\n\n        if (bufferPos != 0)\n        {\n            remainingLength = BLOCK_LENGTH_BYTES - bufferPos;\n            if (remainingLength < len)\n            {\n                System.arraycopy(message, offset, buffer, bufferPos, remainingLength);\n                t0 += BLOCK_LENGTH_BYTES;\n                if (t0 == 0)\n                {\n                    t1++;\n                }\n                compress(buffer, 0);\n                bufferPos = 0;\n                Arrays.fill(buffer, (byte) 0);// clear buffer\n            }\n            else\n            {\n                System.arraycopy(message, offset, buffer, bufferPos, len);\n                bufferPos += len;\n                return;\n            }\n        }\n\n        int messagePos;\n        int blockWiseLastPos = offset + len - BLOCK_LENGTH_BYTES;\n        for (messagePos = offset + remainingLength; messagePos < blockWiseLastPos; messagePos += BLOCK_LENGTH_BYTES)\n        {\n            t0 += BLOCK_LENGTH_BYTES;\n            if (t0 == 0)\n            {\n                t1++;\n            }\n            compress(message, messagePos);\n        }\n\n        // fill the buffer with left bytes, this might be a full block\n        System.arraycopy(message, messagePos, buffer, 0, offset + len - messagePos);\n        bufferPos += offset + len - messagePos;\n    }\n\n    /**\n     * close the digest, producing the final digest value. The doFinal\n     * call leaves the digest reset.\n     * Key, salt and personal string remain.\n     *\n     * @param out       the array the digest is to be copied into.\n     * @param outOffset the offset into the out array the digest is to start at.\n     */\n    void doFinal(byte[] out, int outOffset)\n    {\n\n        f0 = 0xFFFFFFFFFFFFFFFFL;\n        t0 += bufferPos;\n        if (bufferPos > 0 && t0 == 0)\n        {\n            t1++;\n        }\n        compress(buffer, 0);\n        Arrays.fill(buffer, (byte) 0);// Holds eventually the key if input is null\n        Arrays.fill(internalState, 0L);\n\n        for (int i = 0; i < chainValue.length && (i * 8 < digestLength); i++)\n        {\n            byte[] bytes = Utils.longToLittleEndian(chainValue[i]);\n\n            if (i * 8 < digestLength - 8)\n            {\n                System.arraycopy(bytes, 0, out, outOffset + i * 8, 8);\n            }\n            else\n            {\n                System.arraycopy(bytes, 0, out, outOffset + i * 8, digestLength - (i * 8));\n            }\n        }\n\n        Arrays.fill(chainValue, 0L);\n\n        reset();\n    }\n\n    /**\n     * Reset the digest back to it's initial state.\n     * The key, the salt and the personal string will\n     * remain for further computations.\n     */\n    void reset()\n    {\n        bufferPos = 0;\n        f0 = 0L;\n        t0 = 0L;\n        t1 = 0L;\n        chainValue = null;\n        Arrays.fill(buffer, (byte) 0);\n        init();\n    }\n\n    private void compress(byte[] message, int messagePos)\n    {\n\n        initializeInternalState();\n\n        long[] m = new long[16];\n        for (int j = 0; j < 16; j++)\n        {\n            m[j] = Utils.littleEndianToLong(message, messagePos + j * 8);\n        }\n\n        for (int round = 0; round < ROUNDS; round++)\n        {\n\n            // G apply to columns of internalState:m[blake2b_sigma[round][2 *\n            // blockPos]] /+1\n            functionG(m[SIGMA[round][0]], m[SIGMA[round][1]], 0, 4, 8, 12);\n            functionG(m[SIGMA[round][2]], m[SIGMA[round][3]], 1, 5, 9, 13);\n            functionG(m[SIGMA[round][4]], m[SIGMA[round][5]], 2, 6, 10, 14);\n            functionG(m[SIGMA[round][6]], m[SIGMA[round][7]], 3, 7, 11, 15);\n            // G apply to diagonals of internalState:\n            functionG(m[SIGMA[round][8]], m[SIGMA[round][9]], 0, 5, 10, 15);\n            functionG(m[SIGMA[round][10]], m[SIGMA[round][11]], 1, 6, 11, 12);\n            functionG(m[SIGMA[round][12]], m[SIGMA[round][13]], 2, 7, 8, 13);\n            functionG(m[SIGMA[round][14]], m[SIGMA[round][15]], 3, 4, 9, 14);\n        }\n\n        // update chain values:\n        for (int offset = 0; offset < chainValue.length; offset++)\n        {\n            chainValue[offset] = chainValue[offset] ^ internalState[offset] ^ internalState[offset + 8];\n        }\n    }\n\n    private void functionG(long m1, long m2, int posA, int posB, int posC, int posD)\n    {\n\n        internalState[posA] = internalState[posA] + internalState[posB] + m1;\n        internalState[posD] = Long.rotateRight(internalState[posD] ^ internalState[posA], 32);\n        internalState[posC] = internalState[posC] + internalState[posD];\n        internalState[posB] = Long.rotateRight(internalState[posB] ^ internalState[posC], 24); // replaces 25 of BLAKE\n        internalState[posA] = internalState[posA] + internalState[posB] + m2;\n        internalState[posD] = Long.rotateRight(internalState[posD] ^ internalState[posA], 16);\n        internalState[posC] = internalState[posC] + internalState[posD];\n        internalState[posB] = Long.rotateRight(internalState[posB] ^ internalState[posC], 63); // replaces 11 of BLAKE\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_44_chunk_0",
        "original_index": 0,
        "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j;\n\nimport java.util.Arrays;\n\n\nclass Blake2b\n{\n    private static final long[] IV = { 0x6a09e667f3bcc908L, 0xbb67ae8584caa73bL, 0x3c6ef372fe94f82bL, 0xa54ff53a5f1d36f1L,\n            0x510e527fade682d1L, 0x9b05688c2b3e6c1fL, 0x1f83d9abfb41bd6bL, 0x5be0cd19137e2179L };\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_1",
        "original_index": 1,
        "content": "    private static final byte[][] SIGMA = { { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 },\n            { 14, 10, 4, 8, 9, 15, 13, 6, 1, 12, 0, 2, 11, 7, 5, 3 }, { 11, 8, 12, 0, 5, 2, 15, 13, 10, 14, 3, 6, 7, 1, 9, 4 },\n            { 7, 9, 3, 1, 13, 12, 11, 14, 2, 6, 5, 10, 4, 0, 15, 8 }, { 9, 0, 5, 7, 2, 4, 10, 15, 14, 1, 11, 12, 6, 8, 3, 13 },\n            { 2, 12, 6, 10, 0, 11, 8, 3, 4, 13, 7, 5, 15, 14, 1, 9 }, { 12, 5, 1, 15, 14, 13, 4, 10, 0, 7, 6, 3, 9, 2, 8, 11 },\n            { 13, 11, 7, 14, 12, 1, 3, 9, 5, 0, 15, 4, 8, 6, 2, 10 }, { 6, 15, 14, 9, 11, 3, 0, 8, 12, 2, 13, 7, 1, 4, 10, 5 },\n            { 10, 2, 8, 4, 7, 6, 1, 5, 15, 11, 9, 14, 3, 12, 13, 0 }, { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 },\n            { 14, 10, 4, 8, 9, 15, 13, 6, 1, 12, 0, 2, 11, 7, 5, 3 } };\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_2",
        "original_index": 2,
        "content": "    private static final int ROUNDS = 12;\n\n    private static final int BLOCK_LENGTH_BYTES = 128;\n\n    private final int digestLength;\n\n    private final int keyLength;\n\n    private final byte[] buffer;\n\n    private final long[] internalState = new long[16];\n\n    private int bufferPos = 0;\n\n    private long[] chainValue = null;\n\n    private long t0 = 0L;\n\n    private long t1 = 0L;\n\n    private long f0 = 0L;\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_3",
        "original_index": 3,
        "content": "    /**\n     * Basic sized constructor - size in bytes.\n     *\n     * @param digestSize size of the digest in bytes\n     */\n    Blake2b(int digestSize)\n    {\n        if (digestSize < 1 || digestSize > 64)\n        {\n            throw new BadParametersException(\"BLAKE2b digest bytes length must be not greater than 64\");\n        }\n\n        buffer = new byte[BLOCK_LENGTH_BYTES];\n        keyLength = 0;\n        this.digestLength = digestSize;\n        init();\n    }\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_4",
        "original_index": 4,
        "content": "    // initialize chainValue\n    private void init()\n    {\n        chainValue = new long[8];\n        chainValue[0] = IV[0] ^ (digestLength | ((long) keyLength << 8) | 0x1010000);\n        chainValue[1] = IV[1];\n        chainValue[2] = IV[2];\n        chainValue[3] = IV[3];\n        chainValue[4] = IV[4];\n        chainValue[5] = IV[5];\n        chainValue[6] = IV[6];\n        chainValue[7] = IV[7];\n    }\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_5",
        "original_index": 5,
        "content": "    private void initializeInternalState()\n    {\n        System.arraycopy(chainValue, 0, internalState, 0, chainValue.length);\n        System.arraycopy(IV, 0, internalState, chainValue.length, 4);\n        internalState[12] = t0 ^ IV[4];\n        internalState[13] = t1 ^ IV[5];\n        internalState[14] = f0 ^ IV[6];\n        internalState[15] = IV[7];// ^ f1 with f1 = 0\n    }\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_6",
        "original_index": 6,
        "content": "    void update(byte[] message)\n    {\n        if (message == null)\n        {\n            return;\n        }\n        update(message, 0, message.length);\n    }\n\n    /**\n     * update the message digest with a block of bytes.\n     *\n     * @param message the byte array containing the data.\n     * @param offset  the offset into the byte array where the data starts.\n     * @param len     the length of the data.\n     */\n    void update(byte[] message, int offset, int len)\n    {\n        int remainingLength = 0;\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_7",
        "original_index": 7,
        "content": "        if (bufferPos != 0)\n        {\n            remainingLength = BLOCK_LENGTH_BYTES - bufferPos;\n            if (remainingLength < len)\n            {\n                System.arraycopy(message, offset, buffer, bufferPos, remainingLength);\n                t0 += BLOCK_LENGTH_BYTES;\n                if (t0 == 0)\n                {\n                    t1++;\n                }\n                compress(buffer, 0);\n                bufferPos = 0;\n                Arrays.fill(buffer, (byte) 0);// clear buffer\n            }\n            else\n            {\n                System.arraycopy(message, offset, buffer, bufferPos, len);\n                bufferPos += len;\n                return;\n            }\n        }\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_8",
        "original_index": 8,
        "content": "        int messagePos;\n        int blockWiseLastPos = offset + len - BLOCK_LENGTH_BYTES;\n        for (messagePos = offset + remainingLength; messagePos < blockWiseLastPos; messagePos += BLOCK_LENGTH_BYTES)\n        {\n            t0 += BLOCK_LENGTH_BYTES;\n            if (t0 == 0)\n            {\n                t1++;\n            }\n            compress(message, messagePos);\n        }\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_9",
        "original_index": 9,
        "content": "        // fill the buffer with left bytes, this might be a full block\n        System.arraycopy(message, messagePos, buffer, 0, offset + len - messagePos);\n        bufferPos += offset + len - messagePos;\n    }\n\n    /**\n     * close the digest, producing the final digest value. The doFinal\n     * call leaves the digest reset.\n     * Key, salt and personal string remain.\n     *\n     * @param out       the array the digest is to be copied into.\n     * @param outOffset the offset into the out array the digest is to start at.\n     */\n    void doFinal(byte[] out, int outOffset)\n    {\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_10",
        "original_index": 10,
        "content": "        f0 = 0xFFFFFFFFFFFFFFFFL;\n        t0 += bufferPos;\n        if (bufferPos > 0 && t0 == 0)\n        {\n            t1++;\n        }\n        compress(buffer, 0);\n        Arrays.fill(buffer, (byte) 0);// Holds eventually the key if input is null\n        Arrays.fill(internalState, 0L);\n\n        for (int i = 0; i < chainValue.length && (i * 8 < digestLength); i++)\n        {\n            byte[] bytes = Utils.longToLittleEndian(chainValue[i]);\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_11",
        "original_index": 11,
        "content": "            if (i * 8 < digestLength - 8)\n            {\n                System.arraycopy(bytes, 0, out, outOffset + i * 8, 8);\n            }\n            else\n            {\n                System.arraycopy(bytes, 0, out, outOffset + i * 8, digestLength - (i * 8));\n            }\n        }\n\n        Arrays.fill(chainValue, 0L);\n\n        reset();\n    }\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_12",
        "original_index": 12,
        "content": "    /**\n     * Reset the digest back to it's initial state.\n     * The key, the salt and the personal string will\n     * remain for further computations.\n     */\n    void reset()\n    {\n        bufferPos = 0;\n        f0 = 0L;\n        t0 = 0L;\n        t1 = 0L;\n        chainValue = null;\n        Arrays.fill(buffer, (byte) 0);\n        init();\n    }\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_13",
        "original_index": 13,
        "content": "    private void compress(byte[] message, int messagePos)\n    {\n\n        initializeInternalState();\n\n        long[] m = new long[16];\n        for (int j = 0; j < 16; j++)\n        {\n            m[j] = Utils.littleEndianToLong(message, messagePos + j * 8);\n        }\n\n        for (int round = 0; round < ROUNDS; round++)\n        {\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_14",
        "original_index": 14,
        "content": "            // G apply to columns of internalState:m[blake2b_sigma[round][2 *\n            // blockPos]] /+1\n            functionG(m[SIGMA[round][0]], m[SIGMA[round][1]], 0, 4, 8, 12);\n            functionG(m[SIGMA[round][2]], m[SIGMA[round][3]], 1, 5, 9, 13);\n            functionG(m[SIGMA[round][4]], m[SIGMA[round][5]], 2, 6, 10, 14);\n            functionG(m[SIGMA[round][6]], m[SIGMA[round][7]], 3, 7, 11, 15);\n            // G apply to diagonals of internalState:\n            functionG(m[SIGMA[round][8]], m[SIGMA[round][9]], 0, 5, 10, 15);\n            functionG(m[SIGMA[round][10]], m[SIGMA[round][11]], 1, 6, 11, 12);\n            functionG(m[SIGMA[round][12]], m[SIGMA[round][13]], 2, 7, 8, 13);\n            functionG(m[SIGMA[round][14]], m[SIGMA[round][15]], 3, 4, 9, 14);\n        }\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_15",
        "original_index": 15,
        "content": "        // update chain values:\n        for (int offset = 0; offset < chainValue.length; offset++)\n        {\n            chainValue[offset] = chainValue[offset] ^ internalState[offset] ^ internalState[offset + 8];\n        }\n    }\n\n    private void functionG(long m1, long m2, int posA, int posB, int posC, int posD)\n    {\n\n"
      },
      {
        "chunk_id": "doc_44_chunk_16",
        "original_index": 16,
        "content": "        internalState[posA] = internalState[posA] + internalState[posB] + m1;\n        internalState[posD] = Long.rotateRight(internalState[posD] ^ internalState[posA], 32);\n        internalState[posC] = internalState[posC] + internalState[posD];\n        internalState[posB] = Long.rotateRight(internalState[posB] ^ internalState[posC], 24); // replaces 25 of BLAKE\n        internalState[posA] = internalState[posA] + internalState[posB] + m2;\n        internalState[posD] = Long.rotateRight(internalState[posD] ^ internalState[posA], 16);\n        internalState[posC] = internalState[posC] + internalState[posD];\n        internalState[posB] = Long.rotateRight(internalState[posB] ^ internalState[posC], 63); // replaces 11 of BLAKE\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_45",
    "original_uuid": "2c96230c24dfd108a09abadeb43abd5f3220c4890e6e1bef947ab5dbb7628757",
    "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j;\n\n/**\n * This exception is normally thrown when a not well formed parameter\n * is passed as argument to a function.\n * <p>\n * This exception covers all the exceptions raised by underlying logic,\n * grouping them as one exception.\n *\n * @author David Bertoldi\n * @since 0.1.0\n */\npublic class BadParametersException extends IllegalArgumentException\n{\n\n    private static final long serialVersionUID = 9204720180786210237L;\n\n    /**\n     * Constructs the exception.\n     *\n     * @param message the message describing the cause of the exception\n     * @since 0.1.0\n     */\n    public BadParametersException(String message)\n    {\n        super(message);\n    }\n\n    /**\n     * Constructs the exception.\n     *\n     * @param message   the message describing the cause of the exception\n     * @param exception the exception masked by this object\n     * @since 0.1.0\n     */\n    public BadParametersException(String message, Throwable exception)\n    {\n        super(message, exception);\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_45_chunk_0",
        "original_index": 0,
        "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j;\n\n"
      },
      {
        "chunk_id": "doc_45_chunk_1",
        "original_index": 1,
        "content": "/**\n * This exception is normally thrown when a not well formed parameter\n * is passed as argument to a function.\n * <p>\n * This exception covers all the exceptions raised by underlying logic,\n * grouping them as one exception.\n *\n * @author David Bertoldi\n * @since 0.1.0\n */\npublic class BadParametersException extends IllegalArgumentException\n{\n\n    private static final long serialVersionUID = 9204720180786210237L;\n\n    /**\n     * Constructs the exception.\n     *\n     * @param message the message describing the cause of the exception\n     * @since 0.1.0\n     */\n    public BadParametersException(String message)\n    {\n        super(message);\n    }\n\n    /**\n     * Constructs the exception.\n     *\n     * @param message   the message describing the cause of the exception\n     * @param exception the exception masked by this object\n     * @since 0.1.0\n     */\n    public BadParametersException(String message, Throwable exception)\n    {\n        super(message, exception);\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_46",
    "original_uuid": "bf58cf0c65c709224da0f68ad6bd4fed3df1afcf9677f840b923e95af7377a0b",
    "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j;\n\nimport java.util.Arrays;\nimport java.util.Objects;\n\n\n/**\n * This class contains all the information computed after\n * calculating a cryptographic hash.\n * <p>\n * The same {@link HashingFunction} used to generate the hash\n * is used to verify the plain password; in addition <i>cryptographic\n * seasoning</i> such as salt and pepper are stored in this object.\n * <p>\n * A hash is the product of a one-way function that maps data of arbitrary size to\n * fixed-size values; it is called hashing function (HF).\n * This class represent hashes generated by cryptographic hash function (CHF),\n * where each function has the following properties:\n * <ul>\n * <li>it is deterministic, meaning that the same message always results in the same hash</li>\n * <li>it is quick to compute the hash value for any given message</li>\n * <li>it is infeasible to generate a message that yields a given hash value</li>\n * <li>it is infeasible to find two different messages with the same hash value</li>\n * <li>a small change to a message should change the hash value so extensively that the new hash value\n * appears uncorrelated with the old hash value</li>\n * </ul>\n * <p>\n * A salt is a unique, randomly generated string that is added to each password as part of the hashing process.\n * As the salt is unique for every user, an attacker has to crack hashes one at a time using the respective salt,\n * rather than being able to calculate a hash once and compare it against every stored hash.\n * <p>\n * A pepper can be used in additional to salting to provide an additional layer of protection.\n * It is similar to a salt, but has two key differences:\n * <ul>\n * <li>The pepper is shared between all stored passwords, rather than being unique like a salt.</li>\n * <li>The pepper is not stored in the database, unlike the salts.</li>\n * </ul>\n *\n * @author David Bertoldi\n * @see <a href=\"https://owasp.org/www-project-cheat-sheets/cheatsheets/Password_Storage_Cheat_Sheet\">OWASP Password Storage Cheat Sheet</a>\n * @see <a href=\"https://en.wikipedia.org/wiki/Key_derivation_function\">Key derivation function</a>\n * @see <a href=\"https://en.wikipedia.org/wiki/Cryptographic_hash_function\">Cryptographic hash function</a>\n * @since 0.1.0\n */\npublic class Hash\n{\n\n    /**\n     * Represents the full output of a cryptographic hashing function.\n     * Depending on the implementation of the CHF, it may contain\n     * the salt and the configuration of the CHF itself.\n     */\n    private byte[] result;\n\n    /**\n     * Represents the computed output of a cryptographic hashing function.\n     * It never contains salt and other configurations.\n     */\n    private byte[] bytes;\n\n    /**\n     * Represents the salt: random data that is used as an additional input\n     * to a cryptographic hashing function.\n     */\n    private byte[] salt;\n\n    /**\n     * Represents the pepper: a secret added to the input password\n     * prior to being hashed with a cryptographic hash function\n     */\n    private CharSequence pepper;\n\n    /**\n     * Represents the hashing function used to generate this object.\n     *\n     * @see HashingFunction for more details\n     */\n    private HashingFunction hashingFunction;\n\n    /**\n     * It is meant to not be used if not internally.\n     * The other constructor must be used instead.\n     *\n     * @see Hash#Hash(HashingFunction, String, byte[], String)\n     * @since 0.1.0\n     */\n    @SuppressWarnings(\"unused\")\n    private Hash()\n    {\n        //\n    }\n\n    /**\n     * Constructs an {@link Hash} containing the basic information\n     * used and produced by the computational process of hashing a password.\n     * Other information, like <i>pepper</i> can be added with\n     * {@link #setPepper(CharSequence)}.\n     * <p>\n     * This constructor populates the object's attributes.\n     *\n     * @param hashingFunction the cryptographic algorithm used to produce the hash.\n     * @param result          the result of the computation of the hash.\n     *                        Notice that the format varies depending on the algorithm.\n     * @param bytes           the hash without additional information.\n     * @param salt            the salt used for the computation.\n     * @since 0.1.0\n     * @deprecated            As of 1.8.1 because of the salt conversion from {@link String} to byte[].\n     *                        {@link Hash#Hash(HashingFunction, String, byte[], byte[])} should be used instead.\n     */\n    @Deprecated\n    public Hash(HashingFunction hashingFunction, String result, byte[] bytes, String salt)\n    {\n        this(hashingFunction, Utils.fromCharSequenceToBytes(result), bytes, Utils.fromCharSequenceToBytes(salt));\n    }\n\n\n\n    /**\n     * Constructs an {@link Hash} containing the basic information\n     * used and produced by the computational process of hashing a password.\n     * Other information, like <i>pepper</i> can be added with\n     * {@link #setPepper(CharSequence)}.\n     * <p>\n     * This constructor populates the object's attributes.\n     *\n     * @param hashingFunction the cryptographic algorithm used to produce the hash.\n     * @param result          the result of the computation of the hash.\n     *                        Notice that the format varies depending on the algorithm.\n     * @param bytes           the hash without additional information.\n     * @param salt            the salt used for the computation.\n     * @since 0.1.0\n     */\n    public Hash(HashingFunction hashingFunction, String result, byte[] bytes, byte[] salt)\n    {\n        this(hashingFunction, Utils.fromCharSequenceToBytes(result), bytes, salt);\n    }\n\n    /**\n     * Constructs an {@link Hash} containing the basic information\n     * used and produced by the computational process of hashing a password.\n     * Other information, like <i>pepper</i> can be added with\n     * {@link #setPepper(CharSequence)}.\n     * <p>\n     * This constructor populates the object's attributes.\n     *\n     * @param hashingFunction the cryptographic algorithm used to produce the hash.\n     * @param result          the result of the computation of the hash as bytes array.\n     *                        Notice that the format varies depending on the algorithm.\n     * @param bytes           the hash without additional information.\n     * @param salt            the salt used for the computation as bytes array.\n     * @since 1.7.0\n     */\n    public Hash(HashingFunction hashingFunction, byte[] result, byte[] bytes, byte[] salt)\n    {\n        this.hashingFunction = hashingFunction;\n        this.salt = salt;\n        this.result = result;\n        this.bytes = bytes;\n    }\n\n    /**\n     * Retrieves the hash computed by the hashing function.\n     *\n     * @return the hash.\n     * @since 0.1.0\n     */\n    public String getResult()\n    {\n        return Utils.fromBytesToString(result);\n    }\n\n    /**\n     * Retrieves the hash computed by the hashing function.\n     *\n     * @return the hash.\n     * @since 0.1.0\n     */\n    public byte[] getResultAsBytes()\n    {\n        return result;\n    }\n\n    /**\n     * Retrieves the hash as byte array and without the parameters\n     * encoded in the final hash.\n     *\n     * @return the hash.\n     * @since 1.5.1\n     */\n    public byte[] getBytes()\n    {\n        return bytes;\n    }\n\n    /**\n     * Retrieves the {@link HashingFunction} used\n     * to hash the password.\n     *\n     * @return the CHF\n     * @since 0.4.0\n     */\n    public HashingFunction getHashingFunction()\n    {\n        return hashingFunction;\n    }\n\n    /**\n     * Retrieves the salt used by the hashing function.\n     *\n     * @return the salt as {@link String}.\n     * @since 0.1.0\n     */\n    public String getSalt()\n    {\n        return Utils.fromBytesToString(salt);\n    }\n\n    /**\n     * Retrieves the salt used by the hashing function.\n     *\n     * @return the salt as bytes array.\n     * @since 1.7.0\n     */\n    public byte[] getSaltBytes()\n    {\n        return salt;\n    }\n\n    /**\n     * Retrieves the pepper used with the password in the hashing function.\n     *\n     * @return the pepper.\n     * @since 0.1.0\n     */\n    public CharSequence getPepper()\n    {\n        return pepper;\n    }\n\n    /**\n     * Stores the pepper used together with the password in the hashing function.\n     * <p>\n     * This methods should be used just after the creation of this object.\n     *\n     * @param pepper the pepper used.\n     * @since 0.1.0\n     */\n    void setPepper(CharSequence pepper)\n    {\n        this.pepper = pepper;\n    }\n\n    /**\n     * Produces a human-readable description of the {@link Hash}.\n     *\n     * @return a readable version of this object\n     * @since 0.1.0\n     */\n    @Override\n    public String toString()\n    {\n        StringBuilder sb = new StringBuilder();\n        if (this.hashingFunction != null)\n        {\n            sb.append(hashingFunction.getClass().getSimpleName());\n        }\n        sb.append(\"[salt=\").append(getSalt()).append(\", pepper=\").append(getPepper()).append(\", hash=\").append(getResult())\n                .append(\"]\");\n        return sb.toString();\n    }\n\n    /**\n     * Two {@link Hash}es are considered equals if they contain\n     * the same hash, salt, pepper and they are generated with\n     * the same {@link HashingFunction}\n     *\n     * @param obj the object to compare\n     * @return true if equals\n     * @since 0.1.0\n     */\n    @Override\n    public boolean equals(Object obj)\n    {\n        if (obj == null || !this.getClass().equals(obj.getClass()))\n        {\n            return false;\n        }\n\n        Hash otherHash = (Hash) obj;\n        return hasSameValues(otherHash);\n    }\n\n    private boolean hasSameValues(Hash otherHash)\n    {\n        return Arrays.equals(this.result, otherHash.result) //\n                && Arrays.equals(this.bytes, otherHash.bytes) //\n                && Arrays.equals(this.salt, otherHash.salt) //\n                && areEquals(this.pepper, otherHash.pepper) //\n                && this.hashingFunction.equals(otherHash.hashingFunction);\n    }\n\n    private static boolean areEquals(CharSequence cs1, CharSequence cs2)\n    {\n        if (cs1 == cs2)\n        {\n            return true;\n        }\n        else if (cs1 != null && cs2 != null)\n        {\n            return cs1.equals(cs2);\n        }\n        return false;\n    }\n\n    @Override\n    public int hashCode()\n    {\n        return Objects.hash(Arrays.hashCode(result), Arrays.hashCode(salt), pepper, hashingFunction);\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_46_chunk_0",
        "original_index": 0,
        "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j;\n\nimport java.util.Arrays;\nimport java.util.Objects;\n\n"
      },
      {
        "chunk_id": "doc_46_chunk_1",
        "original_index": 1,
        "content": "\n/**\n * This class contains all the information computed after\n * calculating a cryptographic hash.\n * <p>\n * The same {@link HashingFunction} used to generate the hash\n * is used to verify the plain password; in addition <i>cryptographic\n * seasoning</i> such as salt and pepper are stored in this object.\n * <p>\n * A hash is the product of a one-way function that maps data of arbitrary size to\n * fixed-size values; it is called hashing function (HF).\n * This class represent hashes generated by cryptographic hash function (CHF),\n * where each function has the following properties:\n * <ul>\n * <li>it is deterministic, meaning that the same message always results in the same hash</li>\n * <li>it is quick to compute the hash value for any given message</li>\n * <li>it is infeasible to generate a message that yields a given hash value</li>\n * <li>it is infeasible to find two different messages with the same hash value</li>\n"
      },
      {
        "chunk_id": "doc_46_chunk_2",
        "original_index": 2,
        "content": " * <li>a small change to a message should change the hash value so extensively that the new hash value\n * appears uncorrelated with the old hash value</li>\n * </ul>\n * <p>\n * A salt is a unique, randomly generated string that is added to each password as part of the hashing process.\n * As the salt is unique for every user, an attacker has to crack hashes one at a time using the respective salt,\n * rather than being able to calculate a hash once and compare it against every stored hash.\n * <p>\n"
      },
      {
        "chunk_id": "doc_46_chunk_3",
        "original_index": 3,
        "content": " * A pepper can be used in additional to salting to provide an additional layer of protection.\n * It is similar to a salt, but has two key differences:\n * <ul>\n * <li>The pepper is shared between all stored passwords, rather than being unique like a salt.</li>\n * <li>The pepper is not stored in the database, unlike the salts.</li>\n * </ul>\n *\n * @author David Bertoldi\n * @see <a href=\"https://owasp.org/www-project-cheat-sheets/cheatsheets/Password_Storage_Cheat_Sheet\">OWASP Password Storage Cheat Sheet</a>\n * @see <a href=\"https://en.wikipedia.org/wiki/Key_derivation_function\">Key derivation function</a>\n * @see <a href=\"https://en.wikipedia.org/wiki/Cryptographic_hash_function\">Cryptographic hash function</a>\n * @since 0.1.0\n */\npublic class Hash\n{\n\n"
      },
      {
        "chunk_id": "doc_46_chunk_4",
        "original_index": 4,
        "content": "    /**\n     * Represents the full output of a cryptographic hashing function.\n     * Depending on the implementation of the CHF, it may contain\n     * the salt and the configuration of the CHF itself.\n     */\n    private byte[] result;\n\n    /**\n     * Represents the computed output of a cryptographic hashing function.\n     * It never contains salt and other configurations.\n     */\n    private byte[] bytes;\n\n    /**\n     * Represents the salt: random data that is used as an additional input\n     * to a cryptographic hashing function.\n     */\n    private byte[] salt;\n\n"
      },
      {
        "chunk_id": "doc_46_chunk_5",
        "original_index": 5,
        "content": "    /**\n     * Represents the pepper: a secret added to the input password\n     * prior to being hashed with a cryptographic hash function\n     */\n    private CharSequence pepper;\n\n    /**\n     * Represents the hashing function used to generate this object.\n     *\n     * @see HashingFunction for more details\n     */\n    private HashingFunction hashingFunction;\n\n    /**\n     * It is meant to not be used if not internally.\n     * The other constructor must be used instead.\n     *\n     * @see Hash#Hash(HashingFunction, String, byte[], String)\n     * @since 0.1.0\n     */\n    @SuppressWarnings(\"unused\")\n    private Hash()\n    {\n        //\n    }\n\n"
      },
      {
        "chunk_id": "doc_46_chunk_6",
        "original_index": 6,
        "content": "    /**\n     * Constructs an {@link Hash} containing the basic information\n     * used and produced by the computational process of hashing a password.\n     * Other information, like <i>pepper</i> can be added with\n     * {@link #setPepper(CharSequence)}.\n     * <p>\n     * This constructor populates the object's attributes.\n     *\n     * @param hashingFunction the cryptographic algorithm used to produce the hash.\n     * @param result          the result of the computation of the hash.\n     *                        Notice that the format varies depending on the algorithm.\n     * @param bytes           the hash without additional information.\n     * @param salt            the salt used for the computation.\n     * @since 0.1.0\n"
      },
      {
        "chunk_id": "doc_46_chunk_7",
        "original_index": 7,
        "content": "     * @deprecated            As of 1.8.1 because of the salt conversion from {@link String} to byte[].\n     *                        {@link Hash#Hash(HashingFunction, String, byte[], byte[])} should be used instead.\n     */\n    @Deprecated\n    public Hash(HashingFunction hashingFunction, String result, byte[] bytes, String salt)\n    {\n        this(hashingFunction, Utils.fromCharSequenceToBytes(result), bytes, Utils.fromCharSequenceToBytes(salt));\n    }\n\n\n\n"
      },
      {
        "chunk_id": "doc_46_chunk_8",
        "original_index": 8,
        "content": "    /**\n     * Constructs an {@link Hash} containing the basic information\n     * used and produced by the computational process of hashing a password.\n     * Other information, like <i>pepper</i> can be added with\n     * {@link #setPepper(CharSequence)}.\n     * <p>\n     * This constructor populates the object's attributes.\n     *\n     * @param hashingFunction the cryptographic algorithm used to produce the hash.\n     * @param result          the result of the computation of the hash.\n     *                        Notice that the format varies depending on the algorithm.\n     * @param bytes           the hash without additional information.\n     * @param salt            the salt used for the computation.\n     * @since 0.1.0\n     */\n    public Hash(HashingFunction hashingFunction, String result, byte[] bytes, byte[] salt)\n    {\n        this(hashingFunction, Utils.fromCharSequenceToBytes(result), bytes, salt);\n    }\n\n"
      },
      {
        "chunk_id": "doc_46_chunk_9",
        "original_index": 9,
        "content": "    /**\n     * Constructs an {@link Hash} containing the basic information\n     * used and produced by the computational process of hashing a password.\n     * Other information, like <i>pepper</i> can be added with\n     * {@link #setPepper(CharSequence)}.\n     * <p>\n     * This constructor populates the object's attributes.\n     *\n     * @param hashingFunction the cryptographic algorithm used to produce the hash.\n     * @param result          the result of the computation of the hash as bytes array.\n     *                        Notice that the format varies depending on the algorithm.\n     * @param bytes           the hash without additional information.\n"
      },
      {
        "chunk_id": "doc_46_chunk_10",
        "original_index": 10,
        "content": "     * @param salt            the salt used for the computation as bytes array.\n     * @since 1.7.0\n     */\n    public Hash(HashingFunction hashingFunction, byte[] result, byte[] bytes, byte[] salt)\n    {\n        this.hashingFunction = hashingFunction;\n        this.salt = salt;\n        this.result = result;\n        this.bytes = bytes;\n    }\n\n    /**\n     * Retrieves the hash computed by the hashing function.\n     *\n     * @return the hash.\n     * @since 0.1.0\n     */\n    public String getResult()\n    {\n        return Utils.fromBytesToString(result);\n    }\n\n    /**\n     * Retrieves the hash computed by the hashing function.\n     *\n     * @return the hash.\n     * @since 0.1.0\n     */\n    public byte[] getResultAsBytes()\n    {\n        return result;\n    }\n\n    /**\n     * Retrieves the hash as byte array and without the parameters\n     * encoded in the final hash.\n     *\n     * @return the hash.\n     * @since 1.5.1\n     */\n    public byte[] getBytes()\n    {\n        return bytes;\n    }\n\n"
      },
      {
        "chunk_id": "doc_46_chunk_11",
        "original_index": 11,
        "content": "    /**\n     * Retrieves the {@link HashingFunction} used\n     * to hash the password.\n     *\n     * @return the CHF\n     * @since 0.4.0\n     */\n    public HashingFunction getHashingFunction()\n    {\n        return hashingFunction;\n    }\n\n    /**\n     * Retrieves the salt used by the hashing function.\n     *\n     * @return the salt as {@link String}.\n     * @since 0.1.0\n     */\n    public String getSalt()\n    {\n        return Utils.fromBytesToString(salt);\n    }\n\n"
      },
      {
        "chunk_id": "doc_46_chunk_12",
        "original_index": 12,
        "content": "    /**\n     * Retrieves the salt used by the hashing function.\n     *\n     * @return the salt as bytes array.\n     * @since 1.7.0\n     */\n    public byte[] getSaltBytes()\n    {\n        return salt;\n    }\n\n    /**\n     * Retrieves the pepper used with the password in the hashing function.\n     *\n     * @return the pepper.\n     * @since 0.1.0\n     */\n    public CharSequence getPepper()\n    {\n        return pepper;\n    }\n\n    /**\n     * Stores the pepper used together with the password in the hashing function.\n     * <p>\n     * This methods should be used just after the creation of this object.\n     *\n     * @param pepper the pepper used.\n     * @since 0.1.0\n     */\n    void setPepper(CharSequence pepper)\n    {\n        this.pepper = pepper;\n    }\n\n"
      },
      {
        "chunk_id": "doc_46_chunk_13",
        "original_index": 13,
        "content": "    /**\n     * Produces a human-readable description of the {@link Hash}.\n     *\n     * @return a readable version of this object\n     * @since 0.1.0\n     */\n    @Override\n    public String toString()\n    {\n        StringBuilder sb = new StringBuilder();\n        if (this.hashingFunction != null)\n        {\n            sb.append(hashingFunction.getClass().getSimpleName());\n        }\n        sb.append(\"[salt=\").append(getSalt()).append(\", pepper=\").append(getPepper()).append(\", hash=\").append(getResult())\n                .append(\"]\");\n        return sb.toString();\n    }\n\n"
      },
      {
        "chunk_id": "doc_46_chunk_14",
        "original_index": 14,
        "content": "    /**\n     * Two {@link Hash}es are considered equals if they contain\n     * the same hash, salt, pepper and they are generated with\n     * the same {@link HashingFunction}\n     *\n     * @param obj the object to compare\n     * @return true if equals\n     * @since 0.1.0\n     */\n    @Override\n    public boolean equals(Object obj)\n    {\n        if (obj == null || !this.getClass().equals(obj.getClass()))\n        {\n            return false;\n        }\n\n"
      },
      {
        "chunk_id": "doc_46_chunk_15",
        "original_index": 15,
        "content": "        Hash otherHash = (Hash) obj;\n        return hasSameValues(otherHash);\n    }\n\n    private boolean hasSameValues(Hash otherHash)\n    {\n        return Arrays.equals(this.result, otherHash.result) //\n                && Arrays.equals(this.bytes, otherHash.bytes) //\n                && Arrays.equals(this.salt, otherHash.salt) //\n                && areEquals(this.pepper, otherHash.pepper) //\n                && this.hashingFunction.equals(otherHash.hashingFunction);\n    }\n\n    private static boolean areEquals(CharSequence cs1, CharSequence cs2)\n    {\n        if (cs1 == cs2)\n        {\n            return true;\n        }\n        else if (cs1 != null && cs2 != null)\n        {\n            return cs1.equals(cs2);\n        }\n        return false;\n    }\n\n    @Override\n    public int hashCode()\n    {\n        return Objects.hash(Arrays.hashCode(result), Arrays.hashCode(salt), pepper, hashingFunction);\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_47",
    "original_uuid": "4455bcd2fc69f3f80a0322dd01f54d8b880a366e519955adca455ce4f51efbbe",
    "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j;\n\n/**\n * Builder class that helps to create a chain of parameters to be used\n * in the hashing process.\n *\n * @author David Bertoldi\n * @since 1.0.0\n */\npublic class HashBuilder\n{\n    private byte[] plainTextPassword;\n\n    protected byte[] salt;\n\n    protected CharSequence pepper;\n\n    @SuppressWarnings(\"unused\")\n    private HashBuilder()\n    {\n        //\n    }\n\n    /**\n     * @param plainTextPassword the plain text password\n     * @since 1.0.0\n     */\n    protected HashBuilder(CharSequence plainTextPassword)\n    {\n        this.plainTextPassword = Utils.fromCharSequenceToBytes(plainTextPassword);\n    }\n\n    /**\n     * @param plainTextPasswordAsBytes the plain text password as bytes array\n     * @since 1.7.0\n     */\n    protected HashBuilder(byte[] plainTextPasswordAsBytes)\n    {\n        this.plainTextPassword = plainTextPasswordAsBytes;\n    }\n\n    /**\n     * Add a cryptographic salt in the hashing process.\n     * The salt is applied differently depending on the chosen algorithm.\n     *\n     * @param salt cryptographic salt\n     * @return this builder\n     * @since 1.0.0\n     */\n    public HashBuilder addSalt(String salt)\n    {\n        this.salt = Utils.fromCharSequenceToBytes(salt);\n        return this;\n    }\n\n    /**\n     * Add a cryptographic salt in the hashing process.\n     * The salt is applied differently depending on the chosen algorithm.\n     *\n     * @param saltAsBytes cryptographic salt as bytes array\n     * @return this builder\n     * @since 1.7.0\n     */\n    public HashBuilder addSalt(byte[] saltAsBytes)\n    {\n        this.salt = saltAsBytes;\n        return this;\n    }\n\n    /**\n     * Add a random cryptographic salt in the hashing process.\n     * The salt is applied differently depending on the chosen algorithm.\n     * <p>\n     * Calling this method can be omitted for all the CHFs that require a salt.\n     *\n     * @return this builder\n     * @see SaltGenerator#generate() for more information about the length of the product\n     * @since 1.0.0\n     */\n    public HashBuilder addRandomSalt()\n    {\n        this.salt = SaltGenerator.generate();\n        return this;\n    }\n\n    /**\n     * Add a random cryptographic salt in the hashing process with a given length.\n     * The salt is applied differently depending on the chosen algorithm.\n     *\n     * @param length the length of the salt produced\n     * @return this builder\n     * @throws BadParametersException if the length is non-positive\n     * @see SaltGenerator#generate() for more information about the length of the product\n     * @since 1.0.0\n     */\n    public HashBuilder addRandomSalt(int length)\n    {\n        if (length <= 0)\n        {\n            throw new BadParametersException(\"Salt cannot have a non-positive length\");\n        }\n        else\n        {\n            this.salt = SaltGenerator.generate(length);\n        }\n        return this;\n    }\n\n    /**\n     * Concatenates the pepper configured in your `psw4j.properties` file with the plain text password.\n     * The produced sequence (in the form {@code pepper+password}) is processed by the algorithm.\n     *\n     * @return this builder\n     * @see PepperGenerator#get()\n     */\n    public HashBuilder addPepper()\n    {\n        this.pepper = PepperGenerator.get();\n        return this;\n    }\n\n    /**\n     * Concatenates the provided string with the plain text password.\n     * The produced sequence (in the form {@code pepper+password}) is processed by the algorithm.\n     *\n     * @param pepper cryptographic pepper\n     * @return this builder\n     * @since 1.0.0\n     */\n    public HashBuilder addPepper(CharSequence pepper)\n    {\n        this.pepper = pepper;\n        return this;\n    }\n\n    /**\n     * Hashes the previously given plain text password\n     * with a specific implementation of {@link HashingFunction}.\n     * <p>\n     * This method does not read the configurations in the `psw4j.properties` file.\n     *\n     * @param hashingFunction a CHF\n     * @return a {@link Hash} object\n     * @since 1.0.0\n     */\n    public Hash with(HashingFunction hashingFunction)\n    {\n        return hashingFunction.hash(plainTextPassword, salt, pepper);\n    }\n\n    /**\n     * Hashes the previously given plain text password\n     * with {@link PBKDF2Function}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return a {@link Hash} object\n     * @see AlgorithmFinder#getPBKDF2Instance()\n     * @see #with(HashingFunction)\n     * @since 1.0.0\n     */\n    public Hash withPBKDF2()\n    {\n        return with(AlgorithmFinder.getPBKDF2Instance());\n    }\n\n    /**\n     * Hashes the previously given plain text password\n     * with {@link CompressedPBKDF2Function}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return an {@link Hash} object\n     * @see AlgorithmFinder#getCompressedPBKDF2Instance()\n     * @see #with(HashingFunction)\n     * @since 1.0.0\n     */\n    public Hash withCompressedPBKDF2()\n    {\n        return with(AlgorithmFinder.getCompressedPBKDF2Instance());\n    }\n\n    /**\n     * Hashes the previously given plain text password\n     * with {@link BcryptFunction}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return an {@link Hash} object\n     * @see AlgorithmFinder#getBcryptInstance()\n     * @see #with(HashingFunction)\n     * @since 1.0.0\n     */\n    public Hash withBcrypt()\n    {\n        return with(AlgorithmFinder.getBcryptInstance());\n    }\n\n    /**\n     * Hashes the previously given plain text password\n     * with {@link ScryptFunction}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return an {@link Hash} object\n     * @see AlgorithmFinder#getScryptInstance()\n     * @see #with(HashingFunction)\n     * @since 1.0.0\n     */\n    public Hash withScrypt()\n    {\n        return with(AlgorithmFinder.getScryptInstance());\n    }\n\n    /**\n     * Hashes the previously given plain text password\n     * with {@link MessageDigestFunction}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return a {@link Hash} object\n     * @see AlgorithmFinder#getPBKDF2Instance()\n     * @see #with(HashingFunction)\n     * @since 1.4.0\n     */\n    public Hash withMessageDigest()\n    {\n        return with(AlgorithmFinder.getMessageDigestInstance());\n    }\n\n    /**\n     * Hashes the previously given plain text password\n     * with {@link Argon2Function}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return a {@link Hash} object\n     * @see AlgorithmFinder#getArgon2Instance()\n     * @see #with(HashingFunction)\n     * @since 1.5.0\n     */\n    public Hash withArgon2()\n    {\n        return with(AlgorithmFinder.getArgon2Instance());\n    }\n\n    /**\n     * Hashes the previously given plain text password\n     * with {@link BalloonHashingFunction}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return a {@link Hash} object\n     * @see AlgorithmFinder#getArgon2Instance()\n     * @see #with(HashingFunction)\n     * @since 1.8.0\n     */\n    public Hash withBalloonHashing()\n    {\n        return with(AlgorithmFinder.getBalloonHashingInstance());\n    }\n\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_47_chunk_0",
        "original_index": 0,
        "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j;\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_1",
        "original_index": 1,
        "content": "/**\n * Builder class that helps to create a chain of parameters to be used\n * in the hashing process.\n *\n * @author David Bertoldi\n * @since 1.0.0\n */\npublic class HashBuilder\n{\n    private byte[] plainTextPassword;\n\n    protected byte[] salt;\n\n    protected CharSequence pepper;\n\n    @SuppressWarnings(\"unused\")\n    private HashBuilder()\n    {\n        //\n    }\n\n    /**\n     * @param plainTextPassword the plain text password\n     * @since 1.0.0\n     */\n    protected HashBuilder(CharSequence plainTextPassword)\n    {\n        this.plainTextPassword = Utils.fromCharSequenceToBytes(plainTextPassword);\n    }\n\n    /**\n     * @param plainTextPasswordAsBytes the plain text password as bytes array\n     * @since 1.7.0\n     */\n    protected HashBuilder(byte[] plainTextPasswordAsBytes)\n    {\n        this.plainTextPassword = plainTextPasswordAsBytes;\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_2",
        "original_index": 2,
        "content": "    /**\n     * Add a cryptographic salt in the hashing process.\n     * The salt is applied differently depending on the chosen algorithm.\n     *\n     * @param salt cryptographic salt\n     * @return this builder\n     * @since 1.0.0\n     */\n    public HashBuilder addSalt(String salt)\n    {\n        this.salt = Utils.fromCharSequenceToBytes(salt);\n        return this;\n    }\n\n    /**\n     * Add a cryptographic salt in the hashing process.\n     * The salt is applied differently depending on the chosen algorithm.\n     *\n     * @param saltAsBytes cryptographic salt as bytes array\n     * @return this builder\n     * @since 1.7.0\n     */\n    public HashBuilder addSalt(byte[] saltAsBytes)\n    {\n        this.salt = saltAsBytes;\n        return this;\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_3",
        "original_index": 3,
        "content": "    /**\n     * Add a random cryptographic salt in the hashing process.\n     * The salt is applied differently depending on the chosen algorithm.\n     * <p>\n     * Calling this method can be omitted for all the CHFs that require a salt.\n     *\n     * @return this builder\n     * @see SaltGenerator#generate() for more information about the length of the product\n     * @since 1.0.0\n     */\n    public HashBuilder addRandomSalt()\n    {\n        this.salt = SaltGenerator.generate();\n        return this;\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_4",
        "original_index": 4,
        "content": "    /**\n     * Add a random cryptographic salt in the hashing process with a given length.\n     * The salt is applied differently depending on the chosen algorithm.\n     *\n     * @param length the length of the salt produced\n     * @return this builder\n     * @throws BadParametersException if the length is non-positive\n     * @see SaltGenerator#generate() for more information about the length of the product\n     * @since 1.0.0\n     */\n    public HashBuilder addRandomSalt(int length)\n    {\n        if (length <= 0)\n        {\n            throw new BadParametersException(\"Salt cannot have a non-positive length\");\n        }\n        else\n        {\n            this.salt = SaltGenerator.generate(length);\n        }\n        return this;\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_5",
        "original_index": 5,
        "content": "    /**\n     * Concatenates the pepper configured in your `psw4j.properties` file with the plain text password.\n     * The produced sequence (in the form {@code pepper+password}) is processed by the algorithm.\n     *\n     * @return this builder\n     * @see PepperGenerator#get()\n     */\n    public HashBuilder addPepper()\n    {\n        this.pepper = PepperGenerator.get();\n        return this;\n    }\n\n    /**\n     * Concatenates the provided string with the plain text password.\n     * The produced sequence (in the form {@code pepper+password}) is processed by the algorithm.\n     *\n     * @param pepper cryptographic pepper\n     * @return this builder\n     * @since 1.0.0\n     */\n    public HashBuilder addPepper(CharSequence pepper)\n    {\n        this.pepper = pepper;\n        return this;\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_6",
        "original_index": 6,
        "content": "    /**\n     * Hashes the previously given plain text password\n     * with a specific implementation of {@link HashingFunction}.\n     * <p>\n     * This method does not read the configurations in the `psw4j.properties` file.\n     *\n     * @param hashingFunction a CHF\n     * @return a {@link Hash} object\n     * @since 1.0.0\n     */\n    public Hash with(HashingFunction hashingFunction)\n    {\n        return hashingFunction.hash(plainTextPassword, salt, pepper);\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_7",
        "original_index": 7,
        "content": "    /**\n     * Hashes the previously given plain text password\n     * with {@link PBKDF2Function}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return a {@link Hash} object\n     * @see AlgorithmFinder#getPBKDF2Instance()\n     * @see #with(HashingFunction)\n     * @since 1.0.0\n     */\n    public Hash withPBKDF2()\n    {\n        return with(AlgorithmFinder.getPBKDF2Instance());\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_8",
        "original_index": 8,
        "content": "    /**\n     * Hashes the previously given plain text password\n     * with {@link CompressedPBKDF2Function}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return an {@link Hash} object\n     * @see AlgorithmFinder#getCompressedPBKDF2Instance()\n     * @see #with(HashingFunction)\n     * @since 1.0.0\n     */\n    public Hash withCompressedPBKDF2()\n    {\n        return with(AlgorithmFinder.getCompressedPBKDF2Instance());\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_9",
        "original_index": 9,
        "content": "    /**\n     * Hashes the previously given plain text password\n     * with {@link BcryptFunction}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return an {@link Hash} object\n     * @see AlgorithmFinder#getBcryptInstance()\n     * @see #with(HashingFunction)\n     * @since 1.0.0\n     */\n    public Hash withBcrypt()\n    {\n        return with(AlgorithmFinder.getBcryptInstance());\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_10",
        "original_index": 10,
        "content": "    /**\n     * Hashes the previously given plain text password\n     * with {@link ScryptFunction}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return an {@link Hash} object\n     * @see AlgorithmFinder#getScryptInstance()\n     * @see #with(HashingFunction)\n     * @since 1.0.0\n     */\n    public Hash withScrypt()\n    {\n        return with(AlgorithmFinder.getScryptInstance());\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_11",
        "original_index": 11,
        "content": "    /**\n     * Hashes the previously given plain text password\n     * with {@link MessageDigestFunction}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return a {@link Hash} object\n     * @see AlgorithmFinder#getPBKDF2Instance()\n     * @see #with(HashingFunction)\n     * @since 1.4.0\n     */\n    public Hash withMessageDigest()\n    {\n        return with(AlgorithmFinder.getMessageDigestInstance());\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_12",
        "original_index": 12,
        "content": "    /**\n     * Hashes the previously given plain text password\n     * with {@link Argon2Function}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return a {@link Hash} object\n     * @see AlgorithmFinder#getArgon2Instance()\n     * @see #with(HashingFunction)\n     * @since 1.5.0\n     */\n    public Hash withArgon2()\n    {\n        return with(AlgorithmFinder.getArgon2Instance());\n    }\n\n"
      },
      {
        "chunk_id": "doc_47_chunk_13",
        "original_index": 13,
        "content": "    /**\n     * Hashes the previously given plain text password\n     * with {@link BalloonHashingFunction}.\n     * <p>\n     * This method reads the configurations in the `psw4j.properties` file. If no configuration is found,\n     * then the default parameters are used.\n     * <p>\n     * Finally calls {@link #with(HashingFunction)}\n     *\n     * @return a {@link Hash} object\n     * @see AlgorithmFinder#getArgon2Instance()\n     * @see #with(HashingFunction)\n     * @since 1.8.0\n     */\n    public Hash withBalloonHashing()\n    {\n        return with(AlgorithmFinder.getBalloonHashingInstance());\n    }\n\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_48",
    "original_uuid": "d08c07ecf2fa3858f8e744e51c3c6db56b2a73be61e2b4b68ef9007697320ec2",
    "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j;\n\nimport com.password4j.types.Bcrypt;\nimport com.password4j.types.Hmac;\nimport org.junit.Assert;\nimport org.junit.Test;\n\nimport java.util.Base64;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Set;\n\nimport static org.junit.Assert.assertEquals;\n\n\npublic class MessageDigestFunctionTest\n{\n\n\n    @Test\n    public void testMD5()\n    {\n        // GIVEN\n        HashingFunction strategy = MessageDigestFunction.getInstance(\"MD5\");\n        String password = \"password\";\n        String salt = \"abc\";\n\n        // WHEN\n        Hash hash = strategy.hash(password, salt);\n\n        // THEN\n        assertEquals(\"8223fe8dc0533c6ebbb717e7fda2833c\", hash.getResult());\n    }\n\n\n    @Test\n    public void testMD5noSalt()\n    {\n        // GIVEN\n        HashingFunction strategy = MessageDigestFunction.getInstance(\"MD5\");\n        String password = \"password\";\n\n        // WHEN\n        Hash hash = strategy.hash(password);\n\n        // THEN\n        assertEquals(\"5f4dcc3b5aa765d61d8327deb882cf99\", hash.getResult());\n    }\n\n    @Test\n    public void testDifferentConcatenations()\n    {\n        // GIVEN\n        HashingFunction strategy1 = MessageDigestFunction.getInstance(\"MD5\", SaltOption.PREPEND);\n        HashingFunction strategy2 = MessageDigestFunction.getInstance(\"MD5\", SaltOption.APPEND);\n\n        String password = \"password\";\n        String salt = \"abc\";\n\n        // WHEN\n        Hash hash1 = strategy1.hash(password, salt);\n        Hash hash2 = strategy2.hash(password, salt);\n\n        // THEN\n        Assert.assertNotEquals(hash1.getResult(), hash2.getResult());\n    }\n\n    @Test\n    public void testMDVariants()\n    {\n        Set<String> algorithms = AlgorithmFinder.getAllMessageDigests();\n        for (String alg : algorithms)\n        {\n            // GIVEN\n            MessageDigestFunction strategy = MessageDigestFunction.getInstance(alg);\n            String password = \"password\";\n            String salt = \"abc\";\n\n            // WHEN\n            Hash hash = strategy.hash(password);\n            Hash hashWithSalt = strategy.hash(password, salt);\n\n            // THEN\n            Assert.assertTrue(strategy.check(password, hash.getResult()));\n            Assert.assertTrue(strategy.check(password, hashWithSalt.getResult(), salt));\n        }\n    }\n\n    @Test(expected = UnsupportedOperationException.class)\n    public void testMDWrongAlgorithm()\n    {\n        // GIVEN\n        HashingFunction strategy = MessageDigestFunction.getInstance(\"notAnAlgorithm\");\n        String password = \"password\";\n        String salt = \"abc\";\n\n        // WHEN\n        strategy.hash(password, salt);\n\n        // THEN\n    }\n\n    @Test\n    public void testMDWrongSaltOption()\n    {\n        // GIVEN\n\n        PropertyReader.properties.setProperty(\"hash.md.salt.option\", \"1234\");\n\n        // WHEN\n        MessageDigestFunction function = AlgorithmFinder.getMessageDigestInstance();\n\n        // THEN\n        assertEquals(SaltOption.APPEND, function.getSaltOption());\n        PropertyReader.properties.setProperty(\"hash.md.salt.option\", \"append\");\n    }\n\n    @Test\n    public void testMDRightSaltOption()\n    {\n        // GIVEN\n\n        PropertyReader.properties.setProperty(\"hash.md.salt.option\", \"prepend\");\n\n        // WHEN\n        MessageDigestFunction function = AlgorithmFinder.getMessageDigestInstance();\n\n        // THEN\n        assertEquals(SaltOption.PREPEND, function.getSaltOption());\n        PropertyReader.properties.setProperty(\"hash.md.salt.option\", \"append\");\n\n    }\n\n\n    @Test\n    public void testPBKDF2Check()\n    {\n        // GIVEN\n        String hashed = \"$3$42949672960256$YWJj$/WTQfTTc8Hg8GlplP0LthpgdElUG+I3MyuvK8MI4MnQ=\";\n        String userSubmittedPassword = \"password\";\n\n        // WHEN\n        HashingFunction strategy = CompressedPBKDF2Function.getInstanceFromHash(hashed);\n\n        // THEN\n        Assert.assertTrue(strategy.check(userSubmittedPassword, hashed));\n    }\n\n\n    @Test\n    public void testPBKDF2WrongCheck2()\n    {\n        // GIVEN\n        String hashed = \"$3$42949672960256$YWJj$/WTQfTTc8Hg8GlplP0LthpgdElUG+I3MyuvK8MI4MnQ=\";\n        String badHash = \"$342949672960256$YWJj$/WTQfTTc8Hg8GlplP0LthpgdElUG+I3MyuvK8MI4MnQ=\";\n        String userSubmittedPassword = \"password\";\n\n        // WHEN\n        HashingFunction strategy = CompressedPBKDF2Function.getInstanceFromHash(hashed);\n\n        // THEN\n        try {\n            Assert.assertTrue(strategy.check(userSubmittedPassword, badHash));\n        } catch (BadParametersException ex) {\n            assertEquals(\"`\" + badHash + \"` is not a valid hash\", ex.getMessage());\n        }\n    }\n\n\n    @Test(expected = BadParametersException.class)\n    public void testPBKDF2BadCheck()\n    {\n        // GIVEN\n        String hashed = \"$342949672960256$YWJj$/WTQfTTc8Hg8GlplP0LthpgdElUG+I3MyuvK8MI4MnQ=\";\n        String userSubmittedPassword = \"password\";\n\n        // WHEN\n        CompressedPBKDF2Function.getInstanceFromHash(hashed);\n\n\n    }\n\n    @Test\n    public void testAlgorithmFromCode()\n    {\n        // GIVEN\n\n        // WHEN\n        Hmac algNull = Hmac.fromCode(-100);\n        for (Hmac enumAlg : Hmac.values())\n        {\n            Hmac alg = Hmac.fromCode(enumAlg.code());\n\n\n            // THEN\n            Assert.assertNotNull(alg);\n            assertEquals(enumAlg.code(), alg.code());\n            assertEquals(enumAlg.bits(), alg.bits());\n        }\n        Assert.assertNull(algNull);\n\n\n    }\n\n    @Test\n    public void testPBKDF2Coherence()\n    {\n        // GIVEN\n        String password = \"password\";\n\n        // WHEN\n        Hash hash = PBKDF2Function.getInstance(Hmac.SHA256, 8_777, 256).hash(password);\n\n        // THEN\n        Assert.assertTrue(Password.check(password, hash));\n\n    }\n\n    @Test\n    public void testPBKDF2CheckWithFixedConfigurations()\n    {\n        // GIVEN\n        String hashed = \"$3$42949672960256$YWJj$/WTQfTTc8Hg8GlplP0LthpgdElUG+I3MyuvK8MI4MnQ=\";\n        String userSubmittedPassword = \"password\";\n\n        // WHEN\n        HashingFunction strategy = new CompressedPBKDF2Function(Hmac.SHA256, 10_000, 256);\n\n        // THEN\n        Assert.assertTrue(strategy.check(userSubmittedPassword, hashed));\n    }\n\n\n    @Test\n    public void testPBKDF2equality()\n    {\n        // GIVEN\n        PBKDF2Function strategy1 = PBKDF2Function.getInstance(Hmac.SHA256, 10_000, 256);\n        PBKDF2Function strategy2 = PBKDF2Function.getInstance(Hmac.SHA256, 10_000, 256);\n        PBKDF2Function strategy3 = PBKDF2Function.getInstance(Hmac.SHA1, 10_000, 256);\n        PBKDF2Function strategy4 = PBKDF2Function.getInstance(Hmac.SHA256, 64_000, 256);\n        PBKDF2Function strategy5 = PBKDF2Function.getInstance(Hmac.SHA256, 64_000, 123);\n\n\n        // WHEN\n        Map<PBKDF2Function, String> map = new HashMap<>();\n        map.put(strategy1, strategy1.toString());\n        map.put(strategy2, strategy2.toString());\n        map.put(strategy3, strategy3.toString());\n        map.put(strategy4, strategy4.toString());\n        map.put(strategy5, strategy5.toString());\n\n\n        // THEN\n        assertEquals(4, map.size());\n        assertEquals(strategy1, strategy2);\n    }\n\n    @Test\n    public void testCompressed()\n    {\n        Hmac algorithm = Hmac.SHA512;\n\n\n        for (int i = 1; i <= 100; i++)\n        {\n            String password = PepperGenerator.generate(12);\n            String salt = PepperGenerator.generate(i);\n            Hash hash = CompressedPBKDF2Function.getInstance(algorithm, 100 * i, algorithm.bits()).hash(password, salt);\n\n            Hash notCompressedHash = PBKDF2Function.getInstance(algorithm, 100 * i, algorithm.bits()).hash(password, salt);\n\n            String params = Long.toString((((long) 100 * i) << 32) | (algorithm.bits() & 0xffffffffL));\n            String expected = \"$\" + algorithm.code() + \"$\" + params + \"$\" + Base64.getEncoder().encodeToString(salt.getBytes(Utils.DEFAULT_CHARSET)) + \"$\" + notCompressedHash.getResult();\n\n            assertEquals(expected, hash.getResult());\n        }\n    }\n\n    @Test\n    public void testAccessors()\n    {\n        // GIVEN\n\n\n        // WHEN\n        MessageDigestFunction function = MessageDigestFunction.getInstance(\"MD5\", SaltOption.APPEND);\n\n        // THEN\n        assertEquals(\"MD5\", function.getAlgorithm());\n        assertEquals(SaltOption.APPEND, function.getSaltOption());\n        assertEquals(\"MessageDigestFunction(a=MD5, o=APPEND)\", function.toString());\n    }\n\n    @Test\n    public void testEquality()\n    {\n        // GIVEN\n        String a = \"MD5\";\n        SaltOption o = SaltOption.APPEND;\n        MessageDigestFunction function = MessageDigestFunction.getInstance(a, o);\n\n        // THEN\n        boolean eqNull = function.equals(null);\n        boolean eqClass = function.equals(new BcryptFunction(Bcrypt.A, 10));\n        boolean sameInst = function.equals(MessageDigestFunction.getInstance(a, o));\n        boolean sameInst2 = function.equals(new MessageDigestFunction(a, o));\n        String toString = function.toString();\n        int hashCode = function.hashCode();\n        boolean notSameInst1 = function.equals(new MessageDigestFunction(\"SHA1\", o));\n        boolean notSameInst2 = function.equals(new MessageDigestFunction(a, SaltOption.PREPEND));\n\n\n        // END\n        Assert.assertFalse(eqNull);\n        Assert.assertFalse(eqClass);\n        Assert.assertTrue(sameInst);\n        Assert.assertTrue(sameInst2);\n        Assert.assertNotEquals(toString, new MessageDigestFunction(\"SHA1\", o).toString());\n        Assert.assertNotEquals(hashCode, new MessageDigestFunction(a, SaltOption.PREPEND).hashCode());\n        Assert.assertFalse(notSameInst1);\n        Assert.assertFalse(notSameInst2);\n    }\n\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_48_chunk_0",
        "original_index": 0,
        "content": "/*\n *  (C) Copyright 2020 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j;\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_1",
        "original_index": 1,
        "content": "import com.password4j.types.Bcrypt;\nimport com.password4j.types.Hmac;\nimport org.junit.Assert;\nimport org.junit.Test;\n\nimport java.util.Base64;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Set;\n\nimport static org.junit.Assert.assertEquals;\n\n\npublic class MessageDigestFunctionTest\n{\n\n\n    @Test\n    public void testMD5()\n    {\n        // GIVEN\n        HashingFunction strategy = MessageDigestFunction.getInstance(\"MD5\");\n        String password = \"password\";\n        String salt = \"abc\";\n\n        // WHEN\n        Hash hash = strategy.hash(password, salt);\n\n        // THEN\n        assertEquals(\"8223fe8dc0533c6ebbb717e7fda2833c\", hash.getResult());\n    }\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_2",
        "original_index": 2,
        "content": "\n    @Test\n    public void testMD5noSalt()\n    {\n        // GIVEN\n        HashingFunction strategy = MessageDigestFunction.getInstance(\"MD5\");\n        String password = \"password\";\n\n        // WHEN\n        Hash hash = strategy.hash(password);\n\n        // THEN\n        assertEquals(\"5f4dcc3b5aa765d61d8327deb882cf99\", hash.getResult());\n    }\n\n    @Test\n    public void testDifferentConcatenations()\n    {\n        // GIVEN\n        HashingFunction strategy1 = MessageDigestFunction.getInstance(\"MD5\", SaltOption.PREPEND);\n        HashingFunction strategy2 = MessageDigestFunction.getInstance(\"MD5\", SaltOption.APPEND);\n\n        String password = \"password\";\n        String salt = \"abc\";\n\n        // WHEN\n        Hash hash1 = strategy1.hash(password, salt);\n        Hash hash2 = strategy2.hash(password, salt);\n\n        // THEN\n        Assert.assertNotEquals(hash1.getResult(), hash2.getResult());\n    }\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_3",
        "original_index": 3,
        "content": "    @Test\n    public void testMDVariants()\n    {\n        Set<String> algorithms = AlgorithmFinder.getAllMessageDigests();\n        for (String alg : algorithms)\n        {\n            // GIVEN\n            MessageDigestFunction strategy = MessageDigestFunction.getInstance(alg);\n            String password = \"password\";\n            String salt = \"abc\";\n\n            // WHEN\n            Hash hash = strategy.hash(password);\n            Hash hashWithSalt = strategy.hash(password, salt);\n\n            // THEN\n            Assert.assertTrue(strategy.check(password, hash.getResult()));\n            Assert.assertTrue(strategy.check(password, hashWithSalt.getResult(), salt));\n        }\n    }\n\n    @Test(expected = UnsupportedOperationException.class)\n    public void testMDWrongAlgorithm()\n    {\n        // GIVEN\n        HashingFunction strategy = MessageDigestFunction.getInstance(\"notAnAlgorithm\");\n        String password = \"password\";\n        String salt = \"abc\";\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_4",
        "original_index": 4,
        "content": "        // WHEN\n        strategy.hash(password, salt);\n\n        // THEN\n    }\n\n    @Test\n    public void testMDWrongSaltOption()\n    {\n        // GIVEN\n\n        PropertyReader.properties.setProperty(\"hash.md.salt.option\", \"1234\");\n\n        // WHEN\n        MessageDigestFunction function = AlgorithmFinder.getMessageDigestInstance();\n\n        // THEN\n        assertEquals(SaltOption.APPEND, function.getSaltOption());\n        PropertyReader.properties.setProperty(\"hash.md.salt.option\", \"append\");\n    }\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_5",
        "original_index": 5,
        "content": "    @Test\n    public void testMDRightSaltOption()\n    {\n        // GIVEN\n\n        PropertyReader.properties.setProperty(\"hash.md.salt.option\", \"prepend\");\n\n        // WHEN\n        MessageDigestFunction function = AlgorithmFinder.getMessageDigestInstance();\n\n        // THEN\n        assertEquals(SaltOption.PREPEND, function.getSaltOption());\n        PropertyReader.properties.setProperty(\"hash.md.salt.option\", \"append\");\n\n    }\n\n\n    @Test\n    public void testPBKDF2Check()\n    {\n        // GIVEN\n        String hashed = \"$3$42949672960256$YWJj$/WTQfTTc8Hg8GlplP0LthpgdElUG+I3MyuvK8MI4MnQ=\";\n        String userSubmittedPassword = \"password\";\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_6",
        "original_index": 6,
        "content": "        // WHEN\n        HashingFunction strategy = CompressedPBKDF2Function.getInstanceFromHash(hashed);\n\n        // THEN\n        Assert.assertTrue(strategy.check(userSubmittedPassword, hashed));\n    }\n\n\n    @Test\n    public void testPBKDF2WrongCheck2()\n    {\n        // GIVEN\n        String hashed = \"$3$42949672960256$YWJj$/WTQfTTc8Hg8GlplP0LthpgdElUG+I3MyuvK8MI4MnQ=\";\n        String badHash = \"$342949672960256$YWJj$/WTQfTTc8Hg8GlplP0LthpgdElUG+I3MyuvK8MI4MnQ=\";\n        String userSubmittedPassword = \"password\";\n\n        // WHEN\n        HashingFunction strategy = CompressedPBKDF2Function.getInstanceFromHash(hashed);\n\n        // THEN\n        try {\n            Assert.assertTrue(strategy.check(userSubmittedPassword, badHash));\n        } catch (BadParametersException ex) {\n            assertEquals(\"`\" + badHash + \"` is not a valid hash\", ex.getMessage());\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_7",
        "original_index": 7,
        "content": "\n    @Test(expected = BadParametersException.class)\n    public void testPBKDF2BadCheck()\n    {\n        // GIVEN\n        String hashed = \"$342949672960256$YWJj$/WTQfTTc8Hg8GlplP0LthpgdElUG+I3MyuvK8MI4MnQ=\";\n        String userSubmittedPassword = \"password\";\n\n        // WHEN\n        CompressedPBKDF2Function.getInstanceFromHash(hashed);\n\n\n    }\n\n    @Test\n    public void testAlgorithmFromCode()\n    {\n        // GIVEN\n\n        // WHEN\n        Hmac algNull = Hmac.fromCode(-100);\n        for (Hmac enumAlg : Hmac.values())\n        {\n            Hmac alg = Hmac.fromCode(enumAlg.code());\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_8",
        "original_index": 8,
        "content": "\n            // THEN\n            Assert.assertNotNull(alg);\n            assertEquals(enumAlg.code(), alg.code());\n            assertEquals(enumAlg.bits(), alg.bits());\n        }\n        Assert.assertNull(algNull);\n\n\n    }\n\n    @Test\n    public void testPBKDF2Coherence()\n    {\n        // GIVEN\n        String password = \"password\";\n\n        // WHEN\n        Hash hash = PBKDF2Function.getInstance(Hmac.SHA256, 8_777, 256).hash(password);\n\n        // THEN\n        Assert.assertTrue(Password.check(password, hash));\n\n    }\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_9",
        "original_index": 9,
        "content": "    @Test\n    public void testPBKDF2CheckWithFixedConfigurations()\n    {\n        // GIVEN\n        String hashed = \"$3$42949672960256$YWJj$/WTQfTTc8Hg8GlplP0LthpgdElUG+I3MyuvK8MI4MnQ=\";\n        String userSubmittedPassword = \"password\";\n\n        // WHEN\n        HashingFunction strategy = new CompressedPBKDF2Function(Hmac.SHA256, 10_000, 256);\n\n        // THEN\n        Assert.assertTrue(strategy.check(userSubmittedPassword, hashed));\n    }\n\n\n    @Test\n    public void testPBKDF2equality()\n    {\n        // GIVEN\n        PBKDF2Function strategy1 = PBKDF2Function.getInstance(Hmac.SHA256, 10_000, 256);\n        PBKDF2Function strategy2 = PBKDF2Function.getInstance(Hmac.SHA256, 10_000, 256);\n        PBKDF2Function strategy3 = PBKDF2Function.getInstance(Hmac.SHA1, 10_000, 256);\n        PBKDF2Function strategy4 = PBKDF2Function.getInstance(Hmac.SHA256, 64_000, 256);\n        PBKDF2Function strategy5 = PBKDF2Function.getInstance(Hmac.SHA256, 64_000, 123);\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_10",
        "original_index": 10,
        "content": "\n        // WHEN\n        Map<PBKDF2Function, String> map = new HashMap<>();\n        map.put(strategy1, strategy1.toString());\n        map.put(strategy2, strategy2.toString());\n        map.put(strategy3, strategy3.toString());\n        map.put(strategy4, strategy4.toString());\n        map.put(strategy5, strategy5.toString());\n\n\n        // THEN\n        assertEquals(4, map.size());\n        assertEquals(strategy1, strategy2);\n    }\n\n    @Test\n    public void testCompressed()\n    {\n        Hmac algorithm = Hmac.SHA512;\n\n\n        for (int i = 1; i <= 100; i++)\n        {\n            String password = PepperGenerator.generate(12);\n            String salt = PepperGenerator.generate(i);\n            Hash hash = CompressedPBKDF2Function.getInstance(algorithm, 100 * i, algorithm.bits()).hash(password, salt);\n\n            Hash notCompressedHash = PBKDF2Function.getInstance(algorithm, 100 * i, algorithm.bits()).hash(password, salt);\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_11",
        "original_index": 11,
        "content": "            String params = Long.toString((((long) 100 * i) << 32) | (algorithm.bits() & 0xffffffffL));\n            String expected = \"$\" + algorithm.code() + \"$\" + params + \"$\" + Base64.getEncoder().encodeToString(salt.getBytes(Utils.DEFAULT_CHARSET)) + \"$\" + notCompressedHash.getResult();\n\n            assertEquals(expected, hash.getResult());\n        }\n    }\n\n    @Test\n    public void testAccessors()\n    {\n        // GIVEN\n\n\n        // WHEN\n        MessageDigestFunction function = MessageDigestFunction.getInstance(\"MD5\", SaltOption.APPEND);\n\n        // THEN\n        assertEquals(\"MD5\", function.getAlgorithm());\n        assertEquals(SaltOption.APPEND, function.getSaltOption());\n        assertEquals(\"MessageDigestFunction(a=MD5, o=APPEND)\", function.toString());\n    }\n\n    @Test\n    public void testEquality()\n    {\n        // GIVEN\n        String a = \"MD5\";\n        SaltOption o = SaltOption.APPEND;\n        MessageDigestFunction function = MessageDigestFunction.getInstance(a, o);\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_12",
        "original_index": 12,
        "content": "        // THEN\n        boolean eqNull = function.equals(null);\n        boolean eqClass = function.equals(new BcryptFunction(Bcrypt.A, 10));\n        boolean sameInst = function.equals(MessageDigestFunction.getInstance(a, o));\n        boolean sameInst2 = function.equals(new MessageDigestFunction(a, o));\n        String toString = function.toString();\n        int hashCode = function.hashCode();\n        boolean notSameInst1 = function.equals(new MessageDigestFunction(\"SHA1\", o));\n        boolean notSameInst2 = function.equals(new MessageDigestFunction(a, SaltOption.PREPEND));\n\n"
      },
      {
        "chunk_id": "doc_48_chunk_13",
        "original_index": 13,
        "content": "\n        // END\n        Assert.assertFalse(eqNull);\n        Assert.assertFalse(eqClass);\n        Assert.assertTrue(sameInst);\n        Assert.assertTrue(sameInst2);\n        Assert.assertNotEquals(toString, new MessageDigestFunction(\"SHA1\", o).toString());\n        Assert.assertNotEquals(hashCode, new MessageDigestFunction(a, SaltOption.PREPEND).hashCode());\n        Assert.assertFalse(notSameInst1);\n        Assert.assertFalse(notSameInst2);\n    }\n\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_49",
    "original_uuid": "36249e30a48fc8f61995b02dbfc658dd868eaab96d44ce7edc2930b75b51d20a",
    "content": "package com.password4j;\n\nimport com.password4j.types.Argon2;\nimport org.junit.Assert;\nimport org.junit.Test;\n\nimport java.security.Provider;\nimport java.security.Security;\nimport java.util.Set;\n\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertTrue;\n\npublic class IssuesTest\n{\n\n    /**\n     * @see <a href=\"https://github.com/Password4j/password4j/issues/92\">issue #92</a>\n     */\n    @Test\n    public void issue92()\n    {\n        String hash = \"$argon2id$v=19$m=16384,t=2,p=1$nlm7oNI5zquzSYkyby6oVw$JOkJAYrDB0i2gmiJrXC6o2r+u1rszCm/RO9gIQtnxlY\";\n        String plain = \"Test123!\";\n        Argon2Function function = Argon2Function.getInstanceFromHash(hash);\n\n        boolean verified = Password.check(plain, hash).with(function);\n        Hash newHash = Password.hash(plain).addSalt(\"Y9\u03abI2o.W\").with(function);\n        boolean verified2 = Password.check(plain, newHash);\n\n        assertTrue(verified);\n        assertTrue(verified2);\n        assertEquals(\"$argon2id$v=19$m=16384,t=2,p=1$WTnOq0kyby5X$SewIdM+Ywctw0lfNQ0xKYoUIlyRs3qF+gVmEVtpdmyg\", newHash.getResult());\n    }\n\n\n    /**\n     * @see <a href=\"https://github.com/Password4j/password4j/issues/99\">issue #99</a>\n     */\n    @Test\n    public void issue99()\n    {\n        int memory          = 65536;\n        int iterations      = 2;\n        int parallelism     = 3;\n        int outputLength    = 32;\n        int version         = 0x13;\n        byte[] salt         =\n                {\n                        (byte) 0x6b, (byte) 0x25, (byte) 0xc9, (byte) 0xd7, (byte) 0x0e, (byte) 0x5c, (byte) 0x19, (byte) 0xac,\n                        (byte) 0x51, (byte) 0x74, (byte) 0xd7, (byte) 0x74, (byte) 0x53, (byte) 0xad, (byte) 0x23, (byte) 0x70,\n                        (byte) 0x15, (byte) 0x27, (byte) 0x56, (byte) 0x2e, (byte) 0x02, (byte) 0xb8, (byte) 0xec, (byte) 0x5c,\n                        (byte) 0xac, (byte) 0x89, (byte) 0x2d, (byte) 0xc3, (byte) 0xe4, (byte) 0xb5, (byte) 0x1c, (byte) 0x12\n                };\n        byte[] password=\"Test\".getBytes();\n        Argon2 type = Argon2.ID;\n        Argon2Function instance=Argon2Function.getInstance(memory, iterations, parallelism, outputLength, type, version);\n\n        Hash hash = instance.hash(password, salt);\n\n\n        String expResult = \"cbcfdee482c233e525ca405c7014e89cd33142758a2f1d23c420690f950c988c\";\n        assertEquals(expResult, printBytesToString(hash.getBytes()));\n    }\n\n    /**\n     * @see <a href=\"https://github.com/Password4j/password4j/issues/93\">issue #93</a>\n     */\n    @Test\n    public void issue93()\n    {\n        String hash = \"$argon2id$v=19$m=16384,t=2,p=1$nlm7oNI5zquzSYkyby6oVw$JOkJAYrDB0i2gmiJrXC6o2r+u1rszCm/RO9gIQtnxlY\";\n        Argon2Function function = Argon2Function.getInstanceFromHash(hash);\n\n        boolean test1 = Password.check(\"Test123!\", hash).with(function);\n        assertTrue(test1);\n\n        boolean test2 = function.check(\"Test123!\", hash);\n        assertTrue(test2);\n    }\n\n\n    /**\n     * @see <a href=\"https://github.com/Password4j/password4j/issues/120\">issue #120</a>\n     */\n    @Test(expected = Test.None.class)\n    public void issue120()\n    {\n        // GIVEN\n        String name = \"issue120FakeProvider\";\n        Provider emptyProvider = new Provider(name, 1, \"info\")\n        {\n            @Override\n            public synchronized Set<Service> getServices()\n            {\n                return null;\n            }\n        };\n        Security.addProvider(emptyProvider);\n\n        // WHEN\n        Password.hash(\"hash\");\n\n        // THEN\n        Security.removeProvider(name);\n    }\n\n\n    /**\n     * @see <a href=\"https://github.com/Password4j/password4j/issues/126\">issue #126</a>\n     */\n    @Test\n    public void issue126()\n    {\n        byte[] hashBytes = Password.hash(\"\u2019(\u3063\uff3e\u25bf\uff3e)\u06f6\\uD83C\\uDF78\\uD83C\\uDF1F\\uD83C\\uDF7A\u0669(\u02d8\u25e1\u02d8 ) \u274c\u274c \u274c\u274c\u274c\")\n                .addSalt(\"\\uD83E\\uDDC2\")\n                .withScrypt()\n                .getBytes();\n\n        Assert.assertEquals(\"827b022b411e712e5ae4855d8c71cb047d882b2457120d1019974d17dcf6f1bf59644d9a93e470ab14ee5f7a88ae9b0140d2db121de58f6d830fc9c16c82f212\", printBytesToString(hashBytes));\n\n\n        hashBytes = Password.hash(\"\u0178\u0141\u0100PR\u010c\")\n                .addSalt(\"\u0178\u0141\u0100PR\u010cAA\")\n                .withArgon2()\n                .getBytes();\n\n        Assert.assertEquals(\"59dedcf45d7a8604926ca66f6abe3990ce8b6ba108f535836fa18e95b7d94e9f56301e422c1d487dd06dc26061261402a5f7fe912bd545b6aeec866fec74df81\", printBytesToString(hashBytes));\n\n    }\n\n    private static String printBytesToString(byte[] bytes)\n    {\n        StringBuilder byteString= new StringBuilder();\n        if (bytes!=null)\n        {\n            for (byte aByte : bytes)\n            {\n                byteString.append(String.format(\"%02x\", aByte));\n            }\n        }\n        else\n        {\n            byteString = new StringBuilder(\"-\");\n        }\n        return byteString.toString();\n    }\n\n\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_49_chunk_0",
        "original_index": 0,
        "content": "package com.password4j;\n\nimport com.password4j.types.Argon2;\nimport org.junit.Assert;\nimport org.junit.Test;\n\nimport java.security.Provider;\nimport java.security.Security;\nimport java.util.Set;\n\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertTrue;\n\npublic class IssuesTest\n{\n\n    /**\n     * @see <a href=\"https://github.com/Password4j/password4j/issues/92\">issue #92</a>\n     */\n    @Test\n    public void issue92()\n    {\n        String hash = \"$argon2id$v=19$m=16384,t=2,p=1$nlm7oNI5zquzSYkyby6oVw$JOkJAYrDB0i2gmiJrXC6o2r+u1rszCm/RO9gIQtnxlY\";\n        String plain = \"Test123!\";\n        Argon2Function function = Argon2Function.getInstanceFromHash(hash);\n\n"
      },
      {
        "chunk_id": "doc_49_chunk_1",
        "original_index": 1,
        "content": "        boolean verified = Password.check(plain, hash).with(function);\n        Hash newHash = Password.hash(plain).addSalt(\"Y9\u03abI2o.W\").with(function);\n        boolean verified2 = Password.check(plain, newHash);\n\n        assertTrue(verified);\n        assertTrue(verified2);\n        assertEquals(\"$argon2id$v=19$m=16384,t=2,p=1$WTnOq0kyby5X$SewIdM+Ywctw0lfNQ0xKYoUIlyRs3qF+gVmEVtpdmyg\", newHash.getResult());\n    }\n\n"
      },
      {
        "chunk_id": "doc_49_chunk_2",
        "original_index": 2,
        "content": "\n    /**\n     * @see <a href=\"https://github.com/Password4j/password4j/issues/99\">issue #99</a>\n     */\n    @Test\n    public void issue99()\n    {\n        int memory          = 65536;\n        int iterations      = 2;\n        int parallelism     = 3;\n        int outputLength    = 32;\n        int version         = 0x13;\n        byte[] salt         =\n                {\n                        (byte) 0x6b, (byte) 0x25, (byte) 0xc9, (byte) 0xd7, (byte) 0x0e, (byte) 0x5c, (byte) 0x19, (byte) 0xac,\n                        (byte) 0x51, (byte) 0x74, (byte) 0xd7, (byte) 0x74, (byte) 0x53, (byte) 0xad, (byte) 0x23, (byte) 0x70,\n"
      },
      {
        "chunk_id": "doc_49_chunk_3",
        "original_index": 3,
        "content": "                        (byte) 0x15, (byte) 0x27, (byte) 0x56, (byte) 0x2e, (byte) 0x02, (byte) 0xb8, (byte) 0xec, (byte) 0x5c,\n                        (byte) 0xac, (byte) 0x89, (byte) 0x2d, (byte) 0xc3, (byte) 0xe4, (byte) 0xb5, (byte) 0x1c, (byte) 0x12\n                };\n        byte[] password=\"Test\".getBytes();\n        Argon2 type = Argon2.ID;\n        Argon2Function instance=Argon2Function.getInstance(memory, iterations, parallelism, outputLength, type, version);\n\n        Hash hash = instance.hash(password, salt);\n\n\n        String expResult = \"cbcfdee482c233e525ca405c7014e89cd33142758a2f1d23c420690f950c988c\";\n        assertEquals(expResult, printBytesToString(hash.getBytes()));\n    }\n\n"
      },
      {
        "chunk_id": "doc_49_chunk_4",
        "original_index": 4,
        "content": "    /**\n     * @see <a href=\"https://github.com/Password4j/password4j/issues/93\">issue #93</a>\n     */\n    @Test\n    public void issue93()\n    {\n        String hash = \"$argon2id$v=19$m=16384,t=2,p=1$nlm7oNI5zquzSYkyby6oVw$JOkJAYrDB0i2gmiJrXC6o2r+u1rszCm/RO9gIQtnxlY\";\n        Argon2Function function = Argon2Function.getInstanceFromHash(hash);\n\n        boolean test1 = Password.check(\"Test123!\", hash).with(function);\n        assertTrue(test1);\n\n        boolean test2 = function.check(\"Test123!\", hash);\n        assertTrue(test2);\n    }\n\n"
      },
      {
        "chunk_id": "doc_49_chunk_5",
        "original_index": 5,
        "content": "\n    /**\n     * @see <a href=\"https://github.com/Password4j/password4j/issues/120\">issue #120</a>\n     */\n    @Test(expected = Test.None.class)\n    public void issue120()\n    {\n        // GIVEN\n        String name = \"issue120FakeProvider\";\n        Provider emptyProvider = new Provider(name, 1, \"info\")\n        {\n            @Override\n            public synchronized Set<Service> getServices()\n            {\n                return null;\n            }\n        };\n        Security.addProvider(emptyProvider);\n\n"
      },
      {
        "chunk_id": "doc_49_chunk_6",
        "original_index": 6,
        "content": "        // WHEN\n        Password.hash(\"hash\");\n\n        // THEN\n        Security.removeProvider(name);\n    }\n\n\n    /**\n     * @see <a href=\"https://github.com/Password4j/password4j/issues/126\">issue #126</a>\n     */\n    @Test\n    public void issue126()\n    {\n        byte[] hashBytes = Password.hash(\"\u2019(\u3063\uff3e\u25bf\uff3e)\u06f6\\uD83C\\uDF78\\uD83C\\uDF1F\\uD83C\\uDF7A\u0669(\u02d8\u25e1\u02d8 ) \u274c\u274c \u274c\u274c\u274c\")\n                .addSalt(\"\\uD83E\\uDDC2\")\n                .withScrypt()\n                .getBytes();\n\n"
      },
      {
        "chunk_id": "doc_49_chunk_7",
        "original_index": 7,
        "content": "        Assert.assertEquals(\"827b022b411e712e5ae4855d8c71cb047d882b2457120d1019974d17dcf6f1bf59644d9a93e470ab14ee5f7a88ae9b0140d2db121de58f6d830fc9c16c82f212\", printBytesToString(hashBytes));\n\n\n        hashBytes = Password.hash(\"\u0178\u0141\u0100PR\u010c\")\n                .addSalt(\"\u0178\u0141\u0100PR\u010cAA\")\n                .withArgon2()\n                .getBytes();\n\n        Assert.assertEquals(\"59dedcf45d7a8604926ca66f6abe3990ce8b6ba108f535836fa18e95b7d94e9f56301e422c1d487dd06dc26061261402a5f7fe912bd545b6aeec866fec74df81\", printBytesToString(hashBytes));\n\n    }\n\n"
      },
      {
        "chunk_id": "doc_49_chunk_8",
        "original_index": 8,
        "content": "    private static String printBytesToString(byte[] bytes)\n    {\n        StringBuilder byteString= new StringBuilder();\n        if (bytes!=null)\n        {\n            for (byte aByte : bytes)\n            {\n                byteString.append(String.format(\"%02x\", aByte));\n            }\n        }\n        else\n        {\n            byteString = new StringBuilder(\"-\");\n        }\n        return byteString.toString();\n    }\n\n\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_50",
    "original_uuid": "b5c2f52516a708781023ca83bc4b32e3aed11dffee5e877eccb4e8ad57e8697e",
    "content": "/*\n *  (C) Copyright 2021 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j.types;\n\n/**\n * Enum containing the different variations of Argon2.\n *\n * @author David Bertoldi\n * @see <a href=\"https://en.wikipedia.org/wiki/Argon2\">Argon2</a>\n * @since 1.5.0\n */\npublic enum Argon2\n{\n    /**\n     * It maximizes resistance to GPU cracking attacks.\n     * It accesses the memory array in a password dependent order, which reduces the possibility of time\u2013memory trade-off (TMTO) attacks,\n     * but introduces possible side-channel attacks\n     */\n    D,\n\n    /**\n     * It is optimized to resist side-channel attacks. It accesses the memory array in a password independent order.\n     */\n    I,\n\n    /**\n     * It is a hybrid version. It follows the Argon2i approach for the first half pass over memory and the Argon2d approach for subsequent passes.\n     * It is recommended to use Argon2id except when there are reasons to prefer one of the other two modes.\n     */\n    ID;\n\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_50_chunk_0",
        "original_index": 0,
        "content": "/*\n *  (C) Copyright 2021 Password4j (http://password4j.com/).\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage com.password4j.types;\n\n"
      },
      {
        "chunk_id": "doc_50_chunk_1",
        "original_index": 1,
        "content": "/**\n * Enum containing the different variations of Argon2.\n *\n * @author David Bertoldi\n * @see <a href=\"https://en.wikipedia.org/wiki/Argon2\">Argon2</a>\n * @since 1.5.0\n */\npublic enum Argon2\n{\n    /**\n     * It maximizes resistance to GPU cracking attacks.\n     * It accesses the memory array in a password dependent order, which reduces the possibility of time\u2013memory trade-off (TMTO) attacks,\n     * but introduces possible side-channel attacks\n     */\n    D,\n\n    /**\n     * It is optimized to resist side-channel attacks. It accesses the memory array in a password independent order.\n     */\n    I,\n\n    /**\n     * It is a hybrid version. It follows the Argon2i approach for the first half pass over memory and the Argon2d approach for subsequent passes.\n     * It is recommended to use Argon2id except when there are reasons to prefer one of the other two modes.\n     */\n    ID;\n\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_51",
    "original_uuid": "7aa93d0e14ee0838bd30f00d35918a93645c3b8bc8bb390b8b87bb7b77e65298",
    "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n//===-- wasmedge/plugins/wasi_crypto/symmetric/tag.h - Symmetric Tag class ===//\n//\n// Part of the WasmEdge Project.\n//\n//===----------------------------------------------------------------------===//\n///\n/// \\file\n/// This file contains the Symmetric Tag definition.\n///\n//===----------------------------------------------------------------------===//\n#pragma once\n\n#include \"utils/error.h\"\n#include \"utils/secret_vec.h\"\n\n#include \"common/span.h\"\n\n#include <memory>\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasiCrypto {\nnamespace Symmetric {\n\n/// Authentication tag, that can be verified without channels using the provided\n/// APIs. Very small and no streaming.\n///\n/// More detail:\n/// https://github.com/WebAssembly/wasi-crypto/blob/main/docs/wasi-crypto.md#authentication-tags\nclass Tag {\npublic:\n  Tag(Tag &&Data) noexcept = default;\n  Tag &operator=(Tag &&Data) noexcept = default;\n  Tag(const Tag &Data) noexcept = delete;\n  Tag &operator=(const Tag &Data) noexcept = delete;\n\n  Tag(SecretVec &&Data) noexcept : Data(std::move(Data)) {}\n\n  size_t len() const noexcept { return Data.size(); }\n\n  /// The function MUST return `__WASI_CRYPTO_ERRNO_INVALID_TAG` if the\n  /// tags don't match.\n  WasiCryptoExpect<void> verify(Span<const uint8_t> RawTag) const noexcept;\n\n  WasiCryptoExpect<size_t> pull(Span<uint8_t> Raw) const noexcept;\n\nprivate:\n  SecretVec Data;\n};\n\n} // namespace Symmetric\n} // namespace WasiCrypto\n} // namespace Host\n} // namespace WasmEdge\n",
    "chunks": [
      {
        "chunk_id": "doc_51_chunk_0",
        "original_index": 0,
        "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n//===-- wasmedge/plugins/wasi_crypto/symmetric/tag.h - Symmetric Tag class ===//\n//\n// Part of the WasmEdge Project.\n//\n//===----------------------------------------------------------------------===//\n///\n/// \\file\n/// This file contains the Symmetric Tag definition.\n///\n//===----------------------------------------------------------------------===//\n#pragma once\n\n"
      },
      {
        "chunk_id": "doc_51_chunk_1",
        "original_index": 1,
        "content": "#include \"utils/error.h\"\n#include \"utils/secret_vec.h\"\n\n#include \"common/span.h\"\n\n#include <memory>\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasiCrypto {\nnamespace Symmetric {\n\n/// Authentication tag, that can be verified without channels using the provided\n/// APIs. Very small and no streaming.\n///\n/// More detail:\n/// https://github.com/WebAssembly/wasi-crypto/blob/main/docs/wasi-crypto.md#authentication-tags\nclass Tag {\npublic:\n  Tag(Tag &&Data) noexcept = default;\n  Tag &operator=(Tag &&Data) noexcept = default;\n  Tag(const Tag &Data) noexcept = delete;\n  Tag &operator=(const Tag &Data) noexcept = delete;\n\n"
      },
      {
        "chunk_id": "doc_51_chunk_2",
        "original_index": 2,
        "content": "  Tag(SecretVec &&Data) noexcept : Data(std::move(Data)) {}\n\n  size_t len() const noexcept { return Data.size(); }\n\n  /// The function MUST return `__WASI_CRYPTO_ERRNO_INVALID_TAG` if the\n  /// tags don't match.\n  WasiCryptoExpect<void> verify(Span<const uint8_t> RawTag) const noexcept;\n\n  WasiCryptoExpect<size_t> pull(Span<uint8_t> Raw) const noexcept;\n\nprivate:\n  SecretVec Data;\n};\n\n} // namespace Symmetric\n} // namespace WasiCrypto\n} // namespace Host\n} // namespace WasmEdge\n"
      }
    ]
  },
  {
    "doc_id": "doc_52",
    "original_uuid": "0de15e15952dddf36ca2fc607967a2513a2d7ccf59b95710f1091d5b53819238",
    "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n#include \"loader/serialize.h\"\n\n#include <cstdint>\n#include <gtest/gtest.h>\n#include <vector>\n\nnamespace {\n\nWasmEdge::Configure Conf;\nWasmEdge::Loader::Serializer Ser(Conf);\n\nWasmEdge::AST::CodeSection\ncreateCodeSec(std::vector<WasmEdge::AST::Instruction> Instructions) {\n  WasmEdge::AST::CodeSection CodeSec;\n  WasmEdge::AST::CodeSegment CodeSeg;\n  WasmEdge::AST::Expression Expr;\n  Expr.getInstrs() = Instructions;\n  CodeSeg.getExpr() = Expr;\n  CodeSec.getContent().push_back(CodeSeg);\n  return CodeSec;\n}\n\nTEST(SerializeInstructionTest, SerializeBlockControlInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 1. Test block control instructions.\n  //\n  //   1.  Serialize block with only end operation.\n  //   2.  Serialize loop with only end operation.\n  //   3.  Serialize block with instructions.\n  //   4.  Serialize loop with instructions.\n\n  WasmEdge::AST::Instruction Block(WasmEdge::OpCode::Block);\n  WasmEdge::AST::Instruction Loop(WasmEdge::OpCode::Loop);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n  WasmEdge::AST::Instruction I32Eqz(WasmEdge::OpCode::I32__eqz);\n  WasmEdge::AST::Instruction I32Eq(WasmEdge::OpCode::I32__eq);\n  WasmEdge::AST::Instruction I32Ne(WasmEdge::OpCode::I32__ne);\n\n  Block.setEmptyBlockType();\n  Instructions = {Block, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x07U, // Content size = 7\n      0x01U, // Vector length = 1\n      0x05U, // Code segment size = 5\n      0x00U, // Local vec(0)\n      0x02U, // OpCode Block.\n      0x40U, // Block type.\n      0x0BU, // OpCode End.\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  Loop.setEmptyBlockType();\n  Instructions = {Loop, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x07U, // Content size = 7\n      0x01U, // Vector length = 1\n      0x05U, // Code segment size = 5\n      0x00U, // Local vec(0)\n      0x03U, // OpCode Loop.\n      0x40U, // Block type.\n      0x0BU, // OpCode End.\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  Loop.setEmptyBlockType();\n  Instructions = {Block, I32Eqz, I32Eq, I32Ne, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,               // Code section\n      0x0AU,               // Content size = 10\n      0x01U,               // Vector length = 1\n      0x08U,               // Code segment size = 8\n      0x00U,               // Local vec(0)\n      0x02U,               // OpCode Block.\n      0x40U,               // Block type.\n      0x45U, 0x46U, 0x47U, // Valid OpCodes.\n      0x0BU,               // OpCode End.\n      0x0BU                // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  Loop.setEmptyBlockType();\n  Instructions = {Loop, I32Eqz, I32Eq, I32Ne, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,               // Code section\n      0x0AU,               // Content size = 10\n      0x01U,               // Vector length = 1\n      0x08U,               // Code segment size = 8\n      0x00U,               // Local vec(0)\n      0x03U,               // OpCode Loop.\n      0x40U,               // Block type.\n      0x45U, 0x46U, 0x47U, // Valid OpCodes.\n      0x0BU,               // OpCode End.\n      0x0BU                // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\nTEST(SerializeInstructionTest, SerializeIfElseControlInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 2. Test serialize if-else control instruction.\n  //\n  //   1.  Serialize if statement with only end operation.\n  //   2.  Serialize if and else statements with only end operation.\n  //   3.  Serialize if statement with instructions.\n  //   4.  Serialize if and else statements with instructions.\n\n  WasmEdge::AST::Instruction If(WasmEdge::OpCode::If);\n  WasmEdge::AST::Instruction Else(WasmEdge::OpCode::Else);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n  WasmEdge::AST::Instruction I32Eqz(WasmEdge::OpCode::I32__eqz);\n  WasmEdge::AST::Instruction I32Eq(WasmEdge::OpCode::I32__eq);\n  WasmEdge::AST::Instruction I32Ne(WasmEdge::OpCode::I32__ne);\n\n  If.setEmptyBlockType();\n  Instructions = {If, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x07U, // Content size = 7\n      0x01U, // Vector length = 1\n      0x05U, // Code segment size = 5\n      0x00U, // Local vec(0)\n      0x04U, // OpCode If.\n      0x40U, // Block type.\n      0x0BU, // OpCode End.\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  If.setEmptyBlockType();\n  Instructions = {If, Else, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x08U, // Content size = 8\n      0x01U, // Vector length = 1\n      0x06U, // Code segment size = 6\n      0x00U, // Local vec(0)\n      0x04U, // OpCode If.\n      0x40U, // Block type.\n      0x05U, // OpCode Else\n      0x0BU, // OpCode End.\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  If.setEmptyBlockType();\n  Instructions = {If, I32Eqz, I32Eq, I32Ne, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,               // Code section\n      0x0AU,               // Content size = 10\n      0x01U,               // Vector length = 1\n      0x08U,               // Code segment size = 8\n      0x00U,               // Local vec(0)\n      0x04U,               // OpCode If.\n      0x40U,               // Block type.\n      0x45U, 0x46U, 0x47U, // Valid OpCodes in if statement.\n      0x0BU,               // OpCode End.\n      0x0BU                // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  If.setEmptyBlockType();\n  Instructions = {If,     I32Eqz, I32Eq, I32Ne, Else,\n                  I32Eqz, I32Eq,  I32Ne, End,   End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,               // Code section\n      0x0EU,               // Content size = 14\n      0x01U,               // Vector length = 1\n      0x0CU,               // Code segment size = 12\n      0x00U,               // Local vec(0)\n      0x04U,               // OpCode If.\n      0x40U,               // Block type.\n      0x45U, 0x46U, 0x47U, // Valid OpCodes in if statement.\n      0x05U,               // OpCode Else\n      0x45U, 0x46U, 0x47U, // Valid OpCodes in else statement.\n      0x0BU,               // OpCode End.\n      0x0BU                // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\nTEST(SerializeInstructionTest, SerializeBrControlInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 3. Test branch control instructions.\n  //\n  //   1.  Serialize valid label index.\n\n  WasmEdge::AST::Instruction Br(WasmEdge::OpCode::Br);\n  WasmEdge::AST::Instruction BrIf(WasmEdge::OpCode::Br_if);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n  Br.getJump().TargetIndex = 0xFFFFFFFFU;\n  Instructions = {Br, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0AU,                             // Content size = 10\n      0x01U,                             // Vector length = 1\n      0x08U,                             // Code segment size = 8\n      0x00U,                             // Local vec(0)\n      0x0CU,                             // OpCode Br.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Label index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  BrIf.getJump().TargetIndex = 0xFFFFFFFFU;\n  Instructions = {BrIf, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected[5] = 0x0DU; // OpCode Br_if.\n  EXPECT_EQ(Output, Expected);\n}\n\nTEST(SerializeInstructionTest, SerializeBrTableControlInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 4. Test branch table control instruction.\n  //\n  //   1.  Serialize instruction with empty label vector.\n  //   2.  Serialize instruction with label vector.\n\n  WasmEdge::AST::Instruction BrTable(WasmEdge::OpCode::Br_table);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n  BrTable.setLabelListSize(1);\n  BrTable.getLabelList()[0].TargetIndex = 0xFFFFFFFFU;\n  Instructions = {BrTable, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0BU,                             // Content size = 11\n      0x01U,                             // Vector length = 1\n      0x09U,                             // Code segment size = 9\n      0x00U,                             // Local vec(0)\n      0x0EU,                             // OpCode Br_table.\n      0x00U,                             // Vector length = 0\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Label index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  BrTable.setLabelListSize(4);\n  BrTable.getLabelList()[0].TargetIndex = 0xFFFFFFF1U;\n  BrTable.getLabelList()[1].TargetIndex = 0xFFFFFFF2U;\n  BrTable.getLabelList()[2].TargetIndex = 0xFFFFFFF3U;\n  BrTable.getLabelList()[3].TargetIndex = 0xFFFFFFFFU;\n  Instructions = {BrTable, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x1AU,                             // Content size = 26\n      0x01U,                             // Vector length = 1\n      0x18U,                             // Code segment size = 24\n      0x00U,                             // Local vec(0)\n      0x0EU,                             // OpCode Br_table.\n      0x03U,                             // Vector length = 3\n      0xF1U, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // vec[0]\n      0xF2U, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // vec[1]\n      0xF3U, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // vec[2]\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Label index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\nTEST(SerializeInstructionTest, SerializeCallControlInstruction) {\n  WasmEdge::Configure ConfNoRefType;\n  ConfNoRefType.removeProposal(WasmEdge::Proposal::ReferenceTypes);\n  WasmEdge::Loader::Serializer SerNoRefType(ConfNoRefType);\n\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 5. Test call control instructions.\n  //\n  //   1.  Serialize call instruction with valid type index.\n  //   2.  Serialize call_indirect instruction with valid type and table index.\n  //   3.  Serialize call_indirect instruction with invalid table index without\n  //       Ref-Types proposal.\n\n  WasmEdge::AST::Instruction Call(WasmEdge::OpCode::Call);\n  WasmEdge::AST::Instruction CallIndirect(WasmEdge::OpCode::Call_indirect);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n  Call.getTargetIndex() = 0xFFFFFFFFU;\n  Instructions = {Call, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0AU,                             // Content size = 10\n      0x01U,                             // Vector length = 1\n      0x08U,                             // Code segment size = 8\n      0x00U,                             // Local vec(0)\n      0x10U,                             // OpCode Call.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Function type index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  CallIndirect.getTargetIndex() = 0xFFFFFFFFU;\n  CallIndirect.getSourceIndex() = 0x05U;\n  Instructions = {CallIndirect, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0BU,                             // Content size = 11\n      0x01U,                             // Vector length = 1\n      0x09U,                             // Code segment size = 9\n      0x00U,                             // Local vec(0)\n      0x11U,                             // OpCode Call_indirect.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Type index.\n      0x05U,                             // Table index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  EXPECT_FALSE(\n      SerNoRefType.serializeSection(createCodeSec(Instructions), Output));\n}\n\nTEST(SerializeInstructionTest, SerializeReferenceInstruction) {\n  WasmEdge::Configure ConfNoRefType;\n  ConfNoRefType.removeProposal(WasmEdge::Proposal::ReferenceTypes);\n  WasmEdge::Loader::Serializer SerNoRefType(ConfNoRefType);\n\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 6. Test reference instructions.\n  //\n  //   1.  Serialize function reference type.\n  //   2.  Serialize invalid reference type without Ref-Types proposal.\n\n  WasmEdge::AST::Instruction RefNull(WasmEdge::OpCode::Ref__null);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n  RefNull.setValType(WasmEdge::TypeCode::FuncRef);\n  Instructions = {RefNull, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x06U, // Content size = 6\n      0x01U, // Vector length = 1\n      0x04U, // Code segment size = 4\n      0x00U, // Local vec(0)\n      0xD0U, // OpCode Ref__null.\n      0x70U, // FuncRef\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  RefNull.setValType(WasmEdge::TypeCode::ExternRef);\n  Instructions = {RefNull, End};\n  EXPECT_FALSE(\n      SerNoRefType.serializeSection(createCodeSec(Instructions), Output));\n}\n\nTEST(SerializeInstructionTest, SerializeParametricInstruction) {\n  WasmEdge::Configure ConfNoSIMD;\n  ConfNoSIMD.removeProposal(WasmEdge::Proposal::SIMD);\n  WasmEdge::Loader::Serializer SerNoSIMD(ConfNoSIMD);\n\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 7. Test parametric instructions.\n  //\n  //   1.  Serialize valid select_t instruction with value type list.\n  //   2.  Serialize invalid value type list without SIMD proposal.\n\n  WasmEdge::AST::Instruction SelectT(WasmEdge::OpCode::Select_t);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n  SelectT.setValTypeListSize(2);\n  SelectT.getValTypeList()[0] = WasmEdge::TypeCode::I32;\n  SelectT.getValTypeList()[1] = WasmEdge::TypeCode::I64;\n  Instructions = {SelectT, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,        // Code section\n      0x08U,        // Content size = 8\n      0x01U,        // Vector length = 1\n      0x06U,        // Code segment size = 6\n      0x00U,        // Local vec(0)\n      0x1CU,        // OpCode Select_t.\n      0x02U,        // Vector length = 2\n      0x7FU, 0x7EU, // Value types\n      0x0BU         // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  SelectT.getValTypeList()[0] = WasmEdge::TypeCode::V128;\n  SelectT.getValTypeList()[1] = WasmEdge::TypeCode::V128;\n  Instructions = {SelectT, End};\n  EXPECT_FALSE(SerNoSIMD.serializeSection(createCodeSec(Instructions), Output));\n}\n\nTEST(SerializeInstructionTest, SerializeVariableInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 8. Test variable instructions.\n  //\n  //   1.  Serialize valid local or global index.\n\n  WasmEdge::AST::Instruction LocalGet(WasmEdge::OpCode::Local__get);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n  LocalGet.getTargetIndex() = 0xFFFFFFFFU;\n  Instructions = {LocalGet, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0AU,                             // Content size = 10\n      0x01U,                             // Vector length = 1\n      0x08U,                             // Code segment size = 8\n      0x00U,                             // Local vec(0)\n      0x20U,                             // OpCode Local__get.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Local index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\nTEST(SerializeInstructionTest, SerializeTableInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 9. Test table instructions.\n  //\n  //   1.  Serialize table_get instruction.\n  //   2.  Serialize table_init instruction.\n\n  WasmEdge::AST::Instruction TableGet(WasmEdge::OpCode::Table__get);\n  WasmEdge::AST::Instruction TableInit(WasmEdge::OpCode::Table__init);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n  TableGet.getTargetIndex() = 0xFFFFFFFFU;\n  Instructions = {TableGet, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0AU,                             // Content size = 10\n      0x01U,                             // Vector length = 1\n      0x08U,                             // Code segment size = 8\n      0x00U,                             // Local vec(0)\n      0x25U,                             // OpCode Table__get.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Table index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  TableInit.getSourceIndex() = 0x05U;\n  TableInit.getTargetIndex() = 0xFFFFFFFFU;\n  Instructions = {TableInit, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0CU,                             // Content size = 12\n      0x01U,                             // Vector length = 1\n      0x0AU,                             // Code segment size = 10\n      0x00U,                             // Local vec(0)\n      0xFCU, 0x0CU,                      // OpCode Table__init.\n      0x05U,                             // Element idx.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Table index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\nTEST(SerializeInstructionTest, SerializeMemoryInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 10. Test memory instructions.\n  //\n  //   1.  Serialize memory_grow instruction.\n  //   2.  Serialize i32_load instruction.\n\n  WasmEdge::AST::Instruction MemoryGrow(WasmEdge::OpCode::Memory__grow);\n  WasmEdge::AST::Instruction I32Load(WasmEdge::OpCode::I32__load);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n  Instructions = {MemoryGrow, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x06U, // Content size = 6\n      0x01U, // Vector length = 1\n      0x04U, // Code segment size = 4\n      0x00U, // Local vec(0)\n      0x40U, // OpCode Memory__grow.\n      0x00U, // Checking byte\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  I32Load.getMemoryAlign() = 0xFFFFFFFFU;\n  I32Load.getMemoryOffset() = 0xFFFFFFFEU;\n  Instructions = {I32Load, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0FU,                             // Content size = 15\n      0x01U,                             // Vector length = 1\n      0x0DU,                             // Code segment size = 13\n      0x00U,                             // Local vec(0)\n      0x28U,                             // OpCode I32__load.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Align.\n      0xFEU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Offset.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  I32Load.getMemoryAlign() = 0xFFFFFFFFU;\n  I32Load.getMemoryOffset() = 0xFFFFFFFEU;\n  Instructions = {I32Load, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0FU,                             // Content size = 15\n      0x01U,                             // Vector length = 1\n      0x0DU,                             // Code segment size = 13\n      0x00U,                             // Local vec(0)\n      0x28U,                             // OpCode I32__load.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Align.\n      0xFEU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Offset.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\nTEST(SerializeInstructionTest, SerializeConstInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 11. Test const numeric instructions.\n  //\n  //   1.  Serialize I32 const numeric instruction.\n  //   2.  Serialize I64 const numeric instruction.\n  //   3.  Serialize F32 const numeric instruction.\n  //   4.  Serialize F64 const numeric instruction.\n\n  WasmEdge::AST::Instruction I32Const(WasmEdge::OpCode::I32__const);\n  WasmEdge::AST::Instruction I64Const(WasmEdge::OpCode::I64__const);\n  WasmEdge::AST::Instruction F32Const(WasmEdge::OpCode::F32__const);\n  WasmEdge::AST::Instruction F64Const(WasmEdge::OpCode::F64__const);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n  I32Const.setNum(-123456);\n  Instructions = {I32Const, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,               // Code section\n      0x08U,               // Content size = 8\n      0x01U,               // Vector length = 1\n      0x06U,               // Code segment size = 6\n      0x00U,               // Local vec(0)\n      0x41U,               // OpCode I32__const.\n      0xC0U, 0xBBU, 0x78U, // I32 -123456.\n      0x0BU                // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  I64Const.setNum(static_cast<uint64_t>(-112233445566L));\n  Instructions = {I64Const, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                                    // Code section\n      0x0BU,                                    // Content size = 11\n      0x01U,                                    // Vector length = 1\n      0x09U,                                    // Code segment size = 9\n      0x00U,                                    // Local vec(0)\n      0x42U,                                    // OpCode I64__const.\n      0xC2U, 0x8EU, 0xF6U, 0xF2U, 0xDDU, 0x7CU, // I64 -112233445566\n      0x0BU                                     // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  F32Const.setNum(static_cast<float>(-0x1.921fb4p+1)); // -3.1415926F\n  Instructions = {F32Const, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                      // Code section\n      0x09U,                      // Content size = 9\n      0x01U,                      // Vector length = 1\n      0x07U,                      // Code segment size = 7\n      0x00U,                      // Local vec(0)\n      0x43U,                      // OpCode F32__const.\n      0xDAU, 0x0FU, 0x49U, 0xC0U, // F32 -3.1415926\n      0x0BU                       // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n  F64Const.setNum(-3.1415926535897932);\n  Instructions = {F64Const, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x0DU, // Content size = 13\n      0x01U, // Vector length = 1\n      0x0BU, // Code segment size = 11\n      0x00U, // Local vec(0)\n      0x44U, // OpCode F64__const.\n      0x18U, 0x2DU, 0x44U, 0x54U,\n      0xFBU, 0x21U, 0x09U, 0xC0U, // F64 -3.1415926535897932\n      0x0BU                       // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n} // namespace\n",
    "chunks": [
      {
        "chunk_id": "doc_52_chunk_0",
        "original_index": 0,
        "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n#include \"loader/serialize.h\"\n\n#include <cstdint>\n#include <gtest/gtest.h>\n#include <vector>\n\nnamespace {\n\nWasmEdge::Configure Conf;\nWasmEdge::Loader::Serializer Ser(Conf);\n\nWasmEdge::AST::CodeSection\ncreateCodeSec(std::vector<WasmEdge::AST::Instruction> Instructions) {\n  WasmEdge::AST::CodeSection CodeSec;\n  WasmEdge::AST::CodeSegment CodeSeg;\n  WasmEdge::AST::Expression Expr;\n  Expr.getInstrs() = Instructions;\n  CodeSeg.getExpr() = Expr;\n  CodeSec.getContent().push_back(CodeSeg);\n  return CodeSec;\n}\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_1",
        "original_index": 1,
        "content": "TEST(SerializeInstructionTest, SerializeBlockControlInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 1. Test block control instructions.\n  //\n  //   1.  Serialize block with only end operation.\n  //   2.  Serialize loop with only end operation.\n  //   3.  Serialize block with instructions.\n  //   4.  Serialize loop with instructions.\n\n  WasmEdge::AST::Instruction Block(WasmEdge::OpCode::Block);\n  WasmEdge::AST::Instruction Loop(WasmEdge::OpCode::Loop);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n  WasmEdge::AST::Instruction I32Eqz(WasmEdge::OpCode::I32__eqz);\n  WasmEdge::AST::Instruction I32Eq(WasmEdge::OpCode::I32__eq);\n  WasmEdge::AST::Instruction I32Ne(WasmEdge::OpCode::I32__ne);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_2",
        "original_index": 2,
        "content": "  Block.setEmptyBlockType();\n  Instructions = {Block, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x07U, // Content size = 7\n      0x01U, // Vector length = 1\n      0x05U, // Code segment size = 5\n      0x00U, // Local vec(0)\n      0x02U, // OpCode Block.\n      0x40U, // Block type.\n      0x0BU, // OpCode End.\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_3",
        "original_index": 3,
        "content": "  Loop.setEmptyBlockType();\n  Instructions = {Loop, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x07U, // Content size = 7\n      0x01U, // Vector length = 1\n      0x05U, // Code segment size = 5\n      0x00U, // Local vec(0)\n      0x03U, // OpCode Loop.\n      0x40U, // Block type.\n      0x0BU, // OpCode End.\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_4",
        "original_index": 4,
        "content": "  Loop.setEmptyBlockType();\n  Instructions = {Block, I32Eqz, I32Eq, I32Ne, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,               // Code section\n      0x0AU,               // Content size = 10\n      0x01U,               // Vector length = 1\n      0x08U,               // Code segment size = 8\n      0x00U,               // Local vec(0)\n      0x02U,               // OpCode Block.\n      0x40U,               // Block type.\n      0x45U, 0x46U, 0x47U, // Valid OpCodes.\n      0x0BU,               // OpCode End.\n      0x0BU                // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_5",
        "original_index": 5,
        "content": "  Loop.setEmptyBlockType();\n  Instructions = {Loop, I32Eqz, I32Eq, I32Ne, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,               // Code section\n      0x0AU,               // Content size = 10\n      0x01U,               // Vector length = 1\n      0x08U,               // Code segment size = 8\n      0x00U,               // Local vec(0)\n      0x03U,               // OpCode Loop.\n      0x40U,               // Block type.\n      0x45U, 0x46U, 0x47U, // Valid OpCodes.\n      0x0BU,               // OpCode End.\n      0x0BU                // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_6",
        "original_index": 6,
        "content": "TEST(SerializeInstructionTest, SerializeIfElseControlInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 2. Test serialize if-else control instruction.\n  //\n  //   1.  Serialize if statement with only end operation.\n  //   2.  Serialize if and else statements with only end operation.\n  //   3.  Serialize if statement with instructions.\n  //   4.  Serialize if and else statements with instructions.\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_7",
        "original_index": 7,
        "content": "  WasmEdge::AST::Instruction If(WasmEdge::OpCode::If);\n  WasmEdge::AST::Instruction Else(WasmEdge::OpCode::Else);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n  WasmEdge::AST::Instruction I32Eqz(WasmEdge::OpCode::I32__eqz);\n  WasmEdge::AST::Instruction I32Eq(WasmEdge::OpCode::I32__eq);\n  WasmEdge::AST::Instruction I32Ne(WasmEdge::OpCode::I32__ne);\n\n  If.setEmptyBlockType();\n  Instructions = {If, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x07U, // Content size = 7\n      0x01U, // Vector length = 1\n      0x05U, // Code segment size = 5\n      0x00U, // Local vec(0)\n      0x04U, // OpCode If.\n      0x40U, // Block type.\n      0x0BU, // OpCode End.\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_8",
        "original_index": 8,
        "content": "  If.setEmptyBlockType();\n  Instructions = {If, Else, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x08U, // Content size = 8\n      0x01U, // Vector length = 1\n      0x06U, // Code segment size = 6\n      0x00U, // Local vec(0)\n      0x04U, // OpCode If.\n      0x40U, // Block type.\n      0x05U, // OpCode Else\n      0x0BU, // OpCode End.\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_9",
        "original_index": 9,
        "content": "  If.setEmptyBlockType();\n  Instructions = {If, I32Eqz, I32Eq, I32Ne, End, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,               // Code section\n      0x0AU,               // Content size = 10\n      0x01U,               // Vector length = 1\n      0x08U,               // Code segment size = 8\n      0x00U,               // Local vec(0)\n      0x04U,               // OpCode If.\n      0x40U,               // Block type.\n      0x45U, 0x46U, 0x47U, // Valid OpCodes in if statement.\n      0x0BU,               // OpCode End.\n      0x0BU                // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_10",
        "original_index": 10,
        "content": "  If.setEmptyBlockType();\n  Instructions = {If,     I32Eqz, I32Eq, I32Ne, Else,\n                  I32Eqz, I32Eq,  I32Ne, End,   End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,               // Code section\n      0x0EU,               // Content size = 14\n      0x01U,               // Vector length = 1\n      0x0CU,               // Code segment size = 12\n      0x00U,               // Local vec(0)\n      0x04U,               // OpCode If.\n      0x40U,               // Block type.\n      0x45U, 0x46U, 0x47U, // Valid OpCodes in if statement.\n      0x05U,               // OpCode Else\n      0x45U, 0x46U, 0x47U, // Valid OpCodes in else statement.\n      0x0BU,               // OpCode End.\n      0x0BU                // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_11",
        "original_index": 11,
        "content": "TEST(SerializeInstructionTest, SerializeBrControlInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 3. Test branch control instructions.\n  //\n  //   1.  Serialize valid label index.\n\n  WasmEdge::AST::Instruction Br(WasmEdge::OpCode::Br);\n  WasmEdge::AST::Instruction BrIf(WasmEdge::OpCode::Br_if);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_12",
        "original_index": 12,
        "content": "  Br.getJump().TargetIndex = 0xFFFFFFFFU;\n  Instructions = {Br, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0AU,                             // Content size = 10\n      0x01U,                             // Vector length = 1\n      0x08U,                             // Code segment size = 8\n      0x00U,                             // Local vec(0)\n      0x0CU,                             // OpCode Br.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Label index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_13",
        "original_index": 13,
        "content": "  BrIf.getJump().TargetIndex = 0xFFFFFFFFU;\n  Instructions = {BrIf, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected[5] = 0x0DU; // OpCode Br_if.\n  EXPECT_EQ(Output, Expected);\n}\n\nTEST(SerializeInstructionTest, SerializeBrTableControlInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 4. Test branch table control instruction.\n  //\n  //   1.  Serialize instruction with empty label vector.\n  //   2.  Serialize instruction with label vector.\n\n  WasmEdge::AST::Instruction BrTable(WasmEdge::OpCode::Br_table);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_14",
        "original_index": 14,
        "content": "  BrTable.setLabelListSize(1);\n  BrTable.getLabelList()[0].TargetIndex = 0xFFFFFFFFU;\n  Instructions = {BrTable, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0BU,                             // Content size = 11\n      0x01U,                             // Vector length = 1\n      0x09U,                             // Code segment size = 9\n      0x00U,                             // Local vec(0)\n      0x0EU,                             // OpCode Br_table.\n      0x00U,                             // Vector length = 0\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Label index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_15",
        "original_index": 15,
        "content": "  BrTable.setLabelListSize(4);\n  BrTable.getLabelList()[0].TargetIndex = 0xFFFFFFF1U;\n  BrTable.getLabelList()[1].TargetIndex = 0xFFFFFFF2U;\n  BrTable.getLabelList()[2].TargetIndex = 0xFFFFFFF3U;\n  BrTable.getLabelList()[3].TargetIndex = 0xFFFFFFFFU;\n  Instructions = {BrTable, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n"
      },
      {
        "chunk_id": "doc_52_chunk_16",
        "original_index": 16,
        "content": "      0x1AU,                             // Content size = 26\n      0x01U,                             // Vector length = 1\n      0x18U,                             // Code segment size = 24\n      0x00U,                             // Local vec(0)\n      0x0EU,                             // OpCode Br_table.\n      0x03U,                             // Vector length = 3\n      0xF1U, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // vec[0]\n      0xF2U, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // vec[1]\n      0xF3U, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // vec[2]\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Label index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_17",
        "original_index": 17,
        "content": "TEST(SerializeInstructionTest, SerializeCallControlInstruction) {\n  WasmEdge::Configure ConfNoRefType;\n  ConfNoRefType.removeProposal(WasmEdge::Proposal::ReferenceTypes);\n  WasmEdge::Loader::Serializer SerNoRefType(ConfNoRefType);\n\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 5. Test call control instructions.\n  //\n  //   1.  Serialize call instruction with valid type index.\n  //   2.  Serialize call_indirect instruction with valid type and table index.\n  //   3.  Serialize call_indirect instruction with invalid table index without\n  //       Ref-Types proposal.\n\n  WasmEdge::AST::Instruction Call(WasmEdge::OpCode::Call);\n  WasmEdge::AST::Instruction CallIndirect(WasmEdge::OpCode::Call_indirect);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_18",
        "original_index": 18,
        "content": "  Call.getTargetIndex() = 0xFFFFFFFFU;\n  Instructions = {Call, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0AU,                             // Content size = 10\n      0x01U,                             // Vector length = 1\n      0x08U,                             // Code segment size = 8\n      0x00U,                             // Local vec(0)\n      0x10U,                             // OpCode Call.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Function type index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_19",
        "original_index": 19,
        "content": "  CallIndirect.getTargetIndex() = 0xFFFFFFFFU;\n  CallIndirect.getSourceIndex() = 0x05U;\n  Instructions = {CallIndirect, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0BU,                             // Content size = 11\n      0x01U,                             // Vector length = 1\n      0x09U,                             // Code segment size = 9\n      0x00U,                             // Local vec(0)\n      0x11U,                             // OpCode Call_indirect.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Type index.\n      0x05U,                             // Table index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_20",
        "original_index": 20,
        "content": "  EXPECT_FALSE(\n      SerNoRefType.serializeSection(createCodeSec(Instructions), Output));\n}\n\nTEST(SerializeInstructionTest, SerializeReferenceInstruction) {\n  WasmEdge::Configure ConfNoRefType;\n  ConfNoRefType.removeProposal(WasmEdge::Proposal::ReferenceTypes);\n  WasmEdge::Loader::Serializer SerNoRefType(ConfNoRefType);\n\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 6. Test reference instructions.\n  //\n  //   1.  Serialize function reference type.\n  //   2.  Serialize invalid reference type without Ref-Types proposal.\n\n  WasmEdge::AST::Instruction RefNull(WasmEdge::OpCode::Ref__null);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_21",
        "original_index": 21,
        "content": "  RefNull.setValType(WasmEdge::TypeCode::FuncRef);\n  Instructions = {RefNull, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x06U, // Content size = 6\n      0x01U, // Vector length = 1\n      0x04U, // Code segment size = 4\n      0x00U, // Local vec(0)\n      0xD0U, // OpCode Ref__null.\n      0x70U, // FuncRef\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_22",
        "original_index": 22,
        "content": "  RefNull.setValType(WasmEdge::TypeCode::ExternRef);\n  Instructions = {RefNull, End};\n  EXPECT_FALSE(\n      SerNoRefType.serializeSection(createCodeSec(Instructions), Output));\n}\n\nTEST(SerializeInstructionTest, SerializeParametricInstruction) {\n  WasmEdge::Configure ConfNoSIMD;\n  ConfNoSIMD.removeProposal(WasmEdge::Proposal::SIMD);\n  WasmEdge::Loader::Serializer SerNoSIMD(ConfNoSIMD);\n\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 7. Test parametric instructions.\n  //\n  //   1.  Serialize valid select_t instruction with value type list.\n  //   2.  Serialize invalid value type list without SIMD proposal.\n\n  WasmEdge::AST::Instruction SelectT(WasmEdge::OpCode::Select_t);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_23",
        "original_index": 23,
        "content": "  SelectT.setValTypeListSize(2);\n  SelectT.getValTypeList()[0] = WasmEdge::TypeCode::I32;\n  SelectT.getValTypeList()[1] = WasmEdge::TypeCode::I64;\n  Instructions = {SelectT, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,        // Code section\n      0x08U,        // Content size = 8\n      0x01U,        // Vector length = 1\n      0x06U,        // Code segment size = 6\n      0x00U,        // Local vec(0)\n      0x1CU,        // OpCode Select_t.\n      0x02U,        // Vector length = 2\n      0x7FU, 0x7EU, // Value types\n      0x0BU         // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_24",
        "original_index": 24,
        "content": "  SelectT.getValTypeList()[0] = WasmEdge::TypeCode::V128;\n  SelectT.getValTypeList()[1] = WasmEdge::TypeCode::V128;\n  Instructions = {SelectT, End};\n  EXPECT_FALSE(SerNoSIMD.serializeSection(createCodeSec(Instructions), Output));\n}\n\nTEST(SerializeInstructionTest, SerializeVariableInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 8. Test variable instructions.\n  //\n  //   1.  Serialize valid local or global index.\n\n  WasmEdge::AST::Instruction LocalGet(WasmEdge::OpCode::Local__get);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_25",
        "original_index": 25,
        "content": "  LocalGet.getTargetIndex() = 0xFFFFFFFFU;\n  Instructions = {LocalGet, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0AU,                             // Content size = 10\n      0x01U,                             // Vector length = 1\n      0x08U,                             // Code segment size = 8\n      0x00U,                             // Local vec(0)\n      0x20U,                             // OpCode Local__get.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Local index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_26",
        "original_index": 26,
        "content": "TEST(SerializeInstructionTest, SerializeTableInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 9. Test table instructions.\n  //\n  //   1.  Serialize table_get instruction.\n  //   2.  Serialize table_init instruction.\n\n  WasmEdge::AST::Instruction TableGet(WasmEdge::OpCode::Table__get);\n  WasmEdge::AST::Instruction TableInit(WasmEdge::OpCode::Table__init);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_27",
        "original_index": 27,
        "content": "  TableGet.getTargetIndex() = 0xFFFFFFFFU;\n  Instructions = {TableGet, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0AU,                             // Content size = 10\n      0x01U,                             // Vector length = 1\n      0x08U,                             // Code segment size = 8\n      0x00U,                             // Local vec(0)\n      0x25U,                             // OpCode Table__get.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Table index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_28",
        "original_index": 28,
        "content": "  TableInit.getSourceIndex() = 0x05U;\n  TableInit.getTargetIndex() = 0xFFFFFFFFU;\n  Instructions = {TableInit, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0CU,                             // Content size = 12\n      0x01U,                             // Vector length = 1\n      0x0AU,                             // Code segment size = 10\n      0x00U,                             // Local vec(0)\n      0xFCU, 0x0CU,                      // OpCode Table__init.\n      0x05U,                             // Element idx.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Table index.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_29",
        "original_index": 29,
        "content": "TEST(SerializeInstructionTest, SerializeMemoryInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 10. Test memory instructions.\n  //\n  //   1.  Serialize memory_grow instruction.\n  //   2.  Serialize i32_load instruction.\n\n  WasmEdge::AST::Instruction MemoryGrow(WasmEdge::OpCode::Memory__grow);\n  WasmEdge::AST::Instruction I32Load(WasmEdge::OpCode::I32__load);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n  Instructions = {MemoryGrow, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x06U, // Content size = 6\n      0x01U, // Vector length = 1\n      0x04U, // Code segment size = 4\n      0x00U, // Local vec(0)\n      0x40U, // OpCode Memory__grow.\n      0x00U, // Checking byte\n      0x0BU  // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_30",
        "original_index": 30,
        "content": "  I32Load.getMemoryAlign() = 0xFFFFFFFFU;\n  I32Load.getMemoryOffset() = 0xFFFFFFFEU;\n  Instructions = {I32Load, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0FU,                             // Content size = 15\n      0x01U,                             // Vector length = 1\n      0x0DU,                             // Code segment size = 13\n      0x00U,                             // Local vec(0)\n      0x28U,                             // OpCode I32__load.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Align.\n      0xFEU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Offset.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_31",
        "original_index": 31,
        "content": "  I32Load.getMemoryAlign() = 0xFFFFFFFFU;\n  I32Load.getMemoryOffset() = 0xFFFFFFFEU;\n  Instructions = {I32Load, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                             // Code section\n      0x0FU,                             // Content size = 15\n      0x01U,                             // Vector length = 1\n      0x0DU,                             // Code segment size = 13\n      0x00U,                             // Local vec(0)\n      0x28U,                             // OpCode I32__load.\n      0xFFU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Align.\n      0xFEU, 0xFFU, 0xFFU, 0xFFU, 0x0FU, // Offset.\n      0x0BU                              // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_32",
        "original_index": 32,
        "content": "TEST(SerializeInstructionTest, SerializeConstInstruction) {\n  std::vector<uint8_t> Expected;\n  std::vector<uint8_t> Output;\n  std::vector<WasmEdge::AST::Instruction> Instructions;\n\n  // 11. Test const numeric instructions.\n  //\n  //   1.  Serialize I32 const numeric instruction.\n  //   2.  Serialize I64 const numeric instruction.\n  //   3.  Serialize F32 const numeric instruction.\n  //   4.  Serialize F64 const numeric instruction.\n\n  WasmEdge::AST::Instruction I32Const(WasmEdge::OpCode::I32__const);\n  WasmEdge::AST::Instruction I64Const(WasmEdge::OpCode::I64__const);\n  WasmEdge::AST::Instruction F32Const(WasmEdge::OpCode::F32__const);\n  WasmEdge::AST::Instruction F64Const(WasmEdge::OpCode::F64__const);\n  WasmEdge::AST::Instruction End(WasmEdge::OpCode::End);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_33",
        "original_index": 33,
        "content": "  I32Const.setNum(-123456);\n  Instructions = {I32Const, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,               // Code section\n      0x08U,               // Content size = 8\n      0x01U,               // Vector length = 1\n      0x06U,               // Code segment size = 6\n      0x00U,               // Local vec(0)\n      0x41U,               // OpCode I32__const.\n      0xC0U, 0xBBU, 0x78U, // I32 -123456.\n      0x0BU                // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_34",
        "original_index": 34,
        "content": "  I64Const.setNum(static_cast<uint64_t>(-112233445566L));\n  Instructions = {I64Const, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                                    // Code section\n      0x0BU,                                    // Content size = 11\n      0x01U,                                    // Vector length = 1\n      0x09U,                                    // Code segment size = 9\n      0x00U,                                    // Local vec(0)\n      0x42U,                                    // OpCode I64__const.\n      0xC2U, 0x8EU, 0xF6U, 0xF2U, 0xDDU, 0x7CU, // I64 -112233445566\n      0x0BU                                     // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_35",
        "original_index": 35,
        "content": "  F32Const.setNum(static_cast<float>(-0x1.921fb4p+1)); // -3.1415926F\n  Instructions = {F32Const, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU,                      // Code section\n      0x09U,                      // Content size = 9\n      0x01U,                      // Vector length = 1\n      0x07U,                      // Code segment size = 7\n      0x00U,                      // Local vec(0)\n      0x43U,                      // OpCode F32__const.\n      0xDAU, 0x0FU, 0x49U, 0xC0U, // F32 -3.1415926\n      0x0BU                       // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n\n"
      },
      {
        "chunk_id": "doc_52_chunk_36",
        "original_index": 36,
        "content": "  F64Const.setNum(-3.1415926535897932);\n  Instructions = {F64Const, End};\n  Output = {};\n  EXPECT_TRUE(Ser.serializeSection(createCodeSec(Instructions), Output));\n  Expected = {\n      0x0AU, // Code section\n      0x0DU, // Content size = 13\n      0x01U, // Vector length = 1\n      0x0BU, // Code segment size = 11\n      0x00U, // Local vec(0)\n      0x44U, // OpCode F64__const.\n      0x18U, 0x2DU, 0x44U, 0x54U,\n      0xFBU, 0x21U, 0x09U, 0xC0U, // F64 -3.1415926535897932\n      0x0BU                       // Expression End.\n  };\n  EXPECT_EQ(Output, Expected);\n}\n} // namespace\n"
      }
    ]
  },
  {
    "doc_id": "doc_53",
    "original_uuid": "adf8199b3afd25d13810e101d05c538903c40967c595241fa0af4553cb5ef823",
    "content": "#pragma once\n\n#include \"common/errcode.h\"\n#include \"host/mock/log.h\"\n#include \"runtime/callingframe.h\"\n#include \"runtime/hostfunc.h\"\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasiLoggingMock {\n\nusing namespace std::literals;\n\nclass Log : public Runtime::HostFunction<Log> {\npublic:\n  Expect<void> body(const Runtime::CallingFrame &, uint32_t, uint32_t, uint32_t,\n                    uint32_t, uint32_t) {\n    printPluginMock(\"wasi-logging\"sv);\n    return Unexpect(ErrCode::Value::HostFuncError);\n  }\n};\n\n} // namespace WasiLoggingMock\n} // namespace Host\n} // namespace WasmEdge",
    "chunks": [
      {
        "chunk_id": "doc_53_chunk_0",
        "original_index": 0,
        "content": "#pragma once\n\n#include \"common/errcode.h\"\n#include \"host/mock/log.h\"\n#include \"runtime/callingframe.h\"\n#include \"runtime/hostfunc.h\"\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasiLoggingMock {\n\nusing namespace std::literals;\n\nclass Log : public Runtime::HostFunction<Log> {\npublic:\n  Expect<void> body(const Runtime::CallingFrame &, uint32_t, uint32_t, uint32_t,\n                    uint32_t, uint32_t) {\n    printPluginMock(\"wasi-logging\"sv);\n    return Unexpect(ErrCode::Value::HostFuncError);\n  }\n};\n\n} // namespace WasiLoggingMock\n} // namespace Host\n} // namespace WasmEdge"
      }
    ]
  },
  {
    "doc_id": "doc_54",
    "original_uuid": "1aebf7d6ad261452293b74e53b8b7afd8c068e3a8e3d2b7216a21055d2ac9a84",
    "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n#include \"common/defines.h\"\n#if WASMEDGE_OS_MACOS\n\n#include \"common/errcode.h\"\n#include \"host/wasi/environ.h\"\n#include \"macos.h\"\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WASI {\n\nWasiExpect<void> Environ::procRaise(__wasi_signal_t Signal) const noexcept {\n  int SysSignal;\n  switch (Signal) {\n  case __WASI_SIGNAL_NONE:\n    SysSignal = 0;\n    break;\n  case __WASI_SIGNAL_HUP:\n    SysSignal = SIGHUP;\n    break;\n  case __WASI_SIGNAL_INT:\n    SysSignal = SIGINT;\n    break;\n  case __WASI_SIGNAL_QUIT:\n    SysSignal = SIGQUIT;\n    break;\n  case __WASI_SIGNAL_ILL:\n    SysSignal = SIGILL;\n    break;\n  case __WASI_SIGNAL_TRAP:\n    SysSignal = SIGTRAP;\n    break;\n  case __WASI_SIGNAL_ABRT:\n    SysSignal = SIGABRT;\n    break;\n  case __WASI_SIGNAL_BUS:\n    SysSignal = SIGBUS;\n    break;\n  case __WASI_SIGNAL_FPE:\n    SysSignal = SIGFPE;\n    break;\n  case __WASI_SIGNAL_KILL:\n    SysSignal = SIGKILL;\n    break;\n  case __WASI_SIGNAL_USR1:\n    SysSignal = SIGUSR1;\n    break;\n  case __WASI_SIGNAL_SEGV:\n    SysSignal = SIGSEGV;\n    break;\n  case __WASI_SIGNAL_USR2:\n    SysSignal = SIGUSR2;\n    break;\n  case __WASI_SIGNAL_PIPE:\n    SysSignal = SIGPIPE;\n    break;\n  case __WASI_SIGNAL_ALRM:\n    SysSignal = SIGALRM;\n    break;\n  case __WASI_SIGNAL_TERM:\n    SysSignal = SIGTERM;\n    break;\n  case __WASI_SIGNAL_CHLD:\n    SysSignal = SIGCHLD;\n    break;\n  case __WASI_SIGNAL_CONT:\n    SysSignal = SIGCONT;\n    break;\n  case __WASI_SIGNAL_STOP:\n    SysSignal = SIGSTOP;\n    break;\n  case __WASI_SIGNAL_TSTP:\n    SysSignal = SIGTSTP;\n    break;\n  case __WASI_SIGNAL_TTIN:\n    SysSignal = SIGTTIN;\n    break;\n  case __WASI_SIGNAL_TTOU:\n    SysSignal = SIGTTOU;\n    break;\n  case __WASI_SIGNAL_URG:\n    SysSignal = SIGURG;\n    break;\n  case __WASI_SIGNAL_XCPU:\n    SysSignal = SIGXCPU;\n    break;\n  case __WASI_SIGNAL_XFSZ:\n    SysSignal = SIGXFSZ;\n    break;\n  case __WASI_SIGNAL_VTALRM:\n    SysSignal = SIGVTALRM;\n    break;\n  case __WASI_SIGNAL_PROF:\n    SysSignal = SIGPROF;\n    break;\n  case __WASI_SIGNAL_WINCH:\n    SysSignal = SIGWINCH;\n    break;\n  case __WASI_SIGNAL_SYS:\n    SysSignal = SIGSYS;\n    break;\n  case __WASI_SIGNAL_POLL:\n  case __WASI_SIGNAL_PWR:\n  default:\n    return WasiUnexpect(__WASI_ERRNO_NOTSUP);\n  }\n  if (auto Res = std::raise(SysSignal); Res != 0) {\n    return WasiUnexpect(fromErrNo(errno));\n  }\n  return {};\n}\n\nWasiExpect<void> Environ::schedYield() const noexcept {\n  ::sched_yield();\n  return {};\n}\n\n} // namespace WASI\n} // namespace Host\n} // namespace WasmEdge\n\n#endif\n",
    "chunks": [
      {
        "chunk_id": "doc_54_chunk_0",
        "original_index": 0,
        "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n#include \"common/defines.h\"\n#if WASMEDGE_OS_MACOS\n\n#include \"common/errcode.h\"\n#include \"host/wasi/environ.h\"\n#include \"macos.h\"\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WASI {\n\nWasiExpect<void> Environ::procRaise(__wasi_signal_t Signal) const noexcept {\n  int SysSignal;\n  switch (Signal) {\n  case __WASI_SIGNAL_NONE:\n    SysSignal = 0;\n    break;\n  case __WASI_SIGNAL_HUP:\n    SysSignal = SIGHUP;\n    break;\n  case __WASI_SIGNAL_INT:\n    SysSignal = SIGINT;\n    break;\n  case __WASI_SIGNAL_QUIT:\n    SysSignal = SIGQUIT;\n    break;\n  case __WASI_SIGNAL_ILL:\n    SysSignal = SIGILL;\n    break;\n  case __WASI_SIGNAL_TRAP:\n    SysSignal = SIGTRAP;\n    break;\n  case __WASI_SIGNAL_ABRT:\n    SysSignal = SIGABRT;\n    break;\n  case __WASI_SIGNAL_BUS:\n    SysSignal = SIGBUS;\n    break;\n  case __WASI_SIGNAL_FPE:\n    SysSignal = SIGFPE;\n    break;\n"
      },
      {
        "chunk_id": "doc_54_chunk_1",
        "original_index": 1,
        "content": "  case __WASI_SIGNAL_KILL:\n    SysSignal = SIGKILL;\n    break;\n  case __WASI_SIGNAL_USR1:\n    SysSignal = SIGUSR1;\n    break;\n  case __WASI_SIGNAL_SEGV:\n    SysSignal = SIGSEGV;\n    break;\n  case __WASI_SIGNAL_USR2:\n    SysSignal = SIGUSR2;\n    break;\n  case __WASI_SIGNAL_PIPE:\n    SysSignal = SIGPIPE;\n    break;\n  case __WASI_SIGNAL_ALRM:\n    SysSignal = SIGALRM;\n    break;\n  case __WASI_SIGNAL_TERM:\n    SysSignal = SIGTERM;\n    break;\n  case __WASI_SIGNAL_CHLD:\n    SysSignal = SIGCHLD;\n    break;\n  case __WASI_SIGNAL_CONT:\n    SysSignal = SIGCONT;\n    break;\n  case __WASI_SIGNAL_STOP:\n    SysSignal = SIGSTOP;\n    break;\n  case __WASI_SIGNAL_TSTP:\n    SysSignal = SIGTSTP;\n    break;\n  case __WASI_SIGNAL_TTIN:\n    SysSignal = SIGTTIN;\n    break;\n  case __WASI_SIGNAL_TTOU:\n    SysSignal = SIGTTOU;\n    break;\n  case __WASI_SIGNAL_URG:\n    SysSignal = SIGURG;\n    break;\n  case __WASI_SIGNAL_XCPU:\n    SysSignal = SIGXCPU;\n    break;\n"
      },
      {
        "chunk_id": "doc_54_chunk_2",
        "original_index": 2,
        "content": "  case __WASI_SIGNAL_XFSZ:\n    SysSignal = SIGXFSZ;\n    break;\n  case __WASI_SIGNAL_VTALRM:\n    SysSignal = SIGVTALRM;\n    break;\n  case __WASI_SIGNAL_PROF:\n    SysSignal = SIGPROF;\n    break;\n  case __WASI_SIGNAL_WINCH:\n    SysSignal = SIGWINCH;\n    break;\n  case __WASI_SIGNAL_SYS:\n    SysSignal = SIGSYS;\n    break;\n  case __WASI_SIGNAL_POLL:\n  case __WASI_SIGNAL_PWR:\n  default:\n    return WasiUnexpect(__WASI_ERRNO_NOTSUP);\n  }\n  if (auto Res = std::raise(SysSignal); Res != 0) {\n    return WasiUnexpect(fromErrNo(errno));\n  }\n  return {};\n}\n\nWasiExpect<void> Environ::schedYield() const noexcept {\n  ::sched_yield();\n  return {};\n}\n\n} // namespace WASI\n} // namespace Host\n} // namespace WasmEdge\n\n#endif\n"
      }
    ]
  },
  {
    "doc_id": "doc_55",
    "original_uuid": "9c45438b59c7592ded6528bf3c12861598a182f05c8e4ee65217800a1e030582",
    "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n#pragma once\n\n#include \"common/errcode.h\"\n#include \"host/mock/log.h\"\n#include \"runtime/callingframe.h\"\n#include \"runtime/hostfunc.h\"\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasiCryptoMock {\n\nusing namespace std::literals;\nstatic inline constexpr const uint32_t kWASICryptoError = 1U;\n\nnamespace Common {\nclass ArrayOutputLen : public Runtime::HostFunction<ArrayOutputLen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass ArrayOutputPull : public Runtime::HostFunction<ArrayOutputPull> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass OptionsOpen : public Runtime::HostFunction<OptionsOpen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass OptionsClose : public Runtime::HostFunction<OptionsClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass OptionsSet : public Runtime::HostFunction<OptionsSet> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass OptionsSetU64 : public Runtime::HostFunction<OptionsSetU64> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint64_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass OptionsSetGuestBuffer\n    : public Runtime::HostFunction<OptionsSetGuestBuffer> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass SecretsManagerOpen : public Runtime::HostFunction<SecretsManagerOpen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass SecretsManagerClose : public Runtime::HostFunction<SecretsManagerClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass SecretsManagerInvalidate\n    : public Runtime::HostFunction<SecretsManagerInvalidate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint64_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n} // namespace Common\n\nnamespace AsymmetricCommon {\nclass KeypairGenerate : public Runtime::HostFunction<KeypairGenerate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairImport : public Runtime::HostFunction<KeypairImport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairGenerateManaged\n    : public Runtime::HostFunction<KeypairGenerateManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairStoreManaged : public Runtime::HostFunction<KeypairStoreManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairReplaceManaged\n    : public Runtime::HostFunction<KeypairReplaceManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairId : public Runtime::HostFunction<KeypairId> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairFromId : public Runtime::HostFunction<KeypairFromId> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint64_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairFromPkAndSk : public Runtime::HostFunction<KeypairFromPkAndSk> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairExport : public Runtime::HostFunction<KeypairExport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairPublickey : public Runtime::HostFunction<KeypairPublickey> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairSecretkey : public Runtime::HostFunction<KeypairSecretkey> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairClose : public Runtime::HostFunction<KeypairClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass PublickeyImport : public Runtime::HostFunction<PublickeyImport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass PublickeyExport : public Runtime::HostFunction<PublickeyExport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass PublickeyVerify : public Runtime::HostFunction<PublickeyVerify> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass PublickeyFromSecretkey\n    : public Runtime::HostFunction<PublickeyFromSecretkey> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass PublickeyClose : public Runtime::HostFunction<PublickeyClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass SecretkeyImport : public Runtime::HostFunction<SecretkeyImport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass SecretkeyExport : public Runtime::HostFunction<SecretkeyExport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass SecretkeyClose : public Runtime::HostFunction<SecretkeyClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n} // namespace AsymmetricCommon\n\nnamespace Kx {\nclass Dh : public Runtime::HostFunction<Dh> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass Encapsulate : public Runtime::HostFunction<Encapsulate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass Decapsulate : public Runtime::HostFunction<Decapsulate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n} // namespace Kx\n\nnamespace Signatures {\nclass Export : public Runtime::HostFunction<Export> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass Import : public Runtime::HostFunction<Import> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateOpen : public Runtime::HostFunction<StateOpen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateUpdate : public Runtime::HostFunction<StateUpdate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateSign : public Runtime::HostFunction<StateSign> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateClose : public Runtime::HostFunction<StateClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass VerificationStateOpen\n    : public Runtime::HostFunction<VerificationStateOpen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass VerificationStateUpdate\n    : public Runtime::HostFunction<VerificationStateUpdate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass VerificationStateVerify\n    : public Runtime::HostFunction<VerificationStateVerify> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass VerificationStateClose\n    : public Runtime::HostFunction<VerificationStateClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass Close : public Runtime::HostFunction<Close> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n} // namespace Signatures\n\nnamespace Symmetric {\nclass KeyGenerate : public Runtime::HostFunction<KeyGenerate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyImport : public Runtime::HostFunction<KeyImport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyExport : public Runtime::HostFunction<KeyExport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyClose : public Runtime::HostFunction<KeyClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyGenerateManaged : public Runtime::HostFunction<KeyGenerateManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyStoreManaged : public Runtime::HostFunction<KeyStoreManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyReplaceManaged : public Runtime::HostFunction<KeyReplaceManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyId : public Runtime::HostFunction<KeyId> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyFromId : public Runtime::HostFunction<KeyFromId> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint64_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateOpen : public Runtime::HostFunction<StateOpen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateClone : public Runtime::HostFunction<StateClone> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateOptionsGet : public Runtime::HostFunction<StateOptionsGet> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateOptionsGetU64 : public Runtime::HostFunction<StateOptionsGetU64> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateClose : public Runtime::HostFunction<StateClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateAbsorb : public Runtime::HostFunction<StateAbsorb> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateSqueeze : public Runtime::HostFunction<StateSqueeze> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateSqueezeTag : public Runtime::HostFunction<StateSqueezeTag> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateSqueezeKey : public Runtime::HostFunction<StateSqueezeKey> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateMaxTagLen : public Runtime::HostFunction<StateMaxTagLen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateEncrypt : public Runtime::HostFunction<StateEncrypt> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateEncryptDetached\n    : public Runtime::HostFunction<StateEncryptDetached> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateDecrypt : public Runtime::HostFunction<StateDecrypt> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateDecryptDetached\n    : public Runtime::HostFunction<StateDecryptDetached> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateRatchet : public Runtime::HostFunction<StateRatchet> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass TagLen : public Runtime::HostFunction<TagLen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass TagPull : public Runtime::HostFunction<TagPull> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass TagVerify : public Runtime::HostFunction<TagVerify> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass TagClose : public Runtime::HostFunction<TagClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n} // namespace Symmetric\n\n} // namespace WasiCryptoMock\n} // namespace Host\n} // namespace WasmEdge\n",
    "chunks": [
      {
        "chunk_id": "doc_55_chunk_0",
        "original_index": 0,
        "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n#pragma once\n\n#include \"common/errcode.h\"\n#include \"host/mock/log.h\"\n#include \"runtime/callingframe.h\"\n#include \"runtime/hostfunc.h\"\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasiCryptoMock {\n\nusing namespace std::literals;\nstatic inline constexpr const uint32_t kWASICryptoError = 1U;\n\nnamespace Common {\nclass ArrayOutputLen : public Runtime::HostFunction<ArrayOutputLen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass ArrayOutputPull : public Runtime::HostFunction<ArrayOutputPull> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_1",
        "original_index": 1,
        "content": "class OptionsOpen : public Runtime::HostFunction<OptionsOpen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass OptionsClose : public Runtime::HostFunction<OptionsClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_2",
        "original_index": 2,
        "content": "class OptionsSet : public Runtime::HostFunction<OptionsSet> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass OptionsSetU64 : public Runtime::HostFunction<OptionsSetU64> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint64_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_3",
        "original_index": 3,
        "content": "class OptionsSetGuestBuffer\n    : public Runtime::HostFunction<OptionsSetGuestBuffer> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass SecretsManagerOpen : public Runtime::HostFunction<SecretsManagerOpen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass SecretsManagerClose : public Runtime::HostFunction<SecretsManagerClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_4",
        "original_index": 4,
        "content": "class SecretsManagerInvalidate\n    : public Runtime::HostFunction<SecretsManagerInvalidate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint64_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n} // namespace Common\n\nnamespace AsymmetricCommon {\nclass KeypairGenerate : public Runtime::HostFunction<KeypairGenerate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairImport : public Runtime::HostFunction<KeypairImport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_5",
        "original_index": 5,
        "content": "class KeypairGenerateManaged\n    : public Runtime::HostFunction<KeypairGenerateManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairStoreManaged : public Runtime::HostFunction<KeypairStoreManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_6",
        "original_index": 6,
        "content": "class KeypairReplaceManaged\n    : public Runtime::HostFunction<KeypairReplaceManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairId : public Runtime::HostFunction<KeypairId> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_7",
        "original_index": 7,
        "content": "class KeypairFromId : public Runtime::HostFunction<KeypairFromId> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint64_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairFromPkAndSk : public Runtime::HostFunction<KeypairFromPkAndSk> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_8",
        "original_index": 8,
        "content": "class KeypairExport : public Runtime::HostFunction<KeypairExport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairPublickey : public Runtime::HostFunction<KeypairPublickey> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_9",
        "original_index": 9,
        "content": "class KeypairSecretkey : public Runtime::HostFunction<KeypairSecretkey> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeypairClose : public Runtime::HostFunction<KeypairClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass PublickeyImport : public Runtime::HostFunction<PublickeyImport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_10",
        "original_index": 10,
        "content": "class PublickeyExport : public Runtime::HostFunction<PublickeyExport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass PublickeyVerify : public Runtime::HostFunction<PublickeyVerify> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_11",
        "original_index": 11,
        "content": "class PublickeyFromSecretkey\n    : public Runtime::HostFunction<PublickeyFromSecretkey> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass PublickeyClose : public Runtime::HostFunction<PublickeyClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_12",
        "original_index": 12,
        "content": "class SecretkeyImport : public Runtime::HostFunction<SecretkeyImport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass SecretkeyExport : public Runtime::HostFunction<SecretkeyExport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_13",
        "original_index": 13,
        "content": "class SecretkeyClose : public Runtime::HostFunction<SecretkeyClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n} // namespace AsymmetricCommon\n\nnamespace Kx {\nclass Dh : public Runtime::HostFunction<Dh> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_14",
        "original_index": 14,
        "content": "class Encapsulate : public Runtime::HostFunction<Encapsulate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass Decapsulate : public Runtime::HostFunction<Decapsulate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n} // namespace Kx\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_15",
        "original_index": 15,
        "content": "namespace Signatures {\nclass Export : public Runtime::HostFunction<Export> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass Import : public Runtime::HostFunction<Import> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_16",
        "original_index": 16,
        "content": "class StateOpen : public Runtime::HostFunction<StateOpen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateUpdate : public Runtime::HostFunction<StateUpdate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_17",
        "original_index": 17,
        "content": "class StateSign : public Runtime::HostFunction<StateSign> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateClose : public Runtime::HostFunction<StateClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_18",
        "original_index": 18,
        "content": "class VerificationStateOpen\n    : public Runtime::HostFunction<VerificationStateOpen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass VerificationStateUpdate\n    : public Runtime::HostFunction<VerificationStateUpdate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_19",
        "original_index": 19,
        "content": "class VerificationStateVerify\n    : public Runtime::HostFunction<VerificationStateVerify> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass VerificationStateClose\n    : public Runtime::HostFunction<VerificationStateClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass Close : public Runtime::HostFunction<Close> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n} // namespace Signatures\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_20",
        "original_index": 20,
        "content": "namespace Symmetric {\nclass KeyGenerate : public Runtime::HostFunction<KeyGenerate> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyImport : public Runtime::HostFunction<KeyImport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_21",
        "original_index": 21,
        "content": "class KeyExport : public Runtime::HostFunction<KeyExport> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyClose : public Runtime::HostFunction<KeyClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyGenerateManaged : public Runtime::HostFunction<KeyGenerateManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_22",
        "original_index": 22,
        "content": "class KeyStoreManaged : public Runtime::HostFunction<KeyStoreManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyReplaceManaged : public Runtime::HostFunction<KeyReplaceManaged> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, int32_t,\n                        int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_23",
        "original_index": 23,
        "content": "class KeyId : public Runtime::HostFunction<KeyId> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass KeyFromId : public Runtime::HostFunction<KeyFromId> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint64_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_24",
        "original_index": 24,
        "content": "class StateOpen : public Runtime::HostFunction<StateOpen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, uint32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateClone : public Runtime::HostFunction<StateClone> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_25",
        "original_index": 25,
        "content": "class StateOptionsGet : public Runtime::HostFunction<StateOptionsGet> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateOptionsGetU64 : public Runtime::HostFunction<StateOptionsGetU64> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_26",
        "original_index": 26,
        "content": "class StateClose : public Runtime::HostFunction<StateClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateAbsorb : public Runtime::HostFunction<StateAbsorb> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_27",
        "original_index": 27,
        "content": "class StateSqueeze : public Runtime::HostFunction<StateSqueeze> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateSqueezeTag : public Runtime::HostFunction<StateSqueezeTag> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_28",
        "original_index": 28,
        "content": "class StateSqueezeKey : public Runtime::HostFunction<StateSqueezeKey> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateMaxTagLen : public Runtime::HostFunction<StateMaxTagLen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_29",
        "original_index": 29,
        "content": "class StateEncrypt : public Runtime::HostFunction<StateEncrypt> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateEncryptDetached\n    : public Runtime::HostFunction<StateEncryptDetached> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_30",
        "original_index": 30,
        "content": "class StateDecrypt : public Runtime::HostFunction<StateDecrypt> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass StateDecryptDetached\n    : public Runtime::HostFunction<StateDecryptDetached> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t, uint32_t, uint32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_31",
        "original_index": 31,
        "content": "class StateRatchet : public Runtime::HostFunction<StateRatchet> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass TagLen : public Runtime::HostFunction<TagLen> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\n"
      },
      {
        "chunk_id": "doc_55_chunk_32",
        "original_index": 32,
        "content": "class TagPull : public Runtime::HostFunction<TagPull> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t, uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass TagVerify : public Runtime::HostFunction<TagVerify> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t, uint32_t,\n                        uint32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n\nclass TagClose : public Runtime::HostFunction<TagClose> {\npublic:\n  Expect<uint32_t> body(const Runtime::CallingFrame &, int32_t) {\n    printPluginMock(\"WASI-Crypto\"sv);\n    return kWASICryptoError;\n  }\n};\n} // namespace Symmetric\n\n} // namespace WasiCryptoMock\n} // namespace Host\n} // namespace WasmEdge\n"
      }
    ]
  },
  {
    "doc_id": "doc_56",
    "original_uuid": "639d7de912ea6b55610ce64b56e988bd9483b9e8efa260eb7d62326b46b17304",
    "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n//===-- wasmedge/ast/module.h - Module class definition -------------------===//\n//\n// Part of the WasmEdge Project.\n//\n//===----------------------------------------------------------------------===//\n///\n/// \\file\n/// This file contains the declaration of the Module node class, which is the\n/// module node in AST.\n///\n//===----------------------------------------------------------------------===//\n#pragma once\n\n#include \"ast/section.h\"\n\n#include <vector>\n\nnamespace WasmEdge {\nnamespace AST {\n\n/// AST Module node.\nclass Module {\npublic:\n  /// Getter of magic vector.\n  const std::vector<Byte> &getMagic() const noexcept { return Magic; }\n  std::vector<Byte> &getMagic() noexcept { return Magic; }\n\n  /// Getter of version vector.\n  const std::vector<Byte> &getVersion() const noexcept { return Version; }\n  std::vector<Byte> &getVersion() noexcept { return Version; }\n\n  /// Getters of references to sections.\n  Span<const CustomSection> getCustomSections() const noexcept {\n    return CustomSecs;\n  }\n  std::vector<CustomSection> &getCustomSections() noexcept {\n    return CustomSecs;\n  }\n  const TypeSection &getTypeSection() const { return TypeSec; }\n  TypeSection &getTypeSection() { return TypeSec; }\n  const ImportSection &getImportSection() const { return ImportSec; }\n  ImportSection &getImportSection() { return ImportSec; }\n  const FunctionSection &getFunctionSection() const { return FunctionSec; }\n  FunctionSection &getFunctionSection() { return FunctionSec; }\n  const TableSection &getTableSection() const { return TableSec; }\n  TableSection &getTableSection() { return TableSec; }\n  const MemorySection &getMemorySection() const { return MemorySec; }\n  MemorySection &getMemorySection() { return MemorySec; }\n  const GlobalSection &getGlobalSection() const { return GlobalSec; }\n  GlobalSection &getGlobalSection() { return GlobalSec; }\n  const ExportSection &getExportSection() const { return ExportSec; }\n  ExportSection &getExportSection() { return ExportSec; }\n  const StartSection &getStartSection() const { return StartSec; }\n  StartSection &getStartSection() { return StartSec; }\n  const ElementSection &getElementSection() const { return ElementSec; }\n  ElementSection &getElementSection() { return ElementSec; }\n  const CodeSection &getCodeSection() const { return CodeSec; }\n  CodeSection &getCodeSection() { return CodeSec; }\n  const DataSection &getDataSection() const { return DataSec; }\n  DataSection &getDataSection() { return DataSec; }\n  const DataCountSection &getDataCountSection() const { return DataCountSec; }\n  DataCountSection &getDataCountSection() { return DataCountSec; }\n  const AOTSection &getAOTSection() const { return AOTSec; }\n  AOTSection &getAOTSection() { return AOTSec; }\n\n  /// Getter and setter of compiled symbol.\n  const auto &getSymbol() const noexcept { return IntrSymbol; }\n  void setSymbol(Symbol<const Executable::IntrinsicsTable *> S) noexcept {\n    IntrSymbol = std::move(S);\n  }\n\n  /// Getter and setter of validated flag.\n  bool getIsValidated() const noexcept { return IsValidated; }\n  void setIsValidated(bool V = true) noexcept { IsValidated = V; }\n\nprivate:\n  /// \\name Data of Module node.\n  /// @{\n  std::vector<Byte> Magic;\n  std::vector<Byte> Version;\n  /// @}\n\n  /// \\name Section nodes of Module node.\n  /// @{\n  std::vector<CustomSection> CustomSecs;\n  TypeSection TypeSec;\n  ImportSection ImportSec;\n  FunctionSection FunctionSec;\n  TableSection TableSec;\n  MemorySection MemorySec;\n  GlobalSection GlobalSec;\n  ExportSection ExportSec;\n  StartSection StartSec;\n  ElementSection ElementSec;\n  CodeSection CodeSec;\n  DataSection DataSec;\n  DataCountSection DataCountSec;\n  /// @}\n\n  /// \\name Data of AOT.\n  /// @{\n  AOTSection AOTSec;\n  Symbol<const Executable::IntrinsicsTable *> IntrSymbol;\n  /// @}\n\n  /// \\name Validated flag.\n  /// @{\n  bool IsValidated = false;\n  /// @}\n};\n\nclass CoreModuleSection : public Section {\npublic:\n  /// Getter of content.\n  const Module &getContent() const noexcept { return Content; }\n  Module &getContent() noexcept { return Content; }\n\nprivate:\n  Module Content;\n};\n\nnamespace Component {\n\nclass Component {\n  using Section =\n      std::variant<CustomSection, CoreModuleSection, CoreInstanceSection,\n                   CoreTypeSection, ComponentSection, InstanceSection,\n                   AliasSection, TypeSection, CanonSection, StartSection,\n                   ImportSection, ExportSection>;\n\npublic:\n  /// Getter of magic vector.\n  const std::vector<Byte> &getMagic() const noexcept { return Magic; }\n  std::vector<Byte> &getMagic() noexcept { return Magic; }\n\n  /// Getter of version vector.\n  const std::vector<Byte> &getVersion() const noexcept { return Version; }\n  std::vector<Byte> &getVersion() noexcept { return Version; }\n\n  /// Getter of layer vector.\n  const std::vector<Byte> &getLayer() const noexcept { return Layer; }\n  std::vector<Byte> &getLayer() noexcept { return Layer; }\n\n  std::vector<Section> &getSections() noexcept { return Secs; }\n  Span<const Section> getSections() const noexcept { return Secs; }\n\nprivate:\n  /// \\name Data of Module node.\n  /// @{\n  std::vector<Byte> Magic;\n  std::vector<Byte> Version;\n  std::vector<Byte> Layer;\n\n  std::vector<Section> Secs;\n  /// @}\n};\n\n} // namespace Component\n\n} // namespace AST\n} // namespace WasmEdge\n",
    "chunks": [
      {
        "chunk_id": "doc_56_chunk_0",
        "original_index": 0,
        "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n//===-- wasmedge/ast/module.h - Module class definition -------------------===//\n//\n// Part of the WasmEdge Project.\n//\n//===----------------------------------------------------------------------===//\n///\n/// \\file\n/// This file contains the declaration of the Module node class, which is the\n/// module node in AST.\n///\n//===----------------------------------------------------------------------===//\n#pragma once\n\n#include \"ast/section.h\"\n\n#include <vector>\n\nnamespace WasmEdge {\nnamespace AST {\n\n/// AST Module node.\nclass Module {\npublic:\n  /// Getter of magic vector.\n  const std::vector<Byte> &getMagic() const noexcept { return Magic; }\n  std::vector<Byte> &getMagic() noexcept { return Magic; }\n\n  /// Getter of version vector.\n  const std::vector<Byte> &getVersion() const noexcept { return Version; }\n  std::vector<Byte> &getVersion() noexcept { return Version; }\n\n"
      },
      {
        "chunk_id": "doc_56_chunk_1",
        "original_index": 1,
        "content": "  /// Getters of references to sections.\n  Span<const CustomSection> getCustomSections() const noexcept {\n    return CustomSecs;\n  }\n  std::vector<CustomSection> &getCustomSections() noexcept {\n    return CustomSecs;\n  }\n  const TypeSection &getTypeSection() const { return TypeSec; }\n  TypeSection &getTypeSection() { return TypeSec; }\n  const ImportSection &getImportSection() const { return ImportSec; }\n  ImportSection &getImportSection() { return ImportSec; }\n  const FunctionSection &getFunctionSection() const { return FunctionSec; }\n"
      },
      {
        "chunk_id": "doc_56_chunk_2",
        "original_index": 2,
        "content": "  FunctionSection &getFunctionSection() { return FunctionSec; }\n  const TableSection &getTableSection() const { return TableSec; }\n  TableSection &getTableSection() { return TableSec; }\n  const MemorySection &getMemorySection() const { return MemorySec; }\n  MemorySection &getMemorySection() { return MemorySec; }\n  const GlobalSection &getGlobalSection() const { return GlobalSec; }\n  GlobalSection &getGlobalSection() { return GlobalSec; }\n  const ExportSection &getExportSection() const { return ExportSec; }\n  ExportSection &getExportSection() { return ExportSec; }\n  const StartSection &getStartSection() const { return StartSec; }\n  StartSection &getStartSection() { return StartSec; }\n  const ElementSection &getElementSection() const { return ElementSec; }\n  ElementSection &getElementSection() { return ElementSec; }\n  const CodeSection &getCodeSection() const { return CodeSec; }\n"
      },
      {
        "chunk_id": "doc_56_chunk_3",
        "original_index": 3,
        "content": "  CodeSection &getCodeSection() { return CodeSec; }\n  const DataSection &getDataSection() const { return DataSec; }\n  DataSection &getDataSection() { return DataSec; }\n  const DataCountSection &getDataCountSection() const { return DataCountSec; }\n  DataCountSection &getDataCountSection() { return DataCountSec; }\n  const AOTSection &getAOTSection() const { return AOTSec; }\n  AOTSection &getAOTSection() { return AOTSec; }\n\n  /// Getter and setter of compiled symbol.\n  const auto &getSymbol() const noexcept { return IntrSymbol; }\n  void setSymbol(Symbol<const Executable::IntrinsicsTable *> S) noexcept {\n    IntrSymbol = std::move(S);\n  }\n\n  /// Getter and setter of validated flag.\n  bool getIsValidated() const noexcept { return IsValidated; }\n  void setIsValidated(bool V = true) noexcept { IsValidated = V; }\n\nprivate:\n  /// \\name Data of Module node.\n  /// @{\n  std::vector<Byte> Magic;\n  std::vector<Byte> Version;\n  /// @}\n\n"
      },
      {
        "chunk_id": "doc_56_chunk_4",
        "original_index": 4,
        "content": "  /// \\name Section nodes of Module node.\n  /// @{\n  std::vector<CustomSection> CustomSecs;\n  TypeSection TypeSec;\n  ImportSection ImportSec;\n  FunctionSection FunctionSec;\n  TableSection TableSec;\n  MemorySection MemorySec;\n  GlobalSection GlobalSec;\n  ExportSection ExportSec;\n  StartSection StartSec;\n  ElementSection ElementSec;\n  CodeSection CodeSec;\n  DataSection DataSec;\n  DataCountSection DataCountSec;\n  /// @}\n\n  /// \\name Data of AOT.\n  /// @{\n  AOTSection AOTSec;\n  Symbol<const Executable::IntrinsicsTable *> IntrSymbol;\n  /// @}\n\n  /// \\name Validated flag.\n  /// @{\n  bool IsValidated = false;\n  /// @}\n};\n\nclass CoreModuleSection : public Section {\npublic:\n  /// Getter of content.\n  const Module &getContent() const noexcept { return Content; }\n  Module &getContent() noexcept { return Content; }\n\nprivate:\n  Module Content;\n};\n\nnamespace Component {\n\n"
      },
      {
        "chunk_id": "doc_56_chunk_5",
        "original_index": 5,
        "content": "class Component {\n  using Section =\n      std::variant<CustomSection, CoreModuleSection, CoreInstanceSection,\n                   CoreTypeSection, ComponentSection, InstanceSection,\n                   AliasSection, TypeSection, CanonSection, StartSection,\n                   ImportSection, ExportSection>;\n\npublic:\n  /// Getter of magic vector.\n  const std::vector<Byte> &getMagic() const noexcept { return Magic; }\n  std::vector<Byte> &getMagic() noexcept { return Magic; }\n\n  /// Getter of version vector.\n  const std::vector<Byte> &getVersion() const noexcept { return Version; }\n  std::vector<Byte> &getVersion() noexcept { return Version; }\n\n"
      },
      {
        "chunk_id": "doc_56_chunk_6",
        "original_index": 6,
        "content": "  /// Getter of layer vector.\n  const std::vector<Byte> &getLayer() const noexcept { return Layer; }\n  std::vector<Byte> &getLayer() noexcept { return Layer; }\n\n  std::vector<Section> &getSections() noexcept { return Secs; }\n  Span<const Section> getSections() const noexcept { return Secs; }\n\nprivate:\n  /// \\name Data of Module node.\n  /// @{\n  std::vector<Byte> Magic;\n  std::vector<Byte> Version;\n  std::vector<Byte> Layer;\n\n  std::vector<Section> Secs;\n  /// @}\n};\n\n} // namespace Component\n\n} // namespace AST\n} // namespace WasmEdge\n"
      }
    ]
  },
  {
    "doc_id": "doc_57",
    "original_uuid": "21b3edb89205c4e10d73fa5d7c1e90bea2090310ab0795fcddf5b4673d5478ac",
    "content": "#pragma once\n#include \"avutil_base.h\"\n\n#include \"runtime/callingframe.h\"\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasmEdgeFFmpeg {\nnamespace AVUtil {\n\nclass AVLogSetLevel : public WasmEdgeFFmpegAVUtil<AVLogSetLevel> {\npublic:\n  AVLogSetLevel(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<void> body(const Runtime::CallingFrame &Frame, int32_t LogLevelId);\n};\n\nclass AVLogGetLevel : public WasmEdgeFFmpegAVUtil<AVLogGetLevel> {\npublic:\n  AVLogGetLevel(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVLogSetFlags : public WasmEdgeFFmpegAVUtil<AVLogSetFlags> {\npublic:\n  AVLogSetFlags(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<void> body(const Runtime::CallingFrame &Frame, int32_t FlagsId);\n};\n\nclass AVLogGetFlags : public WasmEdgeFFmpegAVUtil<AVLogGetFlags> {\npublic:\n  AVLogGetFlags(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\n// Option funcs.\nclass AVOptSetBin : public WasmEdgeFFmpegAVUtil<AVOptSetBin> {\npublic:\n  AVOptSetBin(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSet : public WasmEdgeFFmpegAVUtil<AVOptSet> {\npublic:\n  AVOptSet(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSetInt : public WasmEdgeFFmpegAVUtil<AVOptSetInt> {\npublic:\n  AVOptSetInt(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSetDouble : public WasmEdgeFFmpegAVUtil<AVOptSetDouble> {\npublic:\n  AVOptSetDouble(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSetQ : public WasmEdgeFFmpegAVUtil<AVOptSetQ> {\npublic:\n  AVOptSetQ(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSetImageSize : public WasmEdgeFFmpegAVUtil<AVOptSetImageSize> {\npublic:\n  AVOptSetImageSize(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSetPixelFmt : public WasmEdgeFFmpegAVUtil<AVOptSetPixelFmt> {\npublic:\n  AVOptSetPixelFmt(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSetSampleFmt : public WasmEdgeFFmpegAVUtil<AVOptSetSampleFmt> {\npublic:\n  AVOptSetSampleFmt(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSetChannelLayout\n    : public WasmEdgeFFmpegAVUtil<AVOptSetChannelLayout> {\npublic:\n  AVOptSetChannelLayout(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVRescaleQ : public WasmEdgeFFmpegAVUtil<AVRescaleQ> {\npublic:\n  AVRescaleQ(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int64_t> body(const Runtime::CallingFrame &Frame, int64_t A,\n                       int32_t BNum, int32_t BDen, int32_t CNum, int32_t CDen);\n};\n\nclass AVRescaleQRnd : public WasmEdgeFFmpegAVUtil<AVRescaleQRnd> {\npublic:\n  AVRescaleQRnd(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int64_t> body(const Runtime::CallingFrame &, int64_t A, int32_t BNum,\n                       int32_t BDen, int32_t CNum, int32_t CDen,\n                       int32_t RoundingId);\n};\n\nclass AVUtilVersion : public WasmEdgeFFmpegAVUtil<AVUtilVersion> {\npublic:\n  AVUtilVersion(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<uint32_t> body(const Runtime::CallingFrame &);\n};\n\nclass AVGetChannelLayoutNbChannels\n    : public WasmEdgeFFmpegAVUtil<AVGetChannelLayoutNbChannels> {\npublic:\n  AVGetChannelLayoutNbChannels(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame,\n                       uint64_t ChannelLayoutId);\n};\n\nclass AVGetChannelLayoutNameLen\n    : public WasmEdgeFFmpegAVUtil<AVGetChannelLayoutNameLen> {\npublic:\n  AVGetChannelLayoutNameLen(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame,\n                       uint64_t ChannelLayoutId);\n};\n\nclass AVGetChannelLayoutName\n    : public WasmEdgeFFmpegAVUtil<AVGetChannelLayoutName> {\npublic:\n  AVGetChannelLayoutName(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame,\n                       uint64_t ChannelLayoutId, uint32_t NamePtr,\n                       uint32_t NameLen);\n};\n\nclass AVGetChannelLayoutMask\n    : public WasmEdgeFFmpegAVUtil<AVGetChannelLayoutMask> {\npublic:\n  AVGetChannelLayoutMask(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<uint64_t> body(const Runtime::CallingFrame &Frame,\n                        uint64_t ChannelLayoutId);\n};\n\nclass AVGetDefaultChannelLayout\n    : public WasmEdgeFFmpegAVUtil<AVGetDefaultChannelLayout> {\npublic:\n  AVGetDefaultChannelLayout(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<uint64_t> body(const Runtime::CallingFrame &Frame,\n                        int32_t ChannelLayoutId);\n};\n\nclass AVUtilConfigurationLength\n    : public WasmEdgeFFmpegAVUtil<AVUtilConfigurationLength> {\npublic:\n  AVUtilConfigurationLength(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVUtilConfiguration : public WasmEdgeFFmpegAVUtil<AVUtilConfiguration> {\npublic:\n  AVUtilConfiguration(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame, uint32_t ConfigPtr,\n                       uint32_t ConfigLen);\n};\n\nclass AVUtilLicenseLength : public WasmEdgeFFmpegAVUtil<AVUtilLicenseLength> {\npublic:\n  AVUtilLicenseLength(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVUtilLicense : public WasmEdgeFFmpegAVUtil<AVUtilLicense> {\npublic:\n  AVUtilLicense(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame, uint32_t LicensePtr,\n                       uint32_t LicenseLen);\n};\n\n} // namespace AVUtil\n} // namespace WasmEdgeFFmpeg\n} // namespace Host\n} // namespace WasmEdge\n",
    "chunks": [
      {
        "chunk_id": "doc_57_chunk_0",
        "original_index": 0,
        "content": "#pragma once\n#include \"avutil_base.h\"\n\n#include \"runtime/callingframe.h\"\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasmEdgeFFmpeg {\nnamespace AVUtil {\n\nclass AVLogSetLevel : public WasmEdgeFFmpegAVUtil<AVLogSetLevel> {\npublic:\n  AVLogSetLevel(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<void> body(const Runtime::CallingFrame &Frame, int32_t LogLevelId);\n};\n\nclass AVLogGetLevel : public WasmEdgeFFmpegAVUtil<AVLogGetLevel> {\npublic:\n  AVLogGetLevel(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVLogSetFlags : public WasmEdgeFFmpegAVUtil<AVLogSetFlags> {\npublic:\n  AVLogSetFlags(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<void> body(const Runtime::CallingFrame &Frame, int32_t FlagsId);\n};\n\n"
      },
      {
        "chunk_id": "doc_57_chunk_1",
        "original_index": 1,
        "content": "class AVLogGetFlags : public WasmEdgeFFmpegAVUtil<AVLogGetFlags> {\npublic:\n  AVLogGetFlags(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\n// Option funcs.\nclass AVOptSetBin : public WasmEdgeFFmpegAVUtil<AVOptSetBin> {\npublic:\n  AVOptSetBin(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSet : public WasmEdgeFFmpegAVUtil<AVOptSet> {\npublic:\n  AVOptSet(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSetInt : public WasmEdgeFFmpegAVUtil<AVOptSetInt> {\npublic:\n  AVOptSetInt(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\n"
      },
      {
        "chunk_id": "doc_57_chunk_2",
        "original_index": 2,
        "content": "class AVOptSetDouble : public WasmEdgeFFmpegAVUtil<AVOptSetDouble> {\npublic:\n  AVOptSetDouble(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSetQ : public WasmEdgeFFmpegAVUtil<AVOptSetQ> {\npublic:\n  AVOptSetQ(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSetImageSize : public WasmEdgeFFmpegAVUtil<AVOptSetImageSize> {\npublic:\n  AVOptSetImageSize(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\n"
      },
      {
        "chunk_id": "doc_57_chunk_3",
        "original_index": 3,
        "content": "class AVOptSetPixelFmt : public WasmEdgeFFmpegAVUtil<AVOptSetPixelFmt> {\npublic:\n  AVOptSetPixelFmt(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVOptSetSampleFmt : public WasmEdgeFFmpegAVUtil<AVOptSetSampleFmt> {\npublic:\n  AVOptSetSampleFmt(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\n"
      },
      {
        "chunk_id": "doc_57_chunk_4",
        "original_index": 4,
        "content": "class AVOptSetChannelLayout\n    : public WasmEdgeFFmpegAVUtil<AVOptSetChannelLayout> {\npublic:\n  AVOptSetChannelLayout(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVRescaleQ : public WasmEdgeFFmpegAVUtil<AVRescaleQ> {\npublic:\n  AVRescaleQ(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int64_t> body(const Runtime::CallingFrame &Frame, int64_t A,\n                       int32_t BNum, int32_t BDen, int32_t CNum, int32_t CDen);\n};\n\nclass AVRescaleQRnd : public WasmEdgeFFmpegAVUtil<AVRescaleQRnd> {\npublic:\n  AVRescaleQRnd(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int64_t> body(const Runtime::CallingFrame &, int64_t A, int32_t BNum,\n                       int32_t BDen, int32_t CNum, int32_t CDen,\n                       int32_t RoundingId);\n};\n\n"
      },
      {
        "chunk_id": "doc_57_chunk_5",
        "original_index": 5,
        "content": "class AVUtilVersion : public WasmEdgeFFmpegAVUtil<AVUtilVersion> {\npublic:\n  AVUtilVersion(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<uint32_t> body(const Runtime::CallingFrame &);\n};\n\nclass AVGetChannelLayoutNbChannels\n    : public WasmEdgeFFmpegAVUtil<AVGetChannelLayoutNbChannels> {\npublic:\n  AVGetChannelLayoutNbChannels(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame,\n                       uint64_t ChannelLayoutId);\n};\n\nclass AVGetChannelLayoutNameLen\n    : public WasmEdgeFFmpegAVUtil<AVGetChannelLayoutNameLen> {\npublic:\n  AVGetChannelLayoutNameLen(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame,\n                       uint64_t ChannelLayoutId);\n};\n\n"
      },
      {
        "chunk_id": "doc_57_chunk_6",
        "original_index": 6,
        "content": "class AVGetChannelLayoutName\n    : public WasmEdgeFFmpegAVUtil<AVGetChannelLayoutName> {\npublic:\n  AVGetChannelLayoutName(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame,\n                       uint64_t ChannelLayoutId, uint32_t NamePtr,\n                       uint32_t NameLen);\n};\n\nclass AVGetChannelLayoutMask\n    : public WasmEdgeFFmpegAVUtil<AVGetChannelLayoutMask> {\npublic:\n  AVGetChannelLayoutMask(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<uint64_t> body(const Runtime::CallingFrame &Frame,\n                        uint64_t ChannelLayoutId);\n};\n\n"
      },
      {
        "chunk_id": "doc_57_chunk_7",
        "original_index": 7,
        "content": "class AVGetDefaultChannelLayout\n    : public WasmEdgeFFmpegAVUtil<AVGetDefaultChannelLayout> {\npublic:\n  AVGetDefaultChannelLayout(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<uint64_t> body(const Runtime::CallingFrame &Frame,\n                        int32_t ChannelLayoutId);\n};\n\nclass AVUtilConfigurationLength\n    : public WasmEdgeFFmpegAVUtil<AVUtilConfigurationLength> {\npublic:\n  AVUtilConfigurationLength(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\n"
      },
      {
        "chunk_id": "doc_57_chunk_8",
        "original_index": 8,
        "content": "class AVUtilConfiguration : public WasmEdgeFFmpegAVUtil<AVUtilConfiguration> {\npublic:\n  AVUtilConfiguration(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame, uint32_t ConfigPtr,\n                       uint32_t ConfigLen);\n};\n\nclass AVUtilLicenseLength : public WasmEdgeFFmpegAVUtil<AVUtilLicenseLength> {\npublic:\n  AVUtilLicenseLength(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame);\n};\n\nclass AVUtilLicense : public WasmEdgeFFmpegAVUtil<AVUtilLicense> {\npublic:\n  AVUtilLicense(std::shared_ptr<WasmEdgeFFmpegEnv> HostEnv)\n      : WasmEdgeFFmpegAVUtil(HostEnv) {}\n  Expect<int32_t> body(const Runtime::CallingFrame &Frame, uint32_t LicensePtr,\n                       uint32_t LicenseLen);\n};\n\n} // namespace AVUtil\n} // namespace WasmEdgeFFmpeg\n} // namespace Host\n} // namespace WasmEdge\n"
      }
    ]
  },
  {
    "doc_id": "doc_58",
    "original_uuid": "58b8335c96ff71630b51a2e5877ca480117c0e39660bb7d672c352a610c23df0",
    "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n//===-- wasmedge/po/parser.h - Argument error -----------------------------===//\n//\n// Part of the WasmEdge Project.\n//\n//===----------------------------------------------------------------------===//\n#pragma once\n\n#include \"experimental/expected.hpp\"\n#include <string>\n#include <string_view>\n#include <utility>\n\nnamespace WasmEdge {\nnamespace PO {\n\nenum class ErrCode {\n  InvalidArgument,\n  OutOfRange,\n};\n\nclass Error {\npublic:\n  Error(const Error &) = default;\n  Error &operator=(const Error &) = default;\n  Error(Error &&) noexcept = default;\n  Error &operator=(Error &&) noexcept = default;\n\n  Error(ErrCode C, std::string M) noexcept : Code(C), Message(std::move(M)) {}\n  ErrCode code() const noexcept { return Code; }\n  std::string_view message() const &noexcept { return Message; }\n  std::string message() &&noexcept { return std::move(Message); }\n\nprivate:\n  ErrCode Code;\n  std::string Message;\n};\n\n} // namespace PO\n} // namespace WasmEdge\n",
    "chunks": [
      {
        "chunk_id": "doc_58_chunk_0",
        "original_index": 0,
        "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n//===-- wasmedge/po/parser.h - Argument error -----------------------------===//\n//\n// Part of the WasmEdge Project.\n//\n//===----------------------------------------------------------------------===//\n#pragma once\n\n#include \"experimental/expected.hpp\"\n#include <string>\n#include <string_view>\n#include <utility>\n\nnamespace WasmEdge {\nnamespace PO {\n\nenum class ErrCode {\n  InvalidArgument,\n  OutOfRange,\n};\n\nclass Error {\npublic:\n  Error(const Error &) = default;\n  Error &operator=(const Error &) = default;\n  Error(Error &&) noexcept = default;\n  Error &operator=(Error &&) noexcept = default;\n\n"
      },
      {
        "chunk_id": "doc_58_chunk_1",
        "original_index": 1,
        "content": "  Error(ErrCode C, std::string M) noexcept : Code(C), Message(std::move(M)) {}\n  ErrCode code() const noexcept { return Code; }\n  std::string_view message() const &noexcept { return Message; }\n  std::string message() &&noexcept { return std::move(Message); }\n\nprivate:\n  ErrCode Code;\n  std::string Message;\n};\n\n} // namespace PO\n} // namespace WasmEdge\n"
      }
    ]
  },
  {
    "doc_id": "doc_59",
    "original_uuid": "0396205d1c4798d535adf488d31a205be75de55cc26b35efd5312ff423f7e7f4",
    "content": "#include \"avChapter.h\"\n\nextern \"C\" {\n#include \"libavformat/avformat.h\"\n}\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasmEdgeFFmpeg {\nnamespace AVFormat {\n\nExpect<int64_t> AVChapterId::body(const Runtime::CallingFrame &,\n                                  uint32_t AvFormatCtxId, uint32_t ChapterIdx) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  return static_cast<AVChapter *>(*AvChapter)->id;\n}\n\nExpect<int32_t> AVChapterSetId::body(const Runtime::CallingFrame &,\n                                     uint32_t AvFormatCtxId,\n                                     uint32_t ChapterIdx, int64_t ChapterId) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  (*AvChapter)->id = ChapterId;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\nExpect<int32_t> AVChapterTimebase::body(const Runtime::CallingFrame &Frame,\n                                        uint32_t NumPtr, uint32_t DenPtr,\n                                        uint32_t AvFormatCtxId,\n                                        uint32_t ChapterIdx) {\n\n  MEMINST_CHECK(MemInst, Frame, 0);\n  MEM_PTR_CHECK(Num, MemInst, int32_t, NumPtr, \"\");\n  MEM_PTR_CHECK(Den, MemInst, int32_t, DenPtr, \"\");\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  AVRational const AvRational = static_cast<AVChapter *>(*AvChapter)->time_base;\n  *Num = AvRational.num;\n  *Den = AvRational.den;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\nExpect<int32_t> AVChapterSetTimebase::body(const Runtime::CallingFrame &,\n                                           int32_t Num, int32_t Den,\n                                           uint32_t AvFormatCtxId,\n                                           uint32_t ChapterIdx) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVRational const Timebase = av_make_q(Num, Den);\n\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  (*AvChapter)->time_base = Timebase;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\nExpect<int64_t> AVChapterStart::body(const Runtime::CallingFrame &,\n                                     uint32_t AvFormatCtxId,\n                                     uint32_t ChapterIdx) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  return static_cast<AVChapter *>(*AvChapter)->start;\n}\n\nExpect<int32_t> AVChapterSetStart::body(const Runtime::CallingFrame &,\n                                        uint32_t AvFormatCtxId,\n                                        uint32_t ChapterIdx,\n                                        int64_t StartValue) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  (*AvChapter)->start = StartValue;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\nExpect<int64_t> AVChapterEnd::body(const Runtime::CallingFrame &,\n                                   uint32_t AvFormatCtxId,\n                                   uint32_t ChapterIdx) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  return static_cast<AVChapter *>(*AvChapter)->end;\n}\n\nExpect<int32_t> AVChapterSetEnd::body(const Runtime::CallingFrame &,\n                                      uint32_t AvFormatCtxId,\n                                      uint32_t ChapterIdx, int64_t EndValue) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  (*AvChapter)->end = EndValue;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\nExpect<int32_t> AVChapterMetadata::body(const Runtime::CallingFrame &Frame,\n                                        uint32_t AvFormatCtxId,\n                                        uint32_t ChapterIdx, uint32_t DictPtr) {\n\n  MEMINST_CHECK(MemInst, Frame, 0);\n  MEM_PTR_CHECK(DictId, MemInst, uint32_t, DictPtr,\n                \"Failed when accessing the return AVDictionary memory\"sv);\n\n  FFMPEG_PTR_FETCH(AvFormatCtx, AvFormatCtxId, AVFormatContext);\n\n  AVDictionary **AvDictionary =\n      static_cast<AVDictionary **>(av_malloc(sizeof(AVDictionary *)));\n  AVChapter **AvChapter = AvFormatCtx->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  *AvDictionary = (*AvChapter)->metadata;\n  FFMPEG_PTR_STORE(AvDictionary, DictId);\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\nExpect<int32_t> AVChapterSetMetadata::body(const Runtime::CallingFrame &,\n                                           uint32_t AvFormatCtxId,\n                                           uint32_t ChapterIdx,\n                                           uint32_t DictId) {\n\n  FFMPEG_PTR_FETCH(AvFormatCtx, AvFormatCtxId, AVFormatContext);\n  FFMPEG_PTR_FETCH(AvDictionary, DictId, AVDictionary *);\n\n  AVChapter **AvChapter = AvFormatCtx->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  if (AvDictionary == nullptr)\n    (*AvChapter)->metadata = nullptr;\n  else\n    (*AvChapter)->metadata = *AvDictionary;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\n} // namespace AVFormat\n} // namespace WasmEdgeFFmpeg\n} // namespace Host\n} // namespace WasmEdge\n",
    "chunks": [
      {
        "chunk_id": "doc_59_chunk_0",
        "original_index": 0,
        "content": "#include \"avChapter.h\"\n\nextern \"C\" {\n#include \"libavformat/avformat.h\"\n}\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasmEdgeFFmpeg {\nnamespace AVFormat {\n\nExpect<int64_t> AVChapterId::body(const Runtime::CallingFrame &,\n                                  uint32_t AvFormatCtxId, uint32_t ChapterIdx) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  return static_cast<AVChapter *>(*AvChapter)->id;\n}\n\nExpect<int32_t> AVChapterSetId::body(const Runtime::CallingFrame &,\n                                     uint32_t AvFormatCtxId,\n                                     uint32_t ChapterIdx, int64_t ChapterId) {\n\n"
      },
      {
        "chunk_id": "doc_59_chunk_1",
        "original_index": 1,
        "content": "  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  (*AvChapter)->id = ChapterId;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\nExpect<int32_t> AVChapterTimebase::body(const Runtime::CallingFrame &Frame,\n                                        uint32_t NumPtr, uint32_t DenPtr,\n                                        uint32_t AvFormatCtxId,\n                                        uint32_t ChapterIdx) {\n\n  MEMINST_CHECK(MemInst, Frame, 0);\n  MEM_PTR_CHECK(Num, MemInst, int32_t, NumPtr, \"\");\n  MEM_PTR_CHECK(Den, MemInst, int32_t, DenPtr, \"\");\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n"
      },
      {
        "chunk_id": "doc_59_chunk_2",
        "original_index": 2,
        "content": "  AVRational const AvRational = static_cast<AVChapter *>(*AvChapter)->time_base;\n  *Num = AvRational.num;\n  *Den = AvRational.den;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\nExpect<int32_t> AVChapterSetTimebase::body(const Runtime::CallingFrame &,\n                                           int32_t Num, int32_t Den,\n                                           uint32_t AvFormatCtxId,\n                                           uint32_t ChapterIdx) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVRational const Timebase = av_make_q(Num, Den);\n\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  (*AvChapter)->time_base = Timebase;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\n"
      },
      {
        "chunk_id": "doc_59_chunk_3",
        "original_index": 3,
        "content": "Expect<int64_t> AVChapterStart::body(const Runtime::CallingFrame &,\n                                     uint32_t AvFormatCtxId,\n                                     uint32_t ChapterIdx) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  return static_cast<AVChapter *>(*AvChapter)->start;\n}\n\n"
      },
      {
        "chunk_id": "doc_59_chunk_4",
        "original_index": 4,
        "content": "Expect<int32_t> AVChapterSetStart::body(const Runtime::CallingFrame &,\n                                        uint32_t AvFormatCtxId,\n                                        uint32_t ChapterIdx,\n                                        int64_t StartValue) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  (*AvChapter)->start = StartValue;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\n"
      },
      {
        "chunk_id": "doc_59_chunk_5",
        "original_index": 5,
        "content": "Expect<int64_t> AVChapterEnd::body(const Runtime::CallingFrame &,\n                                   uint32_t AvFormatCtxId,\n                                   uint32_t ChapterIdx) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  return static_cast<AVChapter *>(*AvChapter)->end;\n}\n\n"
      },
      {
        "chunk_id": "doc_59_chunk_6",
        "original_index": 6,
        "content": "Expect<int32_t> AVChapterSetEnd::body(const Runtime::CallingFrame &,\n                                      uint32_t AvFormatCtxId,\n                                      uint32_t ChapterIdx, int64_t EndValue) {\n\n  FFMPEG_PTR_FETCH(AvFormatContext, AvFormatCtxId, AVFormatContext);\n  AVChapter **AvChapter = AvFormatContext->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  (*AvChapter)->end = EndValue;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\n"
      },
      {
        "chunk_id": "doc_59_chunk_7",
        "original_index": 7,
        "content": "Expect<int32_t> AVChapterMetadata::body(const Runtime::CallingFrame &Frame,\n                                        uint32_t AvFormatCtxId,\n                                        uint32_t ChapterIdx, uint32_t DictPtr) {\n\n  MEMINST_CHECK(MemInst, Frame, 0);\n  MEM_PTR_CHECK(DictId, MemInst, uint32_t, DictPtr,\n                \"Failed when accessing the return AVDictionary memory\"sv);\n\n  FFMPEG_PTR_FETCH(AvFormatCtx, AvFormatCtxId, AVFormatContext);\n\n  AVDictionary **AvDictionary =\n      static_cast<AVDictionary **>(av_malloc(sizeof(AVDictionary *)));\n  AVChapter **AvChapter = AvFormatCtx->chapters;\n\n"
      },
      {
        "chunk_id": "doc_59_chunk_8",
        "original_index": 8,
        "content": "  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  *AvDictionary = (*AvChapter)->metadata;\n  FFMPEG_PTR_STORE(AvDictionary, DictId);\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\nExpect<int32_t> AVChapterSetMetadata::body(const Runtime::CallingFrame &,\n                                           uint32_t AvFormatCtxId,\n                                           uint32_t ChapterIdx,\n                                           uint32_t DictId) {\n\n"
      },
      {
        "chunk_id": "doc_59_chunk_9",
        "original_index": 9,
        "content": "  FFMPEG_PTR_FETCH(AvFormatCtx, AvFormatCtxId, AVFormatContext);\n  FFMPEG_PTR_FETCH(AvDictionary, DictId, AVDictionary *);\n\n  AVChapter **AvChapter = AvFormatCtx->chapters;\n\n  // No check here (Check)\n  // Raw Pointer Iteration.\n  for (unsigned int I = 1; I <= ChapterIdx; I++)\n    AvChapter++;\n\n  if (AvDictionary == nullptr)\n    (*AvChapter)->metadata = nullptr;\n  else\n    (*AvChapter)->metadata = *AvDictionary;\n  return static_cast<int32_t>(ErrNo::Success);\n}\n\n} // namespace AVFormat\n} // namespace WasmEdgeFFmpeg\n} // namespace Host\n} // namespace WasmEdge\n"
      }
    ]
  },
  {
    "doc_id": "doc_60",
    "original_uuid": "ed7a7ce904aa052de3a265fed9df5de8666341480bdf203a7e2f1b8761ea0c26",
    "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n#include \"asymmetric_common/publickey.h\"\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasiCrypto {\nnamespace AsymmetricCommon {\n\nWasiCryptoExpect<PkVariant>\nimportPk(AsymmetricCommon::Algorithm Alg, Span<const uint8_t> Encoded,\n         __wasi_publickey_encoding_e_t Encoding) noexcept {\n  return std::visit(\n      [=](auto Factory) noexcept -> WasiCryptoExpect<PkVariant> {\n        return decltype(Factory)::PublicKey::import(Encoded, Encoding);\n      },\n      Alg);\n}\n\nWasiCryptoExpect<std::vector<uint8_t>>\npkExportData(const PkVariant &PkVariant,\n             __wasi_publickey_encoding_e_t Encoding) noexcept {\n  return std::visit(\n      [Encoding](const auto &Pk) noexcept { return Pk.exportData(Encoding); },\n      PkVariant);\n}\n\nWasiCryptoExpect<void> pkVerify(const PkVariant &PkVariant) noexcept {\n  return std::visit([](const auto &Pk) noexcept { return Pk.verify(); },\n                    PkVariant);\n}\n\n} // namespace AsymmetricCommon\n} // namespace WasiCrypto\n} // namespace Host\n} // namespace WasmEdge\n",
    "chunks": [
      {
        "chunk_id": "doc_60_chunk_0",
        "original_index": 0,
        "content": "// SPDX-License-Identifier: Apache-2.0\n// SPDX-FileCopyrightText: 2019-2022 Second State INC\n\n#include \"asymmetric_common/publickey.h\"\n\nnamespace WasmEdge {\nnamespace Host {\nnamespace WasiCrypto {\nnamespace AsymmetricCommon {\n\nWasiCryptoExpect<PkVariant>\nimportPk(AsymmetricCommon::Algorithm Alg, Span<const uint8_t> Encoded,\n         __wasi_publickey_encoding_e_t Encoding) noexcept {\n  return std::visit(\n      [=](auto Factory) noexcept -> WasiCryptoExpect<PkVariant> {\n        return decltype(Factory)::PublicKey::import(Encoded, Encoding);\n      },\n      Alg);\n}\n\n"
      },
      {
        "chunk_id": "doc_60_chunk_1",
        "original_index": 1,
        "content": "WasiCryptoExpect<std::vector<uint8_t>>\npkExportData(const PkVariant &PkVariant,\n             __wasi_publickey_encoding_e_t Encoding) noexcept {\n  return std::visit(\n      [Encoding](const auto &Pk) noexcept { return Pk.exportData(Encoding); },\n      PkVariant);\n}\n\nWasiCryptoExpect<void> pkVerify(const PkVariant &PkVariant) noexcept {\n  return std::visit([](const auto &Pk) noexcept { return Pk.verify(); },\n                    PkVariant);\n}\n\n} // namespace AsymmetricCommon\n} // namespace WasiCrypto\n} // namespace Host\n} // namespace WasmEdge\n"
      }
    ]
  },
  {
    "doc_id": "doc_61",
    "original_uuid": "8c07c6723715401237471af50bc77e924d3ae094fd1f689aafa60b9845809d94",
    "content": "use std::ffi::OsStr;\nuse std::io::{self, Error, ErrorKind, Result};\nuse std::iter::once;\nuse std::os::windows::ffi::OsStrExt;\nuse std::sync::mpsc::TryRecvError;\nuse std::sync::Arc;\n\nuse crate::event::{OnResize, WindowSize};\nuse crate::tty::windows::child::ChildExitWatcher;\nuse crate::tty::{ChildEvent, EventedPty, EventedReadWrite, Options, Shell};\n\nmod blocking;\nmod child;\nmod conpty;\n\nuse blocking::{UnblockedReader, UnblockedWriter};\nuse conpty::Conpty as Backend;\nuse miow::pipe::{AnonRead, AnonWrite};\nuse polling::{Event, Poller};\n\npub const PTY_CHILD_EVENT_TOKEN: usize = 1;\npub const PTY_READ_WRITE_TOKEN: usize = 2;\n\ntype ReadPipe = UnblockedReader<AnonRead>;\ntype WritePipe = UnblockedWriter<AnonWrite>;\n\npub struct Pty {\n    // XXX: Backend is required to be the first field, to ensure correct drop order. Dropping\n    // `conout` before `backend` will cause a deadlock (with Conpty).\n    backend: Backend,\n    conout: ReadPipe,\n    conin: WritePipe,\n    child_watcher: ChildExitWatcher,\n}\n\npub fn new(config: &Options, window_size: WindowSize, _window_id: u64) -> Result<Pty> {\n    conpty::new(config, window_size)\n        .ok_or_else(|| Error::new(ErrorKind::Other, \"failed to spawn conpty\"))\n}\n\nimpl Pty {\n    fn new(\n        backend: impl Into<Backend>,\n        conout: impl Into<ReadPipe>,\n        conin: impl Into<WritePipe>,\n        child_watcher: ChildExitWatcher,\n    ) -> Self {\n        Self { backend: backend.into(), conout: conout.into(), conin: conin.into(), child_watcher }\n    }\n\n    pub fn child_watcher(&self) -> &ChildExitWatcher {\n        &self.child_watcher\n    }\n}\n\nfn with_key(mut event: Event, key: usize) -> Event {\n    event.key = key;\n    event\n}\n\nimpl EventedReadWrite for Pty {\n    type Reader = ReadPipe;\n    type Writer = WritePipe;\n\n    #[inline]\n    unsafe fn register(\n        &mut self,\n        poll: &Arc<Poller>,\n        interest: polling::Event,\n        poll_opts: polling::PollMode,\n    ) -> io::Result<()> {\n        self.conin.register(poll, with_key(interest, PTY_READ_WRITE_TOKEN), poll_opts);\n        self.conout.register(poll, with_key(interest, PTY_READ_WRITE_TOKEN), poll_opts);\n        self.child_watcher.register(poll, with_key(interest, PTY_CHILD_EVENT_TOKEN));\n\n        Ok(())\n    }\n\n    #[inline]\n    fn reregister(\n        &mut self,\n        poll: &Arc<Poller>,\n        interest: polling::Event,\n        poll_opts: polling::PollMode,\n    ) -> io::Result<()> {\n        self.conin.register(poll, with_key(interest, PTY_READ_WRITE_TOKEN), poll_opts);\n        self.conout.register(poll, with_key(interest, PTY_READ_WRITE_TOKEN), poll_opts);\n        self.child_watcher.register(poll, with_key(interest, PTY_CHILD_EVENT_TOKEN));\n\n        Ok(())\n    }\n\n    #[inline]\n    fn deregister(&mut self, _poll: &Arc<Poller>) -> io::Result<()> {\n        self.conin.deregister();\n        self.conout.deregister();\n        self.child_watcher.deregister();\n\n        Ok(())\n    }\n\n    #[inline]\n    fn reader(&mut self) -> &mut Self::Reader {\n        &mut self.conout\n    }\n\n    #[inline]\n    fn writer(&mut self) -> &mut Self::Writer {\n        &mut self.conin\n    }\n}\n\nimpl EventedPty for Pty {\n    fn next_child_event(&mut self) -> Option<ChildEvent> {\n        match self.child_watcher.event_rx().try_recv() {\n            Ok(ev) => Some(ev),\n            Err(TryRecvError::Empty) => None,\n            Err(TryRecvError::Disconnected) => Some(ChildEvent::Exited(None)),\n        }\n    }\n}\n\nimpl OnResize for Pty {\n    fn on_resize(&mut self, window_size: WindowSize) {\n        self.backend.on_resize(window_size)\n    }\n}\n\nfn cmdline(config: &Options) -> String {\n    let default_shell = Shell::new(\"powershell\".to_owned(), Vec::new());\n    let shell = config.shell.as_ref().unwrap_or(&default_shell);\n\n    once(shell.program.as_str())\n        .chain(shell.args.iter().map(|s| s.as_str()))\n        .collect::<Vec<_>>()\n        .join(\" \")\n}\n\n/// Converts the string slice into a Windows-standard representation for \"W\"-\n/// suffixed function variants, which accept UTF-16 encoded string values.\npub fn win32_string<S: AsRef<OsStr> + ?Sized>(value: &S) -> Vec<u16> {\n    OsStr::new(value).encode_wide().chain(once(0)).collect()\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_61_chunk_0",
        "original_index": 0,
        "content": "use std::ffi::OsStr;\nuse std::io::{self, Error, ErrorKind, Result};\nuse std::iter::once;\nuse std::os::windows::ffi::OsStrExt;\nuse std::sync::mpsc::TryRecvError;\nuse std::sync::Arc;\n\nuse crate::event::{OnResize, WindowSize};\nuse crate::tty::windows::child::ChildExitWatcher;\nuse crate::tty::{ChildEvent, EventedPty, EventedReadWrite, Options, Shell};\n\nmod blocking;\nmod child;\nmod conpty;\n\nuse blocking::{UnblockedReader, UnblockedWriter};\nuse conpty::Conpty as Backend;\nuse miow::pipe::{AnonRead, AnonWrite};\nuse polling::{Event, Poller};\n\npub const PTY_CHILD_EVENT_TOKEN: usize = 1;\npub const PTY_READ_WRITE_TOKEN: usize = 2;\n\ntype ReadPipe = UnblockedReader<AnonRead>;\ntype WritePipe = UnblockedWriter<AnonWrite>;\n\n"
      },
      {
        "chunk_id": "doc_61_chunk_1",
        "original_index": 1,
        "content": "pub struct Pty {\n    // XXX: Backend is required to be the first field, to ensure correct drop order. Dropping\n    // `conout` before `backend` will cause a deadlock (with Conpty).\n    backend: Backend,\n    conout: ReadPipe,\n    conin: WritePipe,\n    child_watcher: ChildExitWatcher,\n}\n\npub fn new(config: &Options, window_size: WindowSize, _window_id: u64) -> Result<Pty> {\n    conpty::new(config, window_size)\n        .ok_or_else(|| Error::new(ErrorKind::Other, \"failed to spawn conpty\"))\n}\n\n"
      },
      {
        "chunk_id": "doc_61_chunk_2",
        "original_index": 2,
        "content": "impl Pty {\n    fn new(\n        backend: impl Into<Backend>,\n        conout: impl Into<ReadPipe>,\n        conin: impl Into<WritePipe>,\n        child_watcher: ChildExitWatcher,\n    ) -> Self {\n        Self { backend: backend.into(), conout: conout.into(), conin: conin.into(), child_watcher }\n    }\n\n    pub fn child_watcher(&self) -> &ChildExitWatcher {\n        &self.child_watcher\n    }\n}\n\nfn with_key(mut event: Event, key: usize) -> Event {\n    event.key = key;\n    event\n}\n\nimpl EventedReadWrite for Pty {\n    type Reader = ReadPipe;\n    type Writer = WritePipe;\n\n"
      },
      {
        "chunk_id": "doc_61_chunk_3",
        "original_index": 3,
        "content": "    #[inline]\n    unsafe fn register(\n        &mut self,\n        poll: &Arc<Poller>,\n        interest: polling::Event,\n        poll_opts: polling::PollMode,\n    ) -> io::Result<()> {\n        self.conin.register(poll, with_key(interest, PTY_READ_WRITE_TOKEN), poll_opts);\n        self.conout.register(poll, with_key(interest, PTY_READ_WRITE_TOKEN), poll_opts);\n        self.child_watcher.register(poll, with_key(interest, PTY_CHILD_EVENT_TOKEN));\n\n"
      },
      {
        "chunk_id": "doc_61_chunk_4",
        "original_index": 4,
        "content": "        Ok(())\n    }\n\n    #[inline]\n    fn reregister(\n        &mut self,\n        poll: &Arc<Poller>,\n        interest: polling::Event,\n        poll_opts: polling::PollMode,\n    ) -> io::Result<()> {\n        self.conin.register(poll, with_key(interest, PTY_READ_WRITE_TOKEN), poll_opts);\n        self.conout.register(poll, with_key(interest, PTY_READ_WRITE_TOKEN), poll_opts);\n        self.child_watcher.register(poll, with_key(interest, PTY_CHILD_EVENT_TOKEN));\n\n"
      },
      {
        "chunk_id": "doc_61_chunk_5",
        "original_index": 5,
        "content": "        Ok(())\n    }\n\n    #[inline]\n    fn deregister(&mut self, _poll: &Arc<Poller>) -> io::Result<()> {\n        self.conin.deregister();\n        self.conout.deregister();\n        self.child_watcher.deregister();\n\n        Ok(())\n    }\n\n    #[inline]\n    fn reader(&mut self) -> &mut Self::Reader {\n        &mut self.conout\n    }\n\n    #[inline]\n    fn writer(&mut self) -> &mut Self::Writer {\n        &mut self.conin\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_61_chunk_6",
        "original_index": 6,
        "content": "impl EventedPty for Pty {\n    fn next_child_event(&mut self) -> Option<ChildEvent> {\n        match self.child_watcher.event_rx().try_recv() {\n            Ok(ev) => Some(ev),\n            Err(TryRecvError::Empty) => None,\n            Err(TryRecvError::Disconnected) => Some(ChildEvent::Exited(None)),\n        }\n    }\n}\n\nimpl OnResize for Pty {\n    fn on_resize(&mut self, window_size: WindowSize) {\n        self.backend.on_resize(window_size)\n    }\n}\n\nfn cmdline(config: &Options) -> String {\n    let default_shell = Shell::new(\"powershell\".to_owned(), Vec::new());\n    let shell = config.shell.as_ref().unwrap_or(&default_shell);\n\n"
      },
      {
        "chunk_id": "doc_61_chunk_7",
        "original_index": 7,
        "content": "    once(shell.program.as_str())\n        .chain(shell.args.iter().map(|s| s.as_str()))\n        .collect::<Vec<_>>()\n        .join(\" \")\n}\n\n/// Converts the string slice into a Windows-standard representation for \"W\"-\n/// suffixed function variants, which accept UTF-16 encoded string values.\npub fn win32_string<S: AsRef<OsStr> + ?Sized>(value: &S) -> Vec<u16> {\n    OsStr::new(value).encode_wide().chain(once(0)).collect()\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_62",
    "original_uuid": "63734181335dc6b208cfc5728b9413f7967c140adcf4332d61a1a16ae8df9fbc",
    "content": "//! Serde helpers.\n\nuse toml::{Table, Value};\n\n/// Merge two serde structures.\n///\n/// This will take all values from `replacement` and use `base` whenever a value isn't present in\n/// `replacement`.\npub fn merge(base: Value, replacement: Value) -> Value {\n    match (base, replacement) {\n        (Value::Array(mut base), Value::Array(mut replacement)) => {\n            base.append(&mut replacement);\n            Value::Array(base)\n        },\n        (Value::Table(base), Value::Table(replacement)) => {\n            Value::Table(merge_tables(base, replacement))\n        },\n        (_, value) => value,\n    }\n}\n\n/// Merge two key/value tables.\nfn merge_tables(mut base: Table, replacement: Table) -> Table {\n    for (key, value) in replacement {\n        let value = match base.remove(&key) {\n            Some(base_value) => merge(base_value, value),\n            None => value,\n        };\n        base.insert(key, value);\n    }\n\n    base\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn merge_primitive() {\n        let base = Value::Table(Table::new());\n        let replacement = Value::Boolean(true);\n        assert_eq!(merge(base, replacement.clone()), replacement);\n\n        let base = Value::Boolean(false);\n        let replacement = Value::Boolean(true);\n        assert_eq!(merge(base, replacement.clone()), replacement);\n\n        let base = Value::Integer(0.into());\n        let replacement = Value::Integer(1.into());\n        assert_eq!(merge(base, replacement.clone()), replacement);\n\n        let base = Value::String(String::new());\n        let replacement = Value::String(String::from(\"test\"));\n        assert_eq!(merge(base, replacement.clone()), replacement);\n\n        let base = Value::Table(Table::new());\n        let replacement = Value::Table(Table::new());\n        assert_eq!(merge(base.clone(), replacement), base);\n    }\n\n    #[test]\n    fn merge_sequence() {\n        let base = Value::Array(vec![Value::Table(Table::new())]);\n        let replacement = Value::Array(vec![Value::Boolean(true)]);\n        let expected = Value::Array(vec![Value::Table(Table::new()), Value::Boolean(true)]);\n        assert_eq!(merge(base, replacement), expected);\n    }\n\n    #[test]\n    fn merge_tables() {\n        let mut base_table = Table::new();\n        base_table.insert(String::from(\"a\"), Value::Boolean(true));\n        base_table.insert(String::from(\"b\"), Value::Boolean(false));\n        let base = Value::Table(base_table);\n\n        let mut replacement_table = Table::new();\n        replacement_table.insert(String::from(\"a\"), Value::Boolean(true));\n        replacement_table.insert(String::from(\"c\"), Value::Boolean(false));\n        let replacement = Value::Table(replacement_table);\n\n        let merged = merge(base, replacement);\n\n        let mut expected_table = Table::new();\n        expected_table.insert(String::from(\"b\"), Value::Boolean(false));\n        expected_table.insert(String::from(\"a\"), Value::Boolean(true));\n        expected_table.insert(String::from(\"c\"), Value::Boolean(false));\n        let expected = Value::Table(expected_table);\n\n        assert_eq!(merged, expected);\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_62_chunk_0",
        "original_index": 0,
        "content": "//! Serde helpers.\n\nuse toml::{Table, Value};\n\n/// Merge two serde structures.\n///\n/// This will take all values from `replacement` and use `base` whenever a value isn't present in\n/// `replacement`.\npub fn merge(base: Value, replacement: Value) -> Value {\n    match (base, replacement) {\n        (Value::Array(mut base), Value::Array(mut replacement)) => {\n            base.append(&mut replacement);\n            Value::Array(base)\n        },\n        (Value::Table(base), Value::Table(replacement)) => {\n            Value::Table(merge_tables(base, replacement))\n        },\n        (_, value) => value,\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_62_chunk_1",
        "original_index": 1,
        "content": "/// Merge two key/value tables.\nfn merge_tables(mut base: Table, replacement: Table) -> Table {\n    for (key, value) in replacement {\n        let value = match base.remove(&key) {\n            Some(base_value) => merge(base_value, value),\n            None => value,\n        };\n        base.insert(key, value);\n    }\n\n    base\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn merge_primitive() {\n        let base = Value::Table(Table::new());\n        let replacement = Value::Boolean(true);\n        assert_eq!(merge(base, replacement.clone()), replacement);\n\n"
      },
      {
        "chunk_id": "doc_62_chunk_2",
        "original_index": 2,
        "content": "        let base = Value::Boolean(false);\n        let replacement = Value::Boolean(true);\n        assert_eq!(merge(base, replacement.clone()), replacement);\n\n        let base = Value::Integer(0.into());\n        let replacement = Value::Integer(1.into());\n        assert_eq!(merge(base, replacement.clone()), replacement);\n\n        let base = Value::String(String::new());\n        let replacement = Value::String(String::from(\"test\"));\n        assert_eq!(merge(base, replacement.clone()), replacement);\n\n        let base = Value::Table(Table::new());\n        let replacement = Value::Table(Table::new());\n        assert_eq!(merge(base.clone(), replacement), base);\n    }\n\n"
      },
      {
        "chunk_id": "doc_62_chunk_3",
        "original_index": 3,
        "content": "    #[test]\n    fn merge_sequence() {\n        let base = Value::Array(vec![Value::Table(Table::new())]);\n        let replacement = Value::Array(vec![Value::Boolean(true)]);\n        let expected = Value::Array(vec![Value::Table(Table::new()), Value::Boolean(true)]);\n        assert_eq!(merge(base, replacement), expected);\n    }\n\n    #[test]\n    fn merge_tables() {\n        let mut base_table = Table::new();\n        base_table.insert(String::from(\"a\"), Value::Boolean(true));\n        base_table.insert(String::from(\"b\"), Value::Boolean(false));\n        let base = Value::Table(base_table);\n\n        let mut replacement_table = Table::new();\n        replacement_table.insert(String::from(\"a\"), Value::Boolean(true));\n        replacement_table.insert(String::from(\"c\"), Value::Boolean(false));\n        let replacement = Value::Table(replacement_table);\n\n        let merged = merge(base, replacement);\n\n"
      },
      {
        "chunk_id": "doc_62_chunk_4",
        "original_index": 4,
        "content": "        let mut expected_table = Table::new();\n        expected_table.insert(String::from(\"b\"), Value::Boolean(false));\n        expected_table.insert(String::from(\"a\"), Value::Boolean(true));\n        expected_table.insert(String::from(\"c\"), Value::Boolean(false));\n        let expected = Value::Table(expected_table);\n\n        assert_eq!(merged, expected);\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_63",
    "original_uuid": "28bc35399cf4cb6c66ebbab6e965034ec7f505aa522f87ff8662409309224dc8",
    "content": "//! TTY related functionality.\n\nuse std::ffi::CStr;\nuse std::fs::File;\nuse std::io::{Error, ErrorKind, Read, Result};\nuse std::mem::MaybeUninit;\nuse std::os::unix::io::{AsRawFd, FromRawFd};\nuse std::os::unix::net::UnixStream;\nuse std::os::unix::process::CommandExt;\nuse std::process::{Child, Command, Stdio};\nuse std::sync::Arc;\nuse std::{env, ptr};\n\nuse libc::{c_int, TIOCSCTTY};\nuse log::error;\nuse polling::{Event, PollMode, Poller};\nuse rustix_openpty::openpty;\nuse rustix_openpty::rustix::termios::Winsize;\n#[cfg(any(target_os = \"linux\", target_os = \"macos\"))]\nuse rustix_openpty::rustix::termios::{self, InputModes, OptionalActions};\nuse signal_hook::consts as sigconsts;\nuse signal_hook::low_level::pipe as signal_pipe;\n\nuse crate::event::{OnResize, WindowSize};\nuse crate::tty::{ChildEvent, EventedPty, EventedReadWrite, Options};\n\n// Interest in PTY read/writes.\npub(crate) const PTY_READ_WRITE_TOKEN: usize = 0;\n\n// Interest in new child events.\npub(crate) const PTY_CHILD_EVENT_TOKEN: usize = 1;\n\nmacro_rules! die {\n    ($($arg:tt)*) => {{\n        error!($($arg)*);\n        std::process::exit(1);\n    }}\n}\n\n/// Really only needed on BSD, but should be fine elsewhere.\nfn set_controlling_terminal(fd: c_int) {\n    let res = unsafe {\n        // TIOSCTTY changes based on platform and the `ioctl` call is different\n        // based on architecture (32/64). So a generic cast is used to make sure\n        // there are no issues. To allow such a generic cast the clippy warning\n        // is disabled.\n        #[allow(clippy::cast_lossless)]\n        libc::ioctl(fd, TIOCSCTTY as _, 0)\n    };\n\n    if res < 0 {\n        die!(\"ioctl TIOCSCTTY failed: {}\", Error::last_os_error());\n    }\n}\n\n#[derive(Debug)]\nstruct Passwd<'a> {\n    name: &'a str,\n    dir: &'a str,\n    shell: &'a str,\n}\n\n/// Return a Passwd struct with pointers into the provided buf.\n///\n/// # Unsafety\n///\n/// If `buf` is changed while `Passwd` is alive, bad thing will almost certainly happen.\nfn get_pw_entry(buf: &mut [i8; 1024]) -> Result<Passwd<'_>> {\n    // Create zeroed passwd struct.\n    let mut entry: MaybeUninit<libc::passwd> = MaybeUninit::uninit();\n\n    let mut res: *mut libc::passwd = ptr::null_mut();\n\n    // Try and read the pw file.\n    let uid = unsafe { libc::getuid() };\n    let status = unsafe {\n        libc::getpwuid_r(uid, entry.as_mut_ptr(), buf.as_mut_ptr() as *mut _, buf.len(), &mut res)\n    };\n    let entry = unsafe { entry.assume_init() };\n\n    if status < 0 {\n        return Err(Error::new(ErrorKind::Other, \"getpwuid_r failed\"));\n    }\n\n    if res.is_null() {\n        return Err(Error::new(ErrorKind::Other, \"pw not found\"));\n    }\n\n    // Sanity check.\n    assert_eq!(entry.pw_uid, uid);\n\n    // Build a borrowed Passwd struct.\n    Ok(Passwd {\n        name: unsafe { CStr::from_ptr(entry.pw_name).to_str().unwrap() },\n        dir: unsafe { CStr::from_ptr(entry.pw_dir).to_str().unwrap() },\n        shell: unsafe { CStr::from_ptr(entry.pw_shell).to_str().unwrap() },\n    })\n}\n\npub struct Pty {\n    child: Child,\n    file: File,\n    signals: UnixStream,\n}\n\nimpl Pty {\n    pub fn child(&self) -> &Child {\n        &self.child\n    }\n\n    pub fn file(&self) -> &File {\n        &self.file\n    }\n}\n\n/// User information that is required for a new shell session.\nstruct ShellUser {\n    user: String,\n    home: String,\n    shell: String,\n}\n\nimpl ShellUser {\n    /// look for shell, username, longname, and home dir in the respective environment variables\n    /// before falling back on looking in to `passwd`.\n    fn from_env() -> Result<Self> {\n        let mut buf = [0; 1024];\n        let pw = get_pw_entry(&mut buf);\n\n        let user = match env::var(\"USER\") {\n            Ok(user) => user,\n            Err(_) => match pw {\n                Ok(ref pw) => pw.name.to_owned(),\n                Err(err) => return Err(err),\n            },\n        };\n\n        let home = match env::var(\"HOME\") {\n            Ok(home) => home,\n            Err(_) => match pw {\n                Ok(ref pw) => pw.dir.to_owned(),\n                Err(err) => return Err(err),\n            },\n        };\n\n        let shell = match env::var(\"SHELL\") {\n            Ok(shell) => shell,\n            Err(_) => match pw {\n                Ok(ref pw) => pw.shell.to_owned(),\n                Err(err) => return Err(err),\n            },\n        };\n\n        Ok(Self { user, home, shell })\n    }\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn default_shell_command(shell: &str, _user: &str) -> Command {\n    Command::new(shell)\n}\n\n#[cfg(target_os = \"macos\")]\nfn default_shell_command(shell: &str, user: &str) -> Command {\n    let shell_name = shell.rsplit('/').next().unwrap();\n\n    // On macOS, use the `login` command so the shell will appear as a tty session.\n    let mut login_command = Command::new(\"/usr/bin/login\");\n\n    // Exec the shell with argv[0] prepended by '-' so it becomes a login shell.\n    // `login` normally does this itself, but `-l` disables this.\n    let exec = format!(\"exec -a -{} {}\", shell_name, shell);\n\n    // -f: Bypasses authentication for the already-logged-in user.\n    // -l: Skips changing directory to $HOME and prepending '-' to argv[0].\n    // -p: Preserves the environment.\n    //\n    // XXX: we use zsh here over sh due to `exec -a`.\n    login_command.args([\"-flp\", user, \"/bin/zsh\", \"-c\", &exec]);\n    login_command\n}\n\n/// Create a new TTY and return a handle to interact with it.\npub fn new(config: &Options, window_size: WindowSize, window_id: u64) -> Result<Pty> {\n    let pty = openpty(None, Some(&window_size.to_winsize()))?;\n    let (master, slave) = (pty.controller, pty.user);\n    let master_fd = master.as_raw_fd();\n    let slave_fd = slave.as_raw_fd();\n\n    #[cfg(any(target_os = \"linux\", target_os = \"macos\"))]\n    if let Ok(mut termios) = termios::tcgetattr(&master) {\n        // Set character encoding to UTF-8.\n        termios.input_modes.set(InputModes::IUTF8, true);\n        let _ = termios::tcsetattr(&master, OptionalActions::Now, &termios);\n    }\n\n    let user = ShellUser::from_env()?;\n\n    let mut builder = if let Some(shell) = config.shell.as_ref() {\n        let mut cmd = Command::new(&shell.program);\n        cmd.args(shell.args.as_slice());\n        cmd\n    } else {\n        default_shell_command(&user.shell, &user.user)\n    };\n\n    // Setup child stdin/stdout/stderr as slave fd of PTY.\n    // Ownership of fd is transferred to the Stdio structs and will be closed by them at the end of\n    // this scope. (It is not an issue that the fd is closed three times since File::drop ignores\n    // error on libc::close.).\n    builder.stdin(unsafe { Stdio::from_raw_fd(slave_fd) });\n    builder.stderr(unsafe { Stdio::from_raw_fd(slave_fd) });\n    builder.stdout(unsafe { Stdio::from_raw_fd(slave_fd) });\n\n    // Setup shell environment.\n    let window_id = window_id.to_string();\n    builder.env(\"ALACRITTY_WINDOW_ID\", &window_id);\n    builder.env(\"USER\", user.user);\n    builder.env(\"HOME\", user.home);\n    // Set Window ID for clients relying on X11 hacks.\n    builder.env(\"WINDOWID\", window_id);\n    for (key, value) in &config.env {\n        builder.env(key, value);\n    }\n\n    unsafe {\n        builder.pre_exec(move || {\n            // Create a new process group.\n            let err = libc::setsid();\n            if err == -1 {\n                return Err(Error::new(ErrorKind::Other, \"Failed to set session id\"));\n            }\n\n            set_controlling_terminal(slave_fd);\n\n            // No longer need slave/master fds.\n            libc::close(slave_fd);\n            libc::close(master_fd);\n\n            libc::signal(libc::SIGCHLD, libc::SIG_DFL);\n            libc::signal(libc::SIGHUP, libc::SIG_DFL);\n            libc::signal(libc::SIGINT, libc::SIG_DFL);\n            libc::signal(libc::SIGQUIT, libc::SIG_DFL);\n            libc::signal(libc::SIGTERM, libc::SIG_DFL);\n            libc::signal(libc::SIGALRM, libc::SIG_DFL);\n\n            Ok(())\n        });\n    }\n\n    // Handle set working directory option.\n    if let Some(dir) = &config.working_directory {\n        builder.current_dir(dir);\n    }\n\n    // Prepare signal handling before spawning child.\n    let signals = {\n        let (sender, recv) = UnixStream::pair()?;\n\n        // Register the recv end of the pipe for SIGCHLD.\n        signal_pipe::register(sigconsts::SIGCHLD, sender)?;\n        recv.set_nonblocking(true)?;\n        recv\n    };\n\n    match builder.spawn() {\n        Ok(child) => {\n            unsafe {\n                // Maybe this should be done outside of this function so nonblocking\n                // isn't forced upon consumers. Although maybe it should be?\n                set_nonblocking(master_fd);\n            }\n\n            Ok(Pty { child, file: File::from(master), signals })\n        },\n        Err(err) => Err(Error::new(\n            err.kind(),\n            format!(\n                \"Failed to spawn command '{}': {}\",\n                builder.get_program().to_string_lossy(),\n                err\n            ),\n        )),\n    }\n}\n\nimpl Drop for Pty {\n    fn drop(&mut self) {\n        // Make sure the PTY is terminated properly.\n        unsafe {\n            libc::kill(self.child.id() as i32, libc::SIGHUP);\n        }\n        let _ = self.child.wait();\n    }\n}\n\nimpl EventedReadWrite for Pty {\n    type Reader = File;\n    type Writer = File;\n\n    #[inline]\n    unsafe fn register(\n        &mut self,\n        poll: &Arc<Poller>,\n        mut interest: Event,\n        poll_opts: PollMode,\n    ) -> Result<()> {\n        interest.key = PTY_READ_WRITE_TOKEN;\n        unsafe {\n            poll.add_with_mode(&self.file, interest, poll_opts)?;\n        }\n\n        unsafe {\n            poll.add_with_mode(\n                &self.signals,\n                Event::readable(PTY_CHILD_EVENT_TOKEN),\n                PollMode::Level,\n            )\n        }\n    }\n\n    #[inline]\n    fn reregister(\n        &mut self,\n        poll: &Arc<Poller>,\n        mut interest: Event,\n        poll_opts: PollMode,\n    ) -> Result<()> {\n        interest.key = PTY_READ_WRITE_TOKEN;\n        poll.modify_with_mode(&self.file, interest, poll_opts)?;\n\n        poll.modify_with_mode(\n            &self.signals,\n            Event::readable(PTY_CHILD_EVENT_TOKEN),\n            PollMode::Level,\n        )\n    }\n\n    #[inline]\n    fn deregister(&mut self, poll: &Arc<Poller>) -> Result<()> {\n        poll.delete(&self.file)?;\n        poll.delete(&self.signals)\n    }\n\n    #[inline]\n    fn reader(&mut self) -> &mut File {\n        &mut self.file\n    }\n\n    #[inline]\n    fn writer(&mut self) -> &mut File {\n        &mut self.file\n    }\n}\n\nimpl EventedPty for Pty {\n    #[inline]\n    fn next_child_event(&mut self) -> Option<ChildEvent> {\n        // See if there has been a SIGCHLD.\n        let mut buf = [0u8; 1];\n        if let Err(err) = self.signals.read(&mut buf) {\n            if err.kind() != ErrorKind::WouldBlock {\n                error!(\"Error reading from signal pipe: {}\", err);\n            }\n            return None;\n        }\n\n        // Match on the child process.\n        match self.child.try_wait() {\n            Err(err) => {\n                error!(\"Error checking child process termination: {}\", err);\n                None\n            },\n            Ok(None) => None,\n            Ok(exit_status) => Some(ChildEvent::Exited(exit_status.and_then(|s| s.code()))),\n        }\n    }\n}\n\nimpl OnResize for Pty {\n    /// Resize the PTY.\n    ///\n    /// Tells the kernel that the window size changed with the new pixel\n    /// dimensions and line/column counts.\n    fn on_resize(&mut self, window_size: WindowSize) {\n        let win = window_size.to_winsize();\n\n        let res = unsafe { libc::ioctl(self.file.as_raw_fd(), libc::TIOCSWINSZ, &win as *const _) };\n\n        if res < 0 {\n            die!(\"ioctl TIOCSWINSZ failed: {}\", Error::last_os_error());\n        }\n    }\n}\n\n/// Types that can produce a `Winsize`.\npub trait ToWinsize {\n    /// Get a `Winsize`.\n    fn to_winsize(self) -> Winsize;\n}\n\nimpl ToWinsize for WindowSize {\n    fn to_winsize(self) -> Winsize {\n        let ws_row = self.num_lines as libc::c_ushort;\n        let ws_col = self.num_cols as libc::c_ushort;\n\n        let ws_xpixel = ws_col * self.cell_width as libc::c_ushort;\n        let ws_ypixel = ws_row * self.cell_height as libc::c_ushort;\n        Winsize { ws_row, ws_col, ws_xpixel, ws_ypixel }\n    }\n}\n\nunsafe fn set_nonblocking(fd: c_int) {\n    use libc::{fcntl, F_GETFL, F_SETFL, O_NONBLOCK};\n\n    let res = fcntl(fd, F_SETFL, fcntl(fd, F_GETFL, 0) | O_NONBLOCK);\n    assert_eq!(res, 0);\n}\n\n#[test]\nfn test_get_pw_entry() {\n    let mut buf: [i8; 1024] = [0; 1024];\n    let _pw = get_pw_entry(&mut buf).unwrap();\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_63_chunk_0",
        "original_index": 0,
        "content": "//! TTY related functionality.\n\nuse std::ffi::CStr;\nuse std::fs::File;\nuse std::io::{Error, ErrorKind, Read, Result};\nuse std::mem::MaybeUninit;\nuse std::os::unix::io::{AsRawFd, FromRawFd};\nuse std::os::unix::net::UnixStream;\nuse std::os::unix::process::CommandExt;\nuse std::process::{Child, Command, Stdio};\nuse std::sync::Arc;\nuse std::{env, ptr};\n\nuse libc::{c_int, TIOCSCTTY};\nuse log::error;\nuse polling::{Event, PollMode, Poller};\nuse rustix_openpty::openpty;\nuse rustix_openpty::rustix::termios::Winsize;\n#[cfg(any(target_os = \"linux\", target_os = \"macos\"))]\nuse rustix_openpty::rustix::termios::{self, InputModes, OptionalActions};\nuse signal_hook::consts as sigconsts;\nuse signal_hook::low_level::pipe as signal_pipe;\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_1",
        "original_index": 1,
        "content": "use crate::event::{OnResize, WindowSize};\nuse crate::tty::{ChildEvent, EventedPty, EventedReadWrite, Options};\n\n// Interest in PTY read/writes.\npub(crate) const PTY_READ_WRITE_TOKEN: usize = 0;\n\n// Interest in new child events.\npub(crate) const PTY_CHILD_EVENT_TOKEN: usize = 1;\n\nmacro_rules! die {\n    ($($arg:tt)*) => {{\n        error!($($arg)*);\n        std::process::exit(1);\n    }}\n}\n\n/// Really only needed on BSD, but should be fine elsewhere.\nfn set_controlling_terminal(fd: c_int) {\n    let res = unsafe {\n        // TIOSCTTY changes based on platform and the `ioctl` call is different\n        // based on architecture (32/64). So a generic cast is used to make sure\n        // there are no issues. To allow such a generic cast the clippy warning\n        // is disabled.\n        #[allow(clippy::cast_lossless)]\n        libc::ioctl(fd, TIOCSCTTY as _, 0)\n    };\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_2",
        "original_index": 2,
        "content": "    if res < 0 {\n        die!(\"ioctl TIOCSCTTY failed: {}\", Error::last_os_error());\n    }\n}\n\n#[derive(Debug)]\nstruct Passwd<'a> {\n    name: &'a str,\n    dir: &'a str,\n    shell: &'a str,\n}\n\n/// Return a Passwd struct with pointers into the provided buf.\n///\n/// # Unsafety\n///\n/// If `buf` is changed while `Passwd` is alive, bad thing will almost certainly happen.\nfn get_pw_entry(buf: &mut [i8; 1024]) -> Result<Passwd<'_>> {\n    // Create zeroed passwd struct.\n    let mut entry: MaybeUninit<libc::passwd> = MaybeUninit::uninit();\n\n    let mut res: *mut libc::passwd = ptr::null_mut();\n\n    // Try and read the pw file.\n    let uid = unsafe { libc::getuid() };\n    let status = unsafe {\n        libc::getpwuid_r(uid, entry.as_mut_ptr(), buf.as_mut_ptr() as *mut _, buf.len(), &mut res)\n    };\n    let entry = unsafe { entry.assume_init() };\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_3",
        "original_index": 3,
        "content": "    if status < 0 {\n        return Err(Error::new(ErrorKind::Other, \"getpwuid_r failed\"));\n    }\n\n    if res.is_null() {\n        return Err(Error::new(ErrorKind::Other, \"pw not found\"));\n    }\n\n    // Sanity check.\n    assert_eq!(entry.pw_uid, uid);\n\n    // Build a borrowed Passwd struct.\n    Ok(Passwd {\n        name: unsafe { CStr::from_ptr(entry.pw_name).to_str().unwrap() },\n        dir: unsafe { CStr::from_ptr(entry.pw_dir).to_str().unwrap() },\n        shell: unsafe { CStr::from_ptr(entry.pw_shell).to_str().unwrap() },\n    })\n}\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_4",
        "original_index": 4,
        "content": "pub struct Pty {\n    child: Child,\n    file: File,\n    signals: UnixStream,\n}\n\nimpl Pty {\n    pub fn child(&self) -> &Child {\n        &self.child\n    }\n\n    pub fn file(&self) -> &File {\n        &self.file\n    }\n}\n\n/// User information that is required for a new shell session.\nstruct ShellUser {\n    user: String,\n    home: String,\n    shell: String,\n}\n\nimpl ShellUser {\n    /// look for shell, username, longname, and home dir in the respective environment variables\n    /// before falling back on looking in to `passwd`.\n    fn from_env() -> Result<Self> {\n        let mut buf = [0; 1024];\n        let pw = get_pw_entry(&mut buf);\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_5",
        "original_index": 5,
        "content": "        let user = match env::var(\"USER\") {\n            Ok(user) => user,\n            Err(_) => match pw {\n                Ok(ref pw) => pw.name.to_owned(),\n                Err(err) => return Err(err),\n            },\n        };\n\n        let home = match env::var(\"HOME\") {\n            Ok(home) => home,\n            Err(_) => match pw {\n                Ok(ref pw) => pw.dir.to_owned(),\n                Err(err) => return Err(err),\n            },\n        };\n\n        let shell = match env::var(\"SHELL\") {\n            Ok(shell) => shell,\n            Err(_) => match pw {\n                Ok(ref pw) => pw.shell.to_owned(),\n                Err(err) => return Err(err),\n            },\n        };\n\n        Ok(Self { user, home, shell })\n    }\n}\n\n#[cfg(not(target_os = \"macos\"))]\nfn default_shell_command(shell: &str, _user: &str) -> Command {\n    Command::new(shell)\n}\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_6",
        "original_index": 6,
        "content": "#[cfg(target_os = \"macos\")]\nfn default_shell_command(shell: &str, user: &str) -> Command {\n    let shell_name = shell.rsplit('/').next().unwrap();\n\n    // On macOS, use the `login` command so the shell will appear as a tty session.\n    let mut login_command = Command::new(\"/usr/bin/login\");\n\n    // Exec the shell with argv[0] prepended by '-' so it becomes a login shell.\n    // `login` normally does this itself, but `-l` disables this.\n    let exec = format!(\"exec -a -{} {}\", shell_name, shell);\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_7",
        "original_index": 7,
        "content": "    // -f: Bypasses authentication for the already-logged-in user.\n    // -l: Skips changing directory to $HOME and prepending '-' to argv[0].\n    // -p: Preserves the environment.\n    //\n    // XXX: we use zsh here over sh due to `exec -a`.\n    login_command.args([\"-flp\", user, \"/bin/zsh\", \"-c\", &exec]);\n    login_command\n}\n\n/// Create a new TTY and return a handle to interact with it.\npub fn new(config: &Options, window_size: WindowSize, window_id: u64) -> Result<Pty> {\n    let pty = openpty(None, Some(&window_size.to_winsize()))?;\n    let (master, slave) = (pty.controller, pty.user);\n    let master_fd = master.as_raw_fd();\n    let slave_fd = slave.as_raw_fd();\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_8",
        "original_index": 8,
        "content": "    #[cfg(any(target_os = \"linux\", target_os = \"macos\"))]\n    if let Ok(mut termios) = termios::tcgetattr(&master) {\n        // Set character encoding to UTF-8.\n        termios.input_modes.set(InputModes::IUTF8, true);\n        let _ = termios::tcsetattr(&master, OptionalActions::Now, &termios);\n    }\n\n    let user = ShellUser::from_env()?;\n\n    let mut builder = if let Some(shell) = config.shell.as_ref() {\n        let mut cmd = Command::new(&shell.program);\n        cmd.args(shell.args.as_slice());\n        cmd\n    } else {\n        default_shell_command(&user.shell, &user.user)\n    };\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_9",
        "original_index": 9,
        "content": "    // Setup child stdin/stdout/stderr as slave fd of PTY.\n    // Ownership of fd is transferred to the Stdio structs and will be closed by them at the end of\n    // this scope. (It is not an issue that the fd is closed three times since File::drop ignores\n    // error on libc::close.).\n    builder.stdin(unsafe { Stdio::from_raw_fd(slave_fd) });\n    builder.stderr(unsafe { Stdio::from_raw_fd(slave_fd) });\n    builder.stdout(unsafe { Stdio::from_raw_fd(slave_fd) });\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_10",
        "original_index": 10,
        "content": "    // Setup shell environment.\n    let window_id = window_id.to_string();\n    builder.env(\"ALACRITTY_WINDOW_ID\", &window_id);\n    builder.env(\"USER\", user.user);\n    builder.env(\"HOME\", user.home);\n    // Set Window ID for clients relying on X11 hacks.\n    builder.env(\"WINDOWID\", window_id);\n    for (key, value) in &config.env {\n        builder.env(key, value);\n    }\n\n    unsafe {\n        builder.pre_exec(move || {\n            // Create a new process group.\n            let err = libc::setsid();\n            if err == -1 {\n                return Err(Error::new(ErrorKind::Other, \"Failed to set session id\"));\n            }\n\n            set_controlling_terminal(slave_fd);\n\n            // No longer need slave/master fds.\n            libc::close(slave_fd);\n            libc::close(master_fd);\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_11",
        "original_index": 11,
        "content": "            libc::signal(libc::SIGCHLD, libc::SIG_DFL);\n            libc::signal(libc::SIGHUP, libc::SIG_DFL);\n            libc::signal(libc::SIGINT, libc::SIG_DFL);\n            libc::signal(libc::SIGQUIT, libc::SIG_DFL);\n            libc::signal(libc::SIGTERM, libc::SIG_DFL);\n            libc::signal(libc::SIGALRM, libc::SIG_DFL);\n\n            Ok(())\n        });\n    }\n\n    // Handle set working directory option.\n    if let Some(dir) = &config.working_directory {\n        builder.current_dir(dir);\n    }\n\n    // Prepare signal handling before spawning child.\n    let signals = {\n        let (sender, recv) = UnixStream::pair()?;\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_12",
        "original_index": 12,
        "content": "        // Register the recv end of the pipe for SIGCHLD.\n        signal_pipe::register(sigconsts::SIGCHLD, sender)?;\n        recv.set_nonblocking(true)?;\n        recv\n    };\n\n    match builder.spawn() {\n        Ok(child) => {\n            unsafe {\n                // Maybe this should be done outside of this function so nonblocking\n                // isn't forced upon consumers. Although maybe it should be?\n                set_nonblocking(master_fd);\n            }\n\n            Ok(Pty { child, file: File::from(master), signals })\n        },\n        Err(err) => Err(Error::new(\n            err.kind(),\n            format!(\n                \"Failed to spawn command '{}': {}\",\n                builder.get_program().to_string_lossy(),\n                err\n            ),\n        )),\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_13",
        "original_index": 13,
        "content": "impl Drop for Pty {\n    fn drop(&mut self) {\n        // Make sure the PTY is terminated properly.\n        unsafe {\n            libc::kill(self.child.id() as i32, libc::SIGHUP);\n        }\n        let _ = self.child.wait();\n    }\n}\n\nimpl EventedReadWrite for Pty {\n    type Reader = File;\n    type Writer = File;\n\n    #[inline]\n    unsafe fn register(\n        &mut self,\n        poll: &Arc<Poller>,\n        mut interest: Event,\n        poll_opts: PollMode,\n    ) -> Result<()> {\n        interest.key = PTY_READ_WRITE_TOKEN;\n        unsafe {\n            poll.add_with_mode(&self.file, interest, poll_opts)?;\n        }\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_14",
        "original_index": 14,
        "content": "        unsafe {\n            poll.add_with_mode(\n                &self.signals,\n                Event::readable(PTY_CHILD_EVENT_TOKEN),\n                PollMode::Level,\n            )\n        }\n    }\n\n    #[inline]\n    fn reregister(\n        &mut self,\n        poll: &Arc<Poller>,\n        mut interest: Event,\n        poll_opts: PollMode,\n    ) -> Result<()> {\n        interest.key = PTY_READ_WRITE_TOKEN;\n        poll.modify_with_mode(&self.file, interest, poll_opts)?;\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_15",
        "original_index": 15,
        "content": "        poll.modify_with_mode(\n            &self.signals,\n            Event::readable(PTY_CHILD_EVENT_TOKEN),\n            PollMode::Level,\n        )\n    }\n\n    #[inline]\n    fn deregister(&mut self, poll: &Arc<Poller>) -> Result<()> {\n        poll.delete(&self.file)?;\n        poll.delete(&self.signals)\n    }\n\n    #[inline]\n    fn reader(&mut self) -> &mut File {\n        &mut self.file\n    }\n\n    #[inline]\n    fn writer(&mut self) -> &mut File {\n        &mut self.file\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_16",
        "original_index": 16,
        "content": "impl EventedPty for Pty {\n    #[inline]\n    fn next_child_event(&mut self) -> Option<ChildEvent> {\n        // See if there has been a SIGCHLD.\n        let mut buf = [0u8; 1];\n        if let Err(err) = self.signals.read(&mut buf) {\n            if err.kind() != ErrorKind::WouldBlock {\n                error!(\"Error reading from signal pipe: {}\", err);\n            }\n            return None;\n        }\n\n        // Match on the child process.\n        match self.child.try_wait() {\n            Err(err) => {\n                error!(\"Error checking child process termination: {}\", err);\n                None\n            },\n            Ok(None) => None,\n            Ok(exit_status) => Some(ChildEvent::Exited(exit_status.and_then(|s| s.code()))),\n        }\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_17",
        "original_index": 17,
        "content": "impl OnResize for Pty {\n    /// Resize the PTY.\n    ///\n    /// Tells the kernel that the window size changed with the new pixel\n    /// dimensions and line/column counts.\n    fn on_resize(&mut self, window_size: WindowSize) {\n        let win = window_size.to_winsize();\n\n        let res = unsafe { libc::ioctl(self.file.as_raw_fd(), libc::TIOCSWINSZ, &win as *const _) };\n\n        if res < 0 {\n            die!(\"ioctl TIOCSWINSZ failed: {}\", Error::last_os_error());\n        }\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_63_chunk_18",
        "original_index": 18,
        "content": "/// Types that can produce a `Winsize`.\npub trait ToWinsize {\n    /// Get a `Winsize`.\n    fn to_winsize(self) -> Winsize;\n}\n\nimpl ToWinsize for WindowSize {\n    fn to_winsize(self) -> Winsize {\n        let ws_row = self.num_lines as libc::c_ushort;\n        let ws_col = self.num_cols as libc::c_ushort;\n\n        let ws_xpixel = ws_col * self.cell_width as libc::c_ushort;\n        let ws_ypixel = ws_row * self.cell_height as libc::c_ushort;\n        Winsize { ws_row, ws_col, ws_xpixel, ws_ypixel }\n    }\n}\n\nunsafe fn set_nonblocking(fd: c_int) {\n    use libc::{fcntl, F_GETFL, F_SETFL, O_NONBLOCK};\n\n    let res = fcntl(fd, F_SETFL, fcntl(fd, F_GETFL, 0) | O_NONBLOCK);\n    assert_eq!(res, 0);\n}\n\n#[test]\nfn test_get_pw_entry() {\n    let mut buf: [i8; 1024] = [0; 1024];\n    let _pw = get_pw_entry(&mut buf).unwrap();\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_64",
    "original_uuid": "e42de8de90207977280409db092d558c129d6d22af59b93274b588900fa6b3f7",
    "content": "use serde::{Deserialize, Deserializer};\n\nuse alacritty_config_derive::{ConfigDeserialize, SerdeReplace};\n\nuse crate::config::bindings::{self, MouseBinding};\nuse crate::config::ui_config;\n\n#[derive(ConfigDeserialize, Default, Clone, Debug, PartialEq, Eq)]\npub struct Mouse {\n    pub hide_when_typing: bool,\n    pub bindings: MouseBindings,\n}\n\n#[derive(SerdeReplace, Clone, Debug, PartialEq, Eq)]\npub struct MouseBindings(pub Vec<MouseBinding>);\n\nimpl Default for MouseBindings {\n    fn default() -> Self {\n        Self(bindings::default_mouse_bindings())\n    }\n}\n\nimpl<'de> Deserialize<'de> for MouseBindings {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: Deserializer<'de>,\n    {\n        Ok(Self(ui_config::deserialize_bindings(deserializer, Self::default().0)?))\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_64_chunk_0",
        "original_index": 0,
        "content": "use serde::{Deserialize, Deserializer};\n\nuse alacritty_config_derive::{ConfigDeserialize, SerdeReplace};\n\nuse crate::config::bindings::{self, MouseBinding};\nuse crate::config::ui_config;\n\n#[derive(ConfigDeserialize, Default, Clone, Debug, PartialEq, Eq)]\npub struct Mouse {\n    pub hide_when_typing: bool,\n    pub bindings: MouseBindings,\n}\n\n#[derive(SerdeReplace, Clone, Debug, PartialEq, Eq)]\npub struct MouseBindings(pub Vec<MouseBinding>);\n\nimpl Default for MouseBindings {\n    fn default() -> Self {\n        Self(bindings::default_mouse_bindings())\n    }\n}\n\nimpl<'de> Deserialize<'de> for MouseBindings {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: Deserializer<'de>,\n    {\n        Ok(Self(ui_config::deserialize_bindings(deserializer, Self::default().0)?))\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_65",
    "original_uuid": "dda576d7cb16763f392463733d36dc4b71bca1b3b20c410732652db82fc54578",
    "content": "use log::{debug, warn};\nuse raw_window_handle::RawDisplayHandle;\n\nuse alacritty_terminal::term::ClipboardType;\n\n#[cfg(any(test, not(any(feature = \"x11\", target_os = \"macos\", windows))))]\nuse copypasta::nop_clipboard::NopClipboardContext;\n#[cfg(all(feature = \"wayland\", not(any(target_os = \"macos\", windows))))]\nuse copypasta::wayland_clipboard;\n#[cfg(all(feature = \"x11\", not(any(target_os = \"macos\", windows))))]\nuse copypasta::x11_clipboard::{Primary as X11SelectionClipboard, X11ClipboardContext};\n#[cfg(any(feature = \"x11\", target_os = \"macos\", windows))]\nuse copypasta::ClipboardContext;\nuse copypasta::ClipboardProvider;\n\npub struct Clipboard {\n    clipboard: Box<dyn ClipboardProvider>,\n    selection: Option<Box<dyn ClipboardProvider>>,\n}\n\nimpl Clipboard {\n    pub unsafe fn new(display: RawDisplayHandle) -> Self {\n        match display {\n            #[cfg(all(feature = \"wayland\", not(any(target_os = \"macos\", windows))))]\n            RawDisplayHandle::Wayland(display) => {\n                let (selection, clipboard) =\n                    wayland_clipboard::create_clipboards_from_external(display.display);\n                Self { clipboard: Box::new(clipboard), selection: Some(Box::new(selection)) }\n            },\n            _ => Self::default(),\n        }\n    }\n\n    /// Used for tests and to handle missing clipboard provider when built without the `x11`\n    /// feature.\n    #[cfg(any(test, not(any(feature = \"x11\", target_os = \"macos\", windows))))]\n    pub fn new_nop() -> Self {\n        Self { clipboard: Box::new(NopClipboardContext::new().unwrap()), selection: None }\n    }\n}\n\nimpl Default for Clipboard {\n    fn default() -> Self {\n        #[cfg(any(target_os = \"macos\", windows))]\n        return Self { clipboard: Box::new(ClipboardContext::new().unwrap()), selection: None };\n\n        #[cfg(all(feature = \"x11\", not(any(target_os = \"macos\", windows))))]\n        return Self {\n            clipboard: Box::new(ClipboardContext::new().unwrap()),\n            selection: Some(Box::new(X11ClipboardContext::<X11SelectionClipboard>::new().unwrap())),\n        };\n\n        #[cfg(not(any(feature = \"x11\", target_os = \"macos\", windows)))]\n        return Self::new_nop();\n    }\n}\n\nimpl Clipboard {\n    pub fn store(&mut self, ty: ClipboardType, text: impl Into<String>) {\n        let clipboard = match (ty, &mut self.selection) {\n            (ClipboardType::Selection, Some(provider)) => provider,\n            (ClipboardType::Selection, None) => return,\n            _ => &mut self.clipboard,\n        };\n\n        clipboard.set_contents(text.into()).unwrap_or_else(|err| {\n            warn!(\"Unable to store text in clipboard: {}\", err);\n        });\n    }\n\n    pub fn load(&mut self, ty: ClipboardType) -> String {\n        let clipboard = match (ty, &mut self.selection) {\n            (ClipboardType::Selection, Some(provider)) => provider,\n            _ => &mut self.clipboard,\n        };\n\n        match clipboard.get_contents() {\n            Err(err) => {\n                debug!(\"Unable to load text from clipboard: {}\", err);\n                String::new()\n            },\n            Ok(text) => text,\n        }\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_65_chunk_0",
        "original_index": 0,
        "content": "use log::{debug, warn};\nuse raw_window_handle::RawDisplayHandle;\n\nuse alacritty_terminal::term::ClipboardType;\n\n#[cfg(any(test, not(any(feature = \"x11\", target_os = \"macos\", windows))))]\nuse copypasta::nop_clipboard::NopClipboardContext;\n#[cfg(all(feature = \"wayland\", not(any(target_os = \"macos\", windows))))]\nuse copypasta::wayland_clipboard;\n#[cfg(all(feature = \"x11\", not(any(target_os = \"macos\", windows))))]\nuse copypasta::x11_clipboard::{Primary as X11SelectionClipboard, X11ClipboardContext};\n#[cfg(any(feature = \"x11\", target_os = \"macos\", windows))]\nuse copypasta::ClipboardContext;\nuse copypasta::ClipboardProvider;\n\n"
      },
      {
        "chunk_id": "doc_65_chunk_1",
        "original_index": 1,
        "content": "pub struct Clipboard {\n    clipboard: Box<dyn ClipboardProvider>,\n    selection: Option<Box<dyn ClipboardProvider>>,\n}\n\nimpl Clipboard {\n    pub unsafe fn new(display: RawDisplayHandle) -> Self {\n        match display {\n            #[cfg(all(feature = \"wayland\", not(any(target_os = \"macos\", windows))))]\n            RawDisplayHandle::Wayland(display) => {\n                let (selection, clipboard) =\n                    wayland_clipboard::create_clipboards_from_external(display.display);\n                Self { clipboard: Box::new(clipboard), selection: Some(Box::new(selection)) }\n            },\n            _ => Self::default(),\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_65_chunk_2",
        "original_index": 2,
        "content": "    /// Used for tests and to handle missing clipboard provider when built without the `x11`\n    /// feature.\n    #[cfg(any(test, not(any(feature = \"x11\", target_os = \"macos\", windows))))]\n    pub fn new_nop() -> Self {\n        Self { clipboard: Box::new(NopClipboardContext::new().unwrap()), selection: None }\n    }\n}\n\nimpl Default for Clipboard {\n    fn default() -> Self {\n        #[cfg(any(target_os = \"macos\", windows))]\n        return Self { clipboard: Box::new(ClipboardContext::new().unwrap()), selection: None };\n\n"
      },
      {
        "chunk_id": "doc_65_chunk_3",
        "original_index": 3,
        "content": "        #[cfg(all(feature = \"x11\", not(any(target_os = \"macos\", windows))))]\n        return Self {\n            clipboard: Box::new(ClipboardContext::new().unwrap()),\n            selection: Some(Box::new(X11ClipboardContext::<X11SelectionClipboard>::new().unwrap())),\n        };\n\n        #[cfg(not(any(feature = \"x11\", target_os = \"macos\", windows)))]\n        return Self::new_nop();\n    }\n}\n\nimpl Clipboard {\n    pub fn store(&mut self, ty: ClipboardType, text: impl Into<String>) {\n        let clipboard = match (ty, &mut self.selection) {\n            (ClipboardType::Selection, Some(provider)) => provider,\n            (ClipboardType::Selection, None) => return,\n            _ => &mut self.clipboard,\n        };\n\n"
      },
      {
        "chunk_id": "doc_65_chunk_4",
        "original_index": 4,
        "content": "        clipboard.set_contents(text.into()).unwrap_or_else(|err| {\n            warn!(\"Unable to store text in clipboard: {}\", err);\n        });\n    }\n\n    pub fn load(&mut self, ty: ClipboardType) -> String {\n        let clipboard = match (ty, &mut self.selection) {\n            (ClipboardType::Selection, Some(provider)) => provider,\n            _ => &mut self.clipboard,\n        };\n\n        match clipboard.get_contents() {\n            Err(err) => {\n                debug!(\"Unable to load text from clipboard: {}\", err);\n                String::new()\n            },\n            Ok(text) => text,\n        }\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_66",
    "original_uuid": "2fc7d7be4454fcb111754643168b4be9ac632f43826883ec917f5698c5a15f54",
    "content": "//! Scheduler for emitting events at a specific time in the future.\n\nuse std::collections::VecDeque;\nuse std::time::{Duration, Instant};\n\nuse winit::event_loop::EventLoopProxy;\nuse winit::window::WindowId;\n\nuse crate::event::Event;\n\n/// ID uniquely identifying a timer.\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\npub struct TimerId {\n    topic: Topic,\n    window_id: WindowId,\n}\n\nimpl TimerId {\n    pub fn new(topic: Topic, window_id: WindowId) -> Self {\n        Self { topic, window_id }\n    }\n}\n\n/// Available timer topics.\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\npub enum Topic {\n    SelectionScrolling,\n    DelayedSearch,\n    BlinkCursor,\n    BlinkTimeout,\n    Frame,\n}\n\n/// Event scheduled to be emitted at a specific time.\npub struct Timer {\n    pub deadline: Instant,\n    pub event: Event,\n    pub id: TimerId,\n\n    interval: Option<Duration>,\n}\n\n/// Scheduler tracking all pending timers.\npub struct Scheduler {\n    timers: VecDeque<Timer>,\n    event_proxy: EventLoopProxy<Event>,\n}\n\nimpl Scheduler {\n    pub fn new(event_proxy: EventLoopProxy<Event>) -> Self {\n        Self { timers: VecDeque::new(), event_proxy }\n    }\n\n    /// Process all pending timers.\n    ///\n    /// If there are still timers pending after all ready events have been processed, the closest\n    /// pending deadline will be returned.\n    pub fn update(&mut self) -> Option<Instant> {\n        let now = Instant::now();\n\n        while !self.timers.is_empty() && self.timers[0].deadline <= now {\n            if let Some(timer) = self.timers.pop_front() {\n                // Automatically repeat the event.\n                if let Some(interval) = timer.interval {\n                    self.schedule(timer.event.clone(), interval, true, timer.id);\n                }\n\n                let _ = self.event_proxy.send_event(timer.event);\n            }\n        }\n\n        self.timers.front().map(|timer| timer.deadline)\n    }\n\n    /// Schedule a new event.\n    pub fn schedule(&mut self, event: Event, interval: Duration, repeat: bool, timer_id: TimerId) {\n        let deadline = Instant::now() + interval;\n\n        // Get insert position in the schedule.\n        let index = self\n            .timers\n            .iter()\n            .position(|timer| timer.deadline > deadline)\n            .unwrap_or(self.timers.len());\n\n        // Set the automatic event repeat rate.\n        let interval = if repeat { Some(interval) } else { None };\n\n        self.timers.insert(index, Timer { interval, deadline, event, id: timer_id });\n    }\n\n    /// Cancel a scheduled event.\n    pub fn unschedule(&mut self, id: TimerId) -> Option<Timer> {\n        let index = self.timers.iter().position(|timer| timer.id == id)?;\n        self.timers.remove(index)\n    }\n\n    /// Check if a timer is already scheduled.\n    pub fn scheduled(&mut self, id: TimerId) -> bool {\n        self.timers.iter().any(|timer| timer.id == id)\n    }\n\n    /// Remove all timers scheduled for a window.\n    ///\n    /// This must be called when a window is removed to ensure that timers on intervals do not\n    /// stick around forever and cause a memory leak.\n    pub fn unschedule_window(&mut self, window_id: WindowId) {\n        self.timers.retain(|timer| timer.id.window_id != window_id);\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_66_chunk_0",
        "original_index": 0,
        "content": "//! Scheduler for emitting events at a specific time in the future.\n\nuse std::collections::VecDeque;\nuse std::time::{Duration, Instant};\n\nuse winit::event_loop::EventLoopProxy;\nuse winit::window::WindowId;\n\nuse crate::event::Event;\n\n/// ID uniquely identifying a timer.\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\npub struct TimerId {\n    topic: Topic,\n    window_id: WindowId,\n}\n\nimpl TimerId {\n    pub fn new(topic: Topic, window_id: WindowId) -> Self {\n        Self { topic, window_id }\n    }\n}\n\n/// Available timer topics.\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\npub enum Topic {\n    SelectionScrolling,\n    DelayedSearch,\n    BlinkCursor,\n    BlinkTimeout,\n    Frame,\n}\n\n/// Event scheduled to be emitted at a specific time.\npub struct Timer {\n    pub deadline: Instant,\n    pub event: Event,\n    pub id: TimerId,\n\n"
      },
      {
        "chunk_id": "doc_66_chunk_1",
        "original_index": 1,
        "content": "    interval: Option<Duration>,\n}\n\n/// Scheduler tracking all pending timers.\npub struct Scheduler {\n    timers: VecDeque<Timer>,\n    event_proxy: EventLoopProxy<Event>,\n}\n\nimpl Scheduler {\n    pub fn new(event_proxy: EventLoopProxy<Event>) -> Self {\n        Self { timers: VecDeque::new(), event_proxy }\n    }\n\n    /// Process all pending timers.\n    ///\n    /// If there are still timers pending after all ready events have been processed, the closest\n    /// pending deadline will be returned.\n    pub fn update(&mut self) -> Option<Instant> {\n        let now = Instant::now();\n\n"
      },
      {
        "chunk_id": "doc_66_chunk_2",
        "original_index": 2,
        "content": "        while !self.timers.is_empty() && self.timers[0].deadline <= now {\n            if let Some(timer) = self.timers.pop_front() {\n                // Automatically repeat the event.\n                if let Some(interval) = timer.interval {\n                    self.schedule(timer.event.clone(), interval, true, timer.id);\n                }\n\n                let _ = self.event_proxy.send_event(timer.event);\n            }\n        }\n\n        self.timers.front().map(|timer| timer.deadline)\n    }\n\n    /// Schedule a new event.\n    pub fn schedule(&mut self, event: Event, interval: Duration, repeat: bool, timer_id: TimerId) {\n        let deadline = Instant::now() + interval;\n\n"
      },
      {
        "chunk_id": "doc_66_chunk_3",
        "original_index": 3,
        "content": "        // Get insert position in the schedule.\n        let index = self\n            .timers\n            .iter()\n            .position(|timer| timer.deadline > deadline)\n            .unwrap_or(self.timers.len());\n\n        // Set the automatic event repeat rate.\n        let interval = if repeat { Some(interval) } else { None };\n\n        self.timers.insert(index, Timer { interval, deadline, event, id: timer_id });\n    }\n\n"
      },
      {
        "chunk_id": "doc_66_chunk_4",
        "original_index": 4,
        "content": "    /// Cancel a scheduled event.\n    pub fn unschedule(&mut self, id: TimerId) -> Option<Timer> {\n        let index = self.timers.iter().position(|timer| timer.id == id)?;\n        self.timers.remove(index)\n    }\n\n    /// Check if a timer is already scheduled.\n    pub fn scheduled(&mut self, id: TimerId) -> bool {\n        self.timers.iter().any(|timer| timer.id == id)\n    }\n\n    /// Remove all timers scheduled for a window.\n    ///\n    /// This must be called when a window is removed to ensure that timers on intervals do not\n    /// stick around forever and cause a memory leak.\n    pub fn unschedule_window(&mut self, window_id: WindowId) {\n        self.timers.retain(|timer| timer.id.window_id != window_id);\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_67",
    "original_uuid": "6e284600be25c8833b866ef0ebfab953a8d0a0f8420cfe56fa17e28664de1b82",
    "content": "use std::io::Write;\nuse std::{io, panic};\n\nuse windows_sys::Win32::UI::WindowsAndMessaging::{\n    MessageBoxW, MB_ICONERROR, MB_OK, MB_SETFOREGROUND, MB_TASKMODAL,\n};\n\nuse alacritty_terminal::tty::windows::win32_string;\n\n// Install a panic handler that renders the panic in a classical Windows error\n// dialog box as well as writes the panic to STDERR.\npub fn attach_handler() {\n    panic::set_hook(Box::new(|panic_info| {\n        let _ = writeln!(io::stderr(), \"{}\", panic_info);\n        let msg = format!(\"{}\\n\\nPress Ctrl-C to Copy\", panic_info);\n        unsafe {\n            MessageBoxW(\n                0isize,\n                win32_string(&msg).as_ptr(),\n                win32_string(\"Alacritty: Runtime Error\").as_ptr(),\n                MB_ICONERROR | MB_OK | MB_SETFOREGROUND | MB_TASKMODAL,\n            );\n        }\n    }));\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_67_chunk_0",
        "original_index": 0,
        "content": "use std::io::Write;\nuse std::{io, panic};\n\nuse windows_sys::Win32::UI::WindowsAndMessaging::{\n    MessageBoxW, MB_ICONERROR, MB_OK, MB_SETFOREGROUND, MB_TASKMODAL,\n};\n\nuse alacritty_terminal::tty::windows::win32_string;\n\n// Install a panic handler that renders the panic in a classical Windows error\n// dialog box as well as writes the panic to STDERR.\npub fn attach_handler() {\n    panic::set_hook(Box::new(|panic_info| {\n        let _ = writeln!(io::stderr(), \"{}\", panic_info);\n        let msg = format!(\"{}\\n\\nPress Ctrl-C to Copy\", panic_info);\n        unsafe {\n            MessageBoxW(\n                0isize,\n                win32_string(&msg).as_ptr(),\n                win32_string(\"Alacritty: Runtime Error\").as_ptr(),\n                MB_ICONERROR | MB_OK | MB_SETFOREGROUND | MB_TASKMODAL,\n            );\n        }\n    }));\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_68",
    "original_uuid": "c630bf795d027fb148a8fb73eaea06efbb510d7c32ae05b7d4c14fc6a9bbe4cb",
    "content": "//! Defines the Row type which makes up lines in the grid.\n\nuse std::cmp::{max, min};\nuse std::ops::{Index, IndexMut, Range, RangeFrom, RangeFull, RangeTo, RangeToInclusive};\nuse std::{ptr, slice};\n\n#[cfg(feature = \"serde\")]\nuse serde::{Deserialize, Serialize};\n\nuse crate::grid::GridCell;\nuse crate::index::Column;\nuse crate::term::cell::ResetDiscriminant;\n\n/// A row in the grid.\n#[derive(Default, Clone, Debug)]\n#[cfg_attr(feature = \"serde\", derive(Serialize, Deserialize))]\npub struct Row<T> {\n    inner: Vec<T>,\n\n    /// Maximum number of occupied entries.\n    ///\n    /// This is the upper bound on the number of elements in the row, which have been modified\n    /// since the last reset. All cells after this point are guaranteed to be equal.\n    pub(crate) occ: usize,\n}\n\nimpl<T: PartialEq> PartialEq for Row<T> {\n    fn eq(&self, other: &Self) -> bool {\n        self.inner == other.inner\n    }\n}\n\nimpl<T: Clone + Default> Row<T> {\n    /// Create a new terminal row.\n    ///\n    /// Ideally the `template` should be `Copy` in all performance sensitive scenarios.\n    pub fn new(columns: usize) -> Row<T> {\n        debug_assert!(columns >= 1);\n\n        let mut inner: Vec<T> = Vec::with_capacity(columns);\n\n        // This is a slightly optimized version of `std::vec::Vec::resize`.\n        unsafe {\n            let mut ptr = inner.as_mut_ptr();\n\n            for _ in 1..columns {\n                ptr::write(ptr, T::default());\n                ptr = ptr.offset(1);\n            }\n            ptr::write(ptr, T::default());\n\n            inner.set_len(columns);\n        }\n\n        Row { inner, occ: 0 }\n    }\n\n    /// Increase the number of columns in the row.\n    #[inline]\n    pub fn grow(&mut self, columns: usize) {\n        if self.inner.len() >= columns {\n            return;\n        }\n\n        self.inner.resize_with(columns, T::default);\n    }\n\n    /// Reduce the number of columns in the row.\n    ///\n    /// This will return all non-empty cells that were removed.\n    pub fn shrink(&mut self, columns: usize) -> Option<Vec<T>>\n    where\n        T: GridCell,\n    {\n        if self.inner.len() <= columns {\n            return None;\n        }\n\n        // Split off cells for a new row.\n        let mut new_row = self.inner.split_off(columns);\n        let index = new_row.iter().rposition(|c| !c.is_empty()).map_or(0, |i| i + 1);\n        new_row.truncate(index);\n\n        self.occ = min(self.occ, columns);\n\n        if new_row.is_empty() {\n            None\n        } else {\n            Some(new_row)\n        }\n    }\n\n    /// Reset all cells in the row to the `template` cell.\n    #[inline]\n    pub fn reset<D>(&mut self, template: &T)\n    where\n        T: ResetDiscriminant<D> + GridCell,\n        D: PartialEq,\n    {\n        debug_assert!(!self.inner.is_empty());\n\n        // Mark all cells as dirty if template cell changed.\n        let len = self.inner.len();\n        if self.inner[len - 1].discriminant() != template.discriminant() {\n            self.occ = len;\n        }\n\n        // Reset every dirty cell in the row.\n        for item in &mut self.inner[0..self.occ] {\n            item.reset(template);\n        }\n\n        self.occ = 0;\n    }\n}\n\n#[allow(clippy::len_without_is_empty)]\nimpl<T> Row<T> {\n    #[inline]\n    pub fn from_vec(vec: Vec<T>, occ: usize) -> Row<T> {\n        Row { inner: vec, occ }\n    }\n\n    #[inline]\n    pub fn len(&self) -> usize {\n        self.inner.len()\n    }\n\n    #[inline]\n    pub fn last(&self) -> Option<&T> {\n        self.inner.last()\n    }\n\n    #[inline]\n    pub fn last_mut(&mut self) -> Option<&mut T> {\n        self.occ = self.inner.len();\n        self.inner.last_mut()\n    }\n\n    #[inline]\n    pub fn append(&mut self, vec: &mut Vec<T>)\n    where\n        T: GridCell,\n    {\n        self.occ += vec.len();\n        self.inner.append(vec);\n    }\n\n    #[inline]\n    pub fn append_front(&mut self, mut vec: Vec<T>) {\n        self.occ += vec.len();\n\n        vec.append(&mut self.inner);\n        self.inner = vec;\n    }\n\n    /// Check if all cells in the row are empty.\n    #[inline]\n    pub fn is_clear(&self) -> bool\n    where\n        T: GridCell,\n    {\n        self.inner.iter().all(GridCell::is_empty)\n    }\n\n    #[inline]\n    pub fn front_split_off(&mut self, at: usize) -> Vec<T> {\n        self.occ = self.occ.saturating_sub(at);\n\n        let mut split = self.inner.split_off(at);\n        std::mem::swap(&mut split, &mut self.inner);\n        split\n    }\n}\n\nimpl<'a, T> IntoIterator for &'a Row<T> {\n    type IntoIter = slice::Iter<'a, T>;\n    type Item = &'a T;\n\n    #[inline]\n    fn into_iter(self) -> slice::Iter<'a, T> {\n        self.inner.iter()\n    }\n}\n\nimpl<'a, T> IntoIterator for &'a mut Row<T> {\n    type IntoIter = slice::IterMut<'a, T>;\n    type Item = &'a mut T;\n\n    #[inline]\n    fn into_iter(self) -> slice::IterMut<'a, T> {\n        self.occ = self.len();\n        self.inner.iter_mut()\n    }\n}\n\nimpl<T> Index<Column> for Row<T> {\n    type Output = T;\n\n    #[inline]\n    fn index(&self, index: Column) -> &T {\n        &self.inner[index.0]\n    }\n}\n\nimpl<T> IndexMut<Column> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, index: Column) -> &mut T {\n        self.occ = max(self.occ, *index + 1);\n        &mut self.inner[index.0]\n    }\n}\n\nimpl<T> Index<Range<Column>> for Row<T> {\n    type Output = [T];\n\n    #[inline]\n    fn index(&self, index: Range<Column>) -> &[T] {\n        &self.inner[(index.start.0)..(index.end.0)]\n    }\n}\n\nimpl<T> IndexMut<Range<Column>> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, index: Range<Column>) -> &mut [T] {\n        self.occ = max(self.occ, *index.end);\n        &mut self.inner[(index.start.0)..(index.end.0)]\n    }\n}\n\nimpl<T> Index<RangeTo<Column>> for Row<T> {\n    type Output = [T];\n\n    #[inline]\n    fn index(&self, index: RangeTo<Column>) -> &[T] {\n        &self.inner[..(index.end.0)]\n    }\n}\n\nimpl<T> IndexMut<RangeTo<Column>> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, index: RangeTo<Column>) -> &mut [T] {\n        self.occ = max(self.occ, *index.end);\n        &mut self.inner[..(index.end.0)]\n    }\n}\n\nimpl<T> Index<RangeFrom<Column>> for Row<T> {\n    type Output = [T];\n\n    #[inline]\n    fn index(&self, index: RangeFrom<Column>) -> &[T] {\n        &self.inner[(index.start.0)..]\n    }\n}\n\nimpl<T> IndexMut<RangeFrom<Column>> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, index: RangeFrom<Column>) -> &mut [T] {\n        self.occ = self.len();\n        &mut self.inner[(index.start.0)..]\n    }\n}\n\nimpl<T> Index<RangeFull> for Row<T> {\n    type Output = [T];\n\n    #[inline]\n    fn index(&self, _: RangeFull) -> &[T] {\n        &self.inner[..]\n    }\n}\n\nimpl<T> IndexMut<RangeFull> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, _: RangeFull) -> &mut [T] {\n        self.occ = self.len();\n        &mut self.inner[..]\n    }\n}\n\nimpl<T> Index<RangeToInclusive<Column>> for Row<T> {\n    type Output = [T];\n\n    #[inline]\n    fn index(&self, index: RangeToInclusive<Column>) -> &[T] {\n        &self.inner[..=(index.end.0)]\n    }\n}\n\nimpl<T> IndexMut<RangeToInclusive<Column>> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, index: RangeToInclusive<Column>) -> &mut [T] {\n        self.occ = max(self.occ, *index.end + 1);\n        &mut self.inner[..=(index.end.0)]\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_68_chunk_0",
        "original_index": 0,
        "content": "//! Defines the Row type which makes up lines in the grid.\n\nuse std::cmp::{max, min};\nuse std::ops::{Index, IndexMut, Range, RangeFrom, RangeFull, RangeTo, RangeToInclusive};\nuse std::{ptr, slice};\n\n#[cfg(feature = \"serde\")]\nuse serde::{Deserialize, Serialize};\n\nuse crate::grid::GridCell;\nuse crate::index::Column;\nuse crate::term::cell::ResetDiscriminant;\n\n/// A row in the grid.\n#[derive(Default, Clone, Debug)]\n#[cfg_attr(feature = \"serde\", derive(Serialize, Deserialize))]\npub struct Row<T> {\n    inner: Vec<T>,\n\n"
      },
      {
        "chunk_id": "doc_68_chunk_1",
        "original_index": 1,
        "content": "    /// Maximum number of occupied entries.\n    ///\n    /// This is the upper bound on the number of elements in the row, which have been modified\n    /// since the last reset. All cells after this point are guaranteed to be equal.\n    pub(crate) occ: usize,\n}\n\nimpl<T: PartialEq> PartialEq for Row<T> {\n    fn eq(&self, other: &Self) -> bool {\n        self.inner == other.inner\n    }\n}\n\nimpl<T: Clone + Default> Row<T> {\n    /// Create a new terminal row.\n    ///\n    /// Ideally the `template` should be `Copy` in all performance sensitive scenarios.\n    pub fn new(columns: usize) -> Row<T> {\n        debug_assert!(columns >= 1);\n\n"
      },
      {
        "chunk_id": "doc_68_chunk_2",
        "original_index": 2,
        "content": "        let mut inner: Vec<T> = Vec::with_capacity(columns);\n\n        // This is a slightly optimized version of `std::vec::Vec::resize`.\n        unsafe {\n            let mut ptr = inner.as_mut_ptr();\n\n            for _ in 1..columns {\n                ptr::write(ptr, T::default());\n                ptr = ptr.offset(1);\n            }\n            ptr::write(ptr, T::default());\n\n            inner.set_len(columns);\n        }\n\n        Row { inner, occ: 0 }\n    }\n\n"
      },
      {
        "chunk_id": "doc_68_chunk_3",
        "original_index": 3,
        "content": "    /// Increase the number of columns in the row.\n    #[inline]\n    pub fn grow(&mut self, columns: usize) {\n        if self.inner.len() >= columns {\n            return;\n        }\n\n        self.inner.resize_with(columns, T::default);\n    }\n\n    /// Reduce the number of columns in the row.\n    ///\n    /// This will return all non-empty cells that were removed.\n    pub fn shrink(&mut self, columns: usize) -> Option<Vec<T>>\n    where\n        T: GridCell,\n    {\n        if self.inner.len() <= columns {\n            return None;\n        }\n\n        // Split off cells for a new row.\n        let mut new_row = self.inner.split_off(columns);\n        let index = new_row.iter().rposition(|c| !c.is_empty()).map_or(0, |i| i + 1);\n        new_row.truncate(index);\n\n        self.occ = min(self.occ, columns);\n\n        if new_row.is_empty() {\n            None\n        } else {\n            Some(new_row)\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_68_chunk_4",
        "original_index": 4,
        "content": "    /// Reset all cells in the row to the `template` cell.\n    #[inline]\n    pub fn reset<D>(&mut self, template: &T)\n    where\n        T: ResetDiscriminant<D> + GridCell,\n        D: PartialEq,\n    {\n        debug_assert!(!self.inner.is_empty());\n\n        // Mark all cells as dirty if template cell changed.\n        let len = self.inner.len();\n        if self.inner[len - 1].discriminant() != template.discriminant() {\n            self.occ = len;\n        }\n\n        // Reset every dirty cell in the row.\n        for item in &mut self.inner[0..self.occ] {\n            item.reset(template);\n        }\n\n        self.occ = 0;\n    }\n}\n\n#[allow(clippy::len_without_is_empty)]\nimpl<T> Row<T> {\n    #[inline]\n    pub fn from_vec(vec: Vec<T>, occ: usize) -> Row<T> {\n        Row { inner: vec, occ }\n    }\n\n"
      },
      {
        "chunk_id": "doc_68_chunk_5",
        "original_index": 5,
        "content": "    #[inline]\n    pub fn len(&self) -> usize {\n        self.inner.len()\n    }\n\n    #[inline]\n    pub fn last(&self) -> Option<&T> {\n        self.inner.last()\n    }\n\n    #[inline]\n    pub fn last_mut(&mut self) -> Option<&mut T> {\n        self.occ = self.inner.len();\n        self.inner.last_mut()\n    }\n\n    #[inline]\n    pub fn append(&mut self, vec: &mut Vec<T>)\n    where\n        T: GridCell,\n    {\n        self.occ += vec.len();\n        self.inner.append(vec);\n    }\n\n    #[inline]\n    pub fn append_front(&mut self, mut vec: Vec<T>) {\n        self.occ += vec.len();\n\n        vec.append(&mut self.inner);\n        self.inner = vec;\n    }\n\n"
      },
      {
        "chunk_id": "doc_68_chunk_6",
        "original_index": 6,
        "content": "    /// Check if all cells in the row are empty.\n    #[inline]\n    pub fn is_clear(&self) -> bool\n    where\n        T: GridCell,\n    {\n        self.inner.iter().all(GridCell::is_empty)\n    }\n\n    #[inline]\n    pub fn front_split_off(&mut self, at: usize) -> Vec<T> {\n        self.occ = self.occ.saturating_sub(at);\n\n        let mut split = self.inner.split_off(at);\n        std::mem::swap(&mut split, &mut self.inner);\n        split\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_68_chunk_7",
        "original_index": 7,
        "content": "impl<'a, T> IntoIterator for &'a Row<T> {\n    type IntoIter = slice::Iter<'a, T>;\n    type Item = &'a T;\n\n    #[inline]\n    fn into_iter(self) -> slice::Iter<'a, T> {\n        self.inner.iter()\n    }\n}\n\nimpl<'a, T> IntoIterator for &'a mut Row<T> {\n    type IntoIter = slice::IterMut<'a, T>;\n    type Item = &'a mut T;\n\n    #[inline]\n    fn into_iter(self) -> slice::IterMut<'a, T> {\n        self.occ = self.len();\n        self.inner.iter_mut()\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_68_chunk_8",
        "original_index": 8,
        "content": "impl<T> Index<Column> for Row<T> {\n    type Output = T;\n\n    #[inline]\n    fn index(&self, index: Column) -> &T {\n        &self.inner[index.0]\n    }\n}\n\nimpl<T> IndexMut<Column> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, index: Column) -> &mut T {\n        self.occ = max(self.occ, *index + 1);\n        &mut self.inner[index.0]\n    }\n}\n\nimpl<T> Index<Range<Column>> for Row<T> {\n    type Output = [T];\n\n    #[inline]\n    fn index(&self, index: Range<Column>) -> &[T] {\n        &self.inner[(index.start.0)..(index.end.0)]\n    }\n}\n\nimpl<T> IndexMut<Range<Column>> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, index: Range<Column>) -> &mut [T] {\n        self.occ = max(self.occ, *index.end);\n        &mut self.inner[(index.start.0)..(index.end.0)]\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_68_chunk_9",
        "original_index": 9,
        "content": "impl<T> Index<RangeTo<Column>> for Row<T> {\n    type Output = [T];\n\n    #[inline]\n    fn index(&self, index: RangeTo<Column>) -> &[T] {\n        &self.inner[..(index.end.0)]\n    }\n}\n\nimpl<T> IndexMut<RangeTo<Column>> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, index: RangeTo<Column>) -> &mut [T] {\n        self.occ = max(self.occ, *index.end);\n        &mut self.inner[..(index.end.0)]\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_68_chunk_10",
        "original_index": 10,
        "content": "impl<T> Index<RangeFrom<Column>> for Row<T> {\n    type Output = [T];\n\n    #[inline]\n    fn index(&self, index: RangeFrom<Column>) -> &[T] {\n        &self.inner[(index.start.0)..]\n    }\n}\n\nimpl<T> IndexMut<RangeFrom<Column>> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, index: RangeFrom<Column>) -> &mut [T] {\n        self.occ = self.len();\n        &mut self.inner[(index.start.0)..]\n    }\n}\n\nimpl<T> Index<RangeFull> for Row<T> {\n    type Output = [T];\n\n    #[inline]\n    fn index(&self, _: RangeFull) -> &[T] {\n        &self.inner[..]\n    }\n}\n\nimpl<T> IndexMut<RangeFull> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, _: RangeFull) -> &mut [T] {\n        self.occ = self.len();\n        &mut self.inner[..]\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_68_chunk_11",
        "original_index": 11,
        "content": "impl<T> Index<RangeToInclusive<Column>> for Row<T> {\n    type Output = [T];\n\n    #[inline]\n    fn index(&self, index: RangeToInclusive<Column>) -> &[T] {\n        &self.inner[..=(index.end.0)]\n    }\n}\n\nimpl<T> IndexMut<RangeToInclusive<Column>> for Row<T> {\n    #[inline]\n    fn index_mut(&mut self, index: RangeToInclusive<Column>) -> &mut [T] {\n        self.occ = max(self.occ, *index.end + 1);\n        &mut self.inner[..=(index.end.0)]\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_69",
    "original_uuid": "3b71dd9257861671e20a407ef83e6fe4eaab1996ebaf57369ea40439e0deb293",
    "content": "use log::LevelFilter;\n\nuse alacritty_config_derive::ConfigDeserialize;\n\n/// Debugging options.\n#[derive(ConfigDeserialize, Copy, Clone, Debug, PartialEq, Eq, PartialOrd, Ord)]\npub struct Debug {\n    pub log_level: LevelFilter,\n\n    pub print_events: bool,\n\n    /// Keep the log file after quitting.\n    pub persistent_logging: bool,\n\n    /// Should show render timer.\n    pub render_timer: bool,\n\n    /// Highlight damage information produced by alacritty.\n    pub highlight_damage: bool,\n\n    /// The renderer alacritty should be using.\n    pub renderer: Option<RendererPreference>,\n\n    /// Use EGL as display API if the current platform allows it.\n    pub prefer_egl: bool,\n\n    /// Record ref test.\n    #[config(skip)]\n    pub ref_test: bool,\n}\n\nimpl Default for Debug {\n    fn default() -> Self {\n        Self {\n            log_level: LevelFilter::Warn,\n            print_events: Default::default(),\n            persistent_logging: Default::default(),\n            render_timer: Default::default(),\n            highlight_damage: Default::default(),\n            ref_test: Default::default(),\n            renderer: Default::default(),\n            prefer_egl: Default::default(),\n        }\n    }\n}\n\n/// The renderer configuration options.\n#[derive(ConfigDeserialize, Copy, Clone, Debug, PartialEq, Eq, PartialOrd, Ord)]\npub enum RendererPreference {\n    /// OpenGL 3.3 renderer.\n    Glsl3,\n\n    /// GLES 2 renderer, with optional extensions like dual source blending.\n    Gles2,\n\n    /// Pure GLES 2 renderer.\n    Gles2Pure,\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_69_chunk_0",
        "original_index": 0,
        "content": "use log::LevelFilter;\n\nuse alacritty_config_derive::ConfigDeserialize;\n\n/// Debugging options.\n#[derive(ConfigDeserialize, Copy, Clone, Debug, PartialEq, Eq, PartialOrd, Ord)]\npub struct Debug {\n    pub log_level: LevelFilter,\n\n    pub print_events: bool,\n\n    /// Keep the log file after quitting.\n    pub persistent_logging: bool,\n\n    /// Should show render timer.\n    pub render_timer: bool,\n\n    /// Highlight damage information produced by alacritty.\n    pub highlight_damage: bool,\n\n    /// The renderer alacritty should be using.\n    pub renderer: Option<RendererPreference>,\n\n    /// Use EGL as display API if the current platform allows it.\n    pub prefer_egl: bool,\n\n    /// Record ref test.\n    #[config(skip)]\n    pub ref_test: bool,\n}\n\n"
      },
      {
        "chunk_id": "doc_69_chunk_1",
        "original_index": 1,
        "content": "impl Default for Debug {\n    fn default() -> Self {\n        Self {\n            log_level: LevelFilter::Warn,\n            print_events: Default::default(),\n            persistent_logging: Default::default(),\n            render_timer: Default::default(),\n            highlight_damage: Default::default(),\n            ref_test: Default::default(),\n            renderer: Default::default(),\n            prefer_egl: Default::default(),\n        }\n    }\n}\n\n/// The renderer configuration options.\n#[derive(ConfigDeserialize, Copy, Clone, Debug, PartialEq, Eq, PartialOrd, Ord)]\npub enum RendererPreference {\n    /// OpenGL 3.3 renderer.\n    Glsl3,\n\n    /// GLES 2 renderer, with optional extensions like dual source blending.\n    Gles2,\n\n    /// Pure GLES 2 renderer.\n    Gles2Pure,\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_70",
    "original_uuid": "96be8bd624e32a74578a45205b0da1cf48669382263d771180360d5a4f40e60b",
    "content": "//! The display subsystem including window management, font rasterization, and\n//! GPU drawing.\n\nuse std::cmp;\nuse std::fmt::{self, Formatter};\nuse std::mem::{self, ManuallyDrop};\nuse std::num::NonZeroU32;\nuse std::ops::{Deref, DerefMut};\nuse std::time::{Duration, Instant};\n\nuse glutin::context::{NotCurrentContext, PossiblyCurrentContext};\nuse glutin::prelude::*;\nuse glutin::surface::{Surface, SwapInterval, WindowSurface};\n\nuse log::{debug, info};\nuse parking_lot::MutexGuard;\nuse raw_window_handle::RawWindowHandle;\nuse serde::{Deserialize, Serialize};\nuse winit::dpi::PhysicalSize;\nuse winit::keyboard::ModifiersState;\nuse winit::window::CursorIcon;\n\nuse crossfont::{Rasterize, Rasterizer, Size as FontSize};\nuse unicode_width::UnicodeWidthChar;\n\nuse alacritty_terminal::event::{EventListener, OnResize, WindowSize};\nuse alacritty_terminal::grid::Dimensions as TermDimensions;\nuse alacritty_terminal::index::{Column, Direction, Line, Point};\nuse alacritty_terminal::selection::Selection;\nuse alacritty_terminal::term::cell::Flags;\nuse alacritty_terminal::term::{\n    self, point_to_viewport, LineDamageBounds, Term, TermDamage, TermMode, MIN_COLUMNS,\n    MIN_SCREEN_LINES,\n};\nuse alacritty_terminal::vte::ansi::{CursorShape, NamedColor};\n\nuse crate::config::font::Font;\nuse crate::config::window::Dimensions;\n#[cfg(not(windows))]\nuse crate::config::window::StartupMode;\nuse crate::config::UiConfig;\nuse crate::display::bell::VisualBell;\nuse crate::display::color::{List, Rgb};\nuse crate::display::content::{RenderableContent, RenderableCursor};\nuse crate::display::cursor::IntoRects;\nuse crate::display::damage::{damage_y_to_viewport_y, DamageTracker};\nuse crate::display::hint::{HintMatch, HintState};\nuse crate::display::meter::Meter;\nuse crate::display::window::Window;\nuse crate::event::{Event, EventType, Mouse, SearchState};\nuse crate::message_bar::{MessageBuffer, MessageType};\nuse crate::renderer::rects::{RenderLine, RenderLines, RenderRect};\nuse crate::renderer::{self, GlyphCache, Renderer};\nuse crate::scheduler::{Scheduler, TimerId, Topic};\nuse crate::string::{ShortenDirection, StrShortener};\n\npub mod color;\npub mod content;\npub mod cursor;\npub mod hint;\npub mod window;\n\nmod bell;\nmod damage;\nmod meter;\n\n/// Label for the forward terminal search bar.\nconst FORWARD_SEARCH_LABEL: &str = \"Search: \";\n\n/// Label for the backward terminal search bar.\nconst BACKWARD_SEARCH_LABEL: &str = \"Backward Search: \";\n\n/// The character used to shorten the visible text like uri preview or search regex.\nconst SHORTENER: char = '\u2026';\n\n/// Color which is used to highlight damaged rects when debugging.\nconst DAMAGE_RECT_COLOR: Rgb = Rgb::new(255, 0, 255);\n\n#[derive(Debug)]\npub enum Error {\n    /// Error with window management.\n    Window(window::Error),\n\n    /// Error dealing with fonts.\n    Font(crossfont::Error),\n\n    /// Error in renderer.\n    Render(renderer::Error),\n\n    /// Error during context operations.\n    Context(glutin::error::Error),\n}\n\nimpl std::error::Error for Error {\n    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {\n        match self {\n            Error::Window(err) => err.source(),\n            Error::Font(err) => err.source(),\n            Error::Render(err) => err.source(),\n            Error::Context(err) => err.source(),\n        }\n    }\n}\n\nimpl fmt::Display for Error {\n    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n        match self {\n            Error::Window(err) => err.fmt(f),\n            Error::Font(err) => err.fmt(f),\n            Error::Render(err) => err.fmt(f),\n            Error::Context(err) => err.fmt(f),\n        }\n    }\n}\n\nimpl From<window::Error> for Error {\n    fn from(val: window::Error) -> Self {\n        Error::Window(val)\n    }\n}\n\nimpl From<crossfont::Error> for Error {\n    fn from(val: crossfont::Error) -> Self {\n        Error::Font(val)\n    }\n}\n\nimpl From<renderer::Error> for Error {\n    fn from(val: renderer::Error) -> Self {\n        Error::Render(val)\n    }\n}\n\nimpl From<glutin::error::Error> for Error {\n    fn from(val: glutin::error::Error) -> Self {\n        Error::Context(val)\n    }\n}\n\n/// Terminal size info.\n#[derive(Serialize, Deserialize, Debug, Copy, Clone, PartialEq, Eq)]\npub struct SizeInfo<T = f32> {\n    /// Terminal window width.\n    width: T,\n\n    /// Terminal window height.\n    height: T,\n\n    /// Width of individual cell.\n    cell_width: T,\n\n    /// Height of individual cell.\n    cell_height: T,\n\n    /// Horizontal window padding.\n    padding_x: T,\n\n    /// Vertical window padding.\n    padding_y: T,\n\n    /// Number of lines in the viewport.\n    screen_lines: usize,\n\n    /// Number of columns in the viewport.\n    columns: usize,\n}\n\nimpl From<SizeInfo<f32>> for SizeInfo<u32> {\n    fn from(size_info: SizeInfo<f32>) -> Self {\n        Self {\n            width: size_info.width as u32,\n            height: size_info.height as u32,\n            cell_width: size_info.cell_width as u32,\n            cell_height: size_info.cell_height as u32,\n            padding_x: size_info.padding_x as u32,\n            padding_y: size_info.padding_y as u32,\n            screen_lines: size_info.screen_lines,\n            columns: size_info.screen_lines,\n        }\n    }\n}\n\nimpl From<SizeInfo<f32>> for WindowSize {\n    fn from(size_info: SizeInfo<f32>) -> Self {\n        Self {\n            num_cols: size_info.columns() as u16,\n            num_lines: size_info.screen_lines() as u16,\n            cell_width: size_info.cell_width() as u16,\n            cell_height: size_info.cell_height() as u16,\n        }\n    }\n}\n\nimpl<T: Clone + Copy> SizeInfo<T> {\n    #[inline]\n    pub fn width(&self) -> T {\n        self.width\n    }\n\n    #[inline]\n    pub fn height(&self) -> T {\n        self.height\n    }\n\n    #[inline]\n    pub fn cell_width(&self) -> T {\n        self.cell_width\n    }\n\n    #[inline]\n    pub fn cell_height(&self) -> T {\n        self.cell_height\n    }\n\n    #[inline]\n    pub fn padding_x(&self) -> T {\n        self.padding_x\n    }\n\n    #[inline]\n    pub fn padding_y(&self) -> T {\n        self.padding_y\n    }\n}\n\nimpl SizeInfo<f32> {\n    #[allow(clippy::too_many_arguments)]\n    pub fn new(\n        width: f32,\n        height: f32,\n        cell_width: f32,\n        cell_height: f32,\n        mut padding_x: f32,\n        mut padding_y: f32,\n        dynamic_padding: bool,\n    ) -> SizeInfo {\n        if dynamic_padding {\n            padding_x = Self::dynamic_padding(padding_x.floor(), width, cell_width);\n            padding_y = Self::dynamic_padding(padding_y.floor(), height, cell_height);\n        }\n\n        let lines = (height - 2. * padding_y) / cell_height;\n        let screen_lines = cmp::max(lines as usize, MIN_SCREEN_LINES);\n\n        let columns = (width - 2. * padding_x) / cell_width;\n        let columns = cmp::max(columns as usize, MIN_COLUMNS);\n\n        SizeInfo {\n            width,\n            height,\n            cell_width,\n            cell_height,\n            padding_x: padding_x.floor(),\n            padding_y: padding_y.floor(),\n            screen_lines,\n            columns,\n        }\n    }\n\n    #[inline]\n    pub fn reserve_lines(&mut self, count: usize) {\n        self.screen_lines = cmp::max(self.screen_lines.saturating_sub(count), MIN_SCREEN_LINES);\n    }\n\n    /// Check if coordinates are inside the terminal grid.\n    ///\n    /// The padding, message bar or search are not counted as part of the grid.\n    #[inline]\n    pub fn contains_point(&self, x: usize, y: usize) -> bool {\n        x <= (self.padding_x + self.columns as f32 * self.cell_width) as usize\n            && x > self.padding_x as usize\n            && y <= (self.padding_y + self.screen_lines as f32 * self.cell_height) as usize\n            && y > self.padding_y as usize\n    }\n\n    /// Calculate padding to spread it evenly around the terminal content.\n    #[inline]\n    fn dynamic_padding(padding: f32, dimension: f32, cell_dimension: f32) -> f32 {\n        padding + ((dimension - 2. * padding) % cell_dimension) / 2.\n    }\n}\n\nimpl TermDimensions for SizeInfo {\n    #[inline]\n    fn columns(&self) -> usize {\n        self.columns\n    }\n\n    #[inline]\n    fn screen_lines(&self) -> usize {\n        self.screen_lines\n    }\n\n    #[inline]\n    fn total_lines(&self) -> usize {\n        self.screen_lines()\n    }\n}\n\n#[derive(Default, Clone, Debug, PartialEq, Eq)]\npub struct DisplayUpdate {\n    pub dirty: bool,\n\n    dimensions: Option<PhysicalSize<u32>>,\n    cursor_dirty: bool,\n    font: Option<Font>,\n}\n\nimpl DisplayUpdate {\n    pub fn dimensions(&self) -> Option<PhysicalSize<u32>> {\n        self.dimensions\n    }\n\n    pub fn font(&self) -> Option<&Font> {\n        self.font.as_ref()\n    }\n\n    pub fn cursor_dirty(&self) -> bool {\n        self.cursor_dirty\n    }\n\n    pub fn set_dimensions(&mut self, dimensions: PhysicalSize<u32>) {\n        self.dimensions = Some(dimensions);\n        self.dirty = true;\n    }\n\n    pub fn set_font(&mut self, font: Font) {\n        self.font = Some(font);\n        self.dirty = true;\n    }\n\n    pub fn set_cursor_dirty(&mut self) {\n        self.cursor_dirty = true;\n        self.dirty = true;\n    }\n}\n\n/// The display wraps a window, font rasterizer, and GPU renderer.\npub struct Display {\n    pub window: Window,\n\n    pub size_info: SizeInfo,\n\n    /// Hint highlighted by the mouse.\n    pub highlighted_hint: Option<HintMatch>,\n\n    /// Hint highlighted by the vi mode cursor.\n    pub vi_highlighted_hint: Option<HintMatch>,\n\n    pub raw_window_handle: RawWindowHandle,\n\n    /// UI cursor visibility for blinking.\n    pub cursor_hidden: bool,\n\n    pub visual_bell: VisualBell,\n\n    /// Mapped RGB values for each terminal color.\n    pub colors: List,\n\n    /// State of the keyboard hints.\n    pub hint_state: HintState,\n\n    /// Unprocessed display updates.\n    pub pending_update: DisplayUpdate,\n\n    /// The renderer update that takes place only once before the actual rendering.\n    pub pending_renderer_update: Option<RendererUpdate>,\n\n    /// The ime on the given display.\n    pub ime: Ime,\n\n    /// The state of the timer for frame scheduling.\n    pub frame_timer: FrameTimer,\n\n    /// Damage tracker for the given display.\n    pub damage_tracker: DamageTracker,\n\n    /// Font size used by the window.\n    pub font_size: FontSize,\n\n    // Mouse point position when highlighting hints.\n    hint_mouse_point: Option<Point>,\n\n    renderer: ManuallyDrop<Renderer>,\n\n    surface: ManuallyDrop<Surface<WindowSurface>>,\n\n    context: ManuallyDrop<Replaceable<PossiblyCurrentContext>>,\n\n    glyph_cache: GlyphCache,\n    meter: Meter,\n}\n\nimpl Display {\n    pub fn new(\n        window: Window,\n        gl_context: NotCurrentContext,\n        config: &UiConfig,\n        _tabbed: bool,\n    ) -> Result<Display, Error> {\n        let raw_window_handle = window.raw_window_handle();\n\n        let scale_factor = window.scale_factor as f32;\n        let rasterizer = Rasterizer::new()?;\n\n        let font_size = config.font.size().scale(scale_factor);\n        debug!(\"Loading \\\"{}\\\" font\", &config.font.normal().family);\n        let font = config.font.clone().with_size(font_size);\n        let mut glyph_cache = GlyphCache::new(rasterizer, &font)?;\n\n        let metrics = glyph_cache.font_metrics();\n        let (cell_width, cell_height) = compute_cell_size(config, &metrics);\n\n        // Resize the window to account for the user configured size.\n        if let Some(dimensions) = config.window.dimensions() {\n            let size = window_size(config, dimensions, cell_width, cell_height, scale_factor);\n            window.request_inner_size(size);\n        }\n\n        // Create the GL surface to draw into.\n        let surface = renderer::platform::create_gl_surface(\n            &gl_context,\n            window.inner_size(),\n            window.raw_window_handle(),\n        )?;\n\n        // Make the context current.\n        let context = gl_context.make_current(&surface)?;\n\n        // Create renderer.\n        let mut renderer = Renderer::new(&context, config.debug.renderer)?;\n\n        // Load font common glyphs to accelerate rendering.\n        debug!(\"Filling glyph cache with common glyphs\");\n        renderer.with_loader(|mut api| {\n            glyph_cache.reset_glyph_cache(&mut api);\n        });\n\n        let padding = config.window.padding(window.scale_factor as f32);\n        let viewport_size = window.inner_size();\n\n        // Create new size with at least one column and row.\n        let size_info = SizeInfo::new(\n            viewport_size.width as f32,\n            viewport_size.height as f32,\n            cell_width,\n            cell_height,\n            padding.0,\n            padding.1,\n            config.window.dynamic_padding && config.window.dimensions().is_none(),\n        );\n\n        info!(\"Cell size: {} x {}\", cell_width, cell_height);\n        info!(\"Padding: {} x {}\", size_info.padding_x(), size_info.padding_y());\n        info!(\"Width: {}, Height: {}\", size_info.width(), size_info.height());\n\n        // Update OpenGL projection.\n        renderer.resize(&size_info);\n\n        // Clear screen.\n        let background_color = config.colors.primary.background;\n        renderer.clear(background_color, config.window_opacity());\n\n        // Disable shadows for transparent windows on macOS.\n        #[cfg(target_os = \"macos\")]\n        window.set_has_shadow(config.window_opacity() >= 1.0);\n\n        let is_wayland = matches!(raw_window_handle, RawWindowHandle::Wayland(_));\n\n        // On Wayland we can safely ignore this call, since the window isn't visible until you\n        // actually draw something into it and commit those changes.\n        if !is_wayland {\n            surface.swap_buffers(&context).expect(\"failed to swap buffers.\");\n            renderer.finish();\n        }\n\n        // Set resize increments for the newly created window.\n        if config.window.resize_increments {\n            window.set_resize_increments(PhysicalSize::new(cell_width, cell_height));\n        }\n\n        window.set_visible(true);\n\n        #[allow(clippy::single_match)]\n        #[cfg(not(windows))]\n        if !_tabbed {\n            match config.window.startup_mode {\n                #[cfg(target_os = \"macos\")]\n                StartupMode::SimpleFullscreen => window.set_simple_fullscreen(true),\n                StartupMode::Maximized if !is_wayland => window.set_maximized(true),\n                _ => (),\n            }\n        }\n\n        let hint_state = HintState::new(config.hints.alphabet());\n\n        let mut damage_tracker = DamageTracker::new(size_info.screen_lines(), size_info.columns());\n        damage_tracker.debug = config.debug.highlight_damage;\n\n        // Disable vsync.\n        if let Err(err) = surface.set_swap_interval(&context, SwapInterval::DontWait) {\n            info!(\"Failed to disable vsync: {}\", err);\n        }\n\n        Ok(Self {\n            context: ManuallyDrop::new(Replaceable::new(context)),\n            visual_bell: VisualBell::from(&config.bell),\n            renderer: ManuallyDrop::new(renderer),\n            surface: ManuallyDrop::new(surface),\n            colors: List::from(&config.colors),\n            frame_timer: FrameTimer::new(),\n            raw_window_handle,\n            damage_tracker,\n            glyph_cache,\n            hint_state,\n            size_info,\n            font_size,\n            window,\n            pending_renderer_update: Default::default(),\n            vi_highlighted_hint: Default::default(),\n            highlighted_hint: Default::default(),\n            hint_mouse_point: Default::default(),\n            pending_update: Default::default(),\n            cursor_hidden: Default::default(),\n            meter: Default::default(),\n            ime: Default::default(),\n        })\n    }\n\n    #[inline]\n    pub fn gl_context(&self) -> &PossiblyCurrentContext {\n        self.context.get()\n    }\n\n    pub fn make_not_current(&mut self) {\n        if self.context.get().is_current() {\n            self.context.replace_with(|context| {\n                context\n                    .make_not_current()\n                    .expect(\"failed to disable context\")\n                    .treat_as_possibly_current()\n            });\n        }\n    }\n\n    pub fn make_current(&self) {\n        if !self.context.get().is_current() {\n            self.context.make_current(&self.surface).expect(\"failed to make context current\")\n        }\n    }\n\n    fn swap_buffers(&self) {\n        #[allow(clippy::single_match)]\n        let res = match (self.surface.deref(), &self.context.get()) {\n            #[cfg(not(any(target_os = \"macos\", windows)))]\n            (Surface::Egl(surface), PossiblyCurrentContext::Egl(context))\n                if matches!(self.raw_window_handle, RawWindowHandle::Wayland(_))\n                    && !self.damage_tracker.debug =>\n            {\n                let damage = self.damage_tracker.shape_frame_damage(self.size_info.into());\n                surface.swap_buffers_with_damage(context, &damage)\n            },\n            (surface, context) => surface.swap_buffers(context),\n        };\n        if let Err(err) = res {\n            debug!(\"error calling swap_buffers: {}\", err);\n        }\n    }\n\n    /// Update font size and cell dimensions.\n    ///\n    /// This will return a tuple of the cell width and height.\n    fn update_font_size(\n        glyph_cache: &mut GlyphCache,\n        config: &UiConfig,\n        font: &Font,\n    ) -> (f32, f32) {\n        let _ = glyph_cache.update_font_size(font);\n\n        // Compute new cell sizes.\n        compute_cell_size(config, &glyph_cache.font_metrics())\n    }\n\n    /// Reset glyph cache.\n    fn reset_glyph_cache(&mut self) {\n        let cache = &mut self.glyph_cache;\n        self.renderer.with_loader(|mut api| {\n            cache.reset_glyph_cache(&mut api);\n        });\n    }\n\n    // XXX: this function must not call to any `OpenGL` related tasks. Renderer updates are\n    // performed in [`Self::process_renderer_update`] right before drawing.\n    //\n    /// Process update events.\n    pub fn handle_update<T>(\n        &mut self,\n        terminal: &mut Term<T>,\n        pty_resize_handle: &mut dyn OnResize,\n        message_buffer: &MessageBuffer,\n        search_state: &mut SearchState,\n        config: &UiConfig,\n    ) where\n        T: EventListener,\n    {\n        let pending_update = mem::take(&mut self.pending_update);\n\n        let (mut cell_width, mut cell_height) =\n            (self.size_info.cell_width(), self.size_info.cell_height());\n\n        if pending_update.font().is_some() || pending_update.cursor_dirty() {\n            let renderer_update = self.pending_renderer_update.get_or_insert(Default::default());\n            renderer_update.clear_font_cache = true\n        }\n\n        // Update font size and cell dimensions.\n        if let Some(font) = pending_update.font() {\n            let cell_dimensions = Self::update_font_size(&mut self.glyph_cache, config, font);\n            cell_width = cell_dimensions.0;\n            cell_height = cell_dimensions.1;\n\n            info!(\"Cell size: {} x {}\", cell_width, cell_height);\n\n            // Mark entire terminal as damaged since glyph size could change without cell size\n            // changes.\n            self.damage_tracker.frame().mark_fully_damaged();\n        }\n\n        let (mut width, mut height) = (self.size_info.width(), self.size_info.height());\n        if let Some(dimensions) = pending_update.dimensions() {\n            width = dimensions.width as f32;\n            height = dimensions.height as f32;\n        }\n\n        let padding = config.window.padding(self.window.scale_factor as f32);\n\n        let mut new_size = SizeInfo::new(\n            width,\n            height,\n            cell_width,\n            cell_height,\n            padding.0,\n            padding.1,\n            config.window.dynamic_padding,\n        );\n\n        // Update number of column/lines in the viewport.\n        let search_active = search_state.history_index.is_some();\n        let message_bar_lines = message_buffer.message().map_or(0, |m| m.text(&new_size).len());\n        let search_lines = usize::from(search_active);\n        new_size.reserve_lines(message_bar_lines + search_lines);\n\n        // Update resize increments.\n        if config.window.resize_increments {\n            self.window.set_resize_increments(PhysicalSize::new(cell_width, cell_height));\n        }\n\n        // Resize when terminal when its dimensions have changed.\n        if self.size_info.screen_lines() != new_size.screen_lines\n            || self.size_info.columns() != new_size.columns()\n        {\n            // Resize PTY.\n            pty_resize_handle.on_resize(new_size.into());\n\n            // Resize terminal.\n            terminal.resize(new_size);\n\n            // Resize damage tracking.\n            self.damage_tracker.resize(new_size.screen_lines(), new_size.columns());\n        }\n\n        // Check if dimensions have changed.\n        if new_size != self.size_info {\n            // Queue renderer update.\n            let renderer_update = self.pending_renderer_update.get_or_insert(Default::default());\n            renderer_update.resize = true;\n\n            // Clear focused search match.\n            search_state.clear_focused_match();\n        }\n        self.size_info = new_size;\n    }\n\n    // NOTE: Renderer updates are split off, since platforms like Wayland require resize and other\n    // OpenGL operations to be performed right before rendering. Otherwise they could lock the\n    // back buffer and render with the previous state. This also solves flickering during resizes.\n    //\n    /// Update the state of the renderer.\n    pub fn process_renderer_update(&mut self) {\n        let renderer_update = match self.pending_renderer_update.take() {\n            Some(renderer_update) => renderer_update,\n            _ => return,\n        };\n\n        // Resize renderer.\n        if renderer_update.resize {\n            let width = NonZeroU32::new(self.size_info.width() as u32).unwrap();\n            let height = NonZeroU32::new(self.size_info.height() as u32).unwrap();\n            self.surface.resize(&self.context, width, height);\n        }\n\n        // Ensure we're modifying the correct OpenGL context.\n        self.make_current();\n\n        if renderer_update.clear_font_cache {\n            self.reset_glyph_cache();\n        }\n\n        self.renderer.resize(&self.size_info);\n\n        info!(\"Padding: {} x {}\", self.size_info.padding_x(), self.size_info.padding_y());\n        info!(\"Width: {}, Height: {}\", self.size_info.width(), self.size_info.height());\n    }\n\n    /// Draw the screen.\n    ///\n    /// A reference to Term whose state is being drawn must be provided.\n    ///\n    /// This call may block if vsync is enabled.\n    pub fn draw<T: EventListener>(\n        &mut self,\n        mut terminal: MutexGuard<'_, Term<T>>,\n        scheduler: &mut Scheduler,\n        message_buffer: &MessageBuffer,\n        config: &UiConfig,\n        search_state: &mut SearchState,\n    ) {\n        // Collect renderable content before the terminal is dropped.\n        let mut content = RenderableContent::new(config, self, &terminal, search_state);\n        let mut grid_cells = Vec::new();\n        for cell in &mut content {\n            grid_cells.push(cell);\n        }\n        let selection_range = content.selection_range();\n        let foreground_color = content.color(NamedColor::Foreground as usize);\n        let background_color = content.color(NamedColor::Background as usize);\n        let display_offset = content.display_offset();\n        let cursor = content.cursor();\n\n        let cursor_point = terminal.grid().cursor.point;\n        let total_lines = terminal.grid().total_lines();\n        let metrics = self.glyph_cache.font_metrics();\n        let size_info = self.size_info;\n\n        let vi_mode = terminal.mode().contains(TermMode::VI);\n        let vi_cursor_point = if vi_mode { Some(terminal.vi_mode_cursor.point) } else { None };\n\n        // Add damage from the terminal.\n        if self.collect_damage() {\n            match terminal.damage() {\n                TermDamage::Full => self.damage_tracker.frame().mark_fully_damaged(),\n                TermDamage::Partial(damaged_lines) => {\n                    for damage in damaged_lines {\n                        self.damage_tracker.frame().damage_line(damage);\n                    }\n                },\n            }\n            terminal.reset_damage();\n        }\n\n        // Drop terminal as early as possible to free lock.\n        drop(terminal);\n\n        // Add damage from alacritty's UI elements overlapping terminal.\n        if self.collect_damage() {\n            let requires_full_damage = self.visual_bell.intensity() != 0.\n                || self.hint_state.active()\n                || search_state.regex().is_some();\n\n            if requires_full_damage {\n                self.damage_tracker.frame().mark_fully_damaged();\n                self.damage_tracker.next_frame().mark_fully_damaged();\n            }\n\n            let vi_cursor_viewport_point =\n                vi_cursor_point.and_then(|cursor| point_to_viewport(display_offset, cursor));\n\n            self.damage_tracker.damage_vi_cursor(vi_cursor_viewport_point);\n            self.damage_tracker.damage_selection(selection_range, display_offset);\n        }\n\n        // Make sure this window's OpenGL context is active.\n        self.make_current();\n\n        self.renderer.clear(background_color, config.window_opacity());\n        let mut lines = RenderLines::new();\n\n        // Optimize loop hint comparator.\n        let has_highlighted_hint =\n            self.highlighted_hint.is_some() || self.vi_highlighted_hint.is_some();\n\n        // Draw grid.\n        {\n            let _sampler = self.meter.sampler();\n\n            // Ensure macOS hasn't reset our viewport.\n            #[cfg(target_os = \"macos\")]\n            self.renderer.set_viewport(&size_info);\n\n            let glyph_cache = &mut self.glyph_cache;\n            let highlighted_hint = &self.highlighted_hint;\n            let vi_highlighted_hint = &self.vi_highlighted_hint;\n            let damage_tracker = &mut self.damage_tracker;\n\n            self.renderer.draw_cells(\n                &size_info,\n                glyph_cache,\n                grid_cells.into_iter().map(|mut cell| {\n                    // Underline hints hovered by mouse or vi mode cursor.\n                    let point = term::viewport_to_point(display_offset, cell.point);\n\n                    if has_highlighted_hint {\n                        let hyperlink =\n                            cell.extra.as_ref().and_then(|extra| extra.hyperlink.as_ref());\n                        if highlighted_hint\n                            .as_ref()\n                            .map_or(false, |hint| hint.should_highlight(point, hyperlink))\n                            || vi_highlighted_hint\n                                .as_ref()\n                                .map_or(false, |hint| hint.should_highlight(point, hyperlink))\n                        {\n                            cell.flags.insert(Flags::UNDERLINE);\n                            // Damage hints for the current and next frames.\n                            damage_tracker.frame().damage_point(cell.point);\n                            damage_tracker.next_frame().damage_point(cell.point);\n                        }\n                    }\n\n                    // Update underline/strikeout.\n                    lines.update(&cell);\n\n                    cell\n                }),\n            );\n        }\n\n        let mut rects = lines.rects(&metrics, &size_info);\n\n        if let Some(vi_cursor_point) = vi_cursor_point {\n            // Indicate vi mode by showing the cursor's position in the top right corner.\n            let line = (-vi_cursor_point.line.0 + size_info.bottommost_line().0) as usize;\n            let obstructed_column = Some(vi_cursor_point)\n                .filter(|point| point.line == -(display_offset as i32))\n                .map(|point| point.column);\n            self.draw_line_indicator(config, total_lines, obstructed_column, line);\n        } else if search_state.regex().is_some() {\n            // Show current display offset in vi-less search to indicate match position.\n            self.draw_line_indicator(config, total_lines, None, display_offset);\n        };\n\n        // Draw cursor.\n        rects.extend(cursor.rects(&size_info, config.cursor.thickness()));\n\n        // Push visual bell after url/underline/strikeout rects.\n        let visual_bell_intensity = self.visual_bell.intensity();\n        if visual_bell_intensity != 0. {\n            let visual_bell_rect = RenderRect::new(\n                0.,\n                0.,\n                size_info.width(),\n                size_info.height(),\n                config.bell.color,\n                visual_bell_intensity as f32,\n            );\n            rects.push(visual_bell_rect);\n        }\n\n        // Handle IME positioning and search bar rendering.\n        let ime_position = match search_state.regex() {\n            Some(regex) => {\n                let search_label = match search_state.direction() {\n                    Direction::Right => FORWARD_SEARCH_LABEL,\n                    Direction::Left => BACKWARD_SEARCH_LABEL,\n                };\n\n                let search_text = Self::format_search(regex, search_label, size_info.columns());\n\n                // Render the search bar.\n                self.draw_search(config, &search_text);\n\n                // Draw search bar cursor.\n                let line = size_info.screen_lines();\n                let column = Column(search_text.chars().count() - 1);\n\n                // Add cursor to search bar if IME is not active.\n                if self.ime.preedit().is_none() {\n                    let fg = config.colors.footer_bar_foreground();\n                    let shape = CursorShape::Underline;\n                    let cursor = RenderableCursor::new(Point::new(line, column), shape, fg, false);\n                    rects.extend(cursor.rects(&size_info, config.cursor.thickness()));\n                }\n\n                Some(Point::new(line, column))\n            },\n            None => {\n                let num_lines = self.size_info.screen_lines();\n                term::point_to_viewport(display_offset, cursor_point)\n                    .filter(|point| point.line < num_lines)\n            },\n        };\n\n        // Handle IME.\n        if self.ime.is_enabled() {\n            if let Some(point) = ime_position {\n                let (fg, bg) = if search_state.regex().is_some() {\n                    (config.colors.footer_bar_foreground(), config.colors.footer_bar_background())\n                } else {\n                    (foreground_color, background_color)\n                };\n\n                self.draw_ime_preview(point, fg, bg, &mut rects, config);\n            }\n        }\n\n        if let Some(message) = message_buffer.message() {\n            let search_offset = usize::from(search_state.regex().is_some());\n            let text = message.text(&size_info);\n\n            // Create a new rectangle for the background.\n            let start_line = size_info.screen_lines() + search_offset;\n            let y = size_info.cell_height().mul_add(start_line as f32, size_info.padding_y());\n\n            let bg = match message.ty() {\n                MessageType::Error => config.colors.normal.red,\n                MessageType::Warning => config.colors.normal.yellow,\n            };\n\n            let x = 0;\n            let width = size_info.width() as i32;\n            let height = (size_info.height() - y) as i32;\n            let message_bar_rect =\n                RenderRect::new(x as f32, y, width as f32, height as f32, bg, 1.);\n\n            // Push message_bar in the end, so it'll be above all other content.\n            rects.push(message_bar_rect);\n\n            // Always damage message bar, since it could have messages of the same size in it.\n            self.damage_tracker.frame().add_viewport_rect(&size_info, x, y as i32, width, height);\n\n            // Draw rectangles.\n            self.renderer.draw_rects(&size_info, &metrics, rects);\n\n            // Relay messages to the user.\n            let glyph_cache = &mut self.glyph_cache;\n            let fg = config.colors.primary.background;\n            for (i, message_text) in text.iter().enumerate() {\n                let point = Point::new(start_line + i, Column(0));\n                self.renderer.draw_string(\n                    point,\n                    fg,\n                    bg,\n                    message_text.chars(),\n                    &size_info,\n                    glyph_cache,\n                );\n            }\n        } else {\n            // Draw rectangles.\n            self.renderer.draw_rects(&size_info, &metrics, rects);\n        }\n\n        self.draw_render_timer(config);\n\n        // Draw hyperlink uri preview.\n        if has_highlighted_hint {\n            let cursor_point = vi_cursor_point.or(Some(cursor_point));\n            self.draw_hyperlink_preview(config, cursor_point, display_offset);\n        }\n\n        // Notify winit that we're about to present.\n        self.window.pre_present_notify();\n\n        // Highlight damage for debugging.\n        if self.damage_tracker.debug {\n            let damage = self.damage_tracker.shape_frame_damage(self.size_info.into());\n            let mut rects = Vec::with_capacity(damage.len());\n            self.highlight_damage(&mut rects);\n            self.renderer.draw_rects(&self.size_info, &metrics, rects);\n        }\n\n        // Clearing debug highlights from the previous frame requires full redraw.\n        self.swap_buffers();\n\n        if matches!(self.raw_window_handle, RawWindowHandle::Xcb(_) | RawWindowHandle::Xlib(_)) {\n            // On X11 `swap_buffers` does not block for vsync. However the next OpenGl command\n            // will block to synchronize (this is `glClear` in Alacritty), which causes a\n            // permanent one frame delay.\n            self.renderer.finish();\n        }\n\n        // XXX: Request the new frame after swapping buffers, so the\n        // time to finish OpenGL operations is accounted for in the timeout.\n        if !matches!(self.raw_window_handle, RawWindowHandle::Wayland(_)) {\n            self.request_frame(scheduler);\n        }\n\n        self.damage_tracker.swap_damage();\n    }\n\n    /// Update to a new configuration.\n    pub fn update_config(&mut self, config: &UiConfig) {\n        self.damage_tracker.debug = config.debug.highlight_damage;\n        self.visual_bell.update_config(&config.bell);\n        self.colors = List::from(&config.colors);\n    }\n\n    /// Update the mouse/vi mode cursor hint highlighting.\n    ///\n    /// This will return whether the highlighted hints changed.\n    pub fn update_highlighted_hints<T>(\n        &mut self,\n        term: &Term<T>,\n        config: &UiConfig,\n        mouse: &Mouse,\n        modifiers: ModifiersState,\n    ) -> bool {\n        // Update vi mode cursor hint.\n        let vi_highlighted_hint = if term.mode().contains(TermMode::VI) {\n            let mods = ModifiersState::all();\n            let point = term.vi_mode_cursor.point;\n            hint::highlighted_at(term, config, point, mods)\n        } else {\n            None\n        };\n        let mut dirty = vi_highlighted_hint != self.vi_highlighted_hint;\n        self.vi_highlighted_hint = vi_highlighted_hint;\n\n        // Abort if mouse highlighting conditions are not met.\n        if !mouse.inside_text_area || !term.selection.as_ref().map_or(true, Selection::is_empty) {\n            dirty |= self.highlighted_hint.is_some();\n            self.highlighted_hint = None;\n            return dirty;\n        }\n\n        // Find highlighted hint at mouse position.\n        let point = mouse.point(&self.size_info, term.grid().display_offset());\n        let highlighted_hint = hint::highlighted_at(term, config, point, modifiers);\n\n        // Update cursor shape.\n        if highlighted_hint.is_some() {\n            // If mouse changed the line, we should update the hyperlink preview, since the\n            // highlighted hint could be disrupted by the old preview.\n            dirty = self.hint_mouse_point.map_or(false, |p| p.line != point.line);\n            self.hint_mouse_point = Some(point);\n            self.window.set_mouse_cursor(CursorIcon::Pointer);\n        } else if self.highlighted_hint.is_some() {\n            self.hint_mouse_point = None;\n            if term.mode().intersects(TermMode::MOUSE_MODE) && !term.mode().contains(TermMode::VI) {\n                self.window.set_mouse_cursor(CursorIcon::Default);\n            } else {\n                self.window.set_mouse_cursor(CursorIcon::Text);\n            }\n        }\n\n        dirty |= self.highlighted_hint != highlighted_hint;\n        self.highlighted_hint = highlighted_hint;\n\n        dirty\n    }\n\n    #[inline(never)]\n    fn draw_ime_preview(\n        &mut self,\n        point: Point<usize>,\n        fg: Rgb,\n        bg: Rgb,\n        rects: &mut Vec<RenderRect>,\n        config: &UiConfig,\n    ) {\n        let preedit = match self.ime.preedit() {\n            Some(preedit) => preedit,\n            None => {\n                // In case we don't have preedit, just set the popup point.\n                self.window.update_ime_position(point, &self.size_info);\n                return;\n            },\n        };\n\n        let num_cols = self.size_info.columns();\n\n        // Get the visible preedit.\n        let visible_text: String = match (preedit.cursor_byte_offset, preedit.cursor_end_offset) {\n            (Some(byte_offset), Some(end_offset)) if end_offset > num_cols => StrShortener::new(\n                &preedit.text[byte_offset..],\n                num_cols,\n                ShortenDirection::Right,\n                Some(SHORTENER),\n            ),\n            _ => {\n                StrShortener::new(&preedit.text, num_cols, ShortenDirection::Left, Some(SHORTENER))\n            },\n        }\n        .collect();\n\n        let visible_len = visible_text.chars().count();\n\n        let end = cmp::min(point.column.0 + visible_len, num_cols);\n        let start = end.saturating_sub(visible_len);\n\n        let start = Point::new(point.line, Column(start));\n        let end = Point::new(point.line, Column(end - 1));\n\n        let glyph_cache = &mut self.glyph_cache;\n        let metrics = glyph_cache.font_metrics();\n\n        self.renderer.draw_string(\n            start,\n            fg,\n            bg,\n            visible_text.chars(),\n            &self.size_info,\n            glyph_cache,\n        );\n\n        // Damage preedit inside the terminal viewport.\n        if self.collect_damage() && point.line < self.size_info.screen_lines() {\n            let damage = LineDamageBounds::new(start.line, 0, num_cols);\n            self.damage_tracker.frame().damage_line(damage);\n            self.damage_tracker.next_frame().damage_line(damage);\n        }\n\n        // Add underline for preedit text.\n        let underline = RenderLine { start, end, color: fg };\n        rects.extend(underline.rects(Flags::UNDERLINE, &metrics, &self.size_info));\n\n        let ime_popup_point = match preedit.cursor_end_offset {\n            Some(cursor_end_offset) if cursor_end_offset != 0 => {\n                let is_wide = preedit.text[preedit.cursor_byte_offset.unwrap_or_default()..]\n                    .chars()\n                    .next()\n                    .map(|ch| ch.width() == Some(2))\n                    .unwrap_or_default();\n\n                let cursor_column = Column(\n                    (end.column.0 as isize - cursor_end_offset as isize + 1).max(0) as usize,\n                );\n                let cursor_point = Point::new(point.line, cursor_column);\n                let cursor =\n                    RenderableCursor::new(cursor_point, CursorShape::HollowBlock, fg, is_wide);\n                rects.extend(cursor.rects(&self.size_info, config.cursor.thickness()));\n                cursor_point\n            },\n            _ => end,\n        };\n\n        self.window.update_ime_position(ime_popup_point, &self.size_info);\n    }\n\n    /// Format search regex to account for the cursor and fullwidth characters.\n    fn format_search(search_regex: &str, search_label: &str, max_width: usize) -> String {\n        let label_len = search_label.len();\n\n        // Skip `search_regex` formatting if only label is visible.\n        if label_len > max_width {\n            return search_label[..max_width].to_owned();\n        }\n\n        // The search string consists of `search_label` + `search_regex` + `cursor`.\n        let mut bar_text = String::from(search_label);\n        bar_text.extend(StrShortener::new(\n            search_regex,\n            max_width.wrapping_sub(label_len + 1),\n            ShortenDirection::Left,\n            Some(SHORTENER),\n        ));\n\n        // Add place for cursor.\n        bar_text.push(' ');\n\n        bar_text\n    }\n\n    /// Draw preview for the currently highlighted `Hyperlink`.\n    #[inline(never)]\n    fn draw_hyperlink_preview(\n        &mut self,\n        config: &UiConfig,\n        cursor_point: Option<Point>,\n        display_offset: usize,\n    ) {\n        let num_cols = self.size_info.columns();\n        let uris: Vec<_> = self\n            .highlighted_hint\n            .iter()\n            .chain(&self.vi_highlighted_hint)\n            .filter_map(|hint| hint.hyperlink().map(|hyperlink| hyperlink.uri()))\n            .map(|uri| StrShortener::new(uri, num_cols, ShortenDirection::Right, Some(SHORTENER)))\n            .collect();\n\n        if uris.is_empty() {\n            return;\n        }\n\n        // The maximum amount of protected lines including the ones we'll show preview on.\n        let max_protected_lines = uris.len() * 2;\n\n        // Lines we shouldn't show preview on, because it'll obscure the highlighted hint.\n        let mut protected_lines = Vec::with_capacity(max_protected_lines);\n        if self.size_info.screen_lines() > max_protected_lines {\n            // Prefer to show preview even when it'll likely obscure the highlighted hint, when\n            // there's no place left for it.\n            protected_lines.push(self.hint_mouse_point.map(|point| point.line));\n            protected_lines.push(cursor_point.map(|point| point.line));\n        }\n\n        // Find the line in viewport we can draw preview on without obscuring protected lines.\n        let viewport_bottom = self.size_info.bottommost_line() - Line(display_offset as i32);\n        let viewport_top = viewport_bottom - (self.size_info.screen_lines() - 1);\n        let uri_lines = (viewport_top.0..=viewport_bottom.0)\n            .rev()\n            .map(|line| Some(Line(line)))\n            .filter_map(|line| {\n                if protected_lines.contains(&line) {\n                    None\n                } else {\n                    protected_lines.push(line);\n                    line\n                }\n            })\n            .take(uris.len())\n            .flat_map(|line| term::point_to_viewport(display_offset, Point::new(line, Column(0))));\n\n        let fg = config.colors.footer_bar_foreground();\n        let bg = config.colors.footer_bar_background();\n        for (uri, point) in uris.into_iter().zip(uri_lines) {\n            // Damage the uri preview.\n            if self.collect_damage() {\n                let damage = LineDamageBounds::new(point.line, point.column.0, num_cols);\n                self.damage_tracker.frame().damage_line(damage);\n\n                // Damage the uri preview for the next frame as well.\n                self.damage_tracker.next_frame().damage_line(damage);\n            }\n\n            self.renderer.draw_string(point, fg, bg, uri, &self.size_info, &mut self.glyph_cache);\n        }\n    }\n\n    /// Draw current search regex.\n    #[inline(never)]\n    fn draw_search(&mut self, config: &UiConfig, text: &str) {\n        // Assure text length is at least num_cols.\n        let num_cols = self.size_info.columns();\n        let text = format!(\"{:<1$}\", text, num_cols);\n\n        let point = Point::new(self.size_info.screen_lines(), Column(0));\n\n        let fg = config.colors.footer_bar_foreground();\n        let bg = config.colors.footer_bar_background();\n\n        self.renderer.draw_string(\n            point,\n            fg,\n            bg,\n            text.chars(),\n            &self.size_info,\n            &mut self.glyph_cache,\n        );\n    }\n\n    /// Draw render timer.\n    #[inline(never)]\n    fn draw_render_timer(&mut self, config: &UiConfig) {\n        if !config.debug.render_timer {\n            return;\n        }\n\n        let timing = format!(\"{:.3} usec\", self.meter.average());\n        let point = Point::new(self.size_info.screen_lines().saturating_sub(2), Column(0));\n        let fg = config.colors.primary.background;\n        let bg = config.colors.normal.red;\n\n        if self.collect_damage() {\n            let damage = LineDamageBounds::new(point.line, point.column.0, timing.len());\n            self.damage_tracker.frame().damage_line(damage);\n            // Damage the render timer for the next frame.\n            self.damage_tracker.next_frame().damage_line(damage);\n        }\n\n        let glyph_cache = &mut self.glyph_cache;\n        self.renderer.draw_string(point, fg, bg, timing.chars(), &self.size_info, glyph_cache);\n    }\n\n    /// Draw an indicator for the position of a line in history.\n    #[inline(never)]\n    fn draw_line_indicator(\n        &mut self,\n        config: &UiConfig,\n        total_lines: usize,\n        obstructed_column: Option<Column>,\n        line: usize,\n    ) {\n        let columns = self.size_info.columns();\n        let text = format!(\"[{}/{}]\", line, total_lines - 1);\n        let column = Column(self.size_info.columns().saturating_sub(text.len()));\n        let point = Point::new(0, column);\n\n        if self.collect_damage() {\n            let damage = LineDamageBounds::new(point.line, point.column.0, columns - 1);\n            self.damage_tracker.frame().damage_line(damage);\n            // Damage it on the next frame in case it goes away.\n            self.damage_tracker.next_frame().damage_line(damage);\n        }\n\n        let colors = &config.colors;\n        let fg = colors.line_indicator.foreground.unwrap_or(colors.primary.background);\n        let bg = colors.line_indicator.background.unwrap_or(colors.primary.foreground);\n\n        // Do not render anything if it would obscure the vi mode cursor.\n        if obstructed_column.map_or(true, |obstructed_column| obstructed_column < column) {\n            let glyph_cache = &mut self.glyph_cache;\n            self.renderer.draw_string(point, fg, bg, text.chars(), &self.size_info, glyph_cache);\n        }\n    }\n\n    /// Returns `true` if damage information should be collected, `false` otherwise.\n    #[inline]\n    fn collect_damage(&self) -> bool {\n        matches!(self.raw_window_handle, RawWindowHandle::Wayland(_)) || self.damage_tracker.debug\n    }\n\n    /// Highlight damaged rects.\n    ///\n    /// This function is for debug purposes only.\n    fn highlight_damage(&self, render_rects: &mut Vec<RenderRect>) {\n        for damage_rect in &self.damage_tracker.shape_frame_damage(self.size_info.into()) {\n            let x = damage_rect.x as f32;\n            let height = damage_rect.height as f32;\n            let width = damage_rect.width as f32;\n            let y = damage_y_to_viewport_y(&self.size_info, damage_rect) as f32;\n            let render_rect = RenderRect::new(x, y, width, height, DAMAGE_RECT_COLOR, 0.5);\n\n            render_rects.push(render_rect);\n        }\n    }\n\n    /// Request a new frame for a window on Wayland.\n    fn request_frame(&mut self, scheduler: &mut Scheduler) {\n        // Mark that we've used a frame.\n        self.window.has_frame = false;\n\n        // Get the display vblank interval.\n        let monitor_vblank_interval = 1_000_000.\n            / self\n                .window\n                .current_monitor()\n                .and_then(|monitor| monitor.refresh_rate_millihertz())\n                .unwrap_or(60_000) as f64;\n\n        // Now convert it to micro seconds.\n        let monitor_vblank_interval =\n            Duration::from_micros((1000. * monitor_vblank_interval) as u64);\n\n        let swap_timeout = self.frame_timer.compute_timeout(monitor_vblank_interval);\n\n        let window_id = self.window.id();\n        let timer_id = TimerId::new(Topic::Frame, window_id);\n        let event = Event::new(EventType::Frame, window_id);\n\n        scheduler.schedule(event, swap_timeout, false, timer_id);\n    }\n}\n\nimpl Drop for Display {\n    fn drop(&mut self) {\n        // Switch OpenGL context before dropping, otherwise objects (like programs) from other\n        // contexts might be deleted when dropping renderer.\n        self.make_current();\n        unsafe {\n            ManuallyDrop::drop(&mut self.renderer);\n            ManuallyDrop::drop(&mut self.context);\n            ManuallyDrop::drop(&mut self.surface);\n        }\n    }\n}\n\n/// Input method state.\n#[derive(Debug, Default)]\npub struct Ime {\n    /// Whether the IME is enabled.\n    enabled: bool,\n\n    /// Current IME preedit.\n    preedit: Option<Preedit>,\n}\n\nimpl Ime {\n    #[inline]\n    pub fn set_enabled(&mut self, is_enabled: bool) {\n        if is_enabled {\n            self.enabled = is_enabled\n        } else {\n            // Clear state when disabling IME.\n            *self = Default::default();\n        }\n    }\n\n    #[inline]\n    pub fn is_enabled(&self) -> bool {\n        self.enabled\n    }\n\n    #[inline]\n    pub fn set_preedit(&mut self, preedit: Option<Preedit>) {\n        self.preedit = preedit;\n    }\n\n    #[inline]\n    pub fn preedit(&self) -> Option<&Preedit> {\n        self.preedit.as_ref()\n    }\n}\n\n#[derive(Debug, Default, PartialEq, Eq)]\npub struct Preedit {\n    /// The preedit text.\n    text: String,\n\n    /// Byte offset for cursor start into the preedit text.\n    ///\n    /// `None` means that the cursor is invisible.\n    cursor_byte_offset: Option<usize>,\n\n    /// The cursor offset from the end of the preedit in char width.\n    cursor_end_offset: Option<usize>,\n}\n\nimpl Preedit {\n    pub fn new(text: String, cursor_byte_offset: Option<usize>) -> Self {\n        let cursor_end_offset = if let Some(byte_offset) = cursor_byte_offset {\n            // Convert byte offset into char offset.\n            let cursor_end_offset =\n                text[byte_offset..].chars().fold(0, |acc, ch| acc + ch.width().unwrap_or(1));\n\n            Some(cursor_end_offset)\n        } else {\n            None\n        };\n\n        Self { text, cursor_byte_offset, cursor_end_offset }\n    }\n}\n\n/// Pending renderer updates.\n///\n/// All renderer updates are cached to be applied just before rendering, to avoid platform-specific\n/// rendering issues.\n#[derive(Debug, Default, Copy, Clone)]\npub struct RendererUpdate {\n    /// Should resize the window.\n    resize: bool,\n\n    /// Clear font caches.\n    clear_font_cache: bool,\n}\n\n/// Struct for safe in-place replacement.\n///\n/// This struct allows easily replacing struct fields that provide `self -> Self` methods in-place,\n/// without having to deal with constantly unwrapping the underlying [`Option`].\nstruct Replaceable<T>(Option<T>);\n\nimpl<T> Replaceable<T> {\n    pub fn new(inner: T) -> Self {\n        Self(Some(inner))\n    }\n\n    /// Replace the contents of the container.\n    pub fn replace_with<F: FnMut(T) -> T>(&mut self, f: F) {\n        self.0 = self.0.take().map(f);\n    }\n\n    /// Get immutable access to the wrapped value.\n    pub fn get(&self) -> &T {\n        self.0.as_ref().unwrap()\n    }\n\n    /// Get mutable access to the wrapped value.\n    pub fn get_mut(&mut self) -> &mut T {\n        self.0.as_mut().unwrap()\n    }\n}\n\nimpl<T> Deref for Replaceable<T> {\n    type Target = T;\n\n    fn deref(&self) -> &Self::Target {\n        self.get()\n    }\n}\n\nimpl<T> DerefMut for Replaceable<T> {\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        self.get_mut()\n    }\n}\n\n/// The frame timer state.\npub struct FrameTimer {\n    /// Base timestamp used to compute sync points.\n    base: Instant,\n\n    /// The last timestamp we synced to.\n    last_synced_timestamp: Instant,\n\n    /// The refresh rate we've used to compute sync timestamps.\n    refresh_interval: Duration,\n}\n\nimpl FrameTimer {\n    pub fn new() -> Self {\n        let now = Instant::now();\n        Self { base: now, last_synced_timestamp: now, refresh_interval: Duration::ZERO }\n    }\n\n    /// Compute the delay that we should use to achieve the target frame\n    /// rate.\n    pub fn compute_timeout(&mut self, refresh_interval: Duration) -> Duration {\n        let now = Instant::now();\n\n        // Handle refresh rate change.\n        if self.refresh_interval != refresh_interval {\n            self.base = now;\n            self.last_synced_timestamp = now;\n            self.refresh_interval = refresh_interval;\n            return refresh_interval;\n        }\n\n        let next_frame = self.last_synced_timestamp + self.refresh_interval;\n\n        if next_frame < now {\n            // Redraw immediately if we haven't drawn in over `refresh_interval` microseconds.\n            let elapsed_micros = (now - self.base).as_micros() as u64;\n            let refresh_micros = self.refresh_interval.as_micros() as u64;\n            self.last_synced_timestamp =\n                now - Duration::from_micros(elapsed_micros % refresh_micros);\n            Duration::ZERO\n        } else {\n            // Redraw on the next `refresh_interval` clock tick.\n            self.last_synced_timestamp = next_frame;\n            next_frame - now\n        }\n    }\n}\n\n/// Calculate the cell dimensions based on font metrics.\n///\n/// This will return a tuple of the cell width and height.\n#[inline]\nfn compute_cell_size(config: &UiConfig, metrics: &crossfont::Metrics) -> (f32, f32) {\n    let offset_x = f64::from(config.font.offset.x);\n    let offset_y = f64::from(config.font.offset.y);\n    (\n        (metrics.average_advance + offset_x).floor().max(1.) as f32,\n        (metrics.line_height + offset_y).floor().max(1.) as f32,\n    )\n}\n\n/// Calculate the size of the window given padding, terminal dimensions and cell size.\nfn window_size(\n    config: &UiConfig,\n    dimensions: Dimensions,\n    cell_width: f32,\n    cell_height: f32,\n    scale_factor: f32,\n) -> PhysicalSize<u32> {\n    let padding = config.window.padding(scale_factor);\n\n    let grid_width = cell_width * dimensions.columns.max(MIN_COLUMNS) as f32;\n    let grid_height = cell_height * dimensions.lines.max(MIN_SCREEN_LINES) as f32;\n\n    let width = (padding.0).mul_add(2., grid_width).floor();\n    let height = (padding.1).mul_add(2., grid_height).floor();\n\n    PhysicalSize::new(width as u32, height as u32)\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_70_chunk_0",
        "original_index": 0,
        "content": "//! The display subsystem including window management, font rasterization, and\n//! GPU drawing.\n\nuse std::cmp;\nuse std::fmt::{self, Formatter};\nuse std::mem::{self, ManuallyDrop};\nuse std::num::NonZeroU32;\nuse std::ops::{Deref, DerefMut};\nuse std::time::{Duration, Instant};\n\nuse glutin::context::{NotCurrentContext, PossiblyCurrentContext};\nuse glutin::prelude::*;\nuse glutin::surface::{Surface, SwapInterval, WindowSurface};\n\nuse log::{debug, info};\nuse parking_lot::MutexGuard;\nuse raw_window_handle::RawWindowHandle;\nuse serde::{Deserialize, Serialize};\nuse winit::dpi::PhysicalSize;\nuse winit::keyboard::ModifiersState;\nuse winit::window::CursorIcon;\n\nuse crossfont::{Rasterize, Rasterizer, Size as FontSize};\nuse unicode_width::UnicodeWidthChar;\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_1",
        "original_index": 1,
        "content": "use alacritty_terminal::event::{EventListener, OnResize, WindowSize};\nuse alacritty_terminal::grid::Dimensions as TermDimensions;\nuse alacritty_terminal::index::{Column, Direction, Line, Point};\nuse alacritty_terminal::selection::Selection;\nuse alacritty_terminal::term::cell::Flags;\nuse alacritty_terminal::term::{\n    self, point_to_viewport, LineDamageBounds, Term, TermDamage, TermMode, MIN_COLUMNS,\n    MIN_SCREEN_LINES,\n};\nuse alacritty_terminal::vte::ansi::{CursorShape, NamedColor};\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_2",
        "original_index": 2,
        "content": "use crate::config::font::Font;\nuse crate::config::window::Dimensions;\n#[cfg(not(windows))]\nuse crate::config::window::StartupMode;\nuse crate::config::UiConfig;\nuse crate::display::bell::VisualBell;\nuse crate::display::color::{List, Rgb};\nuse crate::display::content::{RenderableContent, RenderableCursor};\nuse crate::display::cursor::IntoRects;\nuse crate::display::damage::{damage_y_to_viewport_y, DamageTracker};\nuse crate::display::hint::{HintMatch, HintState};\nuse crate::display::meter::Meter;\nuse crate::display::window::Window;\nuse crate::event::{Event, EventType, Mouse, SearchState};\nuse crate::message_bar::{MessageBuffer, MessageType};\nuse crate::renderer::rects::{RenderLine, RenderLines, RenderRect};\nuse crate::renderer::{self, GlyphCache, Renderer};\nuse crate::scheduler::{Scheduler, TimerId, Topic};\nuse crate::string::{ShortenDirection, StrShortener};\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_3",
        "original_index": 3,
        "content": "pub mod color;\npub mod content;\npub mod cursor;\npub mod hint;\npub mod window;\n\nmod bell;\nmod damage;\nmod meter;\n\n/// Label for the forward terminal search bar.\nconst FORWARD_SEARCH_LABEL: &str = \"Search: \";\n\n/// Label for the backward terminal search bar.\nconst BACKWARD_SEARCH_LABEL: &str = \"Backward Search: \";\n\n/// The character used to shorten the visible text like uri preview or search regex.\nconst SHORTENER: char = '\u2026';\n\n/// Color which is used to highlight damaged rects when debugging.\nconst DAMAGE_RECT_COLOR: Rgb = Rgb::new(255, 0, 255);\n\n#[derive(Debug)]\npub enum Error {\n    /// Error with window management.\n    Window(window::Error),\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_4",
        "original_index": 4,
        "content": "    /// Error dealing with fonts.\n    Font(crossfont::Error),\n\n    /// Error in renderer.\n    Render(renderer::Error),\n\n    /// Error during context operations.\n    Context(glutin::error::Error),\n}\n\nimpl std::error::Error for Error {\n    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {\n        match self {\n            Error::Window(err) => err.source(),\n            Error::Font(err) => err.source(),\n            Error::Render(err) => err.source(),\n            Error::Context(err) => err.source(),\n        }\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_5",
        "original_index": 5,
        "content": "impl fmt::Display for Error {\n    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n        match self {\n            Error::Window(err) => err.fmt(f),\n            Error::Font(err) => err.fmt(f),\n            Error::Render(err) => err.fmt(f),\n            Error::Context(err) => err.fmt(f),\n        }\n    }\n}\n\nimpl From<window::Error> for Error {\n    fn from(val: window::Error) -> Self {\n        Error::Window(val)\n    }\n}\n\nimpl From<crossfont::Error> for Error {\n    fn from(val: crossfont::Error) -> Self {\n        Error::Font(val)\n    }\n}\n\nimpl From<renderer::Error> for Error {\n    fn from(val: renderer::Error) -> Self {\n        Error::Render(val)\n    }\n}\n\nimpl From<glutin::error::Error> for Error {\n    fn from(val: glutin::error::Error) -> Self {\n        Error::Context(val)\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_6",
        "original_index": 6,
        "content": "/// Terminal size info.\n#[derive(Serialize, Deserialize, Debug, Copy, Clone, PartialEq, Eq)]\npub struct SizeInfo<T = f32> {\n    /// Terminal window width.\n    width: T,\n\n    /// Terminal window height.\n    height: T,\n\n    /// Width of individual cell.\n    cell_width: T,\n\n    /// Height of individual cell.\n    cell_height: T,\n\n    /// Horizontal window padding.\n    padding_x: T,\n\n    /// Vertical window padding.\n    padding_y: T,\n\n    /// Number of lines in the viewport.\n    screen_lines: usize,\n\n    /// Number of columns in the viewport.\n    columns: usize,\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_7",
        "original_index": 7,
        "content": "impl From<SizeInfo<f32>> for SizeInfo<u32> {\n    fn from(size_info: SizeInfo<f32>) -> Self {\n        Self {\n            width: size_info.width as u32,\n            height: size_info.height as u32,\n            cell_width: size_info.cell_width as u32,\n            cell_height: size_info.cell_height as u32,\n            padding_x: size_info.padding_x as u32,\n            padding_y: size_info.padding_y as u32,\n            screen_lines: size_info.screen_lines,\n            columns: size_info.screen_lines,\n        }\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_8",
        "original_index": 8,
        "content": "impl From<SizeInfo<f32>> for WindowSize {\n    fn from(size_info: SizeInfo<f32>) -> Self {\n        Self {\n            num_cols: size_info.columns() as u16,\n            num_lines: size_info.screen_lines() as u16,\n            cell_width: size_info.cell_width() as u16,\n            cell_height: size_info.cell_height() as u16,\n        }\n    }\n}\n\nimpl<T: Clone + Copy> SizeInfo<T> {\n    #[inline]\n    pub fn width(&self) -> T {\n        self.width\n    }\n\n    #[inline]\n    pub fn height(&self) -> T {\n        self.height\n    }\n\n    #[inline]\n    pub fn cell_width(&self) -> T {\n        self.cell_width\n    }\n\n    #[inline]\n    pub fn cell_height(&self) -> T {\n        self.cell_height\n    }\n\n    #[inline]\n    pub fn padding_x(&self) -> T {\n        self.padding_x\n    }\n\n    #[inline]\n    pub fn padding_y(&self) -> T {\n        self.padding_y\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_9",
        "original_index": 9,
        "content": "impl SizeInfo<f32> {\n    #[allow(clippy::too_many_arguments)]\n    pub fn new(\n        width: f32,\n        height: f32,\n        cell_width: f32,\n        cell_height: f32,\n        mut padding_x: f32,\n        mut padding_y: f32,\n        dynamic_padding: bool,\n    ) -> SizeInfo {\n        if dynamic_padding {\n            padding_x = Self::dynamic_padding(padding_x.floor(), width, cell_width);\n            padding_y = Self::dynamic_padding(padding_y.floor(), height, cell_height);\n        }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_10",
        "original_index": 10,
        "content": "        let lines = (height - 2. * padding_y) / cell_height;\n        let screen_lines = cmp::max(lines as usize, MIN_SCREEN_LINES);\n\n        let columns = (width - 2. * padding_x) / cell_width;\n        let columns = cmp::max(columns as usize, MIN_COLUMNS);\n\n        SizeInfo {\n            width,\n            height,\n            cell_width,\n            cell_height,\n            padding_x: padding_x.floor(),\n            padding_y: padding_y.floor(),\n            screen_lines,\n            columns,\n        }\n    }\n\n    #[inline]\n    pub fn reserve_lines(&mut self, count: usize) {\n        self.screen_lines = cmp::max(self.screen_lines.saturating_sub(count), MIN_SCREEN_LINES);\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_11",
        "original_index": 11,
        "content": "    /// Check if coordinates are inside the terminal grid.\n    ///\n    /// The padding, message bar or search are not counted as part of the grid.\n    #[inline]\n    pub fn contains_point(&self, x: usize, y: usize) -> bool {\n        x <= (self.padding_x + self.columns as f32 * self.cell_width) as usize\n            && x > self.padding_x as usize\n            && y <= (self.padding_y + self.screen_lines as f32 * self.cell_height) as usize\n            && y > self.padding_y as usize\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_12",
        "original_index": 12,
        "content": "    /// Calculate padding to spread it evenly around the terminal content.\n    #[inline]\n    fn dynamic_padding(padding: f32, dimension: f32, cell_dimension: f32) -> f32 {\n        padding + ((dimension - 2. * padding) % cell_dimension) / 2.\n    }\n}\n\nimpl TermDimensions for SizeInfo {\n    #[inline]\n    fn columns(&self) -> usize {\n        self.columns\n    }\n\n    #[inline]\n    fn screen_lines(&self) -> usize {\n        self.screen_lines\n    }\n\n    #[inline]\n    fn total_lines(&self) -> usize {\n        self.screen_lines()\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_13",
        "original_index": 13,
        "content": "#[derive(Default, Clone, Debug, PartialEq, Eq)]\npub struct DisplayUpdate {\n    pub dirty: bool,\n\n    dimensions: Option<PhysicalSize<u32>>,\n    cursor_dirty: bool,\n    font: Option<Font>,\n}\n\nimpl DisplayUpdate {\n    pub fn dimensions(&self) -> Option<PhysicalSize<u32>> {\n        self.dimensions\n    }\n\n    pub fn font(&self) -> Option<&Font> {\n        self.font.as_ref()\n    }\n\n    pub fn cursor_dirty(&self) -> bool {\n        self.cursor_dirty\n    }\n\n    pub fn set_dimensions(&mut self, dimensions: PhysicalSize<u32>) {\n        self.dimensions = Some(dimensions);\n        self.dirty = true;\n    }\n\n    pub fn set_font(&mut self, font: Font) {\n        self.font = Some(font);\n        self.dirty = true;\n    }\n\n    pub fn set_cursor_dirty(&mut self) {\n        self.cursor_dirty = true;\n        self.dirty = true;\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_14",
        "original_index": 14,
        "content": "/// The display wraps a window, font rasterizer, and GPU renderer.\npub struct Display {\n    pub window: Window,\n\n    pub size_info: SizeInfo,\n\n    /// Hint highlighted by the mouse.\n    pub highlighted_hint: Option<HintMatch>,\n\n    /// Hint highlighted by the vi mode cursor.\n    pub vi_highlighted_hint: Option<HintMatch>,\n\n    pub raw_window_handle: RawWindowHandle,\n\n    /// UI cursor visibility for blinking.\n    pub cursor_hidden: bool,\n\n    pub visual_bell: VisualBell,\n\n    /// Mapped RGB values for each terminal color.\n    pub colors: List,\n\n    /// State of the keyboard hints.\n    pub hint_state: HintState,\n\n    /// Unprocessed display updates.\n    pub pending_update: DisplayUpdate,\n\n    /// The renderer update that takes place only once before the actual rendering.\n    pub pending_renderer_update: Option<RendererUpdate>,\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_15",
        "original_index": 15,
        "content": "    /// The ime on the given display.\n    pub ime: Ime,\n\n    /// The state of the timer for frame scheduling.\n    pub frame_timer: FrameTimer,\n\n    /// Damage tracker for the given display.\n    pub damage_tracker: DamageTracker,\n\n    /// Font size used by the window.\n    pub font_size: FontSize,\n\n    // Mouse point position when highlighting hints.\n    hint_mouse_point: Option<Point>,\n\n    renderer: ManuallyDrop<Renderer>,\n\n    surface: ManuallyDrop<Surface<WindowSurface>>,\n\n    context: ManuallyDrop<Replaceable<PossiblyCurrentContext>>,\n\n    glyph_cache: GlyphCache,\n    meter: Meter,\n}\n\nimpl Display {\n    pub fn new(\n        window: Window,\n        gl_context: NotCurrentContext,\n        config: &UiConfig,\n        _tabbed: bool,\n    ) -> Result<Display, Error> {\n        let raw_window_handle = window.raw_window_handle();\n\n        let scale_factor = window.scale_factor as f32;\n        let rasterizer = Rasterizer::new()?;\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_16",
        "original_index": 16,
        "content": "        let font_size = config.font.size().scale(scale_factor);\n        debug!(\"Loading \\\"{}\\\" font\", &config.font.normal().family);\n        let font = config.font.clone().with_size(font_size);\n        let mut glyph_cache = GlyphCache::new(rasterizer, &font)?;\n\n        let metrics = glyph_cache.font_metrics();\n        let (cell_width, cell_height) = compute_cell_size(config, &metrics);\n\n        // Resize the window to account for the user configured size.\n        if let Some(dimensions) = config.window.dimensions() {\n            let size = window_size(config, dimensions, cell_width, cell_height, scale_factor);\n            window.request_inner_size(size);\n        }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_17",
        "original_index": 17,
        "content": "        // Create the GL surface to draw into.\n        let surface = renderer::platform::create_gl_surface(\n            &gl_context,\n            window.inner_size(),\n            window.raw_window_handle(),\n        )?;\n\n        // Make the context current.\n        let context = gl_context.make_current(&surface)?;\n\n        // Create renderer.\n        let mut renderer = Renderer::new(&context, config.debug.renderer)?;\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_18",
        "original_index": 18,
        "content": "        // Load font common glyphs to accelerate rendering.\n        debug!(\"Filling glyph cache with common glyphs\");\n        renderer.with_loader(|mut api| {\n            glyph_cache.reset_glyph_cache(&mut api);\n        });\n\n        let padding = config.window.padding(window.scale_factor as f32);\n        let viewport_size = window.inner_size();\n\n        // Create new size with at least one column and row.\n        let size_info = SizeInfo::new(\n            viewport_size.width as f32,\n            viewport_size.height as f32,\n            cell_width,\n            cell_height,\n            padding.0,\n            padding.1,\n            config.window.dynamic_padding && config.window.dimensions().is_none(),\n        );\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_19",
        "original_index": 19,
        "content": "        info!(\"Cell size: {} x {}\", cell_width, cell_height);\n        info!(\"Padding: {} x {}\", size_info.padding_x(), size_info.padding_y());\n        info!(\"Width: {}, Height: {}\", size_info.width(), size_info.height());\n\n        // Update OpenGL projection.\n        renderer.resize(&size_info);\n\n        // Clear screen.\n        let background_color = config.colors.primary.background;\n        renderer.clear(background_color, config.window_opacity());\n\n        // Disable shadows for transparent windows on macOS.\n        #[cfg(target_os = \"macos\")]\n        window.set_has_shadow(config.window_opacity() >= 1.0);\n\n        let is_wayland = matches!(raw_window_handle, RawWindowHandle::Wayland(_));\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_20",
        "original_index": 20,
        "content": "        // On Wayland we can safely ignore this call, since the window isn't visible until you\n        // actually draw something into it and commit those changes.\n        if !is_wayland {\n            surface.swap_buffers(&context).expect(\"failed to swap buffers.\");\n            renderer.finish();\n        }\n\n        // Set resize increments for the newly created window.\n        if config.window.resize_increments {\n            window.set_resize_increments(PhysicalSize::new(cell_width, cell_height));\n        }\n\n        window.set_visible(true);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_21",
        "original_index": 21,
        "content": "        #[allow(clippy::single_match)]\n        #[cfg(not(windows))]\n        if !_tabbed {\n            match config.window.startup_mode {\n                #[cfg(target_os = \"macos\")]\n                StartupMode::SimpleFullscreen => window.set_simple_fullscreen(true),\n                StartupMode::Maximized if !is_wayland => window.set_maximized(true),\n                _ => (),\n            }\n        }\n\n        let hint_state = HintState::new(config.hints.alphabet());\n\n        let mut damage_tracker = DamageTracker::new(size_info.screen_lines(), size_info.columns());\n        damage_tracker.debug = config.debug.highlight_damage;\n\n        // Disable vsync.\n        if let Err(err) = surface.set_swap_interval(&context, SwapInterval::DontWait) {\n            info!(\"Failed to disable vsync: {}\", err);\n        }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_22",
        "original_index": 22,
        "content": "        Ok(Self {\n            context: ManuallyDrop::new(Replaceable::new(context)),\n            visual_bell: VisualBell::from(&config.bell),\n            renderer: ManuallyDrop::new(renderer),\n            surface: ManuallyDrop::new(surface),\n            colors: List::from(&config.colors),\n            frame_timer: FrameTimer::new(),\n            raw_window_handle,\n            damage_tracker,\n            glyph_cache,\n            hint_state,\n            size_info,\n            font_size,\n            window,\n            pending_renderer_update: Default::default(),\n            vi_highlighted_hint: Default::default(),\n            highlighted_hint: Default::default(),\n            hint_mouse_point: Default::default(),\n            pending_update: Default::default(),\n            cursor_hidden: Default::default(),\n            meter: Default::default(),\n            ime: Default::default(),\n        })\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_23",
        "original_index": 23,
        "content": "    #[inline]\n    pub fn gl_context(&self) -> &PossiblyCurrentContext {\n        self.context.get()\n    }\n\n    pub fn make_not_current(&mut self) {\n        if self.context.get().is_current() {\n            self.context.replace_with(|context| {\n                context\n                    .make_not_current()\n                    .expect(\"failed to disable context\")\n                    .treat_as_possibly_current()\n            });\n        }\n    }\n\n    pub fn make_current(&self) {\n        if !self.context.get().is_current() {\n            self.context.make_current(&self.surface).expect(\"failed to make context current\")\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_24",
        "original_index": 24,
        "content": "    fn swap_buffers(&self) {\n        #[allow(clippy::single_match)]\n        let res = match (self.surface.deref(), &self.context.get()) {\n            #[cfg(not(any(target_os = \"macos\", windows)))]\n            (Surface::Egl(surface), PossiblyCurrentContext::Egl(context))\n                if matches!(self.raw_window_handle, RawWindowHandle::Wayland(_))\n                    && !self.damage_tracker.debug =>\n            {\n                let damage = self.damage_tracker.shape_frame_damage(self.size_info.into());\n                surface.swap_buffers_with_damage(context, &damage)\n            },\n            (surface, context) => surface.swap_buffers(context),\n        };\n        if let Err(err) = res {\n            debug!(\"error calling swap_buffers: {}\", err);\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_25",
        "original_index": 25,
        "content": "    /// Update font size and cell dimensions.\n    ///\n    /// This will return a tuple of the cell width and height.\n    fn update_font_size(\n        glyph_cache: &mut GlyphCache,\n        config: &UiConfig,\n        font: &Font,\n    ) -> (f32, f32) {\n        let _ = glyph_cache.update_font_size(font);\n\n        // Compute new cell sizes.\n        compute_cell_size(config, &glyph_cache.font_metrics())\n    }\n\n    /// Reset glyph cache.\n    fn reset_glyph_cache(&mut self) {\n        let cache = &mut self.glyph_cache;\n        self.renderer.with_loader(|mut api| {\n            cache.reset_glyph_cache(&mut api);\n        });\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_26",
        "original_index": 26,
        "content": "    // XXX: this function must not call to any `OpenGL` related tasks. Renderer updates are\n    // performed in [`Self::process_renderer_update`] right before drawing.\n    //\n    /// Process update events.\n    pub fn handle_update<T>(\n        &mut self,\n        terminal: &mut Term<T>,\n        pty_resize_handle: &mut dyn OnResize,\n        message_buffer: &MessageBuffer,\n        search_state: &mut SearchState,\n        config: &UiConfig,\n    ) where\n        T: EventListener,\n    {\n        let pending_update = mem::take(&mut self.pending_update);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_27",
        "original_index": 27,
        "content": "        let (mut cell_width, mut cell_height) =\n            (self.size_info.cell_width(), self.size_info.cell_height());\n\n        if pending_update.font().is_some() || pending_update.cursor_dirty() {\n            let renderer_update = self.pending_renderer_update.get_or_insert(Default::default());\n            renderer_update.clear_font_cache = true\n        }\n\n        // Update font size and cell dimensions.\n        if let Some(font) = pending_update.font() {\n            let cell_dimensions = Self::update_font_size(&mut self.glyph_cache, config, font);\n            cell_width = cell_dimensions.0;\n            cell_height = cell_dimensions.1;\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_28",
        "original_index": 28,
        "content": "            info!(\"Cell size: {} x {}\", cell_width, cell_height);\n\n            // Mark entire terminal as damaged since glyph size could change without cell size\n            // changes.\n            self.damage_tracker.frame().mark_fully_damaged();\n        }\n\n        let (mut width, mut height) = (self.size_info.width(), self.size_info.height());\n        if let Some(dimensions) = pending_update.dimensions() {\n            width = dimensions.width as f32;\n            height = dimensions.height as f32;\n        }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_29",
        "original_index": 29,
        "content": "        let padding = config.window.padding(self.window.scale_factor as f32);\n\n        let mut new_size = SizeInfo::new(\n            width,\n            height,\n            cell_width,\n            cell_height,\n            padding.0,\n            padding.1,\n            config.window.dynamic_padding,\n        );\n\n        // Update number of column/lines in the viewport.\n        let search_active = search_state.history_index.is_some();\n        let message_bar_lines = message_buffer.message().map_or(0, |m| m.text(&new_size).len());\n        let search_lines = usize::from(search_active);\n        new_size.reserve_lines(message_bar_lines + search_lines);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_30",
        "original_index": 30,
        "content": "        // Update resize increments.\n        if config.window.resize_increments {\n            self.window.set_resize_increments(PhysicalSize::new(cell_width, cell_height));\n        }\n\n        // Resize when terminal when its dimensions have changed.\n        if self.size_info.screen_lines() != new_size.screen_lines\n            || self.size_info.columns() != new_size.columns()\n        {\n            // Resize PTY.\n            pty_resize_handle.on_resize(new_size.into());\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_31",
        "original_index": 31,
        "content": "            // Resize terminal.\n            terminal.resize(new_size);\n\n            // Resize damage tracking.\n            self.damage_tracker.resize(new_size.screen_lines(), new_size.columns());\n        }\n\n        // Check if dimensions have changed.\n        if new_size != self.size_info {\n            // Queue renderer update.\n            let renderer_update = self.pending_renderer_update.get_or_insert(Default::default());\n            renderer_update.resize = true;\n\n            // Clear focused search match.\n            search_state.clear_focused_match();\n        }\n        self.size_info = new_size;\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_32",
        "original_index": 32,
        "content": "    // NOTE: Renderer updates are split off, since platforms like Wayland require resize and other\n    // OpenGL operations to be performed right before rendering. Otherwise they could lock the\n    // back buffer and render with the previous state. This also solves flickering during resizes.\n    //\n    /// Update the state of the renderer.\n    pub fn process_renderer_update(&mut self) {\n        let renderer_update = match self.pending_renderer_update.take() {\n            Some(renderer_update) => renderer_update,\n            _ => return,\n        };\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_33",
        "original_index": 33,
        "content": "        // Resize renderer.\n        if renderer_update.resize {\n            let width = NonZeroU32::new(self.size_info.width() as u32).unwrap();\n            let height = NonZeroU32::new(self.size_info.height() as u32).unwrap();\n            self.surface.resize(&self.context, width, height);\n        }\n\n        // Ensure we're modifying the correct OpenGL context.\n        self.make_current();\n\n        if renderer_update.clear_font_cache {\n            self.reset_glyph_cache();\n        }\n\n        self.renderer.resize(&self.size_info);\n\n        info!(\"Padding: {} x {}\", self.size_info.padding_x(), self.size_info.padding_y());\n        info!(\"Width: {}, Height: {}\", self.size_info.width(), self.size_info.height());\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_34",
        "original_index": 34,
        "content": "    /// Draw the screen.\n    ///\n    /// A reference to Term whose state is being drawn must be provided.\n    ///\n    /// This call may block if vsync is enabled.\n    pub fn draw<T: EventListener>(\n        &mut self,\n        mut terminal: MutexGuard<'_, Term<T>>,\n        scheduler: &mut Scheduler,\n        message_buffer: &MessageBuffer,\n        config: &UiConfig,\n        search_state: &mut SearchState,\n    ) {\n        // Collect renderable content before the terminal is dropped.\n        let mut content = RenderableContent::new(config, self, &terminal, search_state);\n"
      },
      {
        "chunk_id": "doc_70_chunk_35",
        "original_index": 35,
        "content": "        let mut grid_cells = Vec::new();\n        for cell in &mut content {\n            grid_cells.push(cell);\n        }\n        let selection_range = content.selection_range();\n        let foreground_color = content.color(NamedColor::Foreground as usize);\n        let background_color = content.color(NamedColor::Background as usize);\n        let display_offset = content.display_offset();\n        let cursor = content.cursor();\n\n        let cursor_point = terminal.grid().cursor.point;\n        let total_lines = terminal.grid().total_lines();\n        let metrics = self.glyph_cache.font_metrics();\n        let size_info = self.size_info;\n\n        let vi_mode = terminal.mode().contains(TermMode::VI);\n        let vi_cursor_point = if vi_mode { Some(terminal.vi_mode_cursor.point) } else { None };\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_36",
        "original_index": 36,
        "content": "        // Add damage from the terminal.\n        if self.collect_damage() {\n            match terminal.damage() {\n                TermDamage::Full => self.damage_tracker.frame().mark_fully_damaged(),\n                TermDamage::Partial(damaged_lines) => {\n                    for damage in damaged_lines {\n                        self.damage_tracker.frame().damage_line(damage);\n                    }\n                },\n            }\n            terminal.reset_damage();\n        }\n\n        // Drop terminal as early as possible to free lock.\n        drop(terminal);\n\n        // Add damage from alacritty's UI elements overlapping terminal.\n        if self.collect_damage() {\n            let requires_full_damage = self.visual_bell.intensity() != 0.\n                || self.hint_state.active()\n                || search_state.regex().is_some();\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_37",
        "original_index": 37,
        "content": "            if requires_full_damage {\n                self.damage_tracker.frame().mark_fully_damaged();\n                self.damage_tracker.next_frame().mark_fully_damaged();\n            }\n\n            let vi_cursor_viewport_point =\n                vi_cursor_point.and_then(|cursor| point_to_viewport(display_offset, cursor));\n\n            self.damage_tracker.damage_vi_cursor(vi_cursor_viewport_point);\n            self.damage_tracker.damage_selection(selection_range, display_offset);\n        }\n\n        // Make sure this window's OpenGL context is active.\n        self.make_current();\n\n        self.renderer.clear(background_color, config.window_opacity());\n        let mut lines = RenderLines::new();\n\n        // Optimize loop hint comparator.\n        let has_highlighted_hint =\n            self.highlighted_hint.is_some() || self.vi_highlighted_hint.is_some();\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_38",
        "original_index": 38,
        "content": "        // Draw grid.\n        {\n            let _sampler = self.meter.sampler();\n\n            // Ensure macOS hasn't reset our viewport.\n            #[cfg(target_os = \"macos\")]\n            self.renderer.set_viewport(&size_info);\n\n            let glyph_cache = &mut self.glyph_cache;\n            let highlighted_hint = &self.highlighted_hint;\n            let vi_highlighted_hint = &self.vi_highlighted_hint;\n            let damage_tracker = &mut self.damage_tracker;\n\n            self.renderer.draw_cells(\n                &size_info,\n                glyph_cache,\n                grid_cells.into_iter().map(|mut cell| {\n                    // Underline hints hovered by mouse or vi mode cursor.\n                    let point = term::viewport_to_point(display_offset, cell.point);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_39",
        "original_index": 39,
        "content": "                    if has_highlighted_hint {\n                        let hyperlink =\n                            cell.extra.as_ref().and_then(|extra| extra.hyperlink.as_ref());\n                        if highlighted_hint\n                            .as_ref()\n                            .map_or(false, |hint| hint.should_highlight(point, hyperlink))\n                            || vi_highlighted_hint\n                                .as_ref()\n                                .map_or(false, |hint| hint.should_highlight(point, hyperlink))\n                        {\n                            cell.flags.insert(Flags::UNDERLINE);\n                            // Damage hints for the current and next frames.\n                            damage_tracker.frame().damage_point(cell.point);\n                            damage_tracker.next_frame().damage_point(cell.point);\n                        }\n                    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_40",
        "original_index": 40,
        "content": "                    // Update underline/strikeout.\n                    lines.update(&cell);\n\n                    cell\n                }),\n            );\n        }\n\n        let mut rects = lines.rects(&metrics, &size_info);\n\n        if let Some(vi_cursor_point) = vi_cursor_point {\n            // Indicate vi mode by showing the cursor's position in the top right corner.\n            let line = (-vi_cursor_point.line.0 + size_info.bottommost_line().0) as usize;\n            let obstructed_column = Some(vi_cursor_point)\n                .filter(|point| point.line == -(display_offset as i32))\n                .map(|point| point.column);\n            self.draw_line_indicator(config, total_lines, obstructed_column, line);\n        } else if search_state.regex().is_some() {\n            // Show current display offset in vi-less search to indicate match position.\n            self.draw_line_indicator(config, total_lines, None, display_offset);\n        };\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_41",
        "original_index": 41,
        "content": "        // Draw cursor.\n        rects.extend(cursor.rects(&size_info, config.cursor.thickness()));\n\n        // Push visual bell after url/underline/strikeout rects.\n        let visual_bell_intensity = self.visual_bell.intensity();\n        if visual_bell_intensity != 0. {\n            let visual_bell_rect = RenderRect::new(\n                0.,\n                0.,\n                size_info.width(),\n                size_info.height(),\n                config.bell.color,\n                visual_bell_intensity as f32,\n            );\n            rects.push(visual_bell_rect);\n        }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_42",
        "original_index": 42,
        "content": "        // Handle IME positioning and search bar rendering.\n        let ime_position = match search_state.regex() {\n            Some(regex) => {\n                let search_label = match search_state.direction() {\n                    Direction::Right => FORWARD_SEARCH_LABEL,\n                    Direction::Left => BACKWARD_SEARCH_LABEL,\n                };\n\n                let search_text = Self::format_search(regex, search_label, size_info.columns());\n\n                // Render the search bar.\n                self.draw_search(config, &search_text);\n\n                // Draw search bar cursor.\n                let line = size_info.screen_lines();\n                let column = Column(search_text.chars().count() - 1);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_43",
        "original_index": 43,
        "content": "                // Add cursor to search bar if IME is not active.\n                if self.ime.preedit().is_none() {\n                    let fg = config.colors.footer_bar_foreground();\n                    let shape = CursorShape::Underline;\n                    let cursor = RenderableCursor::new(Point::new(line, column), shape, fg, false);\n                    rects.extend(cursor.rects(&size_info, config.cursor.thickness()));\n                }\n\n                Some(Point::new(line, column))\n            },\n            None => {\n                let num_lines = self.size_info.screen_lines();\n                term::point_to_viewport(display_offset, cursor_point)\n                    .filter(|point| point.line < num_lines)\n            },\n        };\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_44",
        "original_index": 44,
        "content": "        // Handle IME.\n        if self.ime.is_enabled() {\n            if let Some(point) = ime_position {\n                let (fg, bg) = if search_state.regex().is_some() {\n                    (config.colors.footer_bar_foreground(), config.colors.footer_bar_background())\n                } else {\n                    (foreground_color, background_color)\n                };\n\n                self.draw_ime_preview(point, fg, bg, &mut rects, config);\n            }\n        }\n\n        if let Some(message) = message_buffer.message() {\n            let search_offset = usize::from(search_state.regex().is_some());\n            let text = message.text(&size_info);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_45",
        "original_index": 45,
        "content": "            // Create a new rectangle for the background.\n            let start_line = size_info.screen_lines() + search_offset;\n            let y = size_info.cell_height().mul_add(start_line as f32, size_info.padding_y());\n\n            let bg = match message.ty() {\n                MessageType::Error => config.colors.normal.red,\n                MessageType::Warning => config.colors.normal.yellow,\n            };\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_46",
        "original_index": 46,
        "content": "            let x = 0;\n            let width = size_info.width() as i32;\n            let height = (size_info.height() - y) as i32;\n            let message_bar_rect =\n                RenderRect::new(x as f32, y, width as f32, height as f32, bg, 1.);\n\n            // Push message_bar in the end, so it'll be above all other content.\n            rects.push(message_bar_rect);\n\n            // Always damage message bar, since it could have messages of the same size in it.\n            self.damage_tracker.frame().add_viewport_rect(&size_info, x, y as i32, width, height);\n\n            // Draw rectangles.\n            self.renderer.draw_rects(&size_info, &metrics, rects);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_47",
        "original_index": 47,
        "content": "            // Relay messages to the user.\n            let glyph_cache = &mut self.glyph_cache;\n            let fg = config.colors.primary.background;\n            for (i, message_text) in text.iter().enumerate() {\n                let point = Point::new(start_line + i, Column(0));\n                self.renderer.draw_string(\n                    point,\n                    fg,\n                    bg,\n                    message_text.chars(),\n                    &size_info,\n                    glyph_cache,\n                );\n            }\n        } else {\n            // Draw rectangles.\n            self.renderer.draw_rects(&size_info, &metrics, rects);\n        }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_48",
        "original_index": 48,
        "content": "        self.draw_render_timer(config);\n\n        // Draw hyperlink uri preview.\n        if has_highlighted_hint {\n            let cursor_point = vi_cursor_point.or(Some(cursor_point));\n            self.draw_hyperlink_preview(config, cursor_point, display_offset);\n        }\n\n        // Notify winit that we're about to present.\n        self.window.pre_present_notify();\n\n        // Highlight damage for debugging.\n        if self.damage_tracker.debug {\n            let damage = self.damage_tracker.shape_frame_damage(self.size_info.into());\n            let mut rects = Vec::with_capacity(damage.len());\n            self.highlight_damage(&mut rects);\n            self.renderer.draw_rects(&self.size_info, &metrics, rects);\n        }\n\n        // Clearing debug highlights from the previous frame requires full redraw.\n        self.swap_buffers();\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_49",
        "original_index": 49,
        "content": "        if matches!(self.raw_window_handle, RawWindowHandle::Xcb(_) | RawWindowHandle::Xlib(_)) {\n            // On X11 `swap_buffers` does not block for vsync. However the next OpenGl command\n            // will block to synchronize (this is `glClear` in Alacritty), which causes a\n            // permanent one frame delay.\n            self.renderer.finish();\n        }\n\n        // XXX: Request the new frame after swapping buffers, so the\n        // time to finish OpenGL operations is accounted for in the timeout.\n        if !matches!(self.raw_window_handle, RawWindowHandle::Wayland(_)) {\n            self.request_frame(scheduler);\n        }\n\n        self.damage_tracker.swap_damage();\n    }\n\n    /// Update to a new configuration.\n    pub fn update_config(&mut self, config: &UiConfig) {\n        self.damage_tracker.debug = config.debug.highlight_damage;\n        self.visual_bell.update_config(&config.bell);\n        self.colors = List::from(&config.colors);\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_50",
        "original_index": 50,
        "content": "    /// Update the mouse/vi mode cursor hint highlighting.\n    ///\n    /// This will return whether the highlighted hints changed.\n    pub fn update_highlighted_hints<T>(\n        &mut self,\n        term: &Term<T>,\n        config: &UiConfig,\n        mouse: &Mouse,\n        modifiers: ModifiersState,\n    ) -> bool {\n        // Update vi mode cursor hint.\n        let vi_highlighted_hint = if term.mode().contains(TermMode::VI) {\n            let mods = ModifiersState::all();\n            let point = term.vi_mode_cursor.point;\n            hint::highlighted_at(term, config, point, mods)\n        } else {\n            None\n        };\n        let mut dirty = vi_highlighted_hint != self.vi_highlighted_hint;\n        self.vi_highlighted_hint = vi_highlighted_hint;\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_51",
        "original_index": 51,
        "content": "        // Abort if mouse highlighting conditions are not met.\n        if !mouse.inside_text_area || !term.selection.as_ref().map_or(true, Selection::is_empty) {\n            dirty |= self.highlighted_hint.is_some();\n            self.highlighted_hint = None;\n            return dirty;\n        }\n\n        // Find highlighted hint at mouse position.\n        let point = mouse.point(&self.size_info, term.grid().display_offset());\n        let highlighted_hint = hint::highlighted_at(term, config, point, modifiers);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_52",
        "original_index": 52,
        "content": "        // Update cursor shape.\n        if highlighted_hint.is_some() {\n            // If mouse changed the line, we should update the hyperlink preview, since the\n            // highlighted hint could be disrupted by the old preview.\n            dirty = self.hint_mouse_point.map_or(false, |p| p.line != point.line);\n            self.hint_mouse_point = Some(point);\n            self.window.set_mouse_cursor(CursorIcon::Pointer);\n        } else if self.highlighted_hint.is_some() {\n            self.hint_mouse_point = None;\n            if term.mode().intersects(TermMode::MOUSE_MODE) && !term.mode().contains(TermMode::VI) {\n                self.window.set_mouse_cursor(CursorIcon::Default);\n            } else {\n                self.window.set_mouse_cursor(CursorIcon::Text);\n            }\n        }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_53",
        "original_index": 53,
        "content": "        dirty |= self.highlighted_hint != highlighted_hint;\n        self.highlighted_hint = highlighted_hint;\n\n        dirty\n    }\n\n    #[inline(never)]\n    fn draw_ime_preview(\n        &mut self,\n        point: Point<usize>,\n        fg: Rgb,\n        bg: Rgb,\n        rects: &mut Vec<RenderRect>,\n        config: &UiConfig,\n    ) {\n        let preedit = match self.ime.preedit() {\n            Some(preedit) => preedit,\n            None => {\n                // In case we don't have preedit, just set the popup point.\n                self.window.update_ime_position(point, &self.size_info);\n                return;\n            },\n        };\n\n        let num_cols = self.size_info.columns();\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_54",
        "original_index": 54,
        "content": "        // Get the visible preedit.\n        let visible_text: String = match (preedit.cursor_byte_offset, preedit.cursor_end_offset) {\n            (Some(byte_offset), Some(end_offset)) if end_offset > num_cols => StrShortener::new(\n                &preedit.text[byte_offset..],\n                num_cols,\n                ShortenDirection::Right,\n                Some(SHORTENER),\n            ),\n            _ => {\n                StrShortener::new(&preedit.text, num_cols, ShortenDirection::Left, Some(SHORTENER))\n            },\n        }\n        .collect();\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_55",
        "original_index": 55,
        "content": "        let visible_len = visible_text.chars().count();\n\n        let end = cmp::min(point.column.0 + visible_len, num_cols);\n        let start = end.saturating_sub(visible_len);\n\n        let start = Point::new(point.line, Column(start));\n        let end = Point::new(point.line, Column(end - 1));\n\n        let glyph_cache = &mut self.glyph_cache;\n        let metrics = glyph_cache.font_metrics();\n\n        self.renderer.draw_string(\n            start,\n            fg,\n            bg,\n            visible_text.chars(),\n            &self.size_info,\n            glyph_cache,\n        );\n\n        // Damage preedit inside the terminal viewport.\n        if self.collect_damage() && point.line < self.size_info.screen_lines() {\n            let damage = LineDamageBounds::new(start.line, 0, num_cols);\n            self.damage_tracker.frame().damage_line(damage);\n            self.damage_tracker.next_frame().damage_line(damage);\n        }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_56",
        "original_index": 56,
        "content": "        // Add underline for preedit text.\n        let underline = RenderLine { start, end, color: fg };\n        rects.extend(underline.rects(Flags::UNDERLINE, &metrics, &self.size_info));\n\n        let ime_popup_point = match preedit.cursor_end_offset {\n            Some(cursor_end_offset) if cursor_end_offset != 0 => {\n                let is_wide = preedit.text[preedit.cursor_byte_offset.unwrap_or_default()..]\n                    .chars()\n                    .next()\n                    .map(|ch| ch.width() == Some(2))\n                    .unwrap_or_default();\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_57",
        "original_index": 57,
        "content": "                let cursor_column = Column(\n                    (end.column.0 as isize - cursor_end_offset as isize + 1).max(0) as usize,\n                );\n                let cursor_point = Point::new(point.line, cursor_column);\n                let cursor =\n                    RenderableCursor::new(cursor_point, CursorShape::HollowBlock, fg, is_wide);\n                rects.extend(cursor.rects(&self.size_info, config.cursor.thickness()));\n                cursor_point\n            },\n            _ => end,\n        };\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_58",
        "original_index": 58,
        "content": "        self.window.update_ime_position(ime_popup_point, &self.size_info);\n    }\n\n    /// Format search regex to account for the cursor and fullwidth characters.\n    fn format_search(search_regex: &str, search_label: &str, max_width: usize) -> String {\n        let label_len = search_label.len();\n\n        // Skip `search_regex` formatting if only label is visible.\n        if label_len > max_width {\n            return search_label[..max_width].to_owned();\n        }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_59",
        "original_index": 59,
        "content": "        // The search string consists of `search_label` + `search_regex` + `cursor`.\n        let mut bar_text = String::from(search_label);\n        bar_text.extend(StrShortener::new(\n            search_regex,\n            max_width.wrapping_sub(label_len + 1),\n            ShortenDirection::Left,\n            Some(SHORTENER),\n        ));\n\n        // Add place for cursor.\n        bar_text.push(' ');\n\n        bar_text\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_60",
        "original_index": 60,
        "content": "    /// Draw preview for the currently highlighted `Hyperlink`.\n    #[inline(never)]\n    fn draw_hyperlink_preview(\n        &mut self,\n        config: &UiConfig,\n        cursor_point: Option<Point>,\n        display_offset: usize,\n    ) {\n        let num_cols = self.size_info.columns();\n        let uris: Vec<_> = self\n            .highlighted_hint\n            .iter()\n            .chain(&self.vi_highlighted_hint)\n            .filter_map(|hint| hint.hyperlink().map(|hyperlink| hyperlink.uri()))\n            .map(|uri| StrShortener::new(uri, num_cols, ShortenDirection::Right, Some(SHORTENER)))\n            .collect();\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_61",
        "original_index": 61,
        "content": "        if uris.is_empty() {\n            return;\n        }\n\n        // The maximum amount of protected lines including the ones we'll show preview on.\n        let max_protected_lines = uris.len() * 2;\n\n        // Lines we shouldn't show preview on, because it'll obscure the highlighted hint.\n        let mut protected_lines = Vec::with_capacity(max_protected_lines);\n        if self.size_info.screen_lines() > max_protected_lines {\n            // Prefer to show preview even when it'll likely obscure the highlighted hint, when\n            // there's no place left for it.\n            protected_lines.push(self.hint_mouse_point.map(|point| point.line));\n            protected_lines.push(cursor_point.map(|point| point.line));\n        }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_62",
        "original_index": 62,
        "content": "        // Find the line in viewport we can draw preview on without obscuring protected lines.\n        let viewport_bottom = self.size_info.bottommost_line() - Line(display_offset as i32);\n        let viewport_top = viewport_bottom - (self.size_info.screen_lines() - 1);\n        let uri_lines = (viewport_top.0..=viewport_bottom.0)\n            .rev()\n            .map(|line| Some(Line(line)))\n            .filter_map(|line| {\n                if protected_lines.contains(&line) {\n                    None\n                } else {\n                    protected_lines.push(line);\n                    line\n                }\n            })\n            .take(uris.len())\n            .flat_map(|line| term::point_to_viewport(display_offset, Point::new(line, Column(0))));\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_63",
        "original_index": 63,
        "content": "        let fg = config.colors.footer_bar_foreground();\n        let bg = config.colors.footer_bar_background();\n        for (uri, point) in uris.into_iter().zip(uri_lines) {\n            // Damage the uri preview.\n            if self.collect_damage() {\n                let damage = LineDamageBounds::new(point.line, point.column.0, num_cols);\n                self.damage_tracker.frame().damage_line(damage);\n\n                // Damage the uri preview for the next frame as well.\n                self.damage_tracker.next_frame().damage_line(damage);\n            }\n\n            self.renderer.draw_string(point, fg, bg, uri, &self.size_info, &mut self.glyph_cache);\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_64",
        "original_index": 64,
        "content": "    /// Draw current search regex.\n    #[inline(never)]\n    fn draw_search(&mut self, config: &UiConfig, text: &str) {\n        // Assure text length is at least num_cols.\n        let num_cols = self.size_info.columns();\n        let text = format!(\"{:<1$}\", text, num_cols);\n\n        let point = Point::new(self.size_info.screen_lines(), Column(0));\n\n        let fg = config.colors.footer_bar_foreground();\n        let bg = config.colors.footer_bar_background();\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_65",
        "original_index": 65,
        "content": "        self.renderer.draw_string(\n            point,\n            fg,\n            bg,\n            text.chars(),\n            &self.size_info,\n            &mut self.glyph_cache,\n        );\n    }\n\n    /// Draw render timer.\n    #[inline(never)]\n    fn draw_render_timer(&mut self, config: &UiConfig) {\n        if !config.debug.render_timer {\n            return;\n        }\n\n        let timing = format!(\"{:.3} usec\", self.meter.average());\n        let point = Point::new(self.size_info.screen_lines().saturating_sub(2), Column(0));\n        let fg = config.colors.primary.background;\n        let bg = config.colors.normal.red;\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_66",
        "original_index": 66,
        "content": "        if self.collect_damage() {\n            let damage = LineDamageBounds::new(point.line, point.column.0, timing.len());\n            self.damage_tracker.frame().damage_line(damage);\n            // Damage the render timer for the next frame.\n            self.damage_tracker.next_frame().damage_line(damage);\n        }\n\n        let glyph_cache = &mut self.glyph_cache;\n        self.renderer.draw_string(point, fg, bg, timing.chars(), &self.size_info, glyph_cache);\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_67",
        "original_index": 67,
        "content": "    /// Draw an indicator for the position of a line in history.\n    #[inline(never)]\n    fn draw_line_indicator(\n        &mut self,\n        config: &UiConfig,\n        total_lines: usize,\n        obstructed_column: Option<Column>,\n        line: usize,\n    ) {\n        let columns = self.size_info.columns();\n        let text = format!(\"[{}/{}]\", line, total_lines - 1);\n        let column = Column(self.size_info.columns().saturating_sub(text.len()));\n        let point = Point::new(0, column);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_68",
        "original_index": 68,
        "content": "        if self.collect_damage() {\n            let damage = LineDamageBounds::new(point.line, point.column.0, columns - 1);\n            self.damage_tracker.frame().damage_line(damage);\n            // Damage it on the next frame in case it goes away.\n            self.damage_tracker.next_frame().damage_line(damage);\n        }\n\n        let colors = &config.colors;\n        let fg = colors.line_indicator.foreground.unwrap_or(colors.primary.background);\n        let bg = colors.line_indicator.background.unwrap_or(colors.primary.foreground);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_69",
        "original_index": 69,
        "content": "        // Do not render anything if it would obscure the vi mode cursor.\n        if obstructed_column.map_or(true, |obstructed_column| obstructed_column < column) {\n            let glyph_cache = &mut self.glyph_cache;\n            self.renderer.draw_string(point, fg, bg, text.chars(), &self.size_info, glyph_cache);\n        }\n    }\n\n    /// Returns `true` if damage information should be collected, `false` otherwise.\n    #[inline]\n    fn collect_damage(&self) -> bool {\n        matches!(self.raw_window_handle, RawWindowHandle::Wayland(_)) || self.damage_tracker.debug\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_70",
        "original_index": 70,
        "content": "    /// Highlight damaged rects.\n    ///\n    /// This function is for debug purposes only.\n    fn highlight_damage(&self, render_rects: &mut Vec<RenderRect>) {\n        for damage_rect in &self.damage_tracker.shape_frame_damage(self.size_info.into()) {\n            let x = damage_rect.x as f32;\n            let height = damage_rect.height as f32;\n            let width = damage_rect.width as f32;\n            let y = damage_y_to_viewport_y(&self.size_info, damage_rect) as f32;\n            let render_rect = RenderRect::new(x, y, width, height, DAMAGE_RECT_COLOR, 0.5);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_71",
        "original_index": 71,
        "content": "            render_rects.push(render_rect);\n        }\n    }\n\n    /// Request a new frame for a window on Wayland.\n    fn request_frame(&mut self, scheduler: &mut Scheduler) {\n        // Mark that we've used a frame.\n        self.window.has_frame = false;\n\n        // Get the display vblank interval.\n        let monitor_vblank_interval = 1_000_000.\n            / self\n                .window\n                .current_monitor()\n                .and_then(|monitor| monitor.refresh_rate_millihertz())\n                .unwrap_or(60_000) as f64;\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_72",
        "original_index": 72,
        "content": "        // Now convert it to micro seconds.\n        let monitor_vblank_interval =\n            Duration::from_micros((1000. * monitor_vblank_interval) as u64);\n\n        let swap_timeout = self.frame_timer.compute_timeout(monitor_vblank_interval);\n\n        let window_id = self.window.id();\n        let timer_id = TimerId::new(Topic::Frame, window_id);\n        let event = Event::new(EventType::Frame, window_id);\n\n        scheduler.schedule(event, swap_timeout, false, timer_id);\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_73",
        "original_index": 73,
        "content": "impl Drop for Display {\n    fn drop(&mut self) {\n        // Switch OpenGL context before dropping, otherwise objects (like programs) from other\n        // contexts might be deleted when dropping renderer.\n        self.make_current();\n        unsafe {\n            ManuallyDrop::drop(&mut self.renderer);\n            ManuallyDrop::drop(&mut self.context);\n            ManuallyDrop::drop(&mut self.surface);\n        }\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_74",
        "original_index": 74,
        "content": "/// Input method state.\n#[derive(Debug, Default)]\npub struct Ime {\n    /// Whether the IME is enabled.\n    enabled: bool,\n\n    /// Current IME preedit.\n    preedit: Option<Preedit>,\n}\n\nimpl Ime {\n    #[inline]\n    pub fn set_enabled(&mut self, is_enabled: bool) {\n        if is_enabled {\n            self.enabled = is_enabled\n        } else {\n            // Clear state when disabling IME.\n            *self = Default::default();\n        }\n    }\n\n    #[inline]\n    pub fn is_enabled(&self) -> bool {\n        self.enabled\n    }\n\n    #[inline]\n    pub fn set_preedit(&mut self, preedit: Option<Preedit>) {\n        self.preedit = preedit;\n    }\n\n    #[inline]\n    pub fn preedit(&self) -> Option<&Preedit> {\n        self.preedit.as_ref()\n    }\n}\n\n#[derive(Debug, Default, PartialEq, Eq)]\npub struct Preedit {\n    /// The preedit text.\n    text: String,\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_75",
        "original_index": 75,
        "content": "    /// Byte offset for cursor start into the preedit text.\n    ///\n    /// `None` means that the cursor is invisible.\n    cursor_byte_offset: Option<usize>,\n\n    /// The cursor offset from the end of the preedit in char width.\n    cursor_end_offset: Option<usize>,\n}\n\nimpl Preedit {\n    pub fn new(text: String, cursor_byte_offset: Option<usize>) -> Self {\n        let cursor_end_offset = if let Some(byte_offset) = cursor_byte_offset {\n            // Convert byte offset into char offset.\n            let cursor_end_offset =\n                text[byte_offset..].chars().fold(0, |acc, ch| acc + ch.width().unwrap_or(1));\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_76",
        "original_index": 76,
        "content": "            Some(cursor_end_offset)\n        } else {\n            None\n        };\n\n        Self { text, cursor_byte_offset, cursor_end_offset }\n    }\n}\n\n/// Pending renderer updates.\n///\n/// All renderer updates are cached to be applied just before rendering, to avoid platform-specific\n/// rendering issues.\n#[derive(Debug, Default, Copy, Clone)]\npub struct RendererUpdate {\n    /// Should resize the window.\n    resize: bool,\n\n    /// Clear font caches.\n    clear_font_cache: bool,\n}\n\n/// Struct for safe in-place replacement.\n///\n/// This struct allows easily replacing struct fields that provide `self -> Self` methods in-place,\n/// without having to deal with constantly unwrapping the underlying [`Option`].\nstruct Replaceable<T>(Option<T>);\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_77",
        "original_index": 77,
        "content": "impl<T> Replaceable<T> {\n    pub fn new(inner: T) -> Self {\n        Self(Some(inner))\n    }\n\n    /// Replace the contents of the container.\n    pub fn replace_with<F: FnMut(T) -> T>(&mut self, f: F) {\n        self.0 = self.0.take().map(f);\n    }\n\n    /// Get immutable access to the wrapped value.\n    pub fn get(&self) -> &T {\n        self.0.as_ref().unwrap()\n    }\n\n    /// Get mutable access to the wrapped value.\n    pub fn get_mut(&mut self) -> &mut T {\n        self.0.as_mut().unwrap()\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_78",
        "original_index": 78,
        "content": "impl<T> Deref for Replaceable<T> {\n    type Target = T;\n\n    fn deref(&self) -> &Self::Target {\n        self.get()\n    }\n}\n\nimpl<T> DerefMut for Replaceable<T> {\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        self.get_mut()\n    }\n}\n\n/// The frame timer state.\npub struct FrameTimer {\n    /// Base timestamp used to compute sync points.\n    base: Instant,\n\n    /// The last timestamp we synced to.\n    last_synced_timestamp: Instant,\n\n    /// The refresh rate we've used to compute sync timestamps.\n    refresh_interval: Duration,\n}\n\nimpl FrameTimer {\n    pub fn new() -> Self {\n        let now = Instant::now();\n        Self { base: now, last_synced_timestamp: now, refresh_interval: Duration::ZERO }\n    }\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_79",
        "original_index": 79,
        "content": "    /// Compute the delay that we should use to achieve the target frame\n    /// rate.\n    pub fn compute_timeout(&mut self, refresh_interval: Duration) -> Duration {\n        let now = Instant::now();\n\n        // Handle refresh rate change.\n        if self.refresh_interval != refresh_interval {\n            self.base = now;\n            self.last_synced_timestamp = now;\n            self.refresh_interval = refresh_interval;\n            return refresh_interval;\n        }\n\n        let next_frame = self.last_synced_timestamp + self.refresh_interval;\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_80",
        "original_index": 80,
        "content": "        if next_frame < now {\n            // Redraw immediately if we haven't drawn in over `refresh_interval` microseconds.\n            let elapsed_micros = (now - self.base).as_micros() as u64;\n            let refresh_micros = self.refresh_interval.as_micros() as u64;\n            self.last_synced_timestamp =\n                now - Duration::from_micros(elapsed_micros % refresh_micros);\n            Duration::ZERO\n        } else {\n            // Redraw on the next `refresh_interval` clock tick.\n            self.last_synced_timestamp = next_frame;\n            next_frame - now\n        }\n    }\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_81",
        "original_index": 81,
        "content": "/// Calculate the cell dimensions based on font metrics.\n///\n/// This will return a tuple of the cell width and height.\n#[inline]\nfn compute_cell_size(config: &UiConfig, metrics: &crossfont::Metrics) -> (f32, f32) {\n    let offset_x = f64::from(config.font.offset.x);\n    let offset_y = f64::from(config.font.offset.y);\n    (\n        (metrics.average_advance + offset_x).floor().max(1.) as f32,\n        (metrics.line_height + offset_y).floor().max(1.) as f32,\n    )\n}\n\n"
      },
      {
        "chunk_id": "doc_70_chunk_82",
        "original_index": 82,
        "content": "/// Calculate the size of the window given padding, terminal dimensions and cell size.\nfn window_size(\n    config: &UiConfig,\n    dimensions: Dimensions,\n    cell_width: f32,\n    cell_height: f32,\n    scale_factor: f32,\n) -> PhysicalSize<u32> {\n    let padding = config.window.padding(scale_factor);\n\n    let grid_width = cell_width * dimensions.columns.max(MIN_COLUMNS) as f32;\n    let grid_height = cell_height * dimensions.lines.max(MIN_SCREEN_LINES) as f32;\n\n    let width = (padding.0).mul_add(2., grid_width).floor();\n    let height = (padding.1).mul_add(2., grid_height).floor();\n\n    PhysicalSize::new(width as u32, height as u32)\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_71",
    "original_uuid": "9ab68bb3dcc5b2e4bcb65ed03b08b261652c4930960efafea6380ca48c450c65",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.flink.ml.common.param;\n\nimport org.apache.flink.ml.param.Param;\nimport org.apache.flink.ml.param.StringParam;\nimport org.apache.flink.ml.param.WithParams;\n\n/**\n * Interface for the shared weight column param. If this is not set, we treat all instance weights\n * as 1.0.\n */\npublic interface HasWeightCol<T> extends WithParams<T> {\n    Param<String> WEIGHT_COL = new StringParam(\"weightCol\", \"Weight column name.\", null);\n\n    default String getWeightCol() {\n        return get(WEIGHT_COL);\n    }\n\n    default T setWeightCol(String colName) {\n        return set(WEIGHT_COL, colName);\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_71_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_71_chunk_1",
        "original_index": 1,
        "content": "package org.apache.flink.ml.common.param;\n\nimport org.apache.flink.ml.param.Param;\nimport org.apache.flink.ml.param.StringParam;\nimport org.apache.flink.ml.param.WithParams;\n\n/**\n * Interface for the shared weight column param. If this is not set, we treat all instance weights\n * as 1.0.\n */\npublic interface HasWeightCol<T> extends WithParams<T> {\n    Param<String> WEIGHT_COL = new StringParam(\"weightCol\", \"Weight column name.\", null);\n\n    default String getWeightCol() {\n        return get(WEIGHT_COL);\n    }\n\n    default T setWeightCol(String colName) {\n        return set(WEIGHT_COL, colName);\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_72",
    "original_uuid": "139c40956655d0ac49fe337fed8ae7d4e2faaa694b327c7758b84d11169b02de",
    "content": "################################################################################\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  \"License\"); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n# limitations under the License.\n################################################################################\n\nfrom typing import Tuple\nfrom pyflink.ml.wrapper import JavaWithParams\nfrom pyflink.ml.param import IntArrayParam, ParamValidator\nfrom pyflink.ml.feature.common import JavaFeatureTransformer\nfrom pyflink.ml.common.param import HasInputCol, HasOutputCol, Param\n\n\nclass _VectorSlicerParams(\n    JavaWithParams,\n    HasInputCol,\n    HasOutputCol\n):\n    \"\"\"\n      Checks the indices parameter.\n    \"\"\"\n\n    def indices_validator(self) -> ParamValidator[Tuple[int]]:\n        class IndicesValidator(ParamValidator[Tuple[int]]):\n            def validate(self, indices: Tuple[int]) -> bool:\n                for val in indices:\n                    if val < 0:\n                        return False\n                return True\n                indices_set = set(indices)\n                if len(indices_set) != len(indices):\n                    return False\n                return len(indices_set) != 0\n        return IndicesValidator()\n\n    \"\"\"\n    Params for :class:`VectorSlicer`.\n    \"\"\"\n\n    INDICES: Param[Tuple[int, ...]] = IntArrayParam(\n        \"indices\",\n        \"An array of indices to select features from a vector column.\",\n        None,\n        indices_validator(None))\n\n    def __init__(self, java_params):\n        super(_VectorSlicerParams, self).__init__(java_params)\n\n    def set_indices(self, *ind: int):\n        return self.set(self.INDICES, ind)\n\n    def get_indices(self) -> Tuple[int, ...]:\n        return self.get(self.INDICES)\n\n    @property\n    def indices(self) -> Tuple[int, ...]:\n        return self.get_indices()\n\n\nclass VectorSlicer(JavaFeatureTransformer, _VectorSlicerParams):\n    \"\"\"\n    A Transformer that transforms a vector to a new feature, which is a sub-array of\n    the original feature.It is useful for extracting features from a given vector.\n\n    Note that duplicate features are not allowed, so there can be no overlap between\n    selected indices. If the max value of the indices is greater than the size of\n    the input vector, it throws an IllegalArgumentException.\n    \"\"\"\n\n    def __init__(self, java_model=None):\n        super(VectorSlicer, self).__init__(java_model)\n\n    @classmethod\n    def _java_transformer_package_name(cls) -> str:\n        return \"vectorslicer\"\n\n    @classmethod\n    def _java_transformer_class_name(cls) -> str:\n        return \"VectorSlicer\"\n",
    "chunks": [
      {
        "chunk_id": "doc_72_chunk_0",
        "original_index": 0,
        "content": "################################################################################\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  \"License\"); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n# limitations under the License.\n################################################################################\n\n"
      },
      {
        "chunk_id": "doc_72_chunk_1",
        "original_index": 1,
        "content": "from typing import Tuple\nfrom pyflink.ml.wrapper import JavaWithParams\nfrom pyflink.ml.param import IntArrayParam, ParamValidator\nfrom pyflink.ml.feature.common import JavaFeatureTransformer\nfrom pyflink.ml.common.param import HasInputCol, HasOutputCol, Param\n\n\nclass _VectorSlicerParams(\n    JavaWithParams,\n    HasInputCol,\n    HasOutputCol\n):\n    \"\"\"\n      Checks the indices parameter.\n    \"\"\"\n\n    def indices_validator(self) -> ParamValidator[Tuple[int]]:\n        class IndicesValidator(ParamValidator[Tuple[int]]):\n            def validate(self, indices: Tuple[int]) -> bool:\n                for val in indices:\n                    if val < 0:\n                        return False\n                return True\n                indices_set = set(indices)\n                if len(indices_set) != len(indices):\n                    return False\n                return len(indices_set) != 0\n        return IndicesValidator()\n\n"
      },
      {
        "chunk_id": "doc_72_chunk_2",
        "original_index": 2,
        "content": "    \"\"\"\n    Params for :class:`VectorSlicer`.\n    \"\"\"\n\n    INDICES: Param[Tuple[int, ...]] = IntArrayParam(\n        \"indices\",\n        \"An array of indices to select features from a vector column.\",\n        None,\n        indices_validator(None))\n\n    def __init__(self, java_params):\n        super(_VectorSlicerParams, self).__init__(java_params)\n\n    def set_indices(self, *ind: int):\n        return self.set(self.INDICES, ind)\n\n    def get_indices(self) -> Tuple[int, ...]:\n        return self.get(self.INDICES)\n\n    @property\n    def indices(self) -> Tuple[int, ...]:\n        return self.get_indices()\n\n"
      },
      {
        "chunk_id": "doc_72_chunk_3",
        "original_index": 3,
        "content": "\nclass VectorSlicer(JavaFeatureTransformer, _VectorSlicerParams):\n    \"\"\"\n    A Transformer that transforms a vector to a new feature, which is a sub-array of\n    the original feature.It is useful for extracting features from a given vector.\n\n    Note that duplicate features are not allowed, so there can be no overlap between\n    selected indices. If the max value of the indices is greater than the size of\n    the input vector, it throws an IllegalArgumentException.\n    \"\"\"\n\n    def __init__(self, java_model=None):\n        super(VectorSlicer, self).__init__(java_model)\n\n    @classmethod\n    def _java_transformer_package_name(cls) -> str:\n        return \"vectorslicer\"\n\n    @classmethod\n    def _java_transformer_class_name(cls) -> str:\n        return \"VectorSlicer\"\n"
      }
    ]
  },
  {
    "doc_id": "doc_73",
    "original_uuid": "883cd05fef37ca96b99dcde818574a8d83e19acd38638df12532709f6d7183fd",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.flink.iteration.operator.allround;\n\nimport org.apache.flink.annotation.Internal;\n\nimport java.util.function.Supplier;\n\n/**\n * Operators or UDF implements this method would be provided with an supplier that provides the\n * current rounds of the current element.\n */\n@Internal\npublic interface EpochAware {\n\n    void setEpochSupplier(Supplier<Integer> epochSupplier);\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_73_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_73_chunk_1",
        "original_index": 1,
        "content": "package org.apache.flink.iteration.operator.allround;\n\nimport org.apache.flink.annotation.Internal;\n\nimport java.util.function.Supplier;\n\n/**\n * Operators or UDF implements this method would be provided with an supplier that provides the\n * current rounds of the current element.\n */\n@Internal\npublic interface EpochAware {\n\n    void setEpochSupplier(Supplier<Integer> epochSupplier);\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_74",
    "original_uuid": "8de4ca49de47a801aa268a6edb5afc9d1897e53a1a9772957719b5efe783cfc5",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.flink.ml.linalg;\n\nimport org.apache.flink.api.common.typeinfo.TypeInfo;\nimport org.apache.flink.ml.linalg.typeinfo.VectorWithNormTypeInfoFactory;\n\n/** A vector with its norm. */\n@TypeInfo(VectorWithNormTypeInfoFactory.class)\npublic class VectorWithNorm {\n    public final Vector vector;\n\n    public final double l2Norm;\n\n    public VectorWithNorm(Vector vector) {\n        this(vector, BLAS.norm2(vector));\n    }\n\n    public VectorWithNorm(Vector vector, double l2Norm) {\n        this.vector = vector;\n        this.l2Norm = l2Norm;\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_74_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_74_chunk_1",
        "original_index": 1,
        "content": "package org.apache.flink.ml.linalg;\n\nimport org.apache.flink.api.common.typeinfo.TypeInfo;\nimport org.apache.flink.ml.linalg.typeinfo.VectorWithNormTypeInfoFactory;\n\n/** A vector with its norm. */\n@TypeInfo(VectorWithNormTypeInfoFactory.class)\npublic class VectorWithNorm {\n    public final Vector vector;\n\n    public final double l2Norm;\n\n    public VectorWithNorm(Vector vector) {\n        this(vector, BLAS.norm2(vector));\n    }\n\n    public VectorWithNorm(Vector vector, double l2Norm) {\n        this.vector = vector;\n        this.l2Norm = l2Norm;\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_75",
    "original_uuid": "76ef0394d7b3d82a00d0fa83f34874957a0b215a66e3ceede34f013d0f607da3",
    "content": "################################################################################\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  \"License\"); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n# limitations under the License.\n################################################################################\nfrom typing import List\n\nfrom pyflink.common import Types\nfrom pyflink.ml.tests.test_utils import PyFlinkMLTestCase, update_existing_params\n\nfrom pyflink.ml.linalg import DenseVectorTypeInfo, Vectors\n\nfrom pyflink.ml.feature.univariatefeatureselector import UnivariateFeatureSelector, \\\n    UnivariateFeatureSelectorModel\nfrom pyflink.table import Table\n\n\nclass UnivariateFeatureSelectorTest(PyFlinkMLTestCase):\n\n    def setUp(self):\n        super(UnivariateFeatureSelectorTest, self).setUp()\n        self.input_table = self.t_env.from_data_stream(\n            self.env.from_collection([\n                (1, Vectors.dense(4.65415496e-03, 1.03550567e-01, -1.17358140e+00,\n                                  1.61408773e-01, 3.92492111e-01, 7.31240882e-01)),\n                (1, Vectors.dense(-9.01651741e-01, -5.28905302e-01, 1.27636785e+00,\n                                  7.02154563e-01, 6.21348351e-01, 1.88397353e-01)),\n                (1, Vectors.dense(3.85692159e-01, -9.04639637e-01, 5.09782604e-02,\n                                  8.40043971e-01, 7.45977857e-01, 8.78402288e-01)),\n                (1, Vectors.dense(1.36264353e+00, 2.62454094e-01, 7.96306202e-01,\n                                  6.14948000e-01, 7.44948187e-01, 9.74034830e-01)),\n                (1, Vectors.dense(9.65874070e-01, 2.52773665e+00, -2.19380094e+00,\n                                  2.33408080e-01, 1.86340919e-01, 8.23390433e-01)),\n                (2, Vectors.dense(1.12324305e+01, -2.77121515e-01, 1.12740513e-01,\n                                  2.35184013e-01, 3.46668895e-01, 9.38500782e-02)),\n                (2, Vectors.dense(1.06195839e+01, -1.82891238e+00, 2.25085601e-01,\n                                  9.09979851e-01, 6.80257535e-02, 8.24017480e-01)),\n                (2, Vectors.dense(1.12806837e+01, 1.30686889e+00, 9.32839108e-02,\n                                  3.49784755e-01, 1.71322408e-02, 7.48465194e-02)),\n                (2, Vectors.dense(9.98689462e+00, 9.50808938e-01, -2.90786359e-01,\n                                  2.31253009e-01, 7.46270968e-01, 1.60308169e-01)),\n                (2, Vectors.dense(1.08428551e+01, -1.02749936e+00, 1.73951508e-01,\n                                  8.92482744e-02, 1.42651730e-01, 7.66751625e-01)),\n                (3, Vectors.dense(-1.98641448e+00, 1.12811990e+01, -2.35246756e-01,\n                                  8.22809049e-01, 3.26739456e-01, 7.88268404e-01)),\n                (3, Vectors.dense(-6.09864090e-01, 1.07346276e+01, -2.18805509e-01,\n                                  7.33931213e-01, 1.42554396e-01, 7.11225605e-01)),\n                (3, Vectors.dense(-1.58481268e+00, 9.19364039e+00, -5.87490459e-02,\n                                  2.51532056e-01, 2.82729807e-01, 7.16245686e-01)),\n                (3, Vectors.dense(-2.50949277e-01, 1.12815254e+01, -6.94806734e-01,\n                                  5.93898886e-01, 5.68425656e-01, 8.49762330e-01)),\n                (3, Vectors.dense(7.63485129e-01, 1.02605138e+01, 1.32617719e+00,\n                                  5.49682879e-01, 8.59931442e-01, 4.88677978e-02)),\n                (4, Vectors.dense(9.34900015e-01, 4.11379043e-01, 8.65010205e+00,\n                                  9.23509168e-01, 1.16995043e-01, 5.91894106e-03)),\n                (4, Vectors.dense(4.73734933e-01, -1.48321181e+00, 9.73349621e+00,\n                                  4.09421563e-01, 5.09375719e-01, 5.93157850e-01)),\n                (4, Vectors.dense(3.41470679e-01, -6.88972582e-01, 9.60347938e+00,\n                                  3.62654055e-01, 2.43437468e-01, 7.13052838e-01)),\n                (4, Vectors.dense(-5.29614251e-01, -1.39262856e+00, 1.01354144e+01,\n                                  8.24123861e-01, 5.84074506e-01, 6.54461558e-01)),\n                (4, Vectors.dense(-2.99454508e-01, 2.20457263e+00, 1.14586015e+01,\n                                  5.16336729e-01, 9.99776159e-01, 3.15769738e-01)),\n            ],\n                type_info=Types.ROW_NAMED(\n                    ['label', 'features'],\n                    [Types.INT(), DenseVectorTypeInfo()])\n            ))\n\n    def test_param(self):\n        univariate_feature_selector = UnivariateFeatureSelector()\n        self.assertEqual('features', univariate_feature_selector.features_col)\n        self.assertEqual('label', univariate_feature_selector.label_col)\n        self.assertEqual('output', univariate_feature_selector.output_col)\n        with self.assertRaises(Exception) as context:\n            univariate_feature_selector.feature_type\n            self.assertTrue(\"Parameter featureType's value should not be null\" in context.exception)\n        with self.assertRaises(Exception) as context:\n            univariate_feature_selector.label_type\n            self.assertTrue(\"Parameter labelType's value should not be null\" in context.exception)\n        self.assertEqual('numTopFeatures', univariate_feature_selector.selection_mode)\n        self.assertIsNone(univariate_feature_selector.selection_threshold)\n\n        univariate_feature_selector\\\n            .set_features_col(\"test_features\")\\\n            .set_label_col('test_label')\\\n            .set_output_col('test_output')\\\n            .set_feature_type('continuous')\\\n            .set_label_type('categorical')\\\n            .set_selection_mode('fpr')\\\n            .set_selection_threshold(0.01)\n        self.assertEqual('test_features', univariate_feature_selector.features_col)\n        self.assertEqual('test_label', univariate_feature_selector.label_col)\n        self.assertEqual('test_output', univariate_feature_selector.output_col)\n        self.assertEqual('continuous', univariate_feature_selector.feature_type)\n        self.assertEqual('categorical', univariate_feature_selector.label_type)\n        self.assertEqual('fpr', univariate_feature_selector.selection_mode)\n        self.assertEqual(0.01, univariate_feature_selector.selection_threshold)\n\n    def test_output_schema(self):\n        selector = UnivariateFeatureSelector()\\\n            .set_features_col(\"test_features\")\\\n            .set_label_col('test_label')\\\n            .set_output_col('test_output')\\\n            .set_feature_type('continuous')\\\n            .set_label_type('categorical')\n        temp_table = self.input_table.alias('test_label', 'test_features')\n        model = selector.fit(temp_table)\n        output = model.transform(temp_table)[0]\n        self.assertEqual(\n            ['test_label', 'test_features', 'test_output'],\n            output.get_schema().get_field_names())\n\n    def test_fit_and_predict(self):\n        selector = UnivariateFeatureSelector() \\\n            .set_feature_type('continuous') \\\n            .set_label_type('categorical') \\\n            .set_selection_threshold(3)\n        model = selector.fit(self.input_table)\n        output = model.transform(self.input_table)[0]\n        self.verify_output_result(\n            output,\n            output.get_schema().get_field_names(),\n            selector.get_features_col(),\n            selector.get_output_col(),\n            [0, 1, 2])\n\n    def test_get_model_data(self):\n        selector = UnivariateFeatureSelector() \\\n            .set_feature_type('continuous') \\\n            .set_label_type('categorical') \\\n            .set_selection_threshold(3)\n        model = selector.fit(self.input_table)\n        model_data = model.get_model_data()[0]\n        self.assertEqual(['indices'], model_data.get_schema().get_field_names())\n\n        model_rows = [result for result in\n                      self.t_env.to_data_stream(model_data).execute_and_collect()]\n        self.assertEqual(1, len(model_rows))\n        self.assertListEqual([0, 2, 1], model_rows[0][0])\n\n    def test_set_model_data(self):\n        selector = UnivariateFeatureSelector() \\\n            .set_feature_type('continuous') \\\n            .set_label_type('categorical') \\\n            .set_selection_threshold(3)\n        model_a = selector.fit(self.input_table)\n        model_data = model_a.get_model_data()[0]\n\n        model_b = UnivariateFeatureSelectorModel() \\\n            .set_model_data(model_data)\n        update_existing_params(model_b, model_a)\n\n        output = model_b.transform(self.input_table)[0]\n        self.verify_output_result(\n            output,\n            output.get_schema().get_field_names(),\n            selector.get_features_col(),\n            selector.get_output_col(),\n            [0, 1, 2])\n\n    def test_save_load_predict(self):\n        selector = UnivariateFeatureSelector() \\\n            .set_feature_type('continuous') \\\n            .set_label_type('categorical') \\\n            .set_selection_threshold(3)\n        reloaded_selector = self.save_and_reload(selector)\n        model = reloaded_selector.fit(self.input_table)\n        reloaded_model = self.save_and_reload(model)\n        output = reloaded_model.transform(self.input_table)[0]\n        self.verify_output_result(\n            output,\n            output.get_schema().get_field_names(),\n            selector.get_features_col(),\n            selector.get_output_col(),\n            [0, 1, 2])\n\n    def verify_output_result(\n            self, output: Table,\n            field_names: List[str],\n            feature_col: str,\n            output_col: str,\n            indices: List[int]):\n        collected_results = [result for result in\n                             self.t_env.to_data_stream(output).execute_and_collect()]\n        for item in collected_results:\n            item.set_field_names(field_names)\n            self.assertEqual(len(indices), item[output_col].size())\n            for i in range(0, len(indices)):\n                self.assertEqual(item[feature_col].get(indices[i]),\n                                 item[output_col].get(i))\n",
    "chunks": [
      {
        "chunk_id": "doc_75_chunk_0",
        "original_index": 0,
        "content": "################################################################################\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  \"License\"); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n# limitations under the License.\n################################################################################\nfrom typing import List\n\n"
      },
      {
        "chunk_id": "doc_75_chunk_1",
        "original_index": 1,
        "content": "from pyflink.common import Types\nfrom pyflink.ml.tests.test_utils import PyFlinkMLTestCase, update_existing_params\n\nfrom pyflink.ml.linalg import DenseVectorTypeInfo, Vectors\n\nfrom pyflink.ml.feature.univariatefeatureselector import UnivariateFeatureSelector, \\\n    UnivariateFeatureSelectorModel\nfrom pyflink.table import Table\n\n\nclass UnivariateFeatureSelectorTest(PyFlinkMLTestCase):\n\n    def setUp(self):\n        super(UnivariateFeatureSelectorTest, self).setUp()\n        self.input_table = self.t_env.from_data_stream(\n            self.env.from_collection([\n                (1, Vectors.dense(4.65415496e-03, 1.03550567e-01, -1.17358140e+00,\n                                  1.61408773e-01, 3.92492111e-01, 7.31240882e-01)),\n                (1, Vectors.dense(-9.01651741e-01, -5.28905302e-01, 1.27636785e+00,\n                                  7.02154563e-01, 6.21348351e-01, 1.88397353e-01)),\n"
      },
      {
        "chunk_id": "doc_75_chunk_2",
        "original_index": 2,
        "content": "                (1, Vectors.dense(3.85692159e-01, -9.04639637e-01, 5.09782604e-02,\n                                  8.40043971e-01, 7.45977857e-01, 8.78402288e-01)),\n                (1, Vectors.dense(1.36264353e+00, 2.62454094e-01, 7.96306202e-01,\n                                  6.14948000e-01, 7.44948187e-01, 9.74034830e-01)),\n                (1, Vectors.dense(9.65874070e-01, 2.52773665e+00, -2.19380094e+00,\n                                  2.33408080e-01, 1.86340919e-01, 8.23390433e-01)),\n"
      },
      {
        "chunk_id": "doc_75_chunk_3",
        "original_index": 3,
        "content": "                (2, Vectors.dense(1.12324305e+01, -2.77121515e-01, 1.12740513e-01,\n                                  2.35184013e-01, 3.46668895e-01, 9.38500782e-02)),\n                (2, Vectors.dense(1.06195839e+01, -1.82891238e+00, 2.25085601e-01,\n                                  9.09979851e-01, 6.80257535e-02, 8.24017480e-01)),\n                (2, Vectors.dense(1.12806837e+01, 1.30686889e+00, 9.32839108e-02,\n                                  3.49784755e-01, 1.71322408e-02, 7.48465194e-02)),\n                (2, Vectors.dense(9.98689462e+00, 9.50808938e-01, -2.90786359e-01,\n                                  2.31253009e-01, 7.46270968e-01, 1.60308169e-01)),\n"
      },
      {
        "chunk_id": "doc_75_chunk_4",
        "original_index": 4,
        "content": "                (2, Vectors.dense(1.08428551e+01, -1.02749936e+00, 1.73951508e-01,\n                                  8.92482744e-02, 1.42651730e-01, 7.66751625e-01)),\n                (3, Vectors.dense(-1.98641448e+00, 1.12811990e+01, -2.35246756e-01,\n                                  8.22809049e-01, 3.26739456e-01, 7.88268404e-01)),\n                (3, Vectors.dense(-6.09864090e-01, 1.07346276e+01, -2.18805509e-01,\n                                  7.33931213e-01, 1.42554396e-01, 7.11225605e-01)),\n                (3, Vectors.dense(-1.58481268e+00, 9.19364039e+00, -5.87490459e-02,\n                                  2.51532056e-01, 2.82729807e-01, 7.16245686e-01)),\n"
      },
      {
        "chunk_id": "doc_75_chunk_5",
        "original_index": 5,
        "content": "                (3, Vectors.dense(-2.50949277e-01, 1.12815254e+01, -6.94806734e-01,\n                                  5.93898886e-01, 5.68425656e-01, 8.49762330e-01)),\n                (3, Vectors.dense(7.63485129e-01, 1.02605138e+01, 1.32617719e+00,\n                                  5.49682879e-01, 8.59931442e-01, 4.88677978e-02)),\n                (4, Vectors.dense(9.34900015e-01, 4.11379043e-01, 8.65010205e+00,\n                                  9.23509168e-01, 1.16995043e-01, 5.91894106e-03)),\n                (4, Vectors.dense(4.73734933e-01, -1.48321181e+00, 9.73349621e+00,\n                                  4.09421563e-01, 5.09375719e-01, 5.93157850e-01)),\n                (4, Vectors.dense(3.41470679e-01, -6.88972582e-01, 9.60347938e+00,\n                                  3.62654055e-01, 2.43437468e-01, 7.13052838e-01)),\n"
      },
      {
        "chunk_id": "doc_75_chunk_6",
        "original_index": 6,
        "content": "                (4, Vectors.dense(-5.29614251e-01, -1.39262856e+00, 1.01354144e+01,\n                                  8.24123861e-01, 5.84074506e-01, 6.54461558e-01)),\n                (4, Vectors.dense(-2.99454508e-01, 2.20457263e+00, 1.14586015e+01,\n                                  5.16336729e-01, 9.99776159e-01, 3.15769738e-01)),\n            ],\n                type_info=Types.ROW_NAMED(\n                    ['label', 'features'],\n                    [Types.INT(), DenseVectorTypeInfo()])\n            ))\n\n"
      },
      {
        "chunk_id": "doc_75_chunk_7",
        "original_index": 7,
        "content": "    def test_param(self):\n        univariate_feature_selector = UnivariateFeatureSelector()\n        self.assertEqual('features', univariate_feature_selector.features_col)\n        self.assertEqual('label', univariate_feature_selector.label_col)\n        self.assertEqual('output', univariate_feature_selector.output_col)\n        with self.assertRaises(Exception) as context:\n            univariate_feature_selector.feature_type\n            self.assertTrue(\"Parameter featureType's value should not be null\" in context.exception)\n        with self.assertRaises(Exception) as context:\n            univariate_feature_selector.label_type\n            self.assertTrue(\"Parameter labelType's value should not be null\" in context.exception)\n        self.assertEqual('numTopFeatures', univariate_feature_selector.selection_mode)\n        self.assertIsNone(univariate_feature_selector.selection_threshold)\n\n"
      },
      {
        "chunk_id": "doc_75_chunk_8",
        "original_index": 8,
        "content": "        univariate_feature_selector\\\n            .set_features_col(\"test_features\")\\\n            .set_label_col('test_label')\\\n            .set_output_col('test_output')\\\n            .set_feature_type('continuous')\\\n            .set_label_type('categorical')\\\n            .set_selection_mode('fpr')\\\n            .set_selection_threshold(0.01)\n        self.assertEqual('test_features', univariate_feature_selector.features_col)\n        self.assertEqual('test_label', univariate_feature_selector.label_col)\n        self.assertEqual('test_output', univariate_feature_selector.output_col)\n        self.assertEqual('continuous', univariate_feature_selector.feature_type)\n        self.assertEqual('categorical', univariate_feature_selector.label_type)\n        self.assertEqual('fpr', univariate_feature_selector.selection_mode)\n        self.assertEqual(0.01, univariate_feature_selector.selection_threshold)\n\n"
      },
      {
        "chunk_id": "doc_75_chunk_9",
        "original_index": 9,
        "content": "    def test_output_schema(self):\n        selector = UnivariateFeatureSelector()\\\n            .set_features_col(\"test_features\")\\\n            .set_label_col('test_label')\\\n            .set_output_col('test_output')\\\n            .set_feature_type('continuous')\\\n            .set_label_type('categorical')\n        temp_table = self.input_table.alias('test_label', 'test_features')\n        model = selector.fit(temp_table)\n        output = model.transform(temp_table)[0]\n        self.assertEqual(\n            ['test_label', 'test_features', 'test_output'],\n            output.get_schema().get_field_names())\n\n"
      },
      {
        "chunk_id": "doc_75_chunk_10",
        "original_index": 10,
        "content": "    def test_fit_and_predict(self):\n        selector = UnivariateFeatureSelector() \\\n            .set_feature_type('continuous') \\\n            .set_label_type('categorical') \\\n            .set_selection_threshold(3)\n        model = selector.fit(self.input_table)\n        output = model.transform(self.input_table)[0]\n        self.verify_output_result(\n            output,\n            output.get_schema().get_field_names(),\n            selector.get_features_col(),\n            selector.get_output_col(),\n            [0, 1, 2])\n\n    def test_get_model_data(self):\n        selector = UnivariateFeatureSelector() \\\n            .set_feature_type('continuous') \\\n            .set_label_type('categorical') \\\n            .set_selection_threshold(3)\n        model = selector.fit(self.input_table)\n        model_data = model.get_model_data()[0]\n        self.assertEqual(['indices'], model_data.get_schema().get_field_names())\n\n"
      },
      {
        "chunk_id": "doc_75_chunk_11",
        "original_index": 11,
        "content": "        model_rows = [result for result in\n                      self.t_env.to_data_stream(model_data).execute_and_collect()]\n        self.assertEqual(1, len(model_rows))\n        self.assertListEqual([0, 2, 1], model_rows[0][0])\n\n    def test_set_model_data(self):\n        selector = UnivariateFeatureSelector() \\\n            .set_feature_type('continuous') \\\n            .set_label_type('categorical') \\\n            .set_selection_threshold(3)\n        model_a = selector.fit(self.input_table)\n        model_data = model_a.get_model_data()[0]\n\n        model_b = UnivariateFeatureSelectorModel() \\\n            .set_model_data(model_data)\n        update_existing_params(model_b, model_a)\n\n        output = model_b.transform(self.input_table)[0]\n        self.verify_output_result(\n            output,\n            output.get_schema().get_field_names(),\n            selector.get_features_col(),\n            selector.get_output_col(),\n            [0, 1, 2])\n\n"
      },
      {
        "chunk_id": "doc_75_chunk_12",
        "original_index": 12,
        "content": "    def test_save_load_predict(self):\n        selector = UnivariateFeatureSelector() \\\n            .set_feature_type('continuous') \\\n            .set_label_type('categorical') \\\n            .set_selection_threshold(3)\n        reloaded_selector = self.save_and_reload(selector)\n        model = reloaded_selector.fit(self.input_table)\n        reloaded_model = self.save_and_reload(model)\n        output = reloaded_model.transform(self.input_table)[0]\n        self.verify_output_result(\n            output,\n            output.get_schema().get_field_names(),\n            selector.get_features_col(),\n            selector.get_output_col(),\n            [0, 1, 2])\n\n"
      },
      {
        "chunk_id": "doc_75_chunk_13",
        "original_index": 13,
        "content": "    def verify_output_result(\n            self, output: Table,\n            field_names: List[str],\n            feature_col: str,\n            output_col: str,\n            indices: List[int]):\n        collected_results = [result for result in\n                             self.t_env.to_data_stream(output).execute_and_collect()]\n        for item in collected_results:\n            item.set_field_names(field_names)\n            self.assertEqual(len(indices), item[output_col].size())\n            for i in range(0, len(indices)):\n                self.assertEqual(item[feature_col].get(indices[i]),\n                                 item[output_col].get(i))\n"
      }
    ]
  },
  {
    "doc_id": "doc_76",
    "original_uuid": "05d6124b529ce8a984aa95f59f61ccb660082f18e91562e90a60221421a2fba7",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.flink.ml.regression;\n\nimport org.apache.flink.api.common.typeinfo.TypeInformation;\nimport org.apache.flink.api.common.typeinfo.Types;\nimport org.apache.flink.api.java.typeutils.RowTypeInfo;\nimport org.apache.flink.ml.linalg.SparseVector;\nimport org.apache.flink.ml.linalg.Vectors;\nimport org.apache.flink.ml.linalg.typeinfo.DenseVectorTypeInfo;\nimport org.apache.flink.ml.regression.linearregression.LinearRegression;\nimport org.apache.flink.ml.regression.linearregression.LinearRegressionModel;\nimport org.apache.flink.ml.regression.linearregression.LinearRegressionModelData;\nimport org.apache.flink.ml.util.ParamUtils;\nimport org.apache.flink.ml.util.TestUtils;\nimport org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\nimport org.apache.flink.table.api.Table;\nimport org.apache.flink.table.api.bridge.java.StreamTableEnvironment;\nimport org.apache.flink.test.util.AbstractTestBase;\nimport org.apache.flink.types.Row;\n\nimport org.apache.commons.collections.IteratorUtils;\nimport org.apache.commons.lang3.RandomUtils;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.TemporaryFolder;\n\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.List;\n\nimport static org.junit.Assert.assertArrayEquals;\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertNotNull;\nimport static org.junit.Assert.assertNull;\nimport static org.junit.Assert.assertTrue;\n\n/** Tests {@link LinearRegression} and {@link LinearRegressionModel}. */\npublic class LinearRegressionTest extends AbstractTestBase {\n\n    @Rule public final TemporaryFolder tempFolder = new TemporaryFolder();\n\n    private StreamExecutionEnvironment env;\n\n    private StreamTableEnvironment tEnv;\n\n    private static final List<Row> trainData =\n            Arrays.asList(\n                    Row.of(Vectors.dense(2, 1), 4.0, 1.0),\n                    Row.of(Vectors.dense(3, 2), 7.0, 1.0),\n                    Row.of(Vectors.dense(4, 3), 10.0, 1.0),\n                    Row.of(Vectors.dense(2, 4), 10.0, 1.0),\n                    Row.of(Vectors.dense(2, 2), 6.0, 1.0),\n                    Row.of(Vectors.dense(4, 3), 10.0, 1.0),\n                    Row.of(Vectors.dense(1, 2), 5.0, 1.0),\n                    Row.of(Vectors.dense(5, 3), 11.0, 1.0));\n\n    private static final double[] expectedCoefficient = new double[] {1.141, 1.829};\n\n    private static final double TOLERANCE = 1e-7;\n\n    private static final double PREDICTION_TOLERANCE = 0.1;\n\n    private static final double COEFFICIENT_TOLERANCE = 0.1;\n\n    private Table trainDataTable;\n\n    @Before\n    public void before() {\n        env = TestUtils.getExecutionEnvironment();\n        tEnv = StreamTableEnvironment.create(env);\n        Collections.shuffle(trainData);\n        trainDataTable =\n                tEnv.fromDataStream(\n                        env.fromCollection(\n                                trainData,\n                                new RowTypeInfo(\n                                        new TypeInformation[] {\n                                            DenseVectorTypeInfo.INSTANCE, Types.DOUBLE, Types.DOUBLE\n                                        },\n                                        new String[] {\"features\", \"label\", \"weight\"})));\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    private void verifyPredictionResult(Table output, String labelCol, String predictionCol)\n            throws Exception {\n        List<Row> predResult = IteratorUtils.toList(tEnv.toDataStream(output).executeAndCollect());\n        for (Row predictionRow : predResult) {\n            double label = ((Number) predictionRow.getField(labelCol)).doubleValue();\n            double prediction = (double) predictionRow.getField(predictionCol);\n            assertTrue(Math.abs(prediction - label) / label < PREDICTION_TOLERANCE);\n        }\n    }\n\n    @Test\n    public void testParam() {\n        LinearRegression linearRegression = new LinearRegression();\n        assertEquals(\"features\", linearRegression.getFeaturesCol());\n        assertEquals(\"label\", linearRegression.getLabelCol());\n        assertNull(linearRegression.getWeightCol());\n        assertEquals(20, linearRegression.getMaxIter());\n        assertEquals(1e-6, linearRegression.getTol(), TOLERANCE);\n        assertEquals(0.1, linearRegression.getLearningRate(), TOLERANCE);\n        assertEquals(32, linearRegression.getGlobalBatchSize());\n        assertEquals(0, linearRegression.getReg(), TOLERANCE);\n        assertEquals(0, linearRegression.getElasticNet(), TOLERANCE);\n        assertEquals(\"prediction\", linearRegression.getPredictionCol());\n\n        linearRegression\n                .setFeaturesCol(\"test_features\")\n                .setLabelCol(\"test_label\")\n                .setWeightCol(\"test_weight\")\n                .setMaxIter(1000)\n                .setTol(0.001)\n                .setLearningRate(0.5)\n                .setGlobalBatchSize(1000)\n                .setReg(0.1)\n                .setElasticNet(0.5)\n                .setPredictionCol(\"test_predictionCol\");\n        assertEquals(\"test_features\", linearRegression.getFeaturesCol());\n        assertEquals(\"test_label\", linearRegression.getLabelCol());\n        assertEquals(\"test_weight\", linearRegression.getWeightCol());\n        assertEquals(1000, linearRegression.getMaxIter());\n        assertEquals(0.001, linearRegression.getTol(), TOLERANCE);\n        assertEquals(0.5, linearRegression.getLearningRate(), TOLERANCE);\n        assertEquals(1000, linearRegression.getGlobalBatchSize());\n        assertEquals(0.1, linearRegression.getReg(), TOLERANCE);\n        assertEquals(0.5, linearRegression.getElasticNet(), TOLERANCE);\n        assertEquals(\"test_predictionCol\", linearRegression.getPredictionCol());\n    }\n\n    @Test\n    public void testOutputSchema() {\n        Table tempTable = trainDataTable.as(\"test_features\", \"test_label\", \"test_weight\");\n        LinearRegression linearRegression =\n                new LinearRegression()\n                        .setFeaturesCol(\"test_features\")\n                        .setLabelCol(\"test_label\")\n                        .setWeightCol(\"test_weight\")\n                        .setPredictionCol(\"test_predictionCol\");\n        Table output = linearRegression.fit(trainDataTable).transform(tempTable)[0];\n        assertEquals(\n                Arrays.asList(\"test_features\", \"test_label\", \"test_weight\", \"test_predictionCol\"),\n                output.getResolvedSchema().getColumnNames());\n    }\n\n    @Test\n    public void testFitAndPredict() throws Exception {\n        LinearRegression linearRegression = new LinearRegression().setWeightCol(\"weight\");\n        Table output = linearRegression.fit(trainDataTable).transform(trainDataTable)[0];\n        verifyPredictionResult(\n                output, linearRegression.getLabelCol(), linearRegression.getPredictionCol());\n    }\n\n    @Test\n    public void testInputTypeConversion() throws Exception {\n        trainDataTable = TestUtils.convertDataTypesToSparseInt(tEnv, trainDataTable);\n        assertArrayEquals(\n                new Class<?>[] {SparseVector.class, Integer.class, Integer.class},\n                TestUtils.getColumnDataTypes(trainDataTable));\n\n        LinearRegression linearRegression = new LinearRegression().setWeightCol(\"weight\");\n        Table output = linearRegression.fit(trainDataTable).transform(trainDataTable)[0];\n        verifyPredictionResult(\n                output, linearRegression.getLabelCol(), linearRegression.getPredictionCol());\n    }\n\n    @Test\n    public void testSaveLoadAndPredict() throws Exception {\n        LinearRegression linearRegression = new LinearRegression().setWeightCol(\"weight\");\n        linearRegression =\n                TestUtils.saveAndReload(\n                        tEnv,\n                        linearRegression,\n                        tempFolder.newFolder().getAbsolutePath(),\n                        LinearRegression::load);\n        LinearRegressionModel model = linearRegression.fit(trainDataTable);\n        model =\n                TestUtils.saveAndReload(\n                        tEnv,\n                        model,\n                        tempFolder.newFolder().getAbsolutePath(),\n                        LinearRegressionModel::load);\n        assertEquals(\n                Collections.singletonList(\"coefficient\"),\n                model.getModelData()[0].getResolvedSchema().getColumnNames());\n        Table output = model.transform(trainDataTable)[0];\n        verifyPredictionResult(\n                output, linearRegression.getLabelCol(), linearRegression.getPredictionCol());\n    }\n\n    @Test\n    public void testGetModelData() throws Exception {\n        LinearRegression linearRegression = new LinearRegression().setWeightCol(\"weight\");\n        LinearRegressionModel model = linearRegression.fit(trainDataTable);\n        List<LinearRegressionModelData> modelData =\n                IteratorUtils.toList(\n                        LinearRegressionModelData.getModelDataStream(model.getModelData()[0])\n                                .executeAndCollect());\n        assertNotNull(modelData);\n        assertEquals(1, modelData.size());\n        assertArrayEquals(\n                expectedCoefficient, modelData.get(0).coefficient.values, COEFFICIENT_TOLERANCE);\n    }\n\n    @Test\n    public void testSetModelData() throws Exception {\n        LinearRegression linearRegression = new LinearRegression().setWeightCol(\"weight\");\n        LinearRegressionModel model = linearRegression.fit(trainDataTable);\n\n        LinearRegressionModel newModel = new LinearRegressionModel();\n        ParamUtils.updateExistingParams(newModel, model.getParamMap());\n        newModel.setModelData(model.getModelData());\n        Table output = newModel.transform(trainDataTable)[0];\n        verifyPredictionResult(\n                output, linearRegression.getLabelCol(), linearRegression.getPredictionCol());\n    }\n\n    @Test\n    public void testMoreSubtaskThanData() throws Exception {\n        List<Row> trainData =\n                Arrays.asList(\n                        Row.of(Vectors.dense(2, 1), 4.0, 1.0),\n                        Row.of(Vectors.dense(3, 2), 7.0, 1.0));\n\n        Table trainDataTable =\n                tEnv.fromDataStream(\n                        env.fromCollection(\n                                trainData,\n                                new RowTypeInfo(\n                                        new TypeInformation[] {\n                                            DenseVectorTypeInfo.INSTANCE, Types.DOUBLE, Types.DOUBLE\n                                        },\n                                        new String[] {\"features\", \"label\", \"weight\"})));\n\n        LinearRegression linearRegression =\n                new LinearRegression().setWeightCol(\"weight\").setGlobalBatchSize(128);\n        Table output = linearRegression.fit(trainDataTable).transform(trainDataTable)[0];\n        verifyPredictionResult(\n                output, linearRegression.getLabelCol(), linearRegression.getPredictionCol());\n    }\n\n    @Test\n    public void testRegularization() throws Exception {\n        checkRegularization(0, RandomUtils.nextDouble(0, 1), expectedCoefficient);\n        checkRegularization(0.1, 0, new double[] {1.165, 1.780});\n        checkRegularization(0.1, 1, new double[] {1.143, 1.812});\n        checkRegularization(0.1, 0.5, new double[] {1.154, 1.796});\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    private void checkRegularization(double reg, double elasticNet, double[] expectedCoefficient)\n            throws Exception {\n        LinearRegressionModel model =\n                new LinearRegression()\n                        .setWeightCol(\"weight\")\n                        .setReg(reg)\n                        .setElasticNet(elasticNet)\n                        .fit(trainDataTable);\n        List<LinearRegressionModelData> modelData =\n                IteratorUtils.toList(\n                        LinearRegressionModelData.getModelDataStream(model.getModelData()[0])\n                                .executeAndCollect());\n        final double errorTol = 1e-3;\n        assertArrayEquals(expectedCoefficient, modelData.get(0).coefficient.values, errorTol);\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_76_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.flink.ml.regression;\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_1",
        "original_index": 1,
        "content": "import org.apache.flink.api.common.typeinfo.TypeInformation;\nimport org.apache.flink.api.common.typeinfo.Types;\nimport org.apache.flink.api.java.typeutils.RowTypeInfo;\nimport org.apache.flink.ml.linalg.SparseVector;\nimport org.apache.flink.ml.linalg.Vectors;\nimport org.apache.flink.ml.linalg.typeinfo.DenseVectorTypeInfo;\nimport org.apache.flink.ml.regression.linearregression.LinearRegression;\nimport org.apache.flink.ml.regression.linearregression.LinearRegressionModel;\nimport org.apache.flink.ml.regression.linearregression.LinearRegressionModelData;\nimport org.apache.flink.ml.util.ParamUtils;\nimport org.apache.flink.ml.util.TestUtils;\nimport org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\nimport org.apache.flink.table.api.Table;\nimport org.apache.flink.table.api.bridge.java.StreamTableEnvironment;\nimport org.apache.flink.test.util.AbstractTestBase;\nimport org.apache.flink.types.Row;\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_2",
        "original_index": 2,
        "content": "import org.apache.commons.collections.IteratorUtils;\nimport org.apache.commons.lang3.RandomUtils;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.TemporaryFolder;\n\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.List;\n\nimport static org.junit.Assert.assertArrayEquals;\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertNotNull;\nimport static org.junit.Assert.assertNull;\nimport static org.junit.Assert.assertTrue;\n\n/** Tests {@link LinearRegression} and {@link LinearRegressionModel}. */\npublic class LinearRegressionTest extends AbstractTestBase {\n\n    @Rule public final TemporaryFolder tempFolder = new TemporaryFolder();\n\n    private StreamExecutionEnvironment env;\n\n    private StreamTableEnvironment tEnv;\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_3",
        "original_index": 3,
        "content": "    private static final List<Row> trainData =\n            Arrays.asList(\n                    Row.of(Vectors.dense(2, 1), 4.0, 1.0),\n                    Row.of(Vectors.dense(3, 2), 7.0, 1.0),\n                    Row.of(Vectors.dense(4, 3), 10.0, 1.0),\n                    Row.of(Vectors.dense(2, 4), 10.0, 1.0),\n                    Row.of(Vectors.dense(2, 2), 6.0, 1.0),\n                    Row.of(Vectors.dense(4, 3), 10.0, 1.0),\n                    Row.of(Vectors.dense(1, 2), 5.0, 1.0),\n                    Row.of(Vectors.dense(5, 3), 11.0, 1.0));\n\n    private static final double[] expectedCoefficient = new double[] {1.141, 1.829};\n\n    private static final double TOLERANCE = 1e-7;\n\n    private static final double PREDICTION_TOLERANCE = 0.1;\n\n    private static final double COEFFICIENT_TOLERANCE = 0.1;\n\n    private Table trainDataTable;\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_4",
        "original_index": 4,
        "content": "    @Before\n    public void before() {\n        env = TestUtils.getExecutionEnvironment();\n        tEnv = StreamTableEnvironment.create(env);\n        Collections.shuffle(trainData);\n        trainDataTable =\n                tEnv.fromDataStream(\n                        env.fromCollection(\n                                trainData,\n                                new RowTypeInfo(\n                                        new TypeInformation[] {\n                                            DenseVectorTypeInfo.INSTANCE, Types.DOUBLE, Types.DOUBLE\n                                        },\n                                        new String[] {\"features\", \"label\", \"weight\"})));\n    }\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_5",
        "original_index": 5,
        "content": "    @SuppressWarnings(\"unchecked\")\n    private void verifyPredictionResult(Table output, String labelCol, String predictionCol)\n            throws Exception {\n        List<Row> predResult = IteratorUtils.toList(tEnv.toDataStream(output).executeAndCollect());\n        for (Row predictionRow : predResult) {\n            double label = ((Number) predictionRow.getField(labelCol)).doubleValue();\n            double prediction = (double) predictionRow.getField(predictionCol);\n            assertTrue(Math.abs(prediction - label) / label < PREDICTION_TOLERANCE);\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_6",
        "original_index": 6,
        "content": "    @Test\n    public void testParam() {\n        LinearRegression linearRegression = new LinearRegression();\n        assertEquals(\"features\", linearRegression.getFeaturesCol());\n        assertEquals(\"label\", linearRegression.getLabelCol());\n        assertNull(linearRegression.getWeightCol());\n        assertEquals(20, linearRegression.getMaxIter());\n        assertEquals(1e-6, linearRegression.getTol(), TOLERANCE);\n        assertEquals(0.1, linearRegression.getLearningRate(), TOLERANCE);\n        assertEquals(32, linearRegression.getGlobalBatchSize());\n        assertEquals(0, linearRegression.getReg(), TOLERANCE);\n        assertEquals(0, linearRegression.getElasticNet(), TOLERANCE);\n        assertEquals(\"prediction\", linearRegression.getPredictionCol());\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_7",
        "original_index": 7,
        "content": "        linearRegression\n                .setFeaturesCol(\"test_features\")\n                .setLabelCol(\"test_label\")\n                .setWeightCol(\"test_weight\")\n                .setMaxIter(1000)\n                .setTol(0.001)\n                .setLearningRate(0.5)\n                .setGlobalBatchSize(1000)\n                .setReg(0.1)\n                .setElasticNet(0.5)\n                .setPredictionCol(\"test_predictionCol\");\n        assertEquals(\"test_features\", linearRegression.getFeaturesCol());\n        assertEquals(\"test_label\", linearRegression.getLabelCol());\n        assertEquals(\"test_weight\", linearRegression.getWeightCol());\n"
      },
      {
        "chunk_id": "doc_76_chunk_8",
        "original_index": 8,
        "content": "        assertEquals(1000, linearRegression.getMaxIter());\n        assertEquals(0.001, linearRegression.getTol(), TOLERANCE);\n        assertEquals(0.5, linearRegression.getLearningRate(), TOLERANCE);\n        assertEquals(1000, linearRegression.getGlobalBatchSize());\n        assertEquals(0.1, linearRegression.getReg(), TOLERANCE);\n        assertEquals(0.5, linearRegression.getElasticNet(), TOLERANCE);\n        assertEquals(\"test_predictionCol\", linearRegression.getPredictionCol());\n    }\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_9",
        "original_index": 9,
        "content": "    @Test\n    public void testOutputSchema() {\n        Table tempTable = trainDataTable.as(\"test_features\", \"test_label\", \"test_weight\");\n        LinearRegression linearRegression =\n                new LinearRegression()\n                        .setFeaturesCol(\"test_features\")\n                        .setLabelCol(\"test_label\")\n                        .setWeightCol(\"test_weight\")\n                        .setPredictionCol(\"test_predictionCol\");\n        Table output = linearRegression.fit(trainDataTable).transform(tempTable)[0];\n        assertEquals(\n                Arrays.asList(\"test_features\", \"test_label\", \"test_weight\", \"test_predictionCol\"),\n                output.getResolvedSchema().getColumnNames());\n    }\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_10",
        "original_index": 10,
        "content": "    @Test\n    public void testFitAndPredict() throws Exception {\n        LinearRegression linearRegression = new LinearRegression().setWeightCol(\"weight\");\n        Table output = linearRegression.fit(trainDataTable).transform(trainDataTable)[0];\n        verifyPredictionResult(\n                output, linearRegression.getLabelCol(), linearRegression.getPredictionCol());\n    }\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_11",
        "original_index": 11,
        "content": "    @Test\n    public void testInputTypeConversion() throws Exception {\n        trainDataTable = TestUtils.convertDataTypesToSparseInt(tEnv, trainDataTable);\n        assertArrayEquals(\n                new Class<?>[] {SparseVector.class, Integer.class, Integer.class},\n                TestUtils.getColumnDataTypes(trainDataTable));\n\n        LinearRegression linearRegression = new LinearRegression().setWeightCol(\"weight\");\n        Table output = linearRegression.fit(trainDataTable).transform(trainDataTable)[0];\n        verifyPredictionResult(\n                output, linearRegression.getLabelCol(), linearRegression.getPredictionCol());\n    }\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_12",
        "original_index": 12,
        "content": "    @Test\n    public void testSaveLoadAndPredict() throws Exception {\n        LinearRegression linearRegression = new LinearRegression().setWeightCol(\"weight\");\n        linearRegression =\n                TestUtils.saveAndReload(\n                        tEnv,\n                        linearRegression,\n                        tempFolder.newFolder().getAbsolutePath(),\n                        LinearRegression::load);\n        LinearRegressionModel model = linearRegression.fit(trainDataTable);\n"
      },
      {
        "chunk_id": "doc_76_chunk_13",
        "original_index": 13,
        "content": "        model =\n                TestUtils.saveAndReload(\n                        tEnv,\n                        model,\n                        tempFolder.newFolder().getAbsolutePath(),\n                        LinearRegressionModel::load);\n        assertEquals(\n                Collections.singletonList(\"coefficient\"),\n                model.getModelData()[0].getResolvedSchema().getColumnNames());\n        Table output = model.transform(trainDataTable)[0];\n        verifyPredictionResult(\n                output, linearRegression.getLabelCol(), linearRegression.getPredictionCol());\n    }\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_14",
        "original_index": 14,
        "content": "    @Test\n    public void testGetModelData() throws Exception {\n        LinearRegression linearRegression = new LinearRegression().setWeightCol(\"weight\");\n        LinearRegressionModel model = linearRegression.fit(trainDataTable);\n        List<LinearRegressionModelData> modelData =\n                IteratorUtils.toList(\n                        LinearRegressionModelData.getModelDataStream(model.getModelData()[0])\n                                .executeAndCollect());\n        assertNotNull(modelData);\n        assertEquals(1, modelData.size());\n        assertArrayEquals(\n                expectedCoefficient, modelData.get(0).coefficient.values, COEFFICIENT_TOLERANCE);\n    }\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_15",
        "original_index": 15,
        "content": "    @Test\n    public void testSetModelData() throws Exception {\n        LinearRegression linearRegression = new LinearRegression().setWeightCol(\"weight\");\n        LinearRegressionModel model = linearRegression.fit(trainDataTable);\n\n        LinearRegressionModel newModel = new LinearRegressionModel();\n        ParamUtils.updateExistingParams(newModel, model.getParamMap());\n        newModel.setModelData(model.getModelData());\n        Table output = newModel.transform(trainDataTable)[0];\n        verifyPredictionResult(\n                output, linearRegression.getLabelCol(), linearRegression.getPredictionCol());\n    }\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_16",
        "original_index": 16,
        "content": "    @Test\n    public void testMoreSubtaskThanData() throws Exception {\n        List<Row> trainData =\n                Arrays.asList(\n                        Row.of(Vectors.dense(2, 1), 4.0, 1.0),\n                        Row.of(Vectors.dense(3, 2), 7.0, 1.0));\n\n        Table trainDataTable =\n                tEnv.fromDataStream(\n                        env.fromCollection(\n                                trainData,\n                                new RowTypeInfo(\n                                        new TypeInformation[] {\n                                            DenseVectorTypeInfo.INSTANCE, Types.DOUBLE, Types.DOUBLE\n                                        },\n                                        new String[] {\"features\", \"label\", \"weight\"})));\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_17",
        "original_index": 17,
        "content": "        LinearRegression linearRegression =\n                new LinearRegression().setWeightCol(\"weight\").setGlobalBatchSize(128);\n        Table output = linearRegression.fit(trainDataTable).transform(trainDataTable)[0];\n        verifyPredictionResult(\n                output, linearRegression.getLabelCol(), linearRegression.getPredictionCol());\n    }\n\n    @Test\n    public void testRegularization() throws Exception {\n        checkRegularization(0, RandomUtils.nextDouble(0, 1), expectedCoefficient);\n        checkRegularization(0.1, 0, new double[] {1.165, 1.780});\n        checkRegularization(0.1, 1, new double[] {1.143, 1.812});\n        checkRegularization(0.1, 0.5, new double[] {1.154, 1.796});\n    }\n\n"
      },
      {
        "chunk_id": "doc_76_chunk_18",
        "original_index": 18,
        "content": "    @SuppressWarnings(\"unchecked\")\n    private void checkRegularization(double reg, double elasticNet, double[] expectedCoefficient)\n            throws Exception {\n        LinearRegressionModel model =\n                new LinearRegression()\n                        .setWeightCol(\"weight\")\n                        .setReg(reg)\n                        .setElasticNet(elasticNet)\n                        .fit(trainDataTable);\n        List<LinearRegressionModelData> modelData =\n                IteratorUtils.toList(\n                        LinearRegressionModelData.getModelDataStream(model.getModelData()[0])\n                                .executeAndCollect());\n        final double errorTol = 1e-3;\n        assertArrayEquals(expectedCoefficient, modelData.get(0).coefficient.values, errorTol);\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_77",
    "original_uuid": "7d99db65761e10f4f846eba27371bad7ae1f9c66ece73f42888388a4b2949ea6",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.flink.iteration.datacache.nonkeyed;\n\nimport org.apache.flink.annotation.Internal;\nimport org.apache.flink.api.common.typeutils.TypeSerializer;\nimport org.apache.flink.core.fs.Path;\nimport org.apache.flink.core.memory.DataOutputView;\nimport org.apache.flink.core.memory.DataOutputViewStreamWrapper;\nimport org.apache.flink.core.memory.MemorySegment;\nimport org.apache.flink.runtime.memory.MemoryAllocationException;\nimport org.apache.flink.table.runtime.util.MemorySegmentPool;\n\nimport javax.annotation.Nullable;\n\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Optional;\n\n/** A class that writes cache data to memory segments. */\n@Internal\nclass MemorySegmentWriter<T> implements SegmentWriter<T> {\n\n    /** The tool to serialize received records into bytes. */\n    private final TypeSerializer<T> serializer;\n\n    /** The pre-allocated path to hold cached records into the file system. */\n    private final Path path;\n\n    /** The pool to allocate memory segments from. */\n    private final MemorySegmentPool segmentPool;\n\n    /** The output stream to write serialized content to memory segments. */\n    private final ManagedMemoryOutputStream outputStream;\n\n    /** The wrapper view of the output stream to be used with TypeSerializer API. */\n    private final DataOutputView outputView;\n\n    /** The number of records added so far. */\n    private int count;\n\n    MemorySegmentWriter(\n            TypeSerializer<T> serializer,\n            Path path,\n            MemorySegmentPool segmentPool,\n            long expectedSize)\n            throws MemoryAllocationException {\n        this.serializer = serializer;\n        this.path = path;\n        this.segmentPool = segmentPool;\n        this.outputStream = new ManagedMemoryOutputStream(segmentPool, expectedSize);\n        this.outputView = new DataOutputViewStreamWrapper(outputStream);\n        this.count = 0;\n    }\n\n    @Override\n    public boolean addRecord(T record) throws IOException {\n        if (outputStream.getPos() >= DataCacheWriter.MAX_SEGMENT_SIZE) {\n            return false;\n        }\n        try {\n            serializer.serialize(record, outputView);\n            count++;\n            return true;\n        } catch (RuntimeException e) {\n            if (e.getCause() instanceof MemoryAllocationException) {\n                return false;\n            }\n            throw e;\n        }\n    }\n\n    @Override\n    public Optional<Segment> finish() throws IOException {\n        if (count > 0) {\n            return Optional.of(new Segment(path, count, outputStream.getSegments()));\n        } else {\n            segmentPool.returnAll(outputStream.getSegments());\n            return Optional.empty();\n        }\n    }\n\n    /** An output stream subclass that accepts bytes and writes them to memory segments. */\n    private static class ManagedMemoryOutputStream extends OutputStream {\n\n        /** The pool to allocate memory segments from. */\n        private final MemorySegmentPool segmentPool;\n\n        /** The number of bytes in a memory segment. */\n        private final int pageSize;\n\n        /** The memory segments containing written bytes. */\n        private final List<MemorySegment> segments = new ArrayList<>();\n\n        /** The index of the segment that currently accepts written bytes. */\n        private int segmentIndex;\n\n        /** The number of bytes in the current segment that have been written. */\n        private int segmentOffset;\n\n        /** The number of bytes that have been written so far. */\n        private long globalOffset;\n\n        /** The number of bytes that have been allocated so far. */\n        private long allocatedBytes;\n\n        public ManagedMemoryOutputStream(MemorySegmentPool segmentPool, long expectedSize)\n                throws MemoryAllocationException {\n            this.segmentPool = segmentPool;\n            this.pageSize = segmentPool.pageSize();\n            ensureCapacity(Math.max(expectedSize, 1L));\n        }\n\n        public long getPos() {\n            return globalOffset;\n        }\n\n        public List<MemorySegment> getSegments() {\n            return segments;\n        }\n\n        @Override\n        public void write(int b) throws IOException {\n            write(new byte[] {(byte) b}, 0, 1);\n        }\n\n        @Override\n        public void write(@Nullable byte[] b, int off, int len) throws IOException {\n            try {\n                ensureCapacity(globalOffset + len);\n            } catch (MemoryAllocationException e) {\n                throw new RuntimeException(e);\n            }\n\n            while (len > 0) {\n                int currentLen = Math.min(len, pageSize - segmentOffset);\n                segments.get(segmentIndex).put(segmentOffset, b, off, currentLen);\n                segmentOffset += currentLen;\n                globalOffset += currentLen;\n                if (segmentOffset >= pageSize) {\n                    segmentIndex++;\n                    segmentOffset = 0;\n                }\n                off += currentLen;\n                len -= currentLen;\n            }\n        }\n\n        private void ensureCapacity(long capacity) throws MemoryAllocationException {\n            if (allocatedBytes >= capacity) {\n                return;\n            }\n\n            int required =\n                    (int) (capacity % pageSize == 0 ? capacity / pageSize : capacity / pageSize + 1)\n                            - segments.size();\n\n            List<MemorySegment> allocatedSegments = new ArrayList<>();\n            for (int i = 0; i < required; i++) {\n                MemorySegment memorySegment = segmentPool.nextSegment();\n                if (memorySegment == null) {\n                    segmentPool.returnAll(allocatedSegments);\n                    throw new MemoryAllocationException();\n                }\n                allocatedSegments.add(memorySegment);\n            }\n\n            segments.addAll(allocatedSegments);\n            allocatedBytes += (long) allocatedSegments.size() * pageSize;\n        }\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_77_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_77_chunk_1",
        "original_index": 1,
        "content": "package org.apache.flink.iteration.datacache.nonkeyed;\n\nimport org.apache.flink.annotation.Internal;\nimport org.apache.flink.api.common.typeutils.TypeSerializer;\nimport org.apache.flink.core.fs.Path;\nimport org.apache.flink.core.memory.DataOutputView;\nimport org.apache.flink.core.memory.DataOutputViewStreamWrapper;\nimport org.apache.flink.core.memory.MemorySegment;\nimport org.apache.flink.runtime.memory.MemoryAllocationException;\nimport org.apache.flink.table.runtime.util.MemorySegmentPool;\n\nimport javax.annotation.Nullable;\n\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Optional;\n\n/** A class that writes cache data to memory segments. */\n@Internal\nclass MemorySegmentWriter<T> implements SegmentWriter<T> {\n\n    /** The tool to serialize received records into bytes. */\n    private final TypeSerializer<T> serializer;\n\n"
      },
      {
        "chunk_id": "doc_77_chunk_2",
        "original_index": 2,
        "content": "    /** The pre-allocated path to hold cached records into the file system. */\n    private final Path path;\n\n    /** The pool to allocate memory segments from. */\n    private final MemorySegmentPool segmentPool;\n\n    /** The output stream to write serialized content to memory segments. */\n    private final ManagedMemoryOutputStream outputStream;\n\n    /** The wrapper view of the output stream to be used with TypeSerializer API. */\n    private final DataOutputView outputView;\n\n    /** The number of records added so far. */\n    private int count;\n\n"
      },
      {
        "chunk_id": "doc_77_chunk_3",
        "original_index": 3,
        "content": "    MemorySegmentWriter(\n            TypeSerializer<T> serializer,\n            Path path,\n            MemorySegmentPool segmentPool,\n            long expectedSize)\n            throws MemoryAllocationException {\n        this.serializer = serializer;\n        this.path = path;\n        this.segmentPool = segmentPool;\n        this.outputStream = new ManagedMemoryOutputStream(segmentPool, expectedSize);\n        this.outputView = new DataOutputViewStreamWrapper(outputStream);\n        this.count = 0;\n    }\n\n    @Override\n    public boolean addRecord(T record) throws IOException {\n        if (outputStream.getPos() >= DataCacheWriter.MAX_SEGMENT_SIZE) {\n            return false;\n        }\n        try {\n            serializer.serialize(record, outputView);\n            count++;\n            return true;\n        } catch (RuntimeException e) {\n            if (e.getCause() instanceof MemoryAllocationException) {\n                return false;\n            }\n            throw e;\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_77_chunk_4",
        "original_index": 4,
        "content": "    @Override\n    public Optional<Segment> finish() throws IOException {\n        if (count > 0) {\n            return Optional.of(new Segment(path, count, outputStream.getSegments()));\n        } else {\n            segmentPool.returnAll(outputStream.getSegments());\n            return Optional.empty();\n        }\n    }\n\n    /** An output stream subclass that accepts bytes and writes them to memory segments. */\n    private static class ManagedMemoryOutputStream extends OutputStream {\n\n        /** The pool to allocate memory segments from. */\n        private final MemorySegmentPool segmentPool;\n\n        /** The number of bytes in a memory segment. */\n        private final int pageSize;\n\n        /** The memory segments containing written bytes. */\n        private final List<MemorySegment> segments = new ArrayList<>();\n\n"
      },
      {
        "chunk_id": "doc_77_chunk_5",
        "original_index": 5,
        "content": "        /** The index of the segment that currently accepts written bytes. */\n        private int segmentIndex;\n\n        /** The number of bytes in the current segment that have been written. */\n        private int segmentOffset;\n\n        /** The number of bytes that have been written so far. */\n        private long globalOffset;\n\n        /** The number of bytes that have been allocated so far. */\n        private long allocatedBytes;\n\n        public ManagedMemoryOutputStream(MemorySegmentPool segmentPool, long expectedSize)\n                throws MemoryAllocationException {\n            this.segmentPool = segmentPool;\n            this.pageSize = segmentPool.pageSize();\n            ensureCapacity(Math.max(expectedSize, 1L));\n        }\n\n"
      },
      {
        "chunk_id": "doc_77_chunk_6",
        "original_index": 6,
        "content": "        public long getPos() {\n            return globalOffset;\n        }\n\n        public List<MemorySegment> getSegments() {\n            return segments;\n        }\n\n        @Override\n        public void write(int b) throws IOException {\n            write(new byte[] {(byte) b}, 0, 1);\n        }\n\n        @Override\n        public void write(@Nullable byte[] b, int off, int len) throws IOException {\n            try {\n                ensureCapacity(globalOffset + len);\n            } catch (MemoryAllocationException e) {\n                throw new RuntimeException(e);\n            }\n\n"
      },
      {
        "chunk_id": "doc_77_chunk_7",
        "original_index": 7,
        "content": "            while (len > 0) {\n                int currentLen = Math.min(len, pageSize - segmentOffset);\n                segments.get(segmentIndex).put(segmentOffset, b, off, currentLen);\n                segmentOffset += currentLen;\n                globalOffset += currentLen;\n                if (segmentOffset >= pageSize) {\n                    segmentIndex++;\n                    segmentOffset = 0;\n                }\n                off += currentLen;\n                len -= currentLen;\n            }\n        }\n\n        private void ensureCapacity(long capacity) throws MemoryAllocationException {\n            if (allocatedBytes >= capacity) {\n                return;\n            }\n\n            int required =\n                    (int) (capacity % pageSize == 0 ? capacity / pageSize : capacity / pageSize + 1)\n                            - segments.size();\n\n"
      },
      {
        "chunk_id": "doc_77_chunk_8",
        "original_index": 8,
        "content": "            List<MemorySegment> allocatedSegments = new ArrayList<>();\n            for (int i = 0; i < required; i++) {\n                MemorySegment memorySegment = segmentPool.nextSegment();\n                if (memorySegment == null) {\n                    segmentPool.returnAll(allocatedSegments);\n                    throw new MemoryAllocationException();\n                }\n                allocatedSegments.add(memorySegment);\n            }\n\n            segments.addAll(allocatedSegments);\n            allocatedBytes += (long) allocatedSegments.size() * pageSize;\n        }\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_78",
    "original_uuid": "e76b84e8438dda17b4ce9cea1c2966171c7bf77397a4036cede90ee5de345320",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.flink.iteration.operator.coordinator;\n\nimport org.apache.flink.iteration.IterationID;\nimport org.apache.flink.iteration.operator.event.GloballyAlignedEvent;\nimport org.apache.flink.iteration.operator.event.SubtaskAlignedEvent;\nimport org.apache.flink.runtime.jobgraph.OperatorID;\nimport org.apache.flink.runtime.operators.coordination.EventReceivingTasks;\nimport org.apache.flink.runtime.operators.coordination.MockOperatorCoordinatorContext;\nimport org.apache.flink.runtime.operators.coordination.OperatorEvent;\nimport org.apache.flink.util.TestLogger;\n\nimport org.junit.Test;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.function.BiFunction;\n\nimport static org.junit.Assert.assertEquals;\n\n/** Tests the behavior of {@link HeadOperatorCoordinator}. */\npublic class HeadOperatorCoordinatorTest extends TestLogger {\n\n    @Test(timeout = 60000L)\n    public void testForwardEvents() throws Exception {\n        IterationID iterationId = new IterationID();\n        List<OperatorID> operatorIds = Arrays.asList(new OperatorID(), new OperatorID());\n        List<Integer> parallelisms = Arrays.asList(2, 3);\n        List<EventReceivingTasks> receivingTasks =\n                Arrays.asList(\n                        EventReceivingTasks.createForRunningTasks(),\n                        EventReceivingTasks.createForRunningTasks());\n        List<HeadOperatorCoordinator> coordinators = new ArrayList<>();\n\n        int totalParallelism = parallelisms.stream().mapToInt(i -> i).sum();\n\n        for (int i = 0; i < operatorIds.size(); ++i) {\n            HeadOperatorCoordinator coordinator =\n                    createCoordinator(iterationId, parallelisms.get(i), totalParallelism);\n            setAllSubtasksReady(coordinator, receivingTasks.get(i), parallelisms.get(i));\n            coordinators.add(coordinator);\n        }\n\n        receiveEvent(\n                coordinators,\n                parallelisms,\n                (i, j) -> Collections.singletonList(new SubtaskAlignedEvent(2, j, false)));\n        checkSentEvent(1, new GloballyAlignedEvent(2, false), receivingTasks, parallelisms);\n\n        receiveEvent(\n                coordinators,\n                parallelisms,\n                (i, j) -> Collections.singletonList(new SubtaskAlignedEvent(3, 0, false)));\n        checkSentEvent(2, new GloballyAlignedEvent(3, true), receivingTasks, parallelisms);\n    }\n\n    private HeadOperatorCoordinator createCoordinator(\n            IterationID iterationId, int parallelism, int totalHeadParallelism) {\n        MockOperatorCoordinatorContext context =\n                new MockOperatorCoordinatorContext(new OperatorID(), parallelism);\n        return (HeadOperatorCoordinator)\n                new HeadOperatorCoordinator.HeadOperatorCoordinatorProvider(\n                                new OperatorID(), iterationId, totalHeadParallelism)\n                        .create(context);\n    }\n\n    private void setAllSubtasksReady(\n            HeadOperatorCoordinator coordinator,\n            EventReceivingTasks receivingTasks,\n            int parallelism) {\n        for (int i = 0; i < parallelism; i++) {\n            coordinator.executionAttemptReady(i, 0, receivingTasks.createGatewayForSubtask(i, 0));\n        }\n    }\n\n    private void receiveEvent(\n            List<HeadOperatorCoordinator> coordinators,\n            List<Integer> parallelisms,\n            BiFunction<Integer, Integer, List<OperatorEvent>> eventFactory)\n            throws Exception {\n        for (int i = 0; i < coordinators.size(); ++i) {\n            for (int j = 0; j < parallelisms.get(i); ++j) {\n                List<OperatorEvent> events = eventFactory.apply(i, j);\n                for (OperatorEvent event : events) {\n                    coordinators.get(i).handleEventFromOperator(j, 0, event);\n                }\n            }\n        }\n    }\n\n    private void checkSentEvent(\n            int expectedNumEvents,\n            GloballyAlignedEvent expectedLastEvent,\n            List<EventReceivingTasks> receivingTasks,\n            List<Integer> parallelisms)\n            throws InterruptedException {\n        for (int i = 0; i < parallelisms.size(); ++i) {\n            for (int j = 0; j < parallelisms.get(i); ++j) {\n                while (true) {\n                    List<OperatorEvent> events = receivingTasks.get(i).getSentEventsForSubtask(j);\n                    if (events.size() < expectedNumEvents) {\n                        Thread.sleep(50);\n                        continue;\n                    }\n\n                    assertEquals(expectedLastEvent, events.get(events.size() - 1));\n                    break;\n                }\n            }\n        }\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_78_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_78_chunk_1",
        "original_index": 1,
        "content": "package org.apache.flink.iteration.operator.coordinator;\n\nimport org.apache.flink.iteration.IterationID;\nimport org.apache.flink.iteration.operator.event.GloballyAlignedEvent;\nimport org.apache.flink.iteration.operator.event.SubtaskAlignedEvent;\nimport org.apache.flink.runtime.jobgraph.OperatorID;\nimport org.apache.flink.runtime.operators.coordination.EventReceivingTasks;\nimport org.apache.flink.runtime.operators.coordination.MockOperatorCoordinatorContext;\nimport org.apache.flink.runtime.operators.coordination.OperatorEvent;\nimport org.apache.flink.util.TestLogger;\n\nimport org.junit.Test;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.function.BiFunction;\n\nimport static org.junit.Assert.assertEquals;\n\n/** Tests the behavior of {@link HeadOperatorCoordinator}. */\npublic class HeadOperatorCoordinatorTest extends TestLogger {\n\n"
      },
      {
        "chunk_id": "doc_78_chunk_2",
        "original_index": 2,
        "content": "    @Test(timeout = 60000L)\n    public void testForwardEvents() throws Exception {\n        IterationID iterationId = new IterationID();\n        List<OperatorID> operatorIds = Arrays.asList(new OperatorID(), new OperatorID());\n        List<Integer> parallelisms = Arrays.asList(2, 3);\n        List<EventReceivingTasks> receivingTasks =\n                Arrays.asList(\n                        EventReceivingTasks.createForRunningTasks(),\n                        EventReceivingTasks.createForRunningTasks());\n        List<HeadOperatorCoordinator> coordinators = new ArrayList<>();\n\n"
      },
      {
        "chunk_id": "doc_78_chunk_3",
        "original_index": 3,
        "content": "        int totalParallelism = parallelisms.stream().mapToInt(i -> i).sum();\n\n        for (int i = 0; i < operatorIds.size(); ++i) {\n            HeadOperatorCoordinator coordinator =\n                    createCoordinator(iterationId, parallelisms.get(i), totalParallelism);\n            setAllSubtasksReady(coordinator, receivingTasks.get(i), parallelisms.get(i));\n            coordinators.add(coordinator);\n        }\n\n        receiveEvent(\n                coordinators,\n                parallelisms,\n                (i, j) -> Collections.singletonList(new SubtaskAlignedEvent(2, j, false)));\n        checkSentEvent(1, new GloballyAlignedEvent(2, false), receivingTasks, parallelisms);\n\n        receiveEvent(\n                coordinators,\n                parallelisms,\n                (i, j) -> Collections.singletonList(new SubtaskAlignedEvent(3, 0, false)));\n        checkSentEvent(2, new GloballyAlignedEvent(3, true), receivingTasks, parallelisms);\n    }\n\n"
      },
      {
        "chunk_id": "doc_78_chunk_4",
        "original_index": 4,
        "content": "    private HeadOperatorCoordinator createCoordinator(\n            IterationID iterationId, int parallelism, int totalHeadParallelism) {\n        MockOperatorCoordinatorContext context =\n                new MockOperatorCoordinatorContext(new OperatorID(), parallelism);\n        return (HeadOperatorCoordinator)\n                new HeadOperatorCoordinator.HeadOperatorCoordinatorProvider(\n                                new OperatorID(), iterationId, totalHeadParallelism)\n                        .create(context);\n    }\n\n    private void setAllSubtasksReady(\n            HeadOperatorCoordinator coordinator,\n            EventReceivingTasks receivingTasks,\n            int parallelism) {\n        for (int i = 0; i < parallelism; i++) {\n            coordinator.executionAttemptReady(i, 0, receivingTasks.createGatewayForSubtask(i, 0));\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_78_chunk_5",
        "original_index": 5,
        "content": "    private void receiveEvent(\n            List<HeadOperatorCoordinator> coordinators,\n            List<Integer> parallelisms,\n            BiFunction<Integer, Integer, List<OperatorEvent>> eventFactory)\n            throws Exception {\n        for (int i = 0; i < coordinators.size(); ++i) {\n            for (int j = 0; j < parallelisms.get(i); ++j) {\n                List<OperatorEvent> events = eventFactory.apply(i, j);\n                for (OperatorEvent event : events) {\n                    coordinators.get(i).handleEventFromOperator(j, 0, event);\n                }\n            }\n        }\n    }\n\n"
      },
      {
        "chunk_id": "doc_78_chunk_6",
        "original_index": 6,
        "content": "    private void checkSentEvent(\n            int expectedNumEvents,\n            GloballyAlignedEvent expectedLastEvent,\n            List<EventReceivingTasks> receivingTasks,\n            List<Integer> parallelisms)\n            throws InterruptedException {\n        for (int i = 0; i < parallelisms.size(); ++i) {\n            for (int j = 0; j < parallelisms.get(i); ++j) {\n                while (true) {\n                    List<OperatorEvent> events = receivingTasks.get(i).getSentEventsForSubtask(j);\n                    if (events.size() < expectedNumEvents) {\n                        Thread.sleep(50);\n                        continue;\n                    }\n\n                    assertEquals(expectedLastEvent, events.get(events.size() - 1));\n                    break;\n                }\n            }\n        }\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_79",
    "original_uuid": "b5a7a2b677027616a70919913ddc49d329066ba2aa5c266fd47239c36afe5c1e",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.flink.ml.examples.feature;\n\nimport org.apache.flink.ml.feature.stopwordsremover.StopWordsRemover;\nimport org.apache.flink.streaming.api.datastream.DataStream;\nimport org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\nimport org.apache.flink.table.api.Table;\nimport org.apache.flink.table.api.bridge.java.StreamTableEnvironment;\nimport org.apache.flink.types.Row;\nimport org.apache.flink.util.CloseableIterator;\n\nimport java.util.Arrays;\n\n/** Simple program that creates a StopWordsRemover instance and uses it for feature engineering. */\npublic class StopWordsRemoverExample {\n    public static void main(String[] args) {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);\n\n        // Generates input data.\n        DataStream<Row> inputStream =\n                env.fromElements(\n                        Row.of((Object) new String[] {\"test\", \"test\"}),\n                        Row.of((Object) new String[] {\"a\", \"b\", \"c\", \"d\"}),\n                        Row.of((Object) new String[] {\"a\", \"the\", \"an\"}),\n                        Row.of((Object) new String[] {\"A\", \"The\", \"AN\"}),\n                        Row.of((Object) new String[] {null}),\n                        Row.of((Object) new String[] {}));\n        Table inputTable = tEnv.fromDataStream(inputStream).as(\"input\");\n\n        // Creates a StopWordsRemover object and initializes its parameters.\n        StopWordsRemover remover =\n                new StopWordsRemover().setInputCols(\"input\").setOutputCols(\"output\");\n\n        // Uses the StopWordsRemover object for feature transformations.\n        Table outputTable = remover.transform(inputTable)[0];\n\n        // Extracts and displays the results.\n        for (CloseableIterator<Row> it = outputTable.execute().collect(); it.hasNext(); ) {\n            Row row = it.next();\n\n            String[] inputValues = row.getFieldAs(\"input\");\n            String[] outputValues = row.getFieldAs(\"output\");\n\n            System.out.printf(\n                    \"Input Values: %s\\tOutput Values: %s\\n\",\n                    Arrays.toString(inputValues), Arrays.toString(outputValues));\n        }\n    }\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_79_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_79_chunk_1",
        "original_index": 1,
        "content": "package org.apache.flink.ml.examples.feature;\n\nimport org.apache.flink.ml.feature.stopwordsremover.StopWordsRemover;\nimport org.apache.flink.streaming.api.datastream.DataStream;\nimport org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\nimport org.apache.flink.table.api.Table;\nimport org.apache.flink.table.api.bridge.java.StreamTableEnvironment;\nimport org.apache.flink.types.Row;\nimport org.apache.flink.util.CloseableIterator;\n\nimport java.util.Arrays;\n\n/** Simple program that creates a StopWordsRemover instance and uses it for feature engineering. */\npublic class StopWordsRemoverExample {\n    public static void main(String[] args) {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);\n\n"
      },
      {
        "chunk_id": "doc_79_chunk_2",
        "original_index": 2,
        "content": "        // Generates input data.\n        DataStream<Row> inputStream =\n                env.fromElements(\n                        Row.of((Object) new String[] {\"test\", \"test\"}),\n                        Row.of((Object) new String[] {\"a\", \"b\", \"c\", \"d\"}),\n                        Row.of((Object) new String[] {\"a\", \"the\", \"an\"}),\n                        Row.of((Object) new String[] {\"A\", \"The\", \"AN\"}),\n                        Row.of((Object) new String[] {null}),\n                        Row.of((Object) new String[] {}));\n        Table inputTable = tEnv.fromDataStream(inputStream).as(\"input\");\n\n"
      },
      {
        "chunk_id": "doc_79_chunk_3",
        "original_index": 3,
        "content": "        // Creates a StopWordsRemover object and initializes its parameters.\n        StopWordsRemover remover =\n                new StopWordsRemover().setInputCols(\"input\").setOutputCols(\"output\");\n\n        // Uses the StopWordsRemover object for feature transformations.\n        Table outputTable = remover.transform(inputTable)[0];\n\n        // Extracts and displays the results.\n        for (CloseableIterator<Row> it = outputTable.execute().collect(); it.hasNext(); ) {\n            Row row = it.next();\n\n            String[] inputValues = row.getFieldAs(\"input\");\n            String[] outputValues = row.getFieldAs(\"output\");\n\n            System.out.printf(\n                    \"Input Values: %s\\tOutput Values: %s\\n\",\n                    Arrays.toString(inputValues), Arrays.toString(outputValues));\n        }\n    }\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_80",
    "original_uuid": "85b5dc3fe7b963e62c701c7f73ba8e8de3a2b576b31a75d9024c4e529b9b4107",
    "content": "################################################################################\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  \"License\"); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n# limitations under the License.\n################################################################################\n\n# Simple program that creates an IndexToStringModel instance and uses it\n# for feature engineering.\n\nfrom pyflink.common import Types\nfrom pyflink.datastream import StreamExecutionEnvironment\nfrom pyflink.ml.feature.stringindexer import IndexToStringModel\nfrom pyflink.table import StreamTableEnvironment\n\n# create a new StreamExecutionEnvironment\nenv = StreamExecutionEnvironment.get_execution_environment()\n\n# create a StreamTableEnvironment\nt_env = StreamTableEnvironment.create(env)\n\n# generate input data\npredict_table = t_env.from_data_stream(\n    env.from_collection([\n        (0, 3),\n        (1, 2),\n    ],\n        type_info=Types.ROW_NAMED(\n            ['input_col1', 'input_col2'],\n            [Types.INT(), Types.INT()])\n    ))\n\n# create an index-to-string model and initialize its parameters and model data\nmodel_data_table = t_env.from_data_stream(\n    env.from_collection([\n        ([['a', 'b', 'c', 'd'], [-1., 0., 1., 2.]],),\n    ],\n        type_info=Types.ROW_NAMED(\n            ['stringArrays'],\n            [Types.OBJECT_ARRAY(Types.OBJECT_ARRAY(Types.STRING()))])\n    ))\n\nmodel = IndexToStringModel() \\\n    .set_input_cols('input_col1', 'input_col2') \\\n    .set_output_cols('output_col1', 'output_col2') \\\n    .set_model_data(model_data_table)\n\n# use the index-to-string model for feature engineering\noutput = model.transform(predict_table)[0]\n\n# extract and display the results\nfield_names = output.get_schema().get_field_names()\ninput_values = [None for _ in model.get_input_cols()]\noutput_values = [None for _ in model.get_input_cols()]\nfor result in t_env.to_data_stream(output).execute_and_collect():\n    for i in range(len(model.get_input_cols())):\n        input_values[i] = result[field_names.index(model.get_input_cols()[i])]\n        output_values[i] = result[field_names.index(model.get_output_cols()[i])]\n    print('Input Values: ' + str(input_values) + '\\tOutput Values: ' + str(output_values))\n",
    "chunks": [
      {
        "chunk_id": "doc_80_chunk_0",
        "original_index": 0,
        "content": "################################################################################\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  \"License\"); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n# limitations under the License.\n################################################################################\n\n"
      },
      {
        "chunk_id": "doc_80_chunk_1",
        "original_index": 1,
        "content": "# Simple program that creates an IndexToStringModel instance and uses it\n# for feature engineering.\n\nfrom pyflink.common import Types\nfrom pyflink.datastream import StreamExecutionEnvironment\nfrom pyflink.ml.feature.stringindexer import IndexToStringModel\nfrom pyflink.table import StreamTableEnvironment\n\n# create a new StreamExecutionEnvironment\nenv = StreamExecutionEnvironment.get_execution_environment()\n\n# create a StreamTableEnvironment\nt_env = StreamTableEnvironment.create(env)\n\n# generate input data\npredict_table = t_env.from_data_stream(\n    env.from_collection([\n        (0, 3),\n        (1, 2),\n    ],\n        type_info=Types.ROW_NAMED(\n            ['input_col1', 'input_col2'],\n            [Types.INT(), Types.INT()])\n    ))\n\n"
      },
      {
        "chunk_id": "doc_80_chunk_2",
        "original_index": 2,
        "content": "# create an index-to-string model and initialize its parameters and model data\nmodel_data_table = t_env.from_data_stream(\n    env.from_collection([\n        ([['a', 'b', 'c', 'd'], [-1., 0., 1., 2.]],),\n    ],\n        type_info=Types.ROW_NAMED(\n            ['stringArrays'],\n            [Types.OBJECT_ARRAY(Types.OBJECT_ARRAY(Types.STRING()))])\n    ))\n\nmodel = IndexToStringModel() \\\n    .set_input_cols('input_col1', 'input_col2') \\\n    .set_output_cols('output_col1', 'output_col2') \\\n    .set_model_data(model_data_table)\n\n# use the index-to-string model for feature engineering\noutput = model.transform(predict_table)[0]\n\n"
      },
      {
        "chunk_id": "doc_80_chunk_3",
        "original_index": 3,
        "content": "# extract and display the results\nfield_names = output.get_schema().get_field_names()\ninput_values = [None for _ in model.get_input_cols()]\noutput_values = [None for _ in model.get_input_cols()]\nfor result in t_env.to_data_stream(output).execute_and_collect():\n    for i in range(len(model.get_input_cols())):\n        input_values[i] = result[field_names.index(model.get_input_cols()[i])]\n        output_values[i] = result[field_names.index(model.get_output_cols()[i])]\n    print('Input Values: ' + str(input_values) + '\\tOutput Values: ' + str(output_values))\n"
      }
    ]
  },
  {
    "doc_id": "doc_81",
    "original_uuid": "d55e0c184149c0c3a0f23bc11ffd11a958dfb9d8a71ba5ac573cba7d1ab37da0",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#include <log4cxx/logstring.h>\n#include <log4cxx/pattern/colorendpatternconverter.h>\n#include <log4cxx/spi/loggingevent.h>\n#include <log4cxx/spi/location/locationinfo.h>\n#include <log4cxx/helpers/stringhelper.h>\n\nusing namespace LOG4CXX_NS;\nusing namespace LOG4CXX_NS::pattern;\nusing namespace LOG4CXX_NS::spi;\nusing namespace LOG4CXX_NS::helpers;\n\nIMPLEMENT_LOG4CXX_OBJECT(ColorEndPatternConverter)\n\nColorEndPatternConverter::ColorEndPatternConverter() :\n\tLoggingEventPatternConverter(LOG4CXX_STR(\"Color End\"),\n\t\tLOG4CXX_STR(\"colorEnd\"))\n{\n}\n\nPatternConverterPtr ColorEndPatternConverter::newInstance(\n\tconst std::vector<LogString>& /* options */)\n{\n\tstatic WideLife<PatternConverterPtr> instance = std::make_shared<ColorEndPatternConverter>();\n\treturn instance;\n}\n\nvoid ColorEndPatternConverter::format(\n\tconst LoggingEventPtr& event,\n\tLogString& toAppendTo,\n\tPool& p) const\n{\n\n\t// Reset all colors on the output(code 0)\n\t// Code 39 would be to reset colors only\n\ttoAppendTo.append(LOG4CXX_STR(\"\\x1B[0m\"));\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_81_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_81_chunk_1",
        "original_index": 1,
        "content": "#include <log4cxx/logstring.h>\n#include <log4cxx/pattern/colorendpatternconverter.h>\n#include <log4cxx/spi/loggingevent.h>\n#include <log4cxx/spi/location/locationinfo.h>\n#include <log4cxx/helpers/stringhelper.h>\n\nusing namespace LOG4CXX_NS;\nusing namespace LOG4CXX_NS::pattern;\nusing namespace LOG4CXX_NS::spi;\nusing namespace LOG4CXX_NS::helpers;\n\nIMPLEMENT_LOG4CXX_OBJECT(ColorEndPatternConverter)\n\nColorEndPatternConverter::ColorEndPatternConverter() :\n\tLoggingEventPatternConverter(LOG4CXX_STR(\"Color End\"),\n\t\tLOG4CXX_STR(\"colorEnd\"))\n{\n}\n\n"
      },
      {
        "chunk_id": "doc_81_chunk_2",
        "original_index": 2,
        "content": "PatternConverterPtr ColorEndPatternConverter::newInstance(\n\tconst std::vector<LogString>& /* options */)\n{\n\tstatic WideLife<PatternConverterPtr> instance = std::make_shared<ColorEndPatternConverter>();\n\treturn instance;\n}\n\nvoid ColorEndPatternConverter::format(\n\tconst LoggingEventPtr& event,\n\tLogString& toAppendTo,\n\tPool& p) const\n{\n\n\t// Reset all colors on the output(code 0)\n\t// Code 39 would be to reset colors only\n\ttoAppendTo.append(LOG4CXX_STR(\"\\x1B[0m\"));\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_82",
    "original_uuid": "5b1559cf19dd6f22a42968d4489aff3f9df8ae90ba9b002e9d89f9e0f3c981f4",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#include \"xmlfilenamefilter.h\"\n\nusing namespace log4cxx;\nusing namespace log4cxx::helpers;\n\nXMLFilenameFilter::XMLFilenameFilter(const std::string& /*actual*/, const std::string& expected)\n{\n\tstd::string pattern(\" file=\\\\(.\\\\).*\");\n\tpattern += expected;\n\n\tstd::string replacement(\" file=\\\\\\\\1\");\n\treplacement += expected;\n\t//    patterns.push_back( PatternReplacement(pattern, replacement) );\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_82_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_82_chunk_1",
        "original_index": 1,
        "content": "#include \"xmlfilenamefilter.h\"\n\nusing namespace log4cxx;\nusing namespace log4cxx::helpers;\n\nXMLFilenameFilter::XMLFilenameFilter(const std::string& /*actual*/, const std::string& expected)\n{\n\tstd::string pattern(\" file=\\\\(.\\\\).*\");\n\tpattern += expected;\n\n\tstd::string replacement(\" file=\\\\\\\\1\");\n\treplacement += expected;\n\t//    patterns.push_back( PatternReplacement(pattern, replacement) );\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_83",
    "original_uuid": "968bc75b566183e5c5072fff16b22bd071cbcc34e15d48d945b5b870d0f3bfe4",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#define LOG4CXX_TEST 1\n#include <log4cxx/private/log4cxx_private.h>\n\n#include <log4cxx/net/smtpappender.h>\n#include \"../appenderskeletontestcase.h\"\n#include <log4cxx/xml/domconfigurator.h>\n#include <log4cxx/logmanager.h>\n#include <log4cxx/simplelayout.h>\n#include <log4cxx/helpers/onlyonceerrorhandler.h>\n\nnamespace LOG4CXX_NS\n{\nnamespace net\n{\n\nclass MockTriggeringEventEvaluator :\n\tpublic virtual spi::TriggeringEventEvaluator\n{\n\tpublic:\n\t\tDECLARE_LOG4CXX_OBJECT(MockTriggeringEventEvaluator)\n\t\tBEGIN_LOG4CXX_CAST_MAP()\n\t\tLOG4CXX_CAST_ENTRY(MockTriggeringEventEvaluator)\n\t\tLOG4CXX_CAST_ENTRY(spi::TriggeringEventEvaluator)\n\t\tEND_LOG4CXX_CAST_MAP()\n\n\t\tMockTriggeringEventEvaluator()\n\t\t{\n\t\t}\n\n\t\tbool isTriggeringEvent(const spi::LoggingEventPtr& event) override\n\t\t{\n\t\t\treturn true;\n\t\t}\n\tprivate:\n\t\tMockTriggeringEventEvaluator(const MockTriggeringEventEvaluator&);\n\t\tMockTriggeringEventEvaluator& operator=(const MockTriggeringEventEvaluator&);\n};\n}\n}\n\nusing namespace log4cxx;\nusing namespace log4cxx::helpers;\nusing namespace log4cxx::net;\n\nIMPLEMENT_LOG4CXX_OBJECT(MockTriggeringEventEvaluator)\n\n\n/**\n   Unit tests of log4cxx::SocketAppender\n */\nclass SMTPAppenderTestCase : public AppenderSkeletonTestCase\n{\n\t\tLOGUNIT_TEST_SUITE(SMTPAppenderTestCase);\n\t\t//\n\t\t//    tests inherited from AppenderSkeletonTestCase\n\t\t//\n\t\tLOGUNIT_TEST(testDefaultThreshold);\n\t\tLOGUNIT_TEST(testSetOptionThreshold);\n\t\tLOGUNIT_TEST(testTrigger);\n\t\tLOGUNIT_TEST(testInvalid);\n//#define LOG4CXX_TEST_EMAIL_AND_SMTP_HOST_ARE_IN_ENVIRONMENT_VARIABLES\n#ifdef LOG4CXX_TEST_EMAIL_AND_SMTP_HOST_ARE_IN_ENVIRONMENT_VARIABLES\n\t\t// This test requires the following environment variables:\n\t\t// LOG4CXX_TEST_EMAIL_RECIPIENT - where the email is sent\n\t\t// LOG4CXX_TEST_SMTP_HOST_NAME - the email server\n\t\tLOGUNIT_TEST(testValid);\n#endif\n\t\tLOGUNIT_TEST_SUITE_END();\n\n\n\tpublic:\n\n\t\tAppenderSkeleton* createAppenderSkeleton() const\n\t\t{\n\t\t\treturn new log4cxx::net::SMTPAppender();\n\t\t}\n\n\t\tvoid setUp()\n\t\t{\n\t\t}\n\n\t\tvoid tearDown()\n\t\t{\n\t\t\tLogManager::resetConfiguration();\n\t\t}\n\n\t\t/**\n\t\t * Tests that triggeringPolicy element will set evaluator.\n\t\t */\n\t\tvoid testTrigger()\n\t\t{\n\t\t\txml::DOMConfigurator::configure(\"input/xml/smtpAppender1.xml\");\n\t\t\tauto appender = log4cxx::cast<SMTPAppender>(Logger::getRootLogger()->getAppender(LOG4CXX_STR(\"A1\")));\n\t\t\tLOGUNIT_ASSERT(appender);\n\t\t\tauto evaluator = appender->getEvaluator();\n\t\t\tLOGUNIT_ASSERT(evaluator);\n\t\t\tLOGUNIT_ASSERT_EQUAL(true, evaluator->instanceof(MockTriggeringEventEvaluator::getStaticClass()));\n\t\t}\n\n\t\tvoid testInvalid()\n\t\t{\n\t\t\tauto appender = std::make_shared<SMTPAppender>();\n\t\t\tappender->setSMTPHost(LOG4CXX_STR(\"smtp.invalid\"));\n\t\t\tappender->setTo(LOG4CXX_STR(\"you@example.invalid\"));\n\t\t\tappender->setFrom(LOG4CXX_STR(\"me@example.invalid\"));\n\t\t\tappender->setLayout(std::make_shared<SimpleLayout>());\n\t\t\tPool p;\n\t\t\tappender->activateOptions(p);\n\t\t\tauto root = Logger::getRootLogger();\n\t\t\troot->addAppender(appender);\n\t\t\tLOG4CXX_INFO(root, \"Hello, World.\");\n\t\t\tLOG4CXX_ERROR(root, \"Sending Message\"); // The DefaultEvaluator should trigger e-mail generation\n\t\t\tauto eh = dynamic_cast<helpers::OnlyOnceErrorHandler*>(appender->getErrorHandler().get());\n\t\t\tLOGUNIT_ASSERT(eh);\n\t\t\tLOGUNIT_ASSERT(eh->errorReported());\n\t\t}\n\n\n\t\tvoid testValid()\n\t\t{\n\t\t\txml::DOMConfigurator::configure(\"input/xml/smtpAppenderValid.xml\");\n\t\t\tauto root = Logger::getRootLogger();\n\t\t\tLOG4CXX_INFO(root, \"Hello, World.\\n\\nThis paragraph should be preceeded by a blank line.\");\n\n\t\t\tauto appender = log4cxx::cast<SMTPAppender>(root->getAppender(LOG4CXX_STR(\"A1\")));\n\t\t\tLOGUNIT_ASSERT(appender);\n\t\t\tauto eh = dynamic_cast<helpers::OnlyOnceErrorHandler*>(appender->getErrorHandler().get());\n\t\t\tLOGUNIT_ASSERT(eh);\n\t\t\tLOGUNIT_ASSERT(!eh->errorReported());\n\t\t}\n};\n\nLOGUNIT_TEST_SUITE_REGISTRATION(SMTPAppenderTestCase);\n\n",
    "chunks": [
      {
        "chunk_id": "doc_83_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_83_chunk_1",
        "original_index": 1,
        "content": "#define LOG4CXX_TEST 1\n#include <log4cxx/private/log4cxx_private.h>\n\n#include <log4cxx/net/smtpappender.h>\n#include \"../appenderskeletontestcase.h\"\n#include <log4cxx/xml/domconfigurator.h>\n#include <log4cxx/logmanager.h>\n#include <log4cxx/simplelayout.h>\n#include <log4cxx/helpers/onlyonceerrorhandler.h>\n\nnamespace LOG4CXX_NS\n{\nnamespace net\n{\n\nclass MockTriggeringEventEvaluator :\n\tpublic virtual spi::TriggeringEventEvaluator\n{\n\tpublic:\n\t\tDECLARE_LOG4CXX_OBJECT(MockTriggeringEventEvaluator)\n\t\tBEGIN_LOG4CXX_CAST_MAP()\n\t\tLOG4CXX_CAST_ENTRY(MockTriggeringEventEvaluator)\n\t\tLOG4CXX_CAST_ENTRY(spi::TriggeringEventEvaluator)\n\t\tEND_LOG4CXX_CAST_MAP()\n\n"
      },
      {
        "chunk_id": "doc_83_chunk_2",
        "original_index": 2,
        "content": "\t\tMockTriggeringEventEvaluator()\n\t\t{\n\t\t}\n\n\t\tbool isTriggeringEvent(const spi::LoggingEventPtr& event) override\n\t\t{\n\t\t\treturn true;\n\t\t}\n\tprivate:\n\t\tMockTriggeringEventEvaluator(const MockTriggeringEventEvaluator&);\n\t\tMockTriggeringEventEvaluator& operator=(const MockTriggeringEventEvaluator&);\n};\n}\n}\n\nusing namespace log4cxx;\nusing namespace log4cxx::helpers;\nusing namespace log4cxx::net;\n\nIMPLEMENT_LOG4CXX_OBJECT(MockTriggeringEventEvaluator)\n\n"
      },
      {
        "chunk_id": "doc_83_chunk_3",
        "original_index": 3,
        "content": "\n/**\n   Unit tests of log4cxx::SocketAppender\n */\nclass SMTPAppenderTestCase : public AppenderSkeletonTestCase\n{\n\t\tLOGUNIT_TEST_SUITE(SMTPAppenderTestCase);\n\t\t//\n\t\t//    tests inherited from AppenderSkeletonTestCase\n\t\t//\n\t\tLOGUNIT_TEST(testDefaultThreshold);\n\t\tLOGUNIT_TEST(testSetOptionThreshold);\n\t\tLOGUNIT_TEST(testTrigger);\n\t\tLOGUNIT_TEST(testInvalid);\n//#define LOG4CXX_TEST_EMAIL_AND_SMTP_HOST_ARE_IN_ENVIRONMENT_VARIABLES\n#ifdef LOG4CXX_TEST_EMAIL_AND_SMTP_HOST_ARE_IN_ENVIRONMENT_VARIABLES\n\t\t// This test requires the following environment variables:\n\t\t// LOG4CXX_TEST_EMAIL_RECIPIENT - where the email is sent\n\t\t// LOG4CXX_TEST_SMTP_HOST_NAME - the email server\n\t\tLOGUNIT_TEST(testValid);\n#endif\n\t\tLOGUNIT_TEST_SUITE_END();\n\n"
      },
      {
        "chunk_id": "doc_83_chunk_4",
        "original_index": 4,
        "content": "\n\tpublic:\n\n\t\tAppenderSkeleton* createAppenderSkeleton() const\n\t\t{\n\t\t\treturn new log4cxx::net::SMTPAppender();\n\t\t}\n\n\t\tvoid setUp()\n\t\t{\n\t\t}\n\n\t\tvoid tearDown()\n\t\t{\n\t\t\tLogManager::resetConfiguration();\n\t\t}\n\n\t\t/**\n\t\t * Tests that triggeringPolicy element will set evaluator.\n\t\t */\n\t\tvoid testTrigger()\n\t\t{\n\t\t\txml::DOMConfigurator::configure(\"input/xml/smtpAppender1.xml\");\n\t\t\tauto appender = log4cxx::cast<SMTPAppender>(Logger::getRootLogger()->getAppender(LOG4CXX_STR(\"A1\")));\n\t\t\tLOGUNIT_ASSERT(appender);\n\t\t\tauto evaluator = appender->getEvaluator();\n\t\t\tLOGUNIT_ASSERT(evaluator);\n\t\t\tLOGUNIT_ASSERT_EQUAL(true, evaluator->instanceof(MockTriggeringEventEvaluator::getStaticClass()));\n\t\t}\n\n"
      },
      {
        "chunk_id": "doc_83_chunk_5",
        "original_index": 5,
        "content": "\t\tvoid testInvalid()\n\t\t{\n\t\t\tauto appender = std::make_shared<SMTPAppender>();\n\t\t\tappender->setSMTPHost(LOG4CXX_STR(\"smtp.invalid\"));\n\t\t\tappender->setTo(LOG4CXX_STR(\"you@example.invalid\"));\n\t\t\tappender->setFrom(LOG4CXX_STR(\"me@example.invalid\"));\n\t\t\tappender->setLayout(std::make_shared<SimpleLayout>());\n\t\t\tPool p;\n\t\t\tappender->activateOptions(p);\n\t\t\tauto root = Logger::getRootLogger();\n\t\t\troot->addAppender(appender);\n\t\t\tLOG4CXX_INFO(root, \"Hello, World.\");\n\t\t\tLOG4CXX_ERROR(root, \"Sending Message\"); // The DefaultEvaluator should trigger e-mail generation\n\t\t\tauto eh = dynamic_cast<helpers::OnlyOnceErrorHandler*>(appender->getErrorHandler().get());\n\t\t\tLOGUNIT_ASSERT(eh);\n\t\t\tLOGUNIT_ASSERT(eh->errorReported());\n\t\t}\n\n"
      },
      {
        "chunk_id": "doc_83_chunk_6",
        "original_index": 6,
        "content": "\n\t\tvoid testValid()\n\t\t{\n\t\t\txml::DOMConfigurator::configure(\"input/xml/smtpAppenderValid.xml\");\n\t\t\tauto root = Logger::getRootLogger();\n\t\t\tLOG4CXX_INFO(root, \"Hello, World.\\n\\nThis paragraph should be preceeded by a blank line.\");\n\n\t\t\tauto appender = log4cxx::cast<SMTPAppender>(root->getAppender(LOG4CXX_STR(\"A1\")));\n\t\t\tLOGUNIT_ASSERT(appender);\n\t\t\tauto eh = dynamic_cast<helpers::OnlyOnceErrorHandler*>(appender->getErrorHandler().get());\n\t\t\tLOGUNIT_ASSERT(eh);\n\t\t\tLOGUNIT_ASSERT(!eh->errorReported());\n\t\t}\n};\n\nLOGUNIT_TEST_SUITE_REGISTRATION(SMTPAppenderTestCase);\n\n"
      }
    ]
  },
  {
    "doc_id": "doc_84",
    "original_uuid": "652e911eecd9e07046e7e3dd91729064fca4abf1950dc96663a3f734b7673863",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n#include <log4cxx/logstring.h>\n#include <log4cxx/basicconfigurator.h>\n#include <log4cxx/patternlayout.h>\n#include <log4cxx/consoleappender.h>\n#include <log4cxx/logmanager.h>\n#include <log4cxx/logger.h>\n#include <log4cxx/helpers/widelife.h>\n\nusing namespace LOG4CXX_NS;\n\nvoid BasicConfigurator::configure(const LayoutPtr& layoutArg)\n{\n\tLogManager::getLoggerRepository()->setConfigured(true);\n\tauto layout = layoutArg;\n\tif (!layout)\n\t{\n\t\tstatic const helpers::WideLife<LogString> TTCC_CONVERSION_PATTERN(LOG4CXX_STR(\"%r [%t] %p %c %x - %m%n\"));\n\t\tlayout = std::make_shared<PatternLayout>(TTCC_CONVERSION_PATTERN);\n\t}\n\tauto appender = std::make_shared<ConsoleAppender>(layout);\n\tLogger::getRootLogger()->addAppender(appender);\n}\n\nvoid BasicConfigurator::configure(const AppenderPtr& appender)\n{\n\tLoggerPtr root = Logger::getRootLogger();\n\troot->addAppender(appender);\n}\n\nvoid BasicConfigurator::resetConfiguration()\n{\n\tLogManager::resetConfiguration();\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_84_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n"
      },
      {
        "chunk_id": "doc_84_chunk_1",
        "original_index": 1,
        "content": " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n#include <log4cxx/logstring.h>\n#include <log4cxx/basicconfigurator.h>\n#include <log4cxx/patternlayout.h>\n#include <log4cxx/consoleappender.h>\n#include <log4cxx/logmanager.h>\n#include <log4cxx/logger.h>\n#include <log4cxx/helpers/widelife.h>\n\nusing namespace LOG4CXX_NS;\n\n"
      },
      {
        "chunk_id": "doc_84_chunk_2",
        "original_index": 2,
        "content": "void BasicConfigurator::configure(const LayoutPtr& layoutArg)\n{\n\tLogManager::getLoggerRepository()->setConfigured(true);\n\tauto layout = layoutArg;\n\tif (!layout)\n\t{\n\t\tstatic const helpers::WideLife<LogString> TTCC_CONVERSION_PATTERN(LOG4CXX_STR(\"%r [%t] %p %c %x - %m%n\"));\n\t\tlayout = std::make_shared<PatternLayout>(TTCC_CONVERSION_PATTERN);\n\t}\n\tauto appender = std::make_shared<ConsoleAppender>(layout);\n\tLogger::getRootLogger()->addAppender(appender);\n}\n\nvoid BasicConfigurator::configure(const AppenderPtr& appender)\n{\n\tLoggerPtr root = Logger::getRootLogger();\n\troot->addAppender(appender);\n}\n\nvoid BasicConfigurator::resetConfiguration()\n{\n\tLogManager::resetConfiguration();\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_85",
    "original_uuid": "6649ef219cc071b0c0f28a358d32e0ddc8e9e09eeac6707326705f88e286d90a",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#include <log4cxx/log4cxx.h>\n/* Prevent error C2491: 'std::numpunct<_Elem>::id': definition of dllimport static data member not allowed */\n#if defined(_MSC_VER) && (LOG4CXX_UNICHAR_API || LOG4CXX_LOGCHAR_IS_UNICHAR)\n#define __FORCE_INSTANCE\n#endif\n#include <log4cxx/hexdump.h>\n#include <log4cxx/log4cxx.h>\n#include <sstream>\n#include <ios>\n#include <iomanip>\n#include <cctype>\n\nusing namespace LOG4CXX_NS;\n\ntypedef std::basic_stringstream<logchar> LogStream;\n\nLogString LOG4CXX_NS::hexdump(const void* bytes, uint32_t len, HexdumpFlags flags){\n\tLogString ret;\n\tconst uint8_t* bytes_u8 = static_cast<const uint8_t*>(bytes);\n\tLogStream sstream;\n#if LOG4CXX_LOGCHAR_IS_WCHAR\n\tconst wchar_t fill_char = L'0';\n\tconst wchar_t space_fill_char = L' ';\n#else\n\tconst logchar fill_char = '0';\n\tconst logchar space_fill_char = ' ';\n#endif\n\n\tif(flags & HexdumpFlags::AddStartingNewline){\n\t\tsstream << LOG4CXX_EOL;\n\t}\n\n\tfor(uint32_t offset = 0; offset < len; offset += 16){\n\t\tif(offset != 0){\n\t\t\tsstream << LOG4CXX_EOL;\n\t\t}\n\n\t\t// Print out the offset\n\t\tsstream << std::hex << std::setw(8) << std::setfill(fill_char) << offset << std::resetiosflags(std::ios_base::fmtflags(0));\n\n\t\tsstream << std::setw(0) << LOG4CXX_STR(\"  \");\n\n\t\t// Print out the first 8 bytes\n\t\tfor(int byte = 0; byte < 8; byte++){\n\t\t\tif(offset + byte >= len){\n\t\t\t\tsstream << LOG4CXX_STR(\"  \");\n\t\t\t\tif(byte != 8){\n\t\t\t\t\tsstream << LOG4CXX_STR(\" \");\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tsstream << std::hex << std::setw(2) << std::setfill(fill_char) << static_cast<int>(bytes_u8[offset + byte]) << std::resetiosflags(std::ios_base::fmtflags(0));\n\t\t\tsstream << std::setfill(space_fill_char);\n\t\t\tif(byte != 8){\n\t\t\t\tsstream << LOG4CXX_STR(\" \");\n\t\t\t}\n\t\t}\n\n\t\tsstream << LOG4CXX_STR(\" \");\n\n\t\t// Print out the last 8 bytes\n\t\tfor(int byte = 8; byte < 16; byte++){\n\t\t\tif(offset + byte >= len){\n\t\t\t\tsstream << LOG4CXX_STR(\"  \");\n\t\t\t\tif(byte != 15){\n\t\t\t\t\tsstream << LOG4CXX_STR(\" \");\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tsstream << std::hex << std::setw(2) << std::setfill(fill_char) << static_cast<int>(bytes_u8[offset + byte]) << std::resetiosflags(std::ios_base::fmtflags(0));\n\t\t\tif(byte != 15){\n\t\t\t\tsstream << LOG4CXX_STR(\" \");\n\t\t\t}\n\t\t}\n\n\t\t// Print out the ASCII text\n\t\tsstream << LOG4CXX_STR(\"  |\");\n\t\tfor(int byte = 0; byte < 16; byte++){\n\t\t\tif(offset + byte >= len){\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif(std::isprint(bytes_u8[offset + byte])){\n\t\t\t\tlogchar to_append = bytes_u8[offset + byte];\n\t\t\t\tsstream << to_append;\n\t\t\t}else{\n\t\t\t\tsstream << LOG4CXX_STR(\".\");\n\t\t\t}\n\t\t}\n\t\tsstream << LOG4CXX_STR(\"|\");\n\t}\n\n\tif(flags & HexdumpFlags::AddEndingNewline){\n\t\tsstream << LOG4CXX_EOL;\n\t}\n\n\treturn sstream.str();\n}\n",
    "chunks": [
      {
        "chunk_id": "doc_85_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_85_chunk_1",
        "original_index": 1,
        "content": "#include <log4cxx/log4cxx.h>\n/* Prevent error C2491: 'std::numpunct<_Elem>::id': definition of dllimport static data member not allowed */\n#if defined(_MSC_VER) && (LOG4CXX_UNICHAR_API || LOG4CXX_LOGCHAR_IS_UNICHAR)\n#define __FORCE_INSTANCE\n#endif\n#include <log4cxx/hexdump.h>\n#include <log4cxx/log4cxx.h>\n#include <sstream>\n#include <ios>\n#include <iomanip>\n#include <cctype>\n\nusing namespace LOG4CXX_NS;\n\ntypedef std::basic_stringstream<logchar> LogStream;\n\nLogString LOG4CXX_NS::hexdump(const void* bytes, uint32_t len, HexdumpFlags flags){\n\tLogString ret;\n\tconst uint8_t* bytes_u8 = static_cast<const uint8_t*>(bytes);\n\tLogStream sstream;\n#if LOG4CXX_LOGCHAR_IS_WCHAR\n\tconst wchar_t fill_char = L'0';\n\tconst wchar_t space_fill_char = L' ';\n#else\n\tconst logchar fill_char = '0';\n\tconst logchar space_fill_char = ' ';\n#endif\n\n"
      },
      {
        "chunk_id": "doc_85_chunk_2",
        "original_index": 2,
        "content": "\tif(flags & HexdumpFlags::AddStartingNewline){\n\t\tsstream << LOG4CXX_EOL;\n\t}\n\n\tfor(uint32_t offset = 0; offset < len; offset += 16){\n\t\tif(offset != 0){\n\t\t\tsstream << LOG4CXX_EOL;\n\t\t}\n\n\t\t// Print out the offset\n\t\tsstream << std::hex << std::setw(8) << std::setfill(fill_char) << offset << std::resetiosflags(std::ios_base::fmtflags(0));\n\n\t\tsstream << std::setw(0) << LOG4CXX_STR(\"  \");\n\n\t\t// Print out the first 8 bytes\n\t\tfor(int byte = 0; byte < 8; byte++){\n\t\t\tif(offset + byte >= len){\n\t\t\t\tsstream << LOG4CXX_STR(\"  \");\n\t\t\t\tif(byte != 8){\n\t\t\t\t\tsstream << LOG4CXX_STR(\" \");\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tsstream << std::hex << std::setw(2) << std::setfill(fill_char) << static_cast<int>(bytes_u8[offset + byte]) << std::resetiosflags(std::ios_base::fmtflags(0));\n\t\t\tsstream << std::setfill(space_fill_char);\n\t\t\tif(byte != 8){\n\t\t\t\tsstream << LOG4CXX_STR(\" \");\n\t\t\t}\n\t\t}\n\n"
      },
      {
        "chunk_id": "doc_85_chunk_3",
        "original_index": 3,
        "content": "\t\tsstream << LOG4CXX_STR(\" \");\n\n\t\t// Print out the last 8 bytes\n\t\tfor(int byte = 8; byte < 16; byte++){\n\t\t\tif(offset + byte >= len){\n\t\t\t\tsstream << LOG4CXX_STR(\"  \");\n\t\t\t\tif(byte != 15){\n\t\t\t\t\tsstream << LOG4CXX_STR(\" \");\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tsstream << std::hex << std::setw(2) << std::setfill(fill_char) << static_cast<int>(bytes_u8[offset + byte]) << std::resetiosflags(std::ios_base::fmtflags(0));\n\t\t\tif(byte != 15){\n\t\t\t\tsstream << LOG4CXX_STR(\" \");\n\t\t\t}\n\t\t}\n\n\t\t// Print out the ASCII text\n\t\tsstream << LOG4CXX_STR(\"  |\");\n\t\tfor(int byte = 0; byte < 16; byte++){\n\t\t\tif(offset + byte >= len){\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif(std::isprint(bytes_u8[offset + byte])){\n\t\t\t\tlogchar to_append = bytes_u8[offset + byte];\n\t\t\t\tsstream << to_append;\n\t\t\t}else{\n\t\t\t\tsstream << LOG4CXX_STR(\".\");\n\t\t\t}\n\t\t}\n\t\tsstream << LOG4CXX_STR(\"|\");\n\t}\n\n\tif(flags & HexdumpFlags::AddEndingNewline){\n\t\tsstream << LOG4CXX_EOL;\n\t}\n\n\treturn sstream.str();\n}\n"
      }
    ]
  },
  {
    "doc_id": "doc_86",
    "original_uuid": "b06cf4af0fab3962648faef939278c1e4865a64d3a8971230968e55e178a58ac",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n#include <log4cxx/filter/denyallfilter.h>\n#include <log4cxx/logger.h>\n#include <log4cxx/spi/filter.h>\n#include <log4cxx/spi/loggingevent.h>\n#include \"../logunit.h\"\n\nusing namespace log4cxx;\nusing namespace log4cxx::filter;\nusing namespace log4cxx::spi;\nusing namespace log4cxx::helpers;\n\n\n/**\n * Unit tests for DenyAllFilter.\n */\nLOGUNIT_CLASS(DenyAllFilterTest)\n{\n\tLOGUNIT_TEST_SUITE(DenyAllFilterTest);\n\tLOGUNIT_TEST(test1);\n\tLOGUNIT_TEST_SUITE_END();\n\npublic:\n\t/**\n\t * Check that DenyAllFilter.decide() returns Filter.DENY.\n\t */\n\tvoid test1()\n\t{\n\t\tLoggingEventPtr event(new LoggingEvent(\n\t\t\t\tLOG4CXX_STR(\"org.apache.log4j.filter.DenyAllFilterTest\"),\n\t\t\t\tLevel::getInfo(),\n\t\t\t\tLOG4CXX_STR(\"Hello, World\"),\n\t\t\t\tLOG4CXX_LOCATION));\n\t\tFilterPtr filter(new DenyAllFilter());\n\t\tPool p;\n\t\tfilter->activateOptions(p);\n\t\tLOGUNIT_ASSERT_EQUAL(Filter::DENY, filter->decide(event));\n\t}\n\n};\n\nLOGUNIT_TEST_SUITE_REGISTRATION(DenyAllFilterTest);\n\n\n",
    "chunks": [
      {
        "chunk_id": "doc_86_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n#include <log4cxx/filter/denyallfilter.h>\n#include <log4cxx/logger.h>\n#include <log4cxx/spi/filter.h>\n#include <log4cxx/spi/loggingevent.h>\n#include \"../logunit.h\"\n\n"
      },
      {
        "chunk_id": "doc_86_chunk_1",
        "original_index": 1,
        "content": "using namespace log4cxx;\nusing namespace log4cxx::filter;\nusing namespace log4cxx::spi;\nusing namespace log4cxx::helpers;\n\n\n/**\n * Unit tests for DenyAllFilter.\n */\nLOGUNIT_CLASS(DenyAllFilterTest)\n{\n\tLOGUNIT_TEST_SUITE(DenyAllFilterTest);\n\tLOGUNIT_TEST(test1);\n\tLOGUNIT_TEST_SUITE_END();\n\npublic:\n\t/**\n\t * Check that DenyAllFilter.decide() returns Filter.DENY.\n\t */\n\tvoid test1()\n\t{\n\t\tLoggingEventPtr event(new LoggingEvent(\n\t\t\t\tLOG4CXX_STR(\"org.apache.log4j.filter.DenyAllFilterTest\"),\n\t\t\t\tLevel::getInfo(),\n\t\t\t\tLOG4CXX_STR(\"Hello, World\"),\n\t\t\t\tLOG4CXX_LOCATION));\n\t\tFilterPtr filter(new DenyAllFilter());\n\t\tPool p;\n\t\tfilter->activateOptions(p);\n\t\tLOGUNIT_ASSERT_EQUAL(Filter::DENY, filter->decide(event));\n\t}\n\n};\n\nLOGUNIT_TEST_SUITE_REGISTRATION(DenyAllFilterTest);\n\n\n"
      }
    ]
  },
  {
    "doc_id": "doc_87",
    "original_uuid": "e884e6a9a3f013496b4c494449285d20f4832216ad5ed955e0189018361d8c76",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n#include \"logunit.h\"\n#include <log4cxx/logger.h>\n#include <log4cxx/simplelayout.h>\n#include <log4cxx/fileappender.h>\n#include <log4cxx/helpers/absolutetimedateformat.h>\n\n#include \"util/compare.h\"\n#include \"util/transformer.h\"\n#include \"util/linenumberfilter.h\"\n#include \"util/controlfilter.h\"\n#include \"util/absolutedateandtimefilter.h\"\n#include \"util/threadfilter.h\"\n#include <log4cxx/file.h>\n#include <iostream>\n#include <log4cxx/helpers/pool.h>\n#include <apr_strings.h>\n#include \"testchar.h\"\n#include <log4cxx/spi/loggerrepository.h>\n#include <log4cxx/helpers/stringhelper.h>\n#include <apr_strings.h>\n\nusing namespace log4cxx;\nusing namespace log4cxx::helpers;\n\nLOGUNIT_CLASS(MinimumTestCase)\n{\n\tLOGUNIT_TEST_SUITE(MinimumTestCase);\n\tLOGUNIT_TEST(simple);\n\tLOGUNIT_TEST_SUITE_END();\n\npublic:\n\tvoid setUp()\n\t{\n\t\troot = Logger::getRootLogger();\n\t\troot->removeAllAppenders();\n\t}\n\n\tvoid tearDown()\n\t{\n\t\tauto rep = root->getLoggerRepository();\n\n\t\tif (rep)\n\t\t{\n\t\t\trep->resetConfiguration();\n\t\t}\n\t}\n\n\tvoid simple()\n\t{\n\t\tLayoutPtr layout = LayoutPtr(new SimpleLayout());\n\t\tAppenderPtr appender = FileAppenderPtr(new FileAppender(layout, LOG4CXX_STR(\"output/simple\"), false));\n\t\troot->addAppender(appender);\n\t\tcommon();\n\n\t\tLOGUNIT_ASSERT(Compare::compare(LOG4CXX_FILE(\"output/simple\"), LOG4CXX_FILE(\"witness/simple\")));\n\t}\n\n\tstd::string createMessage(int i, Pool & pool)\n\t{\n\t\tstd::string msg(\"Message \");\n\t\tmsg.append(pool.itoa(i));\n\t\treturn msg;\n\t}\n\n\tvoid common()\n\t{\n\t\tint i = 0;\n\n\t\t// In the lines below, the logger names are chosen as an aid in\n\t\t// remembering their level values. In general, the logger names\n\t\t// have no bearing to level values.\n\t\tLoggerPtr ERRlogger = Logger::getLogger(LOG4CXX_TEST_STR(\"ERR\"));\n\t\tERRlogger->setLevel(Level::getError());\n\n\t\tLoggerPtr INF = Logger::getLogger(LOG4CXX_TEST_STR(\"INF\"));\n\t\tINF->setLevel(Level::getInfo());\n\n\t\tLoggerPtr INF_ERR = Logger::getLogger(LOG4CXX_TEST_STR(\"INF.ERR\"));\n\t\tINF_ERR->setLevel(Level::getError());\n\n\t\tLoggerPtr DEB = Logger::getLogger(LOG4CXX_TEST_STR(\"DEB\"));\n\t\tDEB->setLevel(Level::getDebug());\n\n\t\t// Note: categories with undefined level\n\t\tLoggerPtr INF_UNDEF = Logger::getLogger(LOG4CXX_TEST_STR(\"INF.UNDEF\"));\n\t\tLoggerPtr INF_ERR_UNDEF = Logger::getLogger(LOG4CXX_TEST_STR(\"INF.ERR.UNDEF\"));\n\t\tLoggerPtr UNDEF = Logger::getLogger(LOG4CXX_TEST_STR(\"UNDEF\"));\n\n\t\tstd::string msg(\"Message \");\n\n\t\tPool pool;\n\n\t\t// These should all log.----------------------------\n\t\tLOG4CXX_FATAL(ERRlogger, createMessage(i, pool));\n\t\ti++; //0\n\t\tLOG4CXX_ERROR(ERRlogger, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_FATAL(INF, createMessage(i, pool));\n\t\ti++; // 2\n\t\tLOG4CXX_ERROR(INF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_WARN(INF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(INF, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_FATAL(INF_UNDEF, createMessage(i, pool));\n\t\ti++; //6\n\t\tLOG4CXX_ERROR(INF_UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_WARN(INF_UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(INF_UNDEF, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_FATAL(INF_ERR, createMessage(i, pool));\n\t\ti++; // 10\n\t\tLOG4CXX_ERROR(INF_ERR, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_FATAL(INF_ERR_UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_ERROR(INF_ERR_UNDEF, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_FATAL(DEB, createMessage(i, pool));\n\t\ti++; //14\n\t\tLOG4CXX_ERROR(DEB, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_WARN(DEB, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(DEB, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(DEB, createMessage(i, pool));\n\t\ti++;\n\n\t\t// defaultLevel=DEBUG\n\t\tLOG4CXX_FATAL(UNDEF, createMessage(i, pool));\n\t\ti++; // 19\n\t\tLOG4CXX_ERROR(UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_WARN(UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(UNDEF, createMessage(i, pool));\n\t\ti++;\n\n\t\t// -------------------------------------------------\n\t\t// The following should not log\n\t\tLOG4CXX_WARN(ERRlogger, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(ERRlogger, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(ERRlogger, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_DEBUG(INF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(INF_UNDEF, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_WARN(INF_ERR, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(INF_ERR, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(INF_ERR, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_WARN(INF_ERR_UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(INF_ERR_UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(INF_ERR_UNDEF, createMessage(i, pool));\n\t\ti++;\n\n\t\t// -------------------------------------------------\n\t\tLOG4CXX_INFO(INF, LOG4CXX_TEST_STR(\"Messages should bear numbers 0 through 23.\"));\n\t}\n\n\tLoggerPtr root;\n\tLoggerPtr logger;\n\nprivate:\n\tstatic const File FILTERED;\n};\n\n\nconst File MinimumTestCase::FILTERED(\"output/minimumfiltered\");\n\n\nLOGUNIT_TEST_SUITE_REGISTRATION(MinimumTestCase);\n",
    "chunks": [
      {
        "chunk_id": "doc_87_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n#include \"logunit.h\"\n#include <log4cxx/logger.h>\n#include <log4cxx/simplelayout.h>\n#include <log4cxx/fileappender.h>\n#include <log4cxx/helpers/absolutetimedateformat.h>\n\n"
      },
      {
        "chunk_id": "doc_87_chunk_1",
        "original_index": 1,
        "content": "#include \"util/compare.h\"\n#include \"util/transformer.h\"\n#include \"util/linenumberfilter.h\"\n#include \"util/controlfilter.h\"\n#include \"util/absolutedateandtimefilter.h\"\n#include \"util/threadfilter.h\"\n#include <log4cxx/file.h>\n#include <iostream>\n#include <log4cxx/helpers/pool.h>\n#include <apr_strings.h>\n#include \"testchar.h\"\n#include <log4cxx/spi/loggerrepository.h>\n#include <log4cxx/helpers/stringhelper.h>\n#include <apr_strings.h>\n\nusing namespace log4cxx;\nusing namespace log4cxx::helpers;\n\nLOGUNIT_CLASS(MinimumTestCase)\n{\n\tLOGUNIT_TEST_SUITE(MinimumTestCase);\n\tLOGUNIT_TEST(simple);\n\tLOGUNIT_TEST_SUITE_END();\n\npublic:\n\tvoid setUp()\n\t{\n\t\troot = Logger::getRootLogger();\n\t\troot->removeAllAppenders();\n\t}\n\n\tvoid tearDown()\n\t{\n\t\tauto rep = root->getLoggerRepository();\n\n\t\tif (rep)\n\t\t{\n\t\t\trep->resetConfiguration();\n\t\t}\n\t}\n\n"
      },
      {
        "chunk_id": "doc_87_chunk_2",
        "original_index": 2,
        "content": "\tvoid simple()\n\t{\n\t\tLayoutPtr layout = LayoutPtr(new SimpleLayout());\n\t\tAppenderPtr appender = FileAppenderPtr(new FileAppender(layout, LOG4CXX_STR(\"output/simple\"), false));\n\t\troot->addAppender(appender);\n\t\tcommon();\n\n\t\tLOGUNIT_ASSERT(Compare::compare(LOG4CXX_FILE(\"output/simple\"), LOG4CXX_FILE(\"witness/simple\")));\n\t}\n\n\tstd::string createMessage(int i, Pool & pool)\n\t{\n\t\tstd::string msg(\"Message \");\n\t\tmsg.append(pool.itoa(i));\n\t\treturn msg;\n\t}\n\n\tvoid common()\n\t{\n\t\tint i = 0;\n\n\t\t// In the lines below, the logger names are chosen as an aid in\n\t\t// remembering their level values. In general, the logger names\n\t\t// have no bearing to level values.\n\t\tLoggerPtr ERRlogger = Logger::getLogger(LOG4CXX_TEST_STR(\"ERR\"));\n\t\tERRlogger->setLevel(Level::getError());\n\n"
      },
      {
        "chunk_id": "doc_87_chunk_3",
        "original_index": 3,
        "content": "\t\tLoggerPtr INF = Logger::getLogger(LOG4CXX_TEST_STR(\"INF\"));\n\t\tINF->setLevel(Level::getInfo());\n\n\t\tLoggerPtr INF_ERR = Logger::getLogger(LOG4CXX_TEST_STR(\"INF.ERR\"));\n\t\tINF_ERR->setLevel(Level::getError());\n\n\t\tLoggerPtr DEB = Logger::getLogger(LOG4CXX_TEST_STR(\"DEB\"));\n\t\tDEB->setLevel(Level::getDebug());\n\n\t\t// Note: categories with undefined level\n\t\tLoggerPtr INF_UNDEF = Logger::getLogger(LOG4CXX_TEST_STR(\"INF.UNDEF\"));\n\t\tLoggerPtr INF_ERR_UNDEF = Logger::getLogger(LOG4CXX_TEST_STR(\"INF.ERR.UNDEF\"));\n\t\tLoggerPtr UNDEF = Logger::getLogger(LOG4CXX_TEST_STR(\"UNDEF\"));\n\n"
      },
      {
        "chunk_id": "doc_87_chunk_4",
        "original_index": 4,
        "content": "\t\tstd::string msg(\"Message \");\n\n\t\tPool pool;\n\n\t\t// These should all log.----------------------------\n\t\tLOG4CXX_FATAL(ERRlogger, createMessage(i, pool));\n\t\ti++; //0\n\t\tLOG4CXX_ERROR(ERRlogger, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_FATAL(INF, createMessage(i, pool));\n\t\ti++; // 2\n\t\tLOG4CXX_ERROR(INF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_WARN(INF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(INF, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_FATAL(INF_UNDEF, createMessage(i, pool));\n\t\ti++; //6\n\t\tLOG4CXX_ERROR(INF_UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_WARN(INF_UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(INF_UNDEF, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_FATAL(INF_ERR, createMessage(i, pool));\n\t\ti++; // 10\n\t\tLOG4CXX_ERROR(INF_ERR, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_FATAL(INF_ERR_UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_ERROR(INF_ERR_UNDEF, createMessage(i, pool));\n\t\ti++;\n\n"
      },
      {
        "chunk_id": "doc_87_chunk_5",
        "original_index": 5,
        "content": "\t\tLOG4CXX_FATAL(DEB, createMessage(i, pool));\n\t\ti++; //14\n\t\tLOG4CXX_ERROR(DEB, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_WARN(DEB, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(DEB, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(DEB, createMessage(i, pool));\n\t\ti++;\n\n\t\t// defaultLevel=DEBUG\n\t\tLOG4CXX_FATAL(UNDEF, createMessage(i, pool));\n\t\ti++; // 19\n\t\tLOG4CXX_ERROR(UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_WARN(UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(UNDEF, createMessage(i, pool));\n\t\ti++;\n\n\t\t// -------------------------------------------------\n\t\t// The following should not log\n\t\tLOG4CXX_WARN(ERRlogger, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(ERRlogger, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(ERRlogger, createMessage(i, pool));\n\t\ti++;\n\n\t\tLOG4CXX_DEBUG(INF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(INF_UNDEF, createMessage(i, pool));\n\t\ti++;\n\n"
      },
      {
        "chunk_id": "doc_87_chunk_6",
        "original_index": 6,
        "content": "\t\tLOG4CXX_WARN(INF_ERR, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(INF_ERR, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(INF_ERR, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_WARN(INF_ERR_UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_INFO(INF_ERR_UNDEF, createMessage(i, pool));\n\t\ti++;\n\t\tLOG4CXX_DEBUG(INF_ERR_UNDEF, createMessage(i, pool));\n\t\ti++;\n\n\t\t// -------------------------------------------------\n\t\tLOG4CXX_INFO(INF, LOG4CXX_TEST_STR(\"Messages should bear numbers 0 through 23.\"));\n\t}\n\n\tLoggerPtr root;\n\tLoggerPtr logger;\n\nprivate:\n\tstatic const File FILTERED;\n};\n\n\nconst File MinimumTestCase::FILTERED(\"output/minimumfiltered\");\n\n\nLOGUNIT_TEST_SUITE_REGISTRATION(MinimumTestCase);\n"
      }
    ]
  },
  {
    "doc_id": "doc_88",
    "original_uuid": "0726f860e5f7359166e66f5ae80e27f5d0429fbb33e4f4d5ed514d30192e622b",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#ifndef _LOG4CXX_PATTERN_NDC_PATTERN_CONVERTER\n#define _LOG4CXX_PATTERN_NDC_PATTERN_CONVERTER\n\n#include <log4cxx/pattern/loggingeventpatternconverter.h>\n\nnamespace LOG4CXX_NS\n{\nnamespace pattern\n{\n\n\n/**\n * Return the event's NDC in a StringBuffer.\n *\n *\n *\n */\nclass LOG4CXX_EXPORT NDCPatternConverter : public LoggingEventPatternConverter\n{\n\tpublic:\n\t\tDECLARE_LOG4CXX_PATTERN(NDCPatternConverter)\n\t\tBEGIN_LOG4CXX_CAST_MAP()\n\t\tLOG4CXX_CAST_ENTRY(NDCPatternConverter)\n\t\tLOG4CXX_CAST_ENTRY_CHAIN(LoggingEventPatternConverter)\n\t\tEND_LOG4CXX_CAST_MAP()\n\n\t\tNDCPatternConverter();\n\n\t\t/**\n\t\t * Obtains an instance of NDCPatternConverter.\n\t\t * @param options options, may be null.\n\t\t * @return instance of NDCPatternConverter.\n\t\t */\n\t\tstatic PatternConverterPtr newInstance(\n\t\t\tconst std::vector<LogString>& options);\n\n\t\tusing LoggingEventPatternConverter::format;\n\n\t\tvoid format(const spi::LoggingEventPtr& event,\n\t\t\tLogString& toAppendTo,\n\t\t\thelpers::Pool& p) const override;\n};\n}\n}\n#endif\n",
    "chunks": [
      {
        "chunk_id": "doc_88_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_88_chunk_1",
        "original_index": 1,
        "content": "#ifndef _LOG4CXX_PATTERN_NDC_PATTERN_CONVERTER\n#define _LOG4CXX_PATTERN_NDC_PATTERN_CONVERTER\n\n#include <log4cxx/pattern/loggingeventpatternconverter.h>\n\nnamespace LOG4CXX_NS\n{\nnamespace pattern\n{\n\n\n/**\n * Return the event's NDC in a StringBuffer.\n *\n *\n *\n */\nclass LOG4CXX_EXPORT NDCPatternConverter : public LoggingEventPatternConverter\n{\n\tpublic:\n\t\tDECLARE_LOG4CXX_PATTERN(NDCPatternConverter)\n\t\tBEGIN_LOG4CXX_CAST_MAP()\n\t\tLOG4CXX_CAST_ENTRY(NDCPatternConverter)\n\t\tLOG4CXX_CAST_ENTRY_CHAIN(LoggingEventPatternConverter)\n\t\tEND_LOG4CXX_CAST_MAP()\n\n\t\tNDCPatternConverter();\n\n\t\t/**\n\t\t * Obtains an instance of NDCPatternConverter.\n\t\t * @param options options, may be null.\n\t\t * @return instance of NDCPatternConverter.\n\t\t */\n\t\tstatic PatternConverterPtr newInstance(\n\t\t\tconst std::vector<LogString>& options);\n\n\t\tusing LoggingEventPatternConverter::format;\n\n\t\tvoid format(const spi::LoggingEventPtr& event,\n\t\t\tLogString& toAppendTo,\n\t\t\thelpers::Pool& p) const override;\n};\n}\n}\n#endif\n"
      }
    ]
  },
  {
    "doc_id": "doc_89",
    "original_uuid": "fa92d94e026aa09f1ac535418c60e3f3b20d02149a0469d4abdeea08f280f733",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n#include \"logunit.h\"\n#include \"testchar.h\"\n#include \"util/compare.h\"\n#include \"util/transformer.h\"\n#include \"util/absolutedateandtimefilter.h\"\n#include \"util/iso8601filter.h\"\n#include \"util/absolutetimefilter.h\"\n#include \"util/relativetimefilter.h\"\n#include \"util/controlfilter.h\"\n#include \"util/threadfilter.h\"\n#include \"util/linenumberfilter.h\"\n#include \"util/filenamefilter.h\"\n#include \"vectorappender.h\"\n#include <log4cxx/fmtlayout.h>\n#include <log4cxx/propertyconfigurator.h>\n#include <log4cxx/helpers/date.h>\n#include <log4cxx/spi/loggingevent.h>\n#include <iostream>\n#include <iomanip>\n\n#define REGEX_STR(x) x\n#define PAT0 REGEX_STR(\"\\\\[[0-9A-FXx]*]\\\\ (DEBUG|INFO|WARN|ERROR|FATAL) .* - Message [0-9]\\\\{1,2\\\\}\")\n#define PAT1 ISO8601_PAT REGEX_STR(\" \") PAT0\n#define PAT2 ABSOLUTE_DATE_AND_TIME_PAT REGEX_STR(\" \") PAT0\n#define PAT3 ABSOLUTE_TIME_PAT REGEX_STR(\" \") PAT0\n#define PAT4 RELATIVE_TIME_PAT REGEX_STR(\" \") PAT0\n#define PAT5 REGEX_STR(\"\\\\[[0-9A-FXx]*]\\\\ (DEBUG|INFO|WARN|ERROR|FATAL) .* : Message [0-9]\\\\{1,2\\\\}\")\n#define PAT6 REGEX_STR(\"\\\\[[0-9A-FXx]*]\\\\ (DEBUG|INFO |WARN |ERROR|FATAL) .*patternlayouttest.cpp\\\\([0-9]\\\\{1,4\\\\}\\\\): Message [0-9]\\\\{1,3\\\\}\")\n#define PAT11a REGEX_STR(\"^(DEBUG|INFO |WARN |ERROR|FATAL) \\\\[[0-9A-FXx]*]\\\\ log4j.PatternLayoutTest: Message [0-9]\\\\{1,2\\\\}\")\n#define PAT11b REGEX_STR(\"^(DEBUG|INFO |WARN |ERROR|FATAL) \\\\[[0-9A-FXx]*]\\\\ root: Message [0-9]\\\\{1,2\\\\}\")\n#define PAT12 REGEX_STR(\"^\\\\[[0-9A-FXx]*]\\\\ (DEBUG|INFO |WARN |ERROR|FATAL) \")\\\n\tREGEX_STR(\".*patternlayouttest.cpp([0-9]\\\\{1,4\\\\}): \")\\\n\tREGEX_STR(\"Message [0-9]\\\\{1,2\\\\}\")\n#define PAT_MDC_1 REGEX_STR(\"\")\n\nusing namespace log4cxx;\nusing namespace log4cxx::helpers;\n\nLOGUNIT_CLASS(FMTTestCase)\n{\n\tLOGUNIT_TEST_SUITE(FMTTestCase);\n\tLOGUNIT_TEST(test1);\n\tLOGUNIT_TEST(test1_expanded);\n\tLOGUNIT_TEST(test10);\n//\tLOGUNIT_TEST(test_date);\n\tLOGUNIT_TEST_SUITE_END();\n\n\tLoggerPtr root;\n\tLoggerPtr logger;\n\npublic:\n\tvoid setUp()\n\t{\n\t\troot = Logger::getRootLogger();\n\t\tMDC::clear();\n\t\tlogger = Logger::getLogger(LOG4CXX_TEST_STR(\"java.org.apache.log4j.PatternLayoutTest\"));\n\t}\n\n\tvoid tearDown()\n\t{\n\t\tMDC::clear();\n\t\tauto rep = root->getLoggerRepository();\n\n\t\tif (rep)\n\t\t{\n\t\t\trep->resetConfiguration();\n\t\t}\n\t}\n\n\tvoid test1()\n\t{\n\t\tPropertyConfigurator::configure(LOG4CXX_FILE(\"input/fmtLayout1.properties\"));\n\t\tcommon();\n\t\tLOGUNIT_ASSERT(Compare::compare(TEMP, LOG4CXX_FILE(\"witness/patternLayout.1\")));\n\t}\n\n\tvoid test1_expanded()\n\t{\n\t\tPropertyConfigurator::configure(LOG4CXX_FILE(\"input/fmtLayout1_expanded.properties\"));\n\t\tcommon();\n\t\tLOGUNIT_ASSERT(Compare::compare(TEMP, LOG4CXX_FILE(\"witness/patternLayout.1\")));\n\t}\n\n\tvoid test10()\n\t{\n\t\tPropertyConfigurator::configure(LOG4CXX_FILE(\"input/fmtLayout10.properties\"));\n\t\tcommon();\n\n\t\tControlFilter filter1;\n\t\tfilter1 << PAT6;\n\t\tThreadFilter filter2;\n\t\tLineNumberFilter filter3;\n\t\tFilenameFilter filenameFilter(__FILE__, \"patternlayouttest.cpp\");\n\n\n\t\tstd::vector<Filter*> filters;\n\t\tfilters.push_back(&filenameFilter);\n\t\tfilters.push_back(&filter1);\n\t\tfilters.push_back(&filter2);\n\t\tfilters.push_back(&filter3);\n\n\n\t\ttry\n\t\t{\n\t\t\tTransformer::transform(TEMP, FILTERED, filters);\n\t\t}\n\t\tcatch (UnexpectedFormatException& e)\n\t\t{\n\t\t\tstd::cout << \"UnexpectedFormatException :\" << e.what() << std::endl;\n\t\t\tthrow;\n\t\t}\n\n\t\tLOGUNIT_ASSERT(Compare::compare(FILTERED, LOG4CXX_FILE(\"witness/patternLayout.10\")));\n\t}\n\n\tvoid test_date(){\n\t\tstd::tm tm = {};\n\t\tstd::stringstream ss(\"2013-04-11 08:35:34\");\n\t\tss >> std::get_time(&tm, \"%Y-%m-%d %H:%M:%S\");\n\t\tauto tp = std::chrono::system_clock::from_time_t(std::mktime(&tm));\n\t\tuint64_t micros = std::chrono::duration_cast<std::chrono::microseconds>(tp.time_since_epoch()).count();\n\n\t\tlog4cxx::helpers::Date::setGetCurrentTimeFunction([micros](){\n\t\t\treturn micros;\n\t\t});\n\n\t\tlog4cxx::spi::LoggingEventPtr logEvt = std::make_shared<log4cxx::spi::LoggingEvent>(LOG4CXX_STR(\"foo\"),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t Level::getInfo(),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t LOG4CXX_STR(\"A Message\"),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t log4cxx::spi::LocationInfo::getLocationUnavailable());\n\t\tFMTLayout layout(LOG4CXX_STR(\"{d:%Y-%m-%d %H:%M:%S} {message}\"));\n\t\tLogString output;\n\t\tlog4cxx::helpers::Pool pool;\n\t\tlayout.format( output, logEvt, pool);\n\n\t\tlog4cxx::helpers::Date::setGetCurrentTimeFunction(nullptr);\n\n\t\tLOGUNIT_ASSERT_EQUAL(LOG4CXX_STR(\"2013-04-11 09:35:34 A Message\"), output);\n\t}\n\n\tstd::string createMessage(Pool & pool, int i)\n\t{\n\t\tstd::string msg(\"Message \");\n\t\tmsg.append(pool.itoa(i));\n\t\treturn msg;\n\t}\n\n\tvoid common()\n\t{\n\t\tint i = -1;\n\n\t\tPool pool;\n\n\n\t\tLOG4CXX_DEBUG(logger, createMessage(pool, ++i));\n\t\tLOG4CXX_DEBUG(root, createMessage(pool, i));\n\n\t\tLOG4CXX_INFO(logger, createMessage(pool, ++i));\n\t\tLOG4CXX_INFO(root, createMessage(pool, i));\n\n\t\tLOG4CXX_WARN(logger, createMessage(pool, ++i));\n\t\tLOG4CXX_WARN(root, createMessage(pool, i));\n\n\t\tLOG4CXX_ERROR(logger, createMessage(pool, ++i));\n\t\tLOG4CXX_ERROR(root, createMessage(pool, i));\n\n\t\tLOG4CXX_FATAL(logger, createMessage(pool, ++i));\n\t\tLOG4CXX_FATAL(root, createMessage(pool, i));\n\t}\n\n\tprivate:\n\t\tstatic const LogString FILTERED;\n\t\tstatic const LogString TEMP;\n\n};\n\nconst LogString FMTTestCase::TEMP(LOG4CXX_STR(\"output/fmtlayout\"));\nconst LogString FMTTestCase::FILTERED(LOG4CXX_STR(\"output/fmtlayoutfiltered\"));\n\n\nLOGUNIT_TEST_SUITE_REGISTRATION(FMTTestCase);\n",
    "chunks": [
      {
        "chunk_id": "doc_89_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n#include \"logunit.h\"\n#include \"testchar.h\"\n"
      },
      {
        "chunk_id": "doc_89_chunk_1",
        "original_index": 1,
        "content": "#include \"util/compare.h\"\n#include \"util/transformer.h\"\n#include \"util/absolutedateandtimefilter.h\"\n#include \"util/iso8601filter.h\"\n#include \"util/absolutetimefilter.h\"\n#include \"util/relativetimefilter.h\"\n#include \"util/controlfilter.h\"\n#include \"util/threadfilter.h\"\n#include \"util/linenumberfilter.h\"\n#include \"util/filenamefilter.h\"\n#include \"vectorappender.h\"\n#include <log4cxx/fmtlayout.h>\n#include <log4cxx/propertyconfigurator.h>\n#include <log4cxx/helpers/date.h>\n#include <log4cxx/spi/loggingevent.h>\n#include <iostream>\n#include <iomanip>\n\n#define REGEX_STR(x) x\n#define PAT0 REGEX_STR(\"\\\\[[0-9A-FXx]*]\\\\ (DEBUG|INFO|WARN|ERROR|FATAL) .* - Message [0-9]\\\\{1,2\\\\}\")\n#define PAT1 ISO8601_PAT REGEX_STR(\" \") PAT0\n#define PAT2 ABSOLUTE_DATE_AND_TIME_PAT REGEX_STR(\" \") PAT0\n#define PAT3 ABSOLUTE_TIME_PAT REGEX_STR(\" \") PAT0\n#define PAT4 RELATIVE_TIME_PAT REGEX_STR(\" \") PAT0\n#define PAT5 REGEX_STR(\"\\\\[[0-9A-FXx]*]\\\\ (DEBUG|INFO|WARN|ERROR|FATAL) .* : Message [0-9]\\\\{1,2\\\\}\")\n"
      },
      {
        "chunk_id": "doc_89_chunk_2",
        "original_index": 2,
        "content": "#define PAT6 REGEX_STR(\"\\\\[[0-9A-FXx]*]\\\\ (DEBUG|INFO |WARN |ERROR|FATAL) .*patternlayouttest.cpp\\\\([0-9]\\\\{1,4\\\\}\\\\): Message [0-9]\\\\{1,3\\\\}\")\n#define PAT11a REGEX_STR(\"^(DEBUG|INFO |WARN |ERROR|FATAL) \\\\[[0-9A-FXx]*]\\\\ log4j.PatternLayoutTest: Message [0-9]\\\\{1,2\\\\}\")\n#define PAT11b REGEX_STR(\"^(DEBUG|INFO |WARN |ERROR|FATAL) \\\\[[0-9A-FXx]*]\\\\ root: Message [0-9]\\\\{1,2\\\\}\")\n#define PAT12 REGEX_STR(\"^\\\\[[0-9A-FXx]*]\\\\ (DEBUG|INFO |WARN |ERROR|FATAL) \")\\\n\tREGEX_STR(\".*patternlayouttest.cpp([0-9]\\\\{1,4\\\\}): \")\\\n\tREGEX_STR(\"Message [0-9]\\\\{1,2\\\\}\")\n#define PAT_MDC_1 REGEX_STR(\"\")\n\n"
      },
      {
        "chunk_id": "doc_89_chunk_3",
        "original_index": 3,
        "content": "using namespace log4cxx;\nusing namespace log4cxx::helpers;\n\nLOGUNIT_CLASS(FMTTestCase)\n{\n\tLOGUNIT_TEST_SUITE(FMTTestCase);\n\tLOGUNIT_TEST(test1);\n\tLOGUNIT_TEST(test1_expanded);\n\tLOGUNIT_TEST(test10);\n//\tLOGUNIT_TEST(test_date);\n\tLOGUNIT_TEST_SUITE_END();\n\n\tLoggerPtr root;\n\tLoggerPtr logger;\n\npublic:\n\tvoid setUp()\n\t{\n\t\troot = Logger::getRootLogger();\n\t\tMDC::clear();\n\t\tlogger = Logger::getLogger(LOG4CXX_TEST_STR(\"java.org.apache.log4j.PatternLayoutTest\"));\n\t}\n\n"
      },
      {
        "chunk_id": "doc_89_chunk_4",
        "original_index": 4,
        "content": "\tvoid tearDown()\n\t{\n\t\tMDC::clear();\n\t\tauto rep = root->getLoggerRepository();\n\n\t\tif (rep)\n\t\t{\n\t\t\trep->resetConfiguration();\n\t\t}\n\t}\n\n\tvoid test1()\n\t{\n\t\tPropertyConfigurator::configure(LOG4CXX_FILE(\"input/fmtLayout1.properties\"));\n\t\tcommon();\n\t\tLOGUNIT_ASSERT(Compare::compare(TEMP, LOG4CXX_FILE(\"witness/patternLayout.1\")));\n\t}\n\n\tvoid test1_expanded()\n\t{\n\t\tPropertyConfigurator::configure(LOG4CXX_FILE(\"input/fmtLayout1_expanded.properties\"));\n\t\tcommon();\n\t\tLOGUNIT_ASSERT(Compare::compare(TEMP, LOG4CXX_FILE(\"witness/patternLayout.1\")));\n\t}\n\n"
      },
      {
        "chunk_id": "doc_89_chunk_5",
        "original_index": 5,
        "content": "\tvoid test10()\n\t{\n\t\tPropertyConfigurator::configure(LOG4CXX_FILE(\"input/fmtLayout10.properties\"));\n\t\tcommon();\n\n\t\tControlFilter filter1;\n\t\tfilter1 << PAT6;\n\t\tThreadFilter filter2;\n\t\tLineNumberFilter filter3;\n\t\tFilenameFilter filenameFilter(__FILE__, \"patternlayouttest.cpp\");\n\n\n\t\tstd::vector<Filter*> filters;\n\t\tfilters.push_back(&filenameFilter);\n\t\tfilters.push_back(&filter1);\n\t\tfilters.push_back(&filter2);\n\t\tfilters.push_back(&filter3);\n\n"
      },
      {
        "chunk_id": "doc_89_chunk_6",
        "original_index": 6,
        "content": "\n\t\ttry\n\t\t{\n\t\t\tTransformer::transform(TEMP, FILTERED, filters);\n\t\t}\n\t\tcatch (UnexpectedFormatException& e)\n\t\t{\n\t\t\tstd::cout << \"UnexpectedFormatException :\" << e.what() << std::endl;\n\t\t\tthrow;\n\t\t}\n\n\t\tLOGUNIT_ASSERT(Compare::compare(FILTERED, LOG4CXX_FILE(\"witness/patternLayout.10\")));\n\t}\n\n\tvoid test_date(){\n\t\tstd::tm tm = {};\n\t\tstd::stringstream ss(\"2013-04-11 08:35:34\");\n\t\tss >> std::get_time(&tm, \"%Y-%m-%d %H:%M:%S\");\n\t\tauto tp = std::chrono::system_clock::from_time_t(std::mktime(&tm));\n\t\tuint64_t micros = std::chrono::duration_cast<std::chrono::microseconds>(tp.time_since_epoch()).count();\n\n\t\tlog4cxx::helpers::Date::setGetCurrentTimeFunction([micros](){\n\t\t\treturn micros;\n\t\t});\n\n"
      },
      {
        "chunk_id": "doc_89_chunk_7",
        "original_index": 7,
        "content": "\t\tlog4cxx::spi::LoggingEventPtr logEvt = std::make_shared<log4cxx::spi::LoggingEvent>(LOG4CXX_STR(\"foo\"),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t Level::getInfo(),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t LOG4CXX_STR(\"A Message\"),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t log4cxx::spi::LocationInfo::getLocationUnavailable());\n\t\tFMTLayout layout(LOG4CXX_STR(\"{d:%Y-%m-%d %H:%M:%S} {message}\"));\n\t\tLogString output;\n\t\tlog4cxx::helpers::Pool pool;\n\t\tlayout.format( output, logEvt, pool);\n\n"
      },
      {
        "chunk_id": "doc_89_chunk_8",
        "original_index": 8,
        "content": "\t\tlog4cxx::helpers::Date::setGetCurrentTimeFunction(nullptr);\n\n\t\tLOGUNIT_ASSERT_EQUAL(LOG4CXX_STR(\"2013-04-11 09:35:34 A Message\"), output);\n\t}\n\n\tstd::string createMessage(Pool & pool, int i)\n\t{\n\t\tstd::string msg(\"Message \");\n\t\tmsg.append(pool.itoa(i));\n\t\treturn msg;\n\t}\n\n\tvoid common()\n\t{\n\t\tint i = -1;\n\n\t\tPool pool;\n\n\n\t\tLOG4CXX_DEBUG(logger, createMessage(pool, ++i));\n\t\tLOG4CXX_DEBUG(root, createMessage(pool, i));\n\n\t\tLOG4CXX_INFO(logger, createMessage(pool, ++i));\n\t\tLOG4CXX_INFO(root, createMessage(pool, i));\n\n\t\tLOG4CXX_WARN(logger, createMessage(pool, ++i));\n\t\tLOG4CXX_WARN(root, createMessage(pool, i));\n\n"
      },
      {
        "chunk_id": "doc_89_chunk_9",
        "original_index": 9,
        "content": "\t\tLOG4CXX_ERROR(logger, createMessage(pool, ++i));\n\t\tLOG4CXX_ERROR(root, createMessage(pool, i));\n\n\t\tLOG4CXX_FATAL(logger, createMessage(pool, ++i));\n\t\tLOG4CXX_FATAL(root, createMessage(pool, i));\n\t}\n\n\tprivate:\n\t\tstatic const LogString FILTERED;\n\t\tstatic const LogString TEMP;\n\n};\n\nconst LogString FMTTestCase::TEMP(LOG4CXX_STR(\"output/fmtlayout\"));\nconst LogString FMTTestCase::FILTERED(LOG4CXX_STR(\"output/fmtlayoutfiltered\"));\n\n\nLOGUNIT_TEST_SUITE_REGISTRATION(FMTTestCase);\n"
      }
    ]
  },
  {
    "doc_id": "doc_90",
    "original_uuid": "4687d993285f0820ff87223e5927490b5359c788e3e11b14f8de2c4f77c8f60f",
    "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#ifndef _LOG4CXX_HELPERS_BUFFEREDWRITER_H\n#define _LOG4CXX_HELPERS_BUFFEREDWRITER_H\n\n#include <log4cxx/helpers/writer.h>\n\nnamespace LOG4CXX_NS\n{\n\nnamespace helpers\n{\n\n/**\n*   Writes text to a character-output stream buffering\n*       requests to increase efficiency.\n*/\nclass LOG4CXX_EXPORT BufferedWriter : public Writer\n{\n\tprivate:\n\t\tLOG4CXX_DECLARE_PRIVATE_MEMBER_PTR(BufferedWriterPriv, m_priv)\n\n\tpublic:\n\t\tDECLARE_ABSTRACT_LOG4CXX_OBJECT(BufferedWriter)\n\t\tBEGIN_LOG4CXX_CAST_MAP()\n\t\tLOG4CXX_CAST_ENTRY(BufferedWriter)\n\t\tLOG4CXX_CAST_ENTRY_CHAIN(Writer)\n\t\tEND_LOG4CXX_CAST_MAP()\n\n\t\tBufferedWriter(WriterPtr& out);\n\t\tBufferedWriter(WriterPtr& out, size_t sz);\n\t\tvirtual ~BufferedWriter();\n\n\t\tvoid close(Pool& p) override;\n\t\tvoid flush(Pool& p) override;\n\t\tvoid write(const LogString& str, Pool& p) override;\n\n\tprivate:\n\t\tBufferedWriter(const BufferedWriter&);\n\t\tBufferedWriter& operator=(const BufferedWriter&);\n};\n\n} // namespace helpers\n\n}  //namespace log4cxx\n\n#endif //_LOG4CXX_HELPERS_BUFFEREDWRITER_H\n",
    "chunks": [
      {
        "chunk_id": "doc_90_chunk_0",
        "original_index": 0,
        "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n"
      },
      {
        "chunk_id": "doc_90_chunk_1",
        "original_index": 1,
        "content": "#ifndef _LOG4CXX_HELPERS_BUFFEREDWRITER_H\n#define _LOG4CXX_HELPERS_BUFFEREDWRITER_H\n\n#include <log4cxx/helpers/writer.h>\n\nnamespace LOG4CXX_NS\n{\n\nnamespace helpers\n{\n\n/**\n*   Writes text to a character-output stream buffering\n*       requests to increase efficiency.\n*/\nclass LOG4CXX_EXPORT BufferedWriter : public Writer\n{\n\tprivate:\n\t\tLOG4CXX_DECLARE_PRIVATE_MEMBER_PTR(BufferedWriterPriv, m_priv)\n\n"
      },
      {
        "chunk_id": "doc_90_chunk_2",
        "original_index": 2,
        "content": "\tpublic:\n\t\tDECLARE_ABSTRACT_LOG4CXX_OBJECT(BufferedWriter)\n\t\tBEGIN_LOG4CXX_CAST_MAP()\n\t\tLOG4CXX_CAST_ENTRY(BufferedWriter)\n\t\tLOG4CXX_CAST_ENTRY_CHAIN(Writer)\n\t\tEND_LOG4CXX_CAST_MAP()\n\n\t\tBufferedWriter(WriterPtr& out);\n\t\tBufferedWriter(WriterPtr& out, size_t sz);\n\t\tvirtual ~BufferedWriter();\n\n\t\tvoid close(Pool& p) override;\n\t\tvoid flush(Pool& p) override;\n\t\tvoid write(const LogString& str, Pool& p) override;\n\n\tprivate:\n\t\tBufferedWriter(const BufferedWriter&);\n\t\tBufferedWriter& operator=(const BufferedWriter&);\n};\n\n} // namespace helpers\n\n}  //namespace log4cxx\n\n#endif //_LOG4CXX_HELPERS_BUFFEREDWRITER_H\n"
      }
    ]
  }
]